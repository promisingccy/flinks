2021-04-15 16:42:03,307 INFO org.apache.flink.api.java.typeutils.TypeExtractor - class org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit does not contain a setter for field modificationTime
2021-04-15 16:42:03,311 INFO org.apache.flink.api.java.typeutils.TypeExtractor - Class class org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2021-04-15 16:42:03,319 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 16:42:03,324 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 16:42:03,346 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 16:42:03,347 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 16:42:03,353 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 16:42:03,353 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.java.io.TextInputFormat
2021-04-15 16:42:03,354 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 16:42:03,354 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 16:42:03,354 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 16:42:03,354 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 16:42:03,367 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Long
2021-04-15 16:42:03,368 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.streaming.api.functions.source.FileProcessingMode
2021-04-15 16:42:03,368 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Long
2021-04-15 16:42:03,368 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 16:42:03,425 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
2021-04-15 16:42:03,426 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 16:42:03,426 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 16:42:03,426 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 16:42:03,426 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 16:42:03,427 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 16:42:03,503 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.java.typeutils.runtime.PojoComparator
2021-04-15 16:42:03,514 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 16:42:03,515 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [Ljava.lang.Object;
2021-04-15 16:42:03,575 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.java.typeutils.runtime.PojoComparator
2021-04-15 16:42:03,576 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 16:42:03,577 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [Ljava.lang.Object;
2021-04-15 16:42:03,583 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
2021-04-15 16:42:03,584 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 16:42:03,584 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 16:42:03,584 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 16:42:03,584 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 16:42:03,584 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 16:42:03,586 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
2021-04-15 16:42:03,586 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 16:42:03,586 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 16:42:03,587 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 16:42:03,587 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 16:42:03,587 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 16:42:03,620 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=2, name='Split Reader: Custom File Source', outputType=String, parallelism=1}
2021-04-15 16:42:03,620 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySourceTransformation{id=1, name='Custom File Source', outputType=GenericType<org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit>, parallelism=1}
2021-04-15 16:42:03,633 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 1
2021-04-15 16:42:03,635 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 2
2021-04-15 16:42:03,641 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=3, name='Map', outputType=PojoType<org.myorg.quickstart.dto.SensorReading, fields = [id: String, temperature: Double, timestamp: Long]>, parallelism=1}
2021-04-15 16:42:03,641 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 3
2021-04-15 16:42:03,641 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySinkTransformation{id=5, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=1}
2021-04-15 16:42:03,641 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming PartitionTransformation{id=4, name='Partition', outputType=String, parallelism=1}
2021-04-15 16:42:03,642 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 5
2021-04-15 16:42:03,642 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySinkTransformation{id=7, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=1}
2021-04-15 16:42:03,642 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming PartitionTransformation{id=6, name='Partition', outputType=PojoType<org.myorg.quickstart.dto.SensorReading, fields = [id: String, temperature: Double, timestamp: Long]>, parallelism=1}
2021-04-15 16:42:03,642 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 7
2021-04-15 16:42:03,644 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySinkTransformation{id=9, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=1}
2021-04-15 16:42:03,644 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming PartitionTransformation{id=8, name='Partition', outputType=PojoType<org.myorg.quickstart.dto.SensorReading, fields = [id: String, temperature: Double, timestamp: Long]>, parallelism=1}
2021-04-15 16:42:03,645 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 9
2021-04-15 16:42:03,700 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'bc764cd8ddf7a0cff126f51c16239658' for node 'Source: Custom File Source-1' {id: 1, parallelism: 1, user function: org.apache.flink.streaming.api.functions.source.ContinuousFileMonitoringFunction}
2021-04-15 16:42:03,701 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '20ba6b65f97481d5570070de90e4e791' for node 'Split Reader: Custom File Source-2' {id: 2, parallelism: 1, user function: }
2021-04-15 16:42:03,701 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'c09dc291fad93d575e015871097bfc60' for node 'Map-3' {id: 3, parallelism: 1, user function: org.myorg.quickstart.other.DTransform.Shuffle$$Lambda$114/0x0000000100183840}
2021-04-15 16:42:03,701 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'a7ff31a2a262e9bd1fe62e920ca466b3' for node 'Sink: Print to Std. Out-5' {id: 5, parallelism: 1, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
2021-04-15 16:42:03,702 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '700e2d9c0374125bac8dd259c7728377' for node 'Sink: Print to Std. Out-7' {id: 7, parallelism: 1, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
2021-04-15 16:42:03,702 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '5bd02938c768711b3149e43f99433bdd' for node 'Sink: Print to Std. Out-9' {id: 9, parallelism: 1, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
2021-04-15 16:42:03,720 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 7
2021-04-15 16:42:03,760 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 9
2021-04-15 16:42:03,774 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 5
2021-04-15 16:42:03,775 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 2
2021-04-15 16:42:03,804 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - CONNECTED: KeyGroupStreamPartitioner - 2 -> 7
2021-04-15 16:42:03,804 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - CONNECTED: GlobalPartitioner - 2 -> 9
2021-04-15 16:42:03,804 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - CONNECTED: ShufflePartitioner - 2 -> 5
2021-04-15 16:42:03,812 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 1
2021-04-15 16:42:03,816 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - CONNECTED: ForwardPartitioner - 1 -> 2
2021-04-15 16:42:03,870 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.
2021-04-15 16:42:03,870 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.
2021-04-15 16:42:03,870 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.
2021-04-15 16:42:03,871 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.min required for local execution is not set, setting it to its default value 64 mb.
2021-04-15 16:42:03,871 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.max required for local execution is not set, setting it to its default value 64 mb.
2021-04-15 16:42:03,872 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.
2021-04-15 16:42:03,895 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting Flink Mini Cluster
2021-04-15 16:42:03,895 DEBUG org.apache.flink.runtime.minicluster.MiniCluster - Using configuration MiniClusterConfiguration {singleRpcService=SHARED, numTaskManagers=1, commonBindAddress='null', config={taskmanager.memory.network.min=64 mb, taskmanager.cpu.cores=1.7976931348623157E308, taskmanager.memory.task.off-heap.size=9223372036854775807 bytes, execution.target=local, rest.bind-port=0, taskmanager.memory.network.max=64 mb, execution.attached=true, taskmanager.memory.managed.size=128 mb, parallelism.default=4, taskmanager.numberOfTaskSlots=1, taskmanager.memory.task.heap.size=9223372036854775807 bytes, rest.address=localhost}}
2021-04-15 16:42:03,897 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting Metrics Registry
2021-04-15 16:42:03,961 INFO org.apache.flink.runtime.metrics.MetricRegistryImpl - No metrics reporter configured, no metrics will be exposed/reported.
2021-04-15 16:42:03,962 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting RPC Service(s)
2021-04-15 16:42:04,142 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
2021-04-15 16:42:04,153 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Using akka configuration
 Config(SimpleConfigObject({"akka":{"actor":{"default-dispatcher":{"executor":"fork-join-executor","fork-join-executor":{"parallelism-factor":1,"parallelism-max":4,"parallelism-min":2},"throughput":15},"guardian-supervisor-strategy":"org.apache.flink.runtime.akka.EscalatingSupervisorStrategy","supervisor-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"type":"Dispatcher"},"warn-about-java-serializer-usage":"off"},"daemonic":"off","jvm-exit-on-fatal-error":"on","log-config-on-start":"off","log-dead-letters":"off","log-dead-letters-during-shutdown":"off","logger-startup-timeout":"30s","loggers":["akka.event.slf4j.Slf4jLogger"],"logging-filter":"akka.event.slf4j.Slf4jLoggingFilter","loglevel":"DEBUG","serialize-messages":"off","stdout-loglevel":"OFF"}}))
2021-04-15 16:42:04,952 INFO akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2021-04-15 16:42:04,979 DEBUG akka.event.EventStream - logger log1-Slf4jLogger started
2021-04-15 16:42:04,985 DEBUG akka.event.EventStream - Default Loggers started
2021-04-15 16:42:05,624 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink
2021-04-15 16:42:05,653 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
2021-04-15 16:42:05,655 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Using akka configuration
 Config(SimpleConfigObject({"akka":{"actor":{"default-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"thread-priority":1,"throughput":15,"type":"akka.dispatch.PriorityThreadsDispatcher"},"guardian-supervisor-strategy":"org.apache.flink.runtime.akka.EscalatingSupervisorStrategy","supervisor-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"type":"Dispatcher"},"warn-about-java-serializer-usage":"off"},"daemonic":"off","jvm-exit-on-fatal-error":"on","log-config-on-start":"off","log-dead-letters":"off","log-dead-letters-during-shutdown":"off","logger-startup-timeout":"30s","loggers":["akka.event.slf4j.Slf4jLogger"],"logging-filter":"akka.event.slf4j.Slf4jLoggingFilter","loglevel":"DEBUG","serialize-messages":"off","stdout-loglevel":"OFF"}}))
2021-04-15 16:42:05,727 INFO akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2021-04-15 16:42:05,793 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink-metrics
2021-04-15 16:42:05,819 DEBUG akka.event.EventStream - logger log1-Slf4jLogger started
2021-04-15 16:42:05,826 DEBUG akka.event.EventStream - Default Loggers started
2021-04-15 16:42:05,871 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting AkkaRpcActor with name MetricQueryService.
2021-04-15 16:42:05,885 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
2021-04-15 16:42:06,151 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting high-availability services
2021-04-15 16:42:06,940 INFO org.apache.flink.runtime.blob.BlobServer - Created BLOB server storage directory C:\Users\ccy\AppData\Local\Temp\blobStore-86684687-ac50-4d31-bf99-e4ee1528f2bd
2021-04-15 16:42:06,949 DEBUG org.apache.flink.util.NetUtils - Trying to open socket on port 0
2021-04-15 16:42:06,951 INFO org.apache.flink.runtime.blob.BlobServer - Started BLOB server at 0.0.0.0:60745 - max concurrent requests: 50 - max backlog: 1000
2021-04-15 16:42:06,955 INFO org.apache.flink.runtime.blob.PermanentBlobCache - Created BLOB cache storage directory C:\Users\ccy\AppData\Local\Temp\blobStore-506b643f-8b2e-4caf-b68e-f0ab2ce6a954
2021-04-15 16:42:06,957 INFO org.apache.flink.runtime.blob.TransientBlobCache - Created BLOB cache storage directory C:\Users\ccy\AppData\Local\Temp\blobStore-9dc420f1-18b3-45c9-af22-648344aba102
2021-04-15 16:42:06,958 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting 1 TaskManger(s)
2021-04-15 16:42:06,962 INFO org.apache.flink.runtime.taskexecutor.TaskManagerRunner - Starting TaskManager with ResourceID: 0e8cf66e-9f5e-4007-a2c2-5069242a0468
2021-04-15 16:42:06,991 INFO o.apache.flink.runtime.taskexecutor.TaskManagerServices - Temporary file directory 'C:\Users\ccy\AppData\Local\Temp': total 137 GB, usable 24 GB (17.52% usable)
2021-04-15 16:42:07,001 INFO org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\ccy\AppData\Local\Temp\flink-io-415d0b00-2748-42de-b954-b4e19fb54776 for spill files.
2021-04-15 16:42:07,008 INFO org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\ccy\AppData\Local\Temp\flink-netty-shuffle-e1981eed-e920-4a35-a7c1-b7c53850034c for spill files.
2021-04-15 16:42:07,056 INFO o.a.flink.runtime.io.network.buffer.NetworkBufferPool - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2021-04-15 16:42:07,066 INFO o.a.flink.runtime.io.network.NettyShuffleEnvironment - Starting the network environment and its components.
2021-04-15 16:42:07,066 DEBUG o.a.flink.runtime.io.network.NettyShuffleEnvironment - Starting network connection manager
2021-04-15 16:42:07,068 INFO org.apache.flink.runtime.taskexecutor.KvStateService - Starting the kvState service and its components.
2021-04-15 16:42:07,079 DEBUG o.a.flink.runtime.taskexecutor.TaskManagerConfiguration - Messages have a max timeout of 10000 ms
2021-04-15 16:42:07,090 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting AkkaRpcActor with name taskmanager_0.
2021-04-15 16:42:07,090 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2021-04-15 16:42:07,103 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Start job leader service.
2021-04-15 16:42:07,106 INFO org.apache.flink.runtime.filecache.FileCache - User file cache uses directory C:\Users\ccy\AppData\Local\Temp\flink-dist-cache-d076b5c5-e939-4ba7-9de0-a727be8b5d0a
2021-04-15 16:42:07,163 DEBUG o.a.f.r.e.c.DefaultDispatcherResourceManagerComponentFactory - Starting Dispatcher REST endpoint.
2021-04-15 16:42:07,164 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Starting rest endpoint.
2021-04-15 16:42:07,171 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Failed to load web based job submission extension.
org.apache.flink.util.FlinkException: The module flink-runtime-web could not be found in the class path. Please add this jar in order to enable web based job submission.
	at org.apache.flink.runtime.webmonitor.WebMonitorUtils.loadWebSubmissionExtension(WebMonitorUtils.java:199) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint.initializeWebSubmissionHandlers(DispatcherRestEndpoint.java:112) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.webmonitor.WebMonitorEndpoint.initializeHandlers(WebMonitorEndpoint.java:228) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint.initializeHandlers(DispatcherRestEndpoint.java:89) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:144) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:172) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:463) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:422) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:366) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.program.PerJobMiniClusterFactory.submitJob(PerJobMiniClusterFactory.java:75) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:85) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1905) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1796) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:69) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1782) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1765) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.myorg.quickstart.other.DTransform.Shuffle.main(Shuffle.java:35) ~[classes/:na]
2021-04-15 16:42:07,398 DEBUG o.a.f.s.n.i.n.u.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
2021-04-15 16:42:07,399 DEBUG o.a.f.s.n.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2021-04-15 16:42:07,399 DEBUG o.a.f.s.n.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2021-04-15 16:42:07,472 WARN org.apache.flink.runtime.webmonitor.WebMonitorUtils - Log file environment variable 'log.file' is not set.
2021-04-15 16:42:07,472 WARN org.apache.flink.runtime.webmonitor.WebMonitorUtils - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'web.log.path'.
2021-04-15 16:42:07,506 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - Platform: Windows
2021-04-15 16:42:07,509 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
2021-04-15 16:42:07,509 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - Java version: 11
2021-04-15 16:42:07,511 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
2021-04-15 16:42:07,513 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
2021-04-15 16:42:07,514 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
2021-04-15 16:42:07,515 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: unavailable
java.lang.UnsupportedOperationException: Reflective setAccessible(true) disabled
	at org.apache.flink.shaded.netty4.io.netty.util.internal.ReflectionUtil.trySetAccessible(ReflectionUtil.java:31) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0$4.run(PlatformDependent0.java:233) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at java.base/java.security.AccessController.doPrivileged(Native Method) ~[na:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:227) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.isAndroid(PlatformDependent.java:289) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:92) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:223) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:210) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.cached(AsciiString.java:1401) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<clinit>(AsciiString.java:48) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<init>(HttpMethod.java:135) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<clinit>(HttpMethod.java:36) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.runtime.rest.HttpMethodWrapper.<clinit>(HttpMethodWrapper.java:27) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.messages.cluster.ShutdownHeaders.getHttpMethod(ShutdownHeaders.java:57) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.checkAllEndpointsAndHandlersAreUnique(RestServerEndpoint.java:572) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:155) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:172) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:463) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:422) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:366) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.program.PerJobMiniClusterFactory.submitJob(PerJobMiniClusterFactory.java:75) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:85) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1905) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1796) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:69) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1782) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1765) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.myorg.quickstart.other.DTransform.Shuffle.main(Shuffle.java:35) ~[classes/:na]
2021-04-15 16:42:07,517 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
2021-04-15 16:42:07,519 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable
java.lang.IllegalAccessException: class org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0$6 cannot access class jdk.internal.misc.Unsafe (in module java.base) because module java.base does not export jdk.internal.misc to unnamed module @496bc455
	at java.base/jdk.internal.reflect.Reflection.newIllegalAccessException(Reflection.java:361) ~[na:na]
	at java.base/java.lang.reflect.AccessibleObject.checkAccess(AccessibleObject.java:591) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:558) ~[na:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0$6.run(PlatformDependent0.java:347) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at java.base/java.security.AccessController.doPrivileged(Native Method) ~[na:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:338) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.isAndroid(PlatformDependent.java:289) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:92) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:223) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:210) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.cached(AsciiString.java:1401) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<clinit>(AsciiString.java:48) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<init>(HttpMethod.java:135) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<clinit>(HttpMethod.java:36) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.runtime.rest.HttpMethodWrapper.<clinit>(HttpMethodWrapper.java:27) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.messages.cluster.ShutdownHeaders.getHttpMethod(ShutdownHeaders.java:57) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.checkAllEndpointsAndHandlersAreUnique(RestServerEndpoint.java:572) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:155) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:172) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:463) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:422) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:366) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.program.PerJobMiniClusterFactory.submitJob(PerJobMiniClusterFactory.java:75) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:85) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1905) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1796) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:69) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1782) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1765) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.myorg.quickstart.other.DTransform.Shuffle.main(Shuffle.java:35) ~[classes/:na]
2021-04-15 16:42:07,520 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): unavailable
2021-04-15 16:42:07,520 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
2021-04-15 16:42:07,520 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - maxDirectMemory: 2122317824 bytes (maybe)
2021-04-15 16:42:07,521 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\ccy\AppData\Local\Temp (java.io.tmpdir)
2021-04-15 16:42:07,521 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
2021-04-15 16:42:07,522 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: -1 bytes
2021-04-15 16:42:07,522 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
2021-04-15 16:42:07,523 DEBUG o.a.f.shaded.netty4.io.netty.util.internal.CleanerJava9 - java.nio.ByteBuffer.cleaner(): available
2021-04-15 16:42:07,523 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
2021-04-15 16:42:07,531 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@2233cac0 under DELETE@/v1/cluster.
2021-04-15 16:42:07,532 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@2233cac0 under DELETE@/cluster.
2021-04-15 16:42:07,532 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@4e140497 under GET@/v1/config.
2021-04-15 16:42:07,532 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@4e140497 under GET@/config.
2021-04-15 16:42:07,532 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetListHandler@481b2f10 under GET@/v1/datasets.
2021-04-15 16:42:07,533 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetListHandler@481b2f10 under GET@/datasets.
2021-04-15 16:42:07,533 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteStatusHandler@2b6c7012 under GET@/v1/datasets/delete/:triggerid.
2021-04-15 16:42:07,533 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteStatusHandler@2b6c7012 under GET@/datasets/delete/:triggerid.
2021-04-15 16:42:07,533 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteTriggerHandler@31acfd4e under DELETE@/v1/datasets/:datasetid.
2021-04-15 16:42:07,533 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteTriggerHandler@31acfd4e under DELETE@/datasets/:datasetid.
2021-04-15 16:42:07,533 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@5f726750 under GET@/v1/jobmanager/config.
2021-04-15 16:42:07,533 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@5f726750 under GET@/jobmanager/config.
2021-04-15 16:42:07,534 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@4e80a001 under GET@/v1/jobmanager/log.
2021-04-15 16:42:07,534 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@4e80a001 under GET@/jobmanager/log.
2021-04-15 16:42:07,534 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogListHandler@624b523 under GET@/v1/jobmanager/logs.
2021-04-15 16:42:07,534 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogListHandler@624b523 under GET@/jobmanager/logs.
2021-04-15 16:42:07,534 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerCustomLogHandler@50b46e24 under GET@/v1/jobmanager/logs/:filename.
2021-04-15 16:42:07,534 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerCustomLogHandler@50b46e24 under GET@/jobmanager/logs/:filename.
2021-04-15 16:42:07,534 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@1c30cb85 under GET@/v1/jobmanager/metrics.
2021-04-15 16:42:07,534 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@1c30cb85 under GET@/jobmanager/metrics.
2021-04-15 16:42:07,535 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@577bf0aa under GET@/v1/jobmanager/stdout.
2021-04-15 16:42:07,535 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@577bf0aa under GET@/jobmanager/stdout.
2021-04-15 16:42:07,535 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@7455dacb under GET@/v1/jobs.
2021-04-15 16:42:07,535 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@7455dacb under GET@/jobs.
2021-04-15 16:42:07,535 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@7634f2b under POST@/v1/jobs.
2021-04-15 16:42:07,535 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@7634f2b under POST@/jobs.
2021-04-15 16:42:07,535 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@1d15c0a1 under GET@/v1/jobs/metrics.
2021-04-15 16:42:07,535 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@1d15c0a1 under GET@/jobs/metrics.
2021-04-15 16:42:07,535 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@15639d09 under GET@/v1/jobs/overview.
2021-04-15 16:42:07,535 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@15639d09 under GET@/jobs/overview.
2021-04-15 16:42:07,535 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@4fba8eec under GET@/v1/jobs/:jobid.
2021-04-15 16:42:07,535 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@4fba8eec under GET@/jobs/:jobid.
2021-04-15 16:42:07,535 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@52bd9a27 under PATCH@/v1/jobs/:jobid.
2021-04-15 16:42:07,536 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@52bd9a27 under PATCH@/jobs/:jobid.
2021-04-15 16:42:07,536 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@611e5819 under GET@/v1/jobs/:jobid/accumulators.
2021-04-15 16:42:07,536 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@611e5819 under GET@/jobs/:jobid/accumulators.
2021-04-15 16:42:07,536 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@681c0ae6 under GET@/v1/jobs/:jobid/checkpoints.
2021-04-15 16:42:07,536 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@681c0ae6 under GET@/jobs/:jobid/checkpoints.
2021-04-15 16:42:07,536 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@73ca34e7 under GET@/v1/jobs/:jobid/checkpoints/config.
2021-04-15 16:42:07,536 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@73ca34e7 under GET@/jobs/:jobid/checkpoints/config.
2021-04-15 16:42:07,536 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@4d98e41b under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid.
2021-04-15 16:42:07,536 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@4d98e41b under GET@/jobs/:jobid/checkpoints/details/:checkpointid.
2021-04-15 16:42:07,536 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@5ed5b321 under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
2021-04-15 16:42:07,536 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@5ed5b321 under GET@/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
2021-04-15 16:42:07,536 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@5696c927 under GET@/v1/jobs/:jobid/config.
2021-04-15 16:42:07,537 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@5696c927 under GET@/jobs/:jobid/config.
2021-04-15 16:42:07,537 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.coordination.ClientCoordinationHandler@7459a21e under POST@/v1/jobs/:jobid/coordinators/:operatorid.
2021-04-15 16:42:07,537 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.coordination.ClientCoordinationHandler@7459a21e under POST@/jobs/:jobid/coordinators/:operatorid.
2021-04-15 16:42:07,537 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@7eeb38b2 under GET@/v1/jobs/:jobid/exceptions.
2021-04-15 16:42:07,537 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@7eeb38b2 under GET@/jobs/:jobid/exceptions.
2021-04-15 16:42:07,537 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@d54d0f5 under GET@/v1/jobs/:jobid/execution-result.
2021-04-15 16:42:07,537 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@d54d0f5 under GET@/jobs/:jobid/execution-result.
2021-04-15 16:42:07,537 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@6d6bff89 under GET@/v1/jobs/:jobid/metrics.
2021-04-15 16:42:07,537 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@6d6bff89 under GET@/jobs/:jobid/metrics.
2021-04-15 16:42:07,537 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@541bf968 under GET@/v1/jobs/:jobid/plan.
2021-04-15 16:42:07,537 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@541bf968 under GET@/jobs/:jobid/plan.
2021-04-15 16:42:07,537 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@739265f1 under PATCH@/v1/jobs/:jobid/rescaling.
2021-04-15 16:42:07,537 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@739265f1 under PATCH@/jobs/:jobid/rescaling.
2021-04-15 16:42:07,538 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@58eac00e under GET@/v1/jobs/:jobid/rescaling/:triggerid.
2021-04-15 16:42:07,538 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@58eac00e under GET@/jobs/:jobid/rescaling/:triggerid.
2021-04-15 16:42:07,538 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@6acffb2d under POST@/v1/jobs/:jobid/savepoints.
2021-04-15 16:42:07,538 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@6acffb2d under POST@/jobs/:jobid/savepoints.
2021-04-15 16:42:07,538 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@61149fa5 under GET@/v1/jobs/:jobid/savepoints/:triggerid.
2021-04-15 16:42:07,538 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@61149fa5 under GET@/jobs/:jobid/savepoints/:triggerid.
2021-04-15 16:42:07,538 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@149c39b under POST@/v1/jobs/:jobid/stop.
2021-04-15 16:42:07,538 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@149c39b under POST@/jobs/:jobid/stop.
2021-04-15 16:42:07,538 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@f2d890c under GET@/v1/jobs/:jobid/vertices/:vertexid.
2021-04-15 16:42:07,538 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@f2d890c under GET@/jobs/:jobid/vertices/:vertexid.
2021-04-15 16:42:07,538 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@1a2e0d57 under GET@/v1/jobs/:jobid/vertices/:vertexid/accumulators.
2021-04-15 16:42:07,538 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@1a2e0d57 under GET@/jobs/:jobid/vertices/:vertexid/accumulators.
2021-04-15 16:42:07,538 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@5f025000 under GET@/v1/jobs/:jobid/vertices/:vertexid/backpressure.
2021-04-15 16:42:07,539 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@5f025000 under GET@/jobs/:jobid/vertices/:vertexid/backpressure.
2021-04-15 16:42:07,539 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@10980560 under GET@/v1/jobs/:jobid/vertices/:vertexid/metrics.
2021-04-15 16:42:07,539 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@10980560 under GET@/jobs/:jobid/vertices/:vertexid/metrics.
2021-04-15 16:42:07,539 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@739e8b96 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
2021-04-15 16:42:07,539 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@739e8b96 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
2021-04-15 16:42:07,539 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@19b07407 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
2021-04-15 16:42:07,539 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@19b07407 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
2021-04-15 16:42:07,539 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@54ffa561 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
2021-04-15 16:42:07,539 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@54ffa561 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
2021-04-15 16:42:07,539 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@49c099b under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
2021-04-15 16:42:07,539 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@49c099b under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
2021-04-15 16:42:07,540 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@3d9f0a5 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
2021-04-15 16:42:07,540 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@3d9f0a5 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
2021-04-15 16:42:07,540 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@1953bc95 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
2021-04-15 16:42:07,540 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@1953bc95 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
2021-04-15 16:42:07,546 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@30aec673 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasktimes.
2021-04-15 16:42:07,547 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@30aec673 under GET@/jobs/:jobid/vertices/:vertexid/subtasktimes.
2021-04-15 16:42:07,547 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@549ac12c under GET@/v1/jobs/:jobid/vertices/:vertexid/taskmanagers.
2021-04-15 16:42:07,547 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@549ac12c under GET@/jobs/:jobid/vertices/:vertexid/taskmanagers.
2021-04-15 16:42:07,547 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@188a5fc2 under GET@/v1/jobs/:jobid/vertices/:vertexid/watermarks.
2021-04-15 16:42:07,548 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@188a5fc2 under GET@/jobs/:jobid/vertices/:vertexid/watermarks.
2021-04-15 16:42:07,548 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@1cb9ef52 under GET@/v1/jobs/:jobid/yarn-cancel.
2021-04-15 16:42:07,548 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@1cb9ef52 under GET@/jobs/:jobid/yarn-cancel.
2021-04-15 16:42:07,548 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@5a622fe8 under GET@/v1/jobs/:jobid/yarn-stop.
2021-04-15 16:42:07,548 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@5a622fe8 under GET@/jobs/:jobid/yarn-stop.
2021-04-15 16:42:07,548 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@58f31629 under GET@/v1/overview.
2021-04-15 16:42:07,548 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@58f31629 under GET@/overview.
2021-04-15 16:42:07,549 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@124d26ba under POST@/v1/savepoint-disposal.
2021-04-15 16:42:07,550 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@124d26ba under POST@/savepoint-disposal.
2021-04-15 16:42:07,550 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@415d88de under GET@/v1/savepoint-disposal/:triggerid.
2021-04-15 16:42:07,550 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@415d88de under GET@/savepoint-disposal/:triggerid.
2021-04-15 16:42:07,550 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@a0bf272 under GET@/v1/taskmanagers.
2021-04-15 16:42:07,550 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@a0bf272 under GET@/taskmanagers.
2021-04-15 16:42:07,550 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@4a89ef44 under GET@/v1/taskmanagers/metrics.
2021-04-15 16:42:07,550 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@4a89ef44 under GET@/taskmanagers/metrics.
2021-04-15 16:42:07,550 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@310a7859 under GET@/v1/taskmanagers/:taskmanagerid.
2021-04-15 16:42:07,551 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@310a7859 under GET@/taskmanagers/:taskmanagerid.
2021-04-15 16:42:07,551 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@1cbc1dde under GET@/v1/taskmanagers/:taskmanagerid/log.
2021-04-15 16:42:07,551 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@1cbc1dde under GET@/taskmanagers/:taskmanagerid/log.
2021-04-15 16:42:07,551 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogListHandler@4971f459 under GET@/v1/taskmanagers/:taskmanagerid/logs.
2021-04-15 16:42:07,551 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogListHandler@4971f459 under GET@/taskmanagers/:taskmanagerid/logs.
2021-04-15 16:42:07,551 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerCustomLogHandler@4c07d1fc under GET@/v1/taskmanagers/:taskmanagerid/logs/:filename.
2021-04-15 16:42:07,551 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerCustomLogHandler@4c07d1fc under GET@/taskmanagers/:taskmanagerid/logs/:filename.
2021-04-15 16:42:07,551 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@2eada095 under GET@/v1/taskmanagers/:taskmanagerid/metrics.
2021-04-15 16:42:07,551 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@2eada095 under GET@/taskmanagers/:taskmanagerid/metrics.
2021-04-15 16:42:07,551 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@52831a73 under GET@/v1/taskmanagers/:taskmanagerid/stdout.
2021-04-15 16:42:07,551 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@52831a73 under GET@/taskmanagers/:taskmanagerid/stdout.
2021-04-15 16:42:07,552 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerThreadDumpHandler@1416ff46 under GET@/v1/taskmanagers/:taskmanagerid/thread-dump.
2021-04-15 16:42:07,552 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerThreadDumpHandler@1416ff46 under GET@/taskmanagers/:taskmanagerid/thread-dump.
2021-04-15 16:42:07,559 DEBUG o.a.f.s.n.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 8
2021-04-15 16:42:07,592 DEBUG o.a.f.shaded.netty4.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
2021-04-15 16:42:07,592 DEBUG o.a.f.shaded.netty4.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
2021-04-15 16:42:07,607 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
2021-04-15 16:42:07,669 DEBUG o.a.f.shaded.netty4.io.netty.channel.DefaultChannelId - -Dio.netty.processId: 1428 (auto-detected)
2021-04-15 16:42:07,672 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
2021-04-15 16:42:07,674 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
2021-04-15 16:42:08,445 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
2021-04-15 16:42:08,445 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
2021-04-15 16:42:09,181 DEBUG o.a.f.shaded.netty4.io.netty.channel.DefaultChannelId - -Dio.netty.machineId: 2c:6f:c9:ff:fe:1c:21:83 (auto-detected)
2021-04-15 16:42:09,194 DEBUG o.a.f.shaded.netty4.io.netty.util.ResourceLeakDetector - -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.level: simple
2021-04-15 16:42:09,194 DEBUG o.a.f.shaded.netty4.io.netty.util.ResourceLeakDetector - -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.targetRecords: 4
2021-04-15 16:42:09,233 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 8
2021-04-15 16:42:09,233 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 8
2021-04-15 16:42:09,233 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
2021-04-15 16:42:09,233 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 11
2021-04-15 16:42:09,233 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 16777216
2021-04-15 16:42:09,234 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.tinyCacheSize: 512
2021-04-15 16:42:09,234 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
2021-04-15 16:42:09,234 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
2021-04-15 16:42:09,234 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2021-04-15 16:42:09,234 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
2021-04-15 16:42:09,234 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2021-04-15 16:42:09,234 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: true
2021-04-15 16:42:09,234 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2021-04-15 16:42:09,245 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
2021-04-15 16:42:09,245 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 0
2021-04-15 16:42:09,245 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
2021-04-15 16:42:09,259 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Binding rest endpoint to null:0.
2021-04-15 16:42:09,259 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Rest endpoint listening at localhost:60764
2021-04-15 16:42:09,261 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender http://localhost:60764
2021-04-15 16:42:09,265 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - http://localhost:60764 was granted leadership with leaderSessionID=9fb86c8f-6db2-40d2-ad22-1cdd530cf499
2021-04-15 16:42:09,265 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader http://localhost:60764 , session=9fb86c8f-6db2-40d2-ad22-1cdd530cf499
2021-04-15 16:42:09,278 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting FencedAkkaRpcActor with name resourcemanager_1.
2021-04-15 16:42:09,278 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_1 .
2021-04-15 16:42:09,292 DEBUG o.a.f.r.e.c.DefaultDispatcherResourceManagerComponentFactory - Starting Dispatcher.
2021-04-15 16:42:09,295 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
2021-04-15 16:42:09,295 DEBUG o.a.f.r.e.c.DefaultDispatcherResourceManagerComponentFactory - Starting ResourceManager.
2021-04-15 16:42:09,296 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: StandaloneResourceManager
2021-04-15 16:42:09,296 DEBUG o.a.f.runtime.dispatcher.runner.DefaultDispatcherRunner - Create new DispatcherLeaderProcess with leader session id b2946aaf-64c3-4540-ba37-c47d27355877.
2021-04-15 16:42:09,300 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - ResourceManager akka://flink/user/rpc/resourcemanager_1 was granted leadership with fencing token a190380066b0109fc42f38e0068a41ac
2021-04-15 16:42:09,303 INFO org.apache.flink.runtime.minicluster.MiniCluster - Flink Mini Cluster started successfully
2021-04-15 16:42:09,304 INFO o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Starting the SlotManager.
2021-04-15 16:42:09,306 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Start SessionDispatcherLeaderProcess.
2021-04-15 16:42:09,314 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 16:42:09,315 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 16:42:09,316 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Recover all persisted job graphs.
2021-04-15 16:42:09,316 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/resourcemanager_1 , session=c42f38e0-068a-41ac-a190-380066b0109f
2021-04-15 16:42:09,316 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Successfully recovered 0 persisted job graphs.
2021-04-15 16:42:09,319 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 16:42:09,321 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(a190380066b0109fc42f38e0068a41ac).
2021-04-15 16:42:09,323 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting FencedAkkaRpcActor with name dispatcher_2.
2021-04-15 16:42:09,323 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 16:42:09,327 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_2 .
2021-04-15 16:42:09,332 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 16:42:09,343 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/dispatcher_2 , session=b2946aaf-64c3-4540-ba37-c47d27355877
2021-04-15 16:42:09,349 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/dispatcher_2. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
2021-04-15 16:42:09,349 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/dispatcher_2. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
2021-04-15 16:42:09,355 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Resolved ResourceManager address, beginning registration
2021-04-15 16:42:09,355 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Registration at ResourceManager attempt 1 (timeout=100ms)
2021-04-15 16:42:09,361 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
2021-04-15 16:42:09,379 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Registering TaskManager with ResourceID 0e8cf66e-9f5e-4007-a2c2-5069242a0468 (akka://flink/user/rpc/taskmanager_0) at ResourceManager
2021-04-15 16:42:09,380 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Received JobGraph submission 3faa797a88435b0ef0677b9294a4ce7c (Flink Streaming Job).
2021-04-15 16:42:09,384 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Successful registration at resource manager akka://flink/user/rpc/resourcemanager_1 under registration id 5d75443d3996fd611e2245b958ea7d56.
2021-04-15 16:42:09,386 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Submitting job 3faa797a88435b0ef0677b9294a4ce7c (Flink Streaming Job).
2021-04-15 16:42:09,392 DEBUG o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Registering TaskManager 0e8cf66e-9f5e-4007-a2c2-5069242a0468 under 5d75443d3996fd611e2245b958ea7d56 at the SlotManager.
2021-04-15 16:42:09,418 DEBUG org.apache.flink.client.ClientUtils - Wait until job initialization is finished
2021-04-15 16:42:09,426 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: JobManagerRunnerImpl
2021-04-15 16:42:09,436 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting FencedAkkaRpcActor with name jobmanager_3.
2021-04-15 16:42:09,437 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
2021-04-15 16:42:09,453 INFO org.apache.flink.runtime.jobmaster.JobMaster - Initializing job Flink Streaming Job (3faa797a88435b0ef0677b9294a4ce7c).
2021-04-15 16:42:09,484 INFO org.apache.flink.runtime.jobmaster.JobMaster - Using restart back off time strategy NoRestartBackoffTimeStrategy for Flink Streaming Job (3faa797a88435b0ef0677b9294a4ce7c).
2021-04-15 16:42:09,543 INFO org.apache.flink.runtime.jobmaster.JobMaster - Running initialization on master for job Flink Streaming Job (3faa797a88435b0ef0677b9294a4ce7c).
2021-04-15 16:42:09,543 INFO org.apache.flink.runtime.jobmaster.JobMaster - Successfully ran initialization on master in 0 ms.
2021-04-15 16:42:09,543 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Adding 5 vertices from job graph Flink Streaming Job (3faa797a88435b0ef0677b9294a4ce7c).
2021-04-15 16:42:09,544 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Attaching 5 topologically sorted vertices to existing job graph with 0 vertices and 0 intermediate results.
2021-04-15 16:42:09,560 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex bc764cd8ddf7a0cff126f51c16239658 (Source: Custom File Source) to 0 predecessors.
2021-04-15 16:42:09,561 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex 20ba6b65f97481d5570070de90e4e791 (Split Reader: Custom File Source -> Map) to 1 predecessors.
2021-04-15 16:42:09,561 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting input 0 of vertex 20ba6b65f97481d5570070de90e4e791 (Split Reader: Custom File Source -> Map) to intermediate result referenced via predecessor bc764cd8ddf7a0cff126f51c16239658 (Source: Custom File Source).
2021-04-15 16:42:09,562 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex 700e2d9c0374125bac8dd259c7728377 (Sink: Print to Std. Out) to 1 predecessors.
2021-04-15 16:42:09,563 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting input 0 of vertex 700e2d9c0374125bac8dd259c7728377 (Sink: Print to Std. Out) to intermediate result referenced via predecessor 20ba6b65f97481d5570070de90e4e791 (Split Reader: Custom File Source -> Map).
2021-04-15 16:42:09,564 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex 5bd02938c768711b3149e43f99433bdd (Sink: Print to Std. Out) to 1 predecessors.
2021-04-15 16:42:09,564 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting input 0 of vertex 5bd02938c768711b3149e43f99433bdd (Sink: Print to Std. Out) to intermediate result referenced via predecessor 20ba6b65f97481d5570070de90e4e791 (Split Reader: Custom File Source -> Map).
2021-04-15 16:42:09,564 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex a7ff31a2a262e9bd1fe62e920ca466b3 (Sink: Print to Std. Out) to 1 predecessors.
2021-04-15 16:42:09,565 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting input 0 of vertex a7ff31a2a262e9bd1fe62e920ca466b3 (Sink: Print to Std. Out) to intermediate result referenced via predecessor 20ba6b65f97481d5570070de90e4e791 (Split Reader: Custom File Source -> Map).
2021-04-15 16:42:09,572 INFO o.a.f.r.scheduler.adapter.DefaultExecutionTopology - Built 1 pipelined regions in 0 ms
2021-04-15 16:42:09,573 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Successfully created execution graph from job graph Flink Streaming Job (3faa797a88435b0ef0677b9294a4ce7c).
2021-04-15 16:42:09,586 INFO org.apache.flink.runtime.jobmaster.JobMaster - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 16:42:09,602 DEBUG o.apache.flink.runtime.checkpoint.CheckpointCoordinator - Status of the shared state registry of job 3faa797a88435b0ef0677b9294a4ce7c after restore: SharedStateRegistry{registeredStates={}}.
2021-04-15 16:42:09,602 INFO o.apache.flink.runtime.checkpoint.CheckpointCoordinator - No checkpoint found during restore.
2021-04-15 16:42:09,604 INFO org.apache.flink.runtime.jobmaster.JobMaster - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@6586f4cd for Flink Streaming Job (3faa797a88435b0ef0677b9294a4ce7c).
2021-04-15 16:42:09,617 INFO org.apache.flink.runtime.jobmaster.JobManagerRunnerImpl - JobManager runner for job Flink Streaming Job (3faa797a88435b0ef0677b9294a4ce7c) was granted leadership with session id 59eb5d45-68a1-4ddb-a927-ba8199e461cd at akka://flink/user/rpc/jobmanager_3.
2021-04-15 16:42:09,621 INFO org.apache.flink.runtime.jobmaster.JobMaster - Starting execution of job Flink Streaming Job (3faa797a88435b0ef0677b9294a4ce7c) under job master id a927ba8199e461cd59eb5d4568a14ddb.
2021-04-15 16:42:09,623 INFO org.apache.flink.runtime.jobmaster.JobMaster - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2021-04-15 16:42:09,624 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Job Flink Streaming Job (3faa797a88435b0ef0677b9294a4ce7c) switched from state CREATED to RUNNING.
2021-04-15 16:42:09,631 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File Source (1/1) (5e74036b69eafb8aae22c461cbe94103) switched from CREATED to SCHEDULED.
2021-04-15 16:42:09,631 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Split Reader: Custom File Source -> Map (1/1) (4858412eecdb3f6d113d8ebe3691c6c3) switched from CREATED to SCHEDULED.
2021-04-15 16:42:09,631 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (1/1) (f2397a8d6677164c2ff2a2b7e938a507) switched from CREATED to SCHEDULED.
2021-04-15 16:42:09,631 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (1/1) (c877f0a4be6a5b3336617e6a51c4a60a) switched from CREATED to SCHEDULED.
2021-04-15 16:42:09,631 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (1/1) (0e60cf60924bc9f09119be8d3a72649b) switched from CREATED to SCHEDULED.
2021-04-15 16:42:09,642 DEBUG o.a.f.r.jobmaster.slotpool.PhysicalSlotProviderImpl - Received slot request [SlotRequestId{684829b4e2028009ff1e3e6261ffb834}] with resource requirements: ResourceProfile{UNKNOWN}
2021-04-15 16:42:09,646 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{684829b4e2028009ff1e3e6261ffb834}]
2021-04-15 16:42:09,648 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{a38ff626c34e18ef641fd1d593194e4b}) for execution vertex (id bc764cd8ddf7a0cff126f51c16239658_0) from the physical slot (SlotRequestId{684829b4e2028009ff1e3e6261ffb834})
2021-04-15 16:42:09,650 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{5983cf90d537d97243a6fde044f804e7}) for execution vertex (id 20ba6b65f97481d5570070de90e4e791_0) from the physical slot (SlotRequestId{684829b4e2028009ff1e3e6261ffb834})
2021-04-15 16:42:09,650 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{8a297e254da69e779776532d07e0da75}) for execution vertex (id 700e2d9c0374125bac8dd259c7728377_0) from the physical slot (SlotRequestId{684829b4e2028009ff1e3e6261ffb834})
2021-04-15 16:42:09,650 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{afa28cb278b682e95be54efef81386db}) for execution vertex (id 5bd02938c768711b3149e43f99433bdd_0) from the physical slot (SlotRequestId{684829b4e2028009ff1e3e6261ffb834})
2021-04-15 16:42:09,651 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{81bb6e24a61070ed3e8de65185e111cd}) for execution vertex (id a7ff31a2a262e9bd1fe62e920ca466b3_0) from the physical slot (SlotRequestId{684829b4e2028009ff1e3e6261ffb834})
2021-04-15 16:42:09,655 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
2021-04-15 16:42:09,655 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/jobmanager_3 , session=59eb5d45-68a1-4ddb-a927-ba8199e461cd
2021-04-15 16:42:09,655 INFO org.apache.flink.runtime.jobmaster.JobMaster - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(a190380066b0109fc42f38e0068a41ac)
2021-04-15 16:42:09,657 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 16:42:09,658 INFO org.apache.flink.runtime.jobmaster.JobMaster - Resolved ResourceManager address, beginning registration
2021-04-15 16:42:09,658 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Registration at ResourceManager attempt 1 (timeout=100ms)
2021-04-15 16:42:09,658 DEBUG o.a.flink.runtime.resourcemanager.JobLeaderIdService - Add job 3faa797a88435b0ef0677b9294a4ce7c to job leader id monitoring.
2021-04-15 16:42:09,659 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Registering job manager a927ba8199e461cd59eb5d4568a14ddb@akka://flink/user/rpc/jobmanager_3 for job 3faa797a88435b0ef0677b9294a4ce7c.
2021-04-15 16:42:09,660 DEBUG o.a.flink.runtime.resourcemanager.JobLeaderIdService - Found a new job leader 59eb5d45-68a1-4ddb-a927-ba8199e461cd@akka://flink/user/rpc/jobmanager_3.
2021-04-15 16:42:09,660 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/jobmanager_3. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2021-04-15 16:42:09,664 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Registered job manager a927ba8199e461cd59eb5d4568a14ddb@akka://flink/user/rpc/jobmanager_3 for job 3faa797a88435b0ef0677b9294a4ce7c.
2021-04-15 16:42:09,666 INFO org.apache.flink.runtime.jobmaster.JobMaster - JobManager successfully registered at ResourceManager, leader id: a190380066b0109fc42f38e0068a41ac.
2021-04-15 16:42:09,668 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{684829b4e2028009ff1e3e6261ffb834}] and profile ResourceProfile{UNKNOWN} with allocation id e008f7508b8d125944a51f400364fa60 from resource manager.
2021-04-15 16:42:09,669 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 3faa797a88435b0ef0677b9294a4ce7c with allocation id e008f7508b8d125944a51f400364fa60.
2021-04-15 16:42:09,673 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request e008f7508b8d125944a51f400364fa60 for job 3faa797a88435b0ef0677b9294a4ce7c from resource manager with leader id a190380066b0109fc42f38e0068a41ac.
2021-04-15 16:42:09,683 DEBUG org.apache.flink.runtime.memory.MemoryManager - Initialized MemoryManager with total memory size 134217728 and page size 32768.
2021-04-15 16:42:09,684 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for e008f7508b8d125944a51f400364fa60.
2021-04-15 16:42:09,686 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Add job 3faa797a88435b0ef0677b9294a4ce7c for job leader monitoring.
2021-04-15 16:42:09,687 DEBUG o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - New leader information for job 3faa797a88435b0ef0677b9294a4ce7c. Address: akka://flink/user/rpc/jobmanager_3, leader id: a927ba8199e461cd59eb5d4568a14ddb.
2021-04-15 16:42:09,688 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Try to register at job manager akka://flink/user/rpc/jobmanager_3 with leader id 59eb5d45-68a1-4ddb-a927-ba8199e461cd.
2021-04-15 16:42:09,688 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/jobmanager_3. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2021-04-15 16:42:09,699 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Resolved JobManager address, beginning registration
2021-04-15 16:42:09,700 DEBUG o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Registration at JobManager attempt 1 (timeout=100ms)
2021-04-15 16:42:09,703 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
2021-04-15 16:42:09,718 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Register new TaskExecutor 0e8cf66e-9f5e-4007-a2c2-5069242a0468.
2021-04-15 16:42:09,719 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Successful registration at job manager akka://flink/user/rpc/jobmanager_3 for job 3faa797a88435b0ef0677b9294a4ce7c.
2021-04-15 16:42:09,721 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Establish JobManager connection for job 3faa797a88435b0ef0677b9294a4ce7c.
2021-04-15 16:42:09,728 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Offer reserved slots to the leader of job 3faa797a88435b0ef0677b9294a4ce7c.
2021-04-15 16:42:09,732 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Fulfilling pending slot request [SlotRequestId{684829b4e2028009ff1e3e6261ffb834}] with slot [e008f7508b8d125944a51f400364fa60]
2021-04-15 16:42:09,735 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{a38ff626c34e18ef641fd1d593194e4b}) for execution vertex (id bc764cd8ddf7a0cff126f51c16239658_0) from the physical slot (SlotRequestId{684829b4e2028009ff1e3e6261ffb834})
2021-04-15 16:42:09,745 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{5983cf90d537d97243a6fde044f804e7}) for execution vertex (id 20ba6b65f97481d5570070de90e4e791_0) from the physical slot (SlotRequestId{684829b4e2028009ff1e3e6261ffb834})
2021-04-15 16:42:09,745 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{8a297e254da69e779776532d07e0da75}) for execution vertex (id 700e2d9c0374125bac8dd259c7728377_0) from the physical slot (SlotRequestId{684829b4e2028009ff1e3e6261ffb834})
2021-04-15 16:42:09,745 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{afa28cb278b682e95be54efef81386db}) for execution vertex (id 5bd02938c768711b3149e43f99433bdd_0) from the physical slot (SlotRequestId{684829b4e2028009ff1e3e6261ffb834})
2021-04-15 16:42:09,745 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{81bb6e24a61070ed3e8de65185e111cd}) for execution vertex (id a7ff31a2a262e9bd1fe62e920ca466b3_0) from the physical slot (SlotRequestId{684829b4e2028009ff1e3e6261ffb834})
2021-04-15 16:42:09,746 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File Source (1/1) (5e74036b69eafb8aae22c461cbe94103) switched from SCHEDULED to DEPLOYING.
2021-04-15 16:42:09,746 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom File Source (1/1) (attempt #0) with attempt id 5e74036b69eafb8aae22c461cbe94103 to 0e8cf66e-9f5e-4007-a2c2-5069242a0468 @ server1 (dataPort=-1) with allocation id e008f7508b8d125944a51f400364fa60
2021-04-15 16:42:09,759 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Split Reader: Custom File Source -> Map (1/1) (4858412eecdb3f6d113d8ebe3691c6c3) switched from SCHEDULED to DEPLOYING.
2021-04-15 16:42:09,760 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Split Reader: Custom File Source -> Map (1/1) (attempt #0) with attempt id 4858412eecdb3f6d113d8ebe3691c6c3 to 0e8cf66e-9f5e-4007-a2c2-5069242a0468 @ server1 (dataPort=-1) with allocation id e008f7508b8d125944a51f400364fa60
2021-04-15 16:42:09,760 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot e008f7508b8d125944a51f400364fa60.
2021-04-15 16:42:09,761 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (1/1) (f2397a8d6677164c2ff2a2b7e938a507) switched from SCHEDULED to DEPLOYING.
2021-04-15 16:42:09,761 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Sink: Print to Std. Out (1/1) (attempt #0) with attempt id f2397a8d6677164c2ff2a2b7e938a507 to 0e8cf66e-9f5e-4007-a2c2-5069242a0468 @ server1 (dataPort=-1) with allocation id e008f7508b8d125944a51f400364fa60
2021-04-15 16:42:09,763 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (1/1) (c877f0a4be6a5b3336617e6a51c4a60a) switched from SCHEDULED to DEPLOYING.
2021-04-15 16:42:09,765 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Sink: Print to Std. Out (1/1) (attempt #0) with attempt id c877f0a4be6a5b3336617e6a51c4a60a to 0e8cf66e-9f5e-4007-a2c2-5069242a0468 @ server1 (dataPort=-1) with allocation id e008f7508b8d125944a51f400364fa60
2021-04-15 16:42:09,766 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (1/1) (0e60cf60924bc9f09119be8d3a72649b) switched from SCHEDULED to DEPLOYING.
2021-04-15 16:42:09,766 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Sink: Print to Std. Out (1/1) (attempt #0) with attempt id 0e60cf60924bc9f09119be8d3a72649b to 0e8cf66e-9f5e-4007-a2c2-5069242a0468 @ server1 (dataPort=-1) with allocation id e008f7508b8d125944a51f400364fa60
2021-04-15 16:42:09,774 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new allocation id e008f7508b8d125944a51f400364fa60 for local state stores for job 3faa797a88435b0ef0677b9294a4ce7c.
2021-04-15 16:42:09,778 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_e008f7508b8d125944a51f400364fa60], jobID=3faa797a88435b0ef0677b9294a4ce7c, jobVertexID=bc764cd8ddf7a0cff126f51c16239658, subtaskIndex=0}} for 3faa797a88435b0ef0677b9294a4ce7c - bc764cd8ddf7a0cff126f51c16239658 - 0 under allocation id e008f7508b8d125944a51f400364fa60.
2021-04-15 16:42:09,803 DEBUG o.a.f.r.io.network.partition.ResultPartitionFactory - Source: Custom File Source (1/1)#0 (5e74036b69eafb8aae22c461cbe94103): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@514a9199
2021-04-15 16:42:09,810 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom File Source (1/1)#0 (5e74036b69eafb8aae22c461cbe94103), deploy into slot with allocation id e008f7508b8d125944a51f400364fa60.
2021-04-15 16:42:09,811 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File Source (1/1)#0 (5e74036b69eafb8aae22c461cbe94103) switched from CREATED to DEPLOYING.
2021-04-15 16:42:09,811 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Source: Custom File Source (1/1)#0 (5e74036b69eafb8aae22c461cbe94103) [DEPLOYING]
2021-04-15 16:42:09,815 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot e008f7508b8d125944a51f400364fa60.
2021-04-15 16:42:09,817 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom File Source (1/1)#0 (5e74036b69eafb8aae22c461cbe94103) [DEPLOYING].
2021-04-15 16:42:09,818 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 5e74036b69eafb8aae22c461cbe94103 at library cache manager took 1 milliseconds
2021-04-15 16:42:09,821 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_e008f7508b8d125944a51f400364fa60], jobID=3faa797a88435b0ef0677b9294a4ce7c, jobVertexID=20ba6b65f97481d5570070de90e4e791, subtaskIndex=0}} for 3faa797a88435b0ef0677b9294a4ce7c - 20ba6b65f97481d5570070de90e4e791 - 0 under allocation id e008f7508b8d125944a51f400364fa60.
2021-04-15 16:42:09,821 DEBUG o.a.f.r.io.network.partition.ResultPartitionFactory - Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@514a9199
2021-04-15 16:42:09,821 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom File Source (1/1)#0 (5e74036b69eafb8aae22c461cbe94103) [DEPLOYING].
2021-04-15 16:42:09,822 DEBUG o.a.f.r.io.network.partition.ResultPartitionFactory - Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@514a9199
2021-04-15 16:42:09,822 DEBUG o.a.f.r.io.network.partition.ResultPartitionFactory - Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@514a9199
2021-04-15 16:42:09,824 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 2-10 buffers
2021-04-15 16:42:09,825 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Registered PipelinedResultPartition 9565fae3463ae216c1eaf2346de31b72#0@5e74036b69eafb8aae22c461cbe94103 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 16:42:09,826 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - registering 9565fae3463ae216c1eaf2346de31b72#0@5e74036b69eafb8aae22c461cbe94103
2021-04-15 16:42:09,832 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 16:42:09,835 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3), deploy into slot with allocation id e008f7508b8d125944a51f400364fa60.
2021-04-15 16:42:09,836 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot e008f7508b8d125944a51f400364fa60.
2021-04-15 16:42:09,836 INFO org.apache.flink.runtime.taskmanager.Task - Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3) switched from CREATED to DEPLOYING.
2021-04-15 16:42:09,836 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3) [DEPLOYING]
2021-04-15 16:42:09,839 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_e008f7508b8d125944a51f400364fa60], jobID=3faa797a88435b0ef0677b9294a4ce7c, jobVertexID=700e2d9c0374125bac8dd259c7728377, subtaskIndex=0}} for 3faa797a88435b0ef0677b9294a4ce7c - 700e2d9c0374125bac8dd259c7728377 - 0 under allocation id e008f7508b8d125944a51f400364fa60.
2021-04-15 16:42:09,839 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - Sink: Print to Std. Out (1/1)#0 (f2397a8d6677164c2ff2a2b7e938a507): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 16:42:09,837 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3) [DEPLOYING].
2021-04-15 16:42:09,840 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Sink: Print to Std. Out (1/1)#0 (f2397a8d6677164c2ff2a2b7e938a507), deploy into slot with allocation id e008f7508b8d125944a51f400364fa60.
2021-04-15 16:42:09,840 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot e008f7508b8d125944a51f400364fa60.
2021-04-15 16:42:09,842 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_e008f7508b8d125944a51f400364fa60], jobID=3faa797a88435b0ef0677b9294a4ce7c, jobVertexID=5bd02938c768711b3149e43f99433bdd, subtaskIndex=0}} for 3faa797a88435b0ef0677b9294a4ce7c - 5bd02938c768711b3149e43f99433bdd - 0 under allocation id e008f7508b8d125944a51f400364fa60.
2021-04-15 16:42:09,843 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - Sink: Print to Std. Out (1/1)#0 (c877f0a4be6a5b3336617e6a51c4a60a): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 16:42:09,843 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Sink: Print to Std. Out (1/1)#0 (c877f0a4be6a5b3336617e6a51c4a60a), deploy into slot with allocation id e008f7508b8d125944a51f400364fa60.
2021-04-15 16:42:09,847 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot e008f7508b8d125944a51f400364fa60.
2021-04-15 16:42:09,848 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot e008f7508b8d125944a51f400364fa60.
2021-04-15 16:42:09,855 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_e008f7508b8d125944a51f400364fa60], jobID=3faa797a88435b0ef0677b9294a4ce7c, jobVertexID=a7ff31a2a262e9bd1fe62e920ca466b3, subtaskIndex=0}} for 3faa797a88435b0ef0677b9294a4ce7c - a7ff31a2a262e9bd1fe62e920ca466b3 - 0 under allocation id e008f7508b8d125944a51f400364fa60.
2021-04-15 16:42:09,856 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - Sink: Print to Std. Out (1/1)#0 (0e60cf60924bc9f09119be8d3a72649b): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 16:42:09,856 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Using partitioner FORWARD for output 0 of task Source: Custom File Source
2021-04-15 16:42:09,856 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Sink: Print to Std. Out (1/1)#0 (0e60cf60924bc9f09119be8d3a72649b), deploy into slot with allocation id e008f7508b8d125944a51f400364fa60.
2021-04-15 16:42:09,857 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 4858412eecdb3f6d113d8ebe3691c6c3 at library cache manager took 18 milliseconds
2021-04-15 16:42:09,858 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3) [DEPLOYING].
2021-04-15 16:42:09,859 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 2-10 buffers
2021-04-15 16:42:09,860 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Registered PipelinedResultPartition f983f0475270ec4e11b8992d4f8a2d9f#0@4858412eecdb3f6d113d8ebe3691c6c3 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 16:42:09,860 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 2-10 buffers
2021-04-15 16:42:09,861 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Registered PipelinedResultPartition 0c01a5a4416986f051aeabdae995fd4e#0@4858412eecdb3f6d113d8ebe3691c6c3 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 16:42:09,861 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 2-10 buffers
2021-04-15 16:42:09,861 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Registered PipelinedResultPartition e946045e7ef045c8c954e9d67e3df3c9#0@4858412eecdb3f6d113d8ebe3691c6c3 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 16:42:09,861 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 16:42:09,862 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - registering f983f0475270ec4e11b8992d4f8a2d9f#0@4858412eecdb3f6d113d8ebe3691c6c3
2021-04-15 16:42:09,862 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - registering 0c01a5a4416986f051aeabdae995fd4e#0@4858412eecdb3f6d113d8ebe3691c6c3
2021-04-15 16:42:09,862 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - registering e946045e7ef045c8c954e9d67e3df3c9#0@4858412eecdb3f6d113d8ebe3691c6c3
2021-04-15 16:42:09,860 INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (1/1)#0 (f2397a8d6677164c2ff2a2b7e938a507) switched from CREATED to DEPLOYING.
2021-04-15 16:42:09,864 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (1/1)#0 (f2397a8d6677164c2ff2a2b7e938a507) [DEPLOYING]
2021-04-15 16:42:09,860 INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (1/1)#0 (c877f0a4be6a5b3336617e6a51c4a60a) switched from CREATED to DEPLOYING.
2021-04-15 16:42:09,873 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (1/1)#0 (c877f0a4be6a5b3336617e6a51c4a60a) [DEPLOYING]
2021-04-15 16:42:09,860 INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (1/1)#0 (0e60cf60924bc9f09119be8d3a72649b) switched from CREATED to DEPLOYING.
2021-04-15 16:42:09,875 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (1/1)#0 (0e60cf60924bc9f09119be8d3a72649b) [DEPLOYING]
2021-04-15 16:42:09,865 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Sink: Print to Std. Out (1/1)#0 (f2397a8d6677164c2ff2a2b7e938a507) [DEPLOYING].
2021-04-15 16:42:09,878 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task f2397a8d6677164c2ff2a2b7e938a507 at library cache manager took 2 milliseconds
2021-04-15 16:42:09,871 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 16:42:09,888 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Using partitioner HASH for output 0 of task Split Reader: Custom File Source -> Map
2021-04-15 16:42:09,889 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Using partitioner GLOBAL for output 1 of task Split Reader: Custom File Source -> Map
2021-04-15 16:42:09,889 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Using partitioner SHUFFLE for output 2 of task Split Reader: Custom File Source -> Map
2021-04-15 16:42:09,874 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Sink: Print to Std. Out (1/1)#0 (c877f0a4be6a5b3336617e6a51c4a60a) [DEPLOYING].
2021-04-15 16:42:09,896 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task c877f0a4be6a5b3336617e6a51c4a60a at library cache manager took 0 milliseconds
2021-04-15 16:42:09,875 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Sink: Print to Std. Out (1/1)#0 (0e60cf60924bc9f09119be8d3a72649b) [DEPLOYING].
2021-04-15 16:42:09,909 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 0e60cf60924bc9f09119be8d3a72649b at library cache manager took 0 milliseconds
2021-04-15 16:42:09,880 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Sink: Print to Std. Out (1/1)#0 (f2397a8d6677164c2ff2a2b7e938a507) [DEPLOYING].
2021-04-15 16:42:09,909 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 16:42:09,891 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 16:42:09,904 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Sink: Print to Std. Out (1/1)#0 (c877f0a4be6a5b3336617e6a51c4a60a) [DEPLOYING].
2021-04-15 16:42:09,913 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 16:42:09,905 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File Source (1/1)#0 (5e74036b69eafb8aae22c461cbe94103) switched from DEPLOYING to RUNNING.
2021-04-15 16:42:09,916 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Source: Custom File Source (1/1)#0.
2021-04-15 16:42:09,912 INFO org.apache.flink.runtime.taskmanager.Task - Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3) switched from DEPLOYING to RUNNING.
2021-04-15 16:42:09,916 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Split Reader: Custom File Source -> Map (1/1)#0.
2021-04-15 16:42:09,913 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 16:42:09,915 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Sink: Print to Std. Out (1/1)#0 (0e60cf60924bc9f09119be8d3a72649b) [DEPLOYING].
2021-04-15 16:42:09,928 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 16:42:09,919 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 16:42:09,920 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File Source (1/1) (5e74036b69eafb8aae22c461cbe94103) switched from DEPLOYING to RUNNING.
2021-04-15 16:42:09,920 INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (1/1)#0 (f2397a8d6677164c2ff2a2b7e938a507) switched from DEPLOYING to RUNNING.
2021-04-15 16:42:09,943 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Sink: Print to Std. Out (1/1)#0.
2021-04-15 16:42:09,929 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 16:42:09,970 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Source: Custom File Source (1/1)#0
2021-04-15 16:42:09,942 INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (1/1)#0 (c877f0a4be6a5b3336617e6a51c4a60a) switched from DEPLOYING to RUNNING.
2021-04-15 16:42:09,997 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Sink: Print to Std. Out (1/1)#0.
2021-04-15 16:42:09,943 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Split Reader: Custom File Source -> Map (1/1) (4858412eecdb3f6d113d8ebe3691c6c3) switched from DEPLOYING to RUNNING.
2021-04-15 16:42:09,959 INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (1/1)#0 (0e60cf60924bc9f09119be8d3a72649b) switched from DEPLOYING to RUNNING.
2021-04-15 16:42:10,029 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSource_bc764cd8ddf7a0cff126f51c16239658_(1/1) with empty state.
2021-04-15 16:42:10,029 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Sink: Print to Std. Out (1/1)#0.
2021-04-15 16:42:10,020 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (1/1) (f2397a8d6677164c2ff2a2b7e938a507) switched from DEPLOYING to RUNNING.
2021-04-15 16:42:10,032 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (1/1) (c877f0a4be6a5b3336617e6a51c4a60a) switched from DEPLOYING to RUNNING.
2021-04-15 16:42:10,032 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (1/1) (0e60cf60924bc9f09119be8d3a72649b) switched from DEPLOYING to RUNNING.
2021-04-15 16:42:10,044 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Sink: Print to Std. Out (1/1)#0
2021-04-15 16:42:10,045 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_a7ff31a2a262e9bd1fe62e920ca466b3_(1/1) with empty state.
2021-04-15 16:42:10,046 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Split Reader: Custom File Source -> Map (1/1)#0
2021-04-15 16:42:10,046 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Sink: Print to Std. Out (1/1)#0
2021-04-15 16:42:10,047 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamMap_c09dc291fad93d575e015871097bfc60_(1/1) with empty state.
2021-04-15 16:42:10,047 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Sink: Print to Std. Out (1/1)#0
2021-04-15 16:42:10,047 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_5bd02938c768711b3149e43f99433bdd_(1/1) with empty state.
2021-04-15 16:42:10,050 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating keyed state backend for StreamSink_700e2d9c0374125bac8dd259c7728377_(1/1) with empty state.
2021-04-15 16:42:10,055 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for ContinuousFileReaderOperator_20ba6b65f97481d5570070de90e4e791_(1/1) with empty state.
2021-04-15 16:42:10,061 INFO o.a.f.runtime.state.heap.HeapKeyedStateBackendBuilder - Finished to build heap keyed state-backend.
2021-04-15 16:42:10,067 INFO o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - No state to restore for the ContinuousFileMonitoringFunction.
2021-04-15 16:42:10,068 DEBUG o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Opened ContinuousFileMonitoringFunction (taskIdx= 0) for path: src/main/resources/sensor.txt
2021-04-15 16:42:10,068 INFO o.a.f.s.a.functions.source.ContinuousFileReaderOperator - No state to restore for the ContinuousFileReaderOperator (taskIdx=0).
2021-04-15 16:42:10,072 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf - -Dorg.apache.flink.shaded.netty4.io.netty.buffer.checkAccessible: true
2021-04-15 16:42:10,072 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf - -Dorg.apache.flink.shaded.netty4.io.netty.buffer.checkBounds: true
2021-04-15 16:42:10,073 INFO o.apache.flink.runtime.state.heap.HeapKeyedStateBackend - Initializing heap keyed state backend with stream factory.
2021-04-15 16:42:10,073 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_700e2d9c0374125bac8dd259c7728377_(1/1) with empty state.
2021-04-15 16:42:10,075 DEBUG o.a.f.s.n.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.flink.shaded.netty4.io.netty.util.ResourceLeakDetector@56629732
2021-04-15 16:42:10,078 INFO org.apache.flink.core.fs.FileSystem - Hadoop is not in the classpath/dependencies. The extended set of supported File Systems via Hadoop is not available.
2021-04-15 16:42:10,078 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - Sink: Print to Std. Out (1/1)#0 (0e60cf60924bc9f09119be8d3a72649b)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 16:42:10,078 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - Sink: Print to Std. Out (1/1)#0 (c877f0a4be6a5b3336617e6a51c4a60a)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 16:42:10,079 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 16:42:10,080 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 16:42:10,082 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - Sink: Print to Std. Out (1/1)#0 (f2397a8d6677164c2ff2a2b7e938a507)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 16:42:10,082 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 16:42:10,082 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 16:42:10,083 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 16:42:10,083 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 16:42:10,083 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 16:42:10,084 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 16:42:10,084 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 16:42:10,084 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [9565fae3463ae216c1eaf2346de31b72#0@5e74036b69eafb8aae22c461cbe94103]: Requesting LOCAL subpartition 0 of partition 9565fae3463ae216c1eaf2346de31b72#0@5e74036b69eafb8aae22c461cbe94103. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 16:42:10,084 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [e946045e7ef045c8c954e9d67e3df3c9#0@4858412eecdb3f6d113d8ebe3691c6c3]: Requesting LOCAL subpartition 0 of partition e946045e7ef045c8c954e9d67e3df3c9#0@4858412eecdb3f6d113d8ebe3691c6c3. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 16:42:10,085 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [f983f0475270ec4e11b8992d4f8a2d9f#0@4858412eecdb3f6d113d8ebe3691c6c3]: Requesting LOCAL subpartition 0 of partition f983f0475270ec4e11b8992d4f8a2d9f#0@4858412eecdb3f6d113d8ebe3691c6c3. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 16:42:10,085 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [0c01a5a4416986f051aeabdae995fd4e#0@4858412eecdb3f6d113d8ebe3691c6c3]: Requesting LOCAL subpartition 0 of partition 0c01a5a4416986f051aeabdae995fd4e#0@4858412eecdb3f6d113d8ebe3691c6c3. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 16:42:10,085 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 0 of PipelinedResultPartition 9565fae3463ae216c1eaf2346de31b72#0@5e74036b69eafb8aae22c461cbe94103 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 16:42:10,086 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File Source (1/1)#0 (5e74036b69eafb8aae22c461cbe94103): Creating read view for subpartition 0 of partition 9565fae3463ae216c1eaf2346de31b72#0@5e74036b69eafb8aae22c461cbe94103.
2021-04-15 16:42:10,086 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 0) of ResultPartition 9565fae3463ae216c1eaf2346de31b72#0@5e74036b69eafb8aae22c461cbe94103
2021-04-15 16:42:10,087 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 0 of PipelinedResultPartition 0c01a5a4416986f051aeabdae995fd4e#0@4858412eecdb3f6d113d8ebe3691c6c3 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 16:42:10,087 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3): Creating read view for subpartition 0 of partition 0c01a5a4416986f051aeabdae995fd4e#0@4858412eecdb3f6d113d8ebe3691c6c3.
2021-04-15 16:42:10,087 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 0) of ResultPartition 0c01a5a4416986f051aeabdae995fd4e#0@4858412eecdb3f6d113d8ebe3691c6c3
2021-04-15 16:42:10,087 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 0 of PipelinedResultPartition f983f0475270ec4e11b8992d4f8a2d9f#0@4858412eecdb3f6d113d8ebe3691c6c3 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 16:42:10,087 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3): Creating read view for subpartition 0 of partition f983f0475270ec4e11b8992d4f8a2d9f#0@4858412eecdb3f6d113d8ebe3691c6c3.
2021-04-15 16:42:10,088 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 0) of ResultPartition f983f0475270ec4e11b8992d4f8a2d9f#0@4858412eecdb3f6d113d8ebe3691c6c3
2021-04-15 16:42:10,089 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 0 of PipelinedResultPartition e946045e7ef045c8c954e9d67e3df3c9#0@4858412eecdb3f6d113d8ebe3691c6c3 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 16:42:10,090 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3): Creating read view for subpartition 0 of partition e946045e7ef045c8c954e9d67e3df3c9#0@4858412eecdb3f6d113d8ebe3691c6c3.
2021-04-15 16:42:10,090 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 0) of ResultPartition e946045e7ef045c8c954e9d67e3df3c9#0@4858412eecdb3f6d113d8ebe3691c6c3
2021-04-15 16:42:10,106 DEBUG org.apache.flink.core.fs.FileSystem - Loading extension file systems via services
2021-04-15 16:42:10,111 INFO o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Forwarding split: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 16:42:10,328 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task Source: Custom File Source (1/1)#0
2021-04-15 16:42:10,337 DEBUG o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Closed File Monitoring Source for path: src/main/resources/sensor.txt.
2021-04-15 16:42:10,338 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task Source: Custom File Source (1/1)#0
2021-04-15 16:42:10,355 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File Source (1/1)#0 (5e74036b69eafb8aae22c461cbe94103): Finished PipelinedSubpartition#0 [number of buffers: 2 (120 bytes), number of buffers in backlog: 1, finished? true, read view? true].
2021-04-15 16:42:10,355 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File Source (1/1)#0 (5e74036b69eafb8aae22c461cbe94103) switched from RUNNING to FINISHED.
2021-04-15 16:42:10,355 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Source: Custom File Source (1/1)#0 (5e74036b69eafb8aae22c461cbe94103).
2021-04-15 16:42:10,355 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task Source: Custom File Source (1/1)#0 network resources (state: FINISHED).
2021-04-15 16:42:10,355 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - unregistering 9565fae3463ae216c1eaf2346de31b72#0@5e74036b69eafb8aae22c461cbe94103
2021-04-15 16:42:10,369 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Source: Custom File Source (1/1)#0 (5e74036b69eafb8aae22c461cbe94103) [FINISHED]
2021-04-15 16:42:10,375 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task Source: Custom File Source (1/1)#0 5e74036b69eafb8aae22c461cbe94103.
2021-04-15 16:42:10,398 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File Source (1/1) (5e74036b69eafb8aae22c461cbe94103) switched from RUNNING to FINISHED.
2021-04-15 16:42:10,399 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Source: Custom File Source (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 16:42:10,400 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{a38ff626c34e18ef641fd1d593194e4b}) for execution vertex (id bc764cd8ddf7a0cff126f51c16239658_0) from the physical slot (SlotRequestId{684829b4e2028009ff1e3e6261ffb834})
2021-04-15 16:42:10,416 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: IDLE -> OPENING
2021-04-15 16:42:10,416 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - load split: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 16:42:10,416 DEBUG org.apache.flink.api.common.io.FileInputFormat - Opening input split file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt [0,315]
2021-04-15 16:42:10,419 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: OPENING -> READING
2021-04-15 16:42:10,422 INFO org.myorg.quickstart.util.MapUtil - sensor_1,1547718199,35.8
2021-04-15 16:42:10,448 INFO org.myorg.quickstart.util.MapUtil - SensorReading{id='sensor_1', timestamp=1547718199, temperature=35.8}
2021-04-15 16:42:10,450 INFO org.myorg.quickstart.util.MapUtil - sensor_6,1547718201,15.4
2021-04-15 16:42:10,450 INFO org.myorg.quickstart.util.MapUtil - SensorReading{id='sensor_6', timestamp=1547718201, temperature=15.4}
2021-04-15 16:42:10,452 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - PipelinedResultPartition 9565fae3463ae216c1eaf2346de31b72#0@5e74036b69eafb8aae22c461cbe94103 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
2021-04-15 16:42:10,452 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Received consume notification from PipelinedResultPartition 9565fae3463ae216c1eaf2346de31b72#0@5e74036b69eafb8aae22c461cbe94103 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 16:42:10,452 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Source: Custom File Source (1/1)#0 (5e74036b69eafb8aae22c461cbe94103): Releasing PipelinedResultPartition 9565fae3463ae216c1eaf2346de31b72#0@5e74036b69eafb8aae22c461cbe94103 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 16:42:10,453 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File Source (1/1)#0 (5e74036b69eafb8aae22c461cbe94103): Released PipelinedSubpartition#0 [number of buffers: 2 (137 bytes), number of buffers in backlog: 0, finished? true, read view? false].
2021-04-15 16:42:10,453 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Released partition 9565fae3463ae216c1eaf2346de31b72#0 produced by 5e74036b69eafb8aae22c461cbe94103.
2021-04-15 16:42:10,453 INFO org.myorg.quickstart.util.MapUtil - sensor_7,1547718202,6.7
2021-04-15 16:42:10,453 INFO org.myorg.quickstart.util.MapUtil - SensorReading{id='sensor_7', timestamp=1547718202, temperature=6.7}
2021-04-15 16:42:10,454 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task Split Reader: Custom File Source -> Map (1/1)#0
2021-04-15 16:42:10,454 INFO org.myorg.quickstart.util.MapUtil - sensor_10,1547718205,38.1
2021-04-15 16:42:10,454 INFO org.myorg.quickstart.util.MapUtil - SensorReading{id='sensor_10', timestamp=1547718205, temperature=38.1}
2021-04-15 16:42:10,454 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - closing
2021-04-15 16:42:10,455 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: READING -> CLOSING
2021-04-15 16:42:10,455 INFO org.myorg.quickstart.util.MapUtil - sensor_2,1547718207,36.3
2021-04-15 16:42:10,455 INFO org.myorg.quickstart.util.MapUtil - SensorReading{id='sensor_2', timestamp=1547718207, temperature=36.3}
2021-04-15 16:42:10,455 INFO org.myorg.quickstart.util.MapUtil - sensor_4,1547718209,32.8
2021-04-15 16:42:10,455 INFO org.myorg.quickstart.util.MapUtil - SensorReading{id='sensor_4', timestamp=1547718209, temperature=32.8}
2021-04-15 16:42:10,456 INFO org.myorg.quickstart.util.MapUtil - sensor_6,1547718212,37.1
2021-04-15 16:42:10,456 INFO org.myorg.quickstart.util.MapUtil - SensorReading{id='sensor_6', timestamp=1547718212, temperature=37.1}
2021-04-15 16:42:10,456 INFO org.myorg.quickstart.util.MapUtil - sensor_4,1547718215,34.1
2021-04-15 16:42:10,456 INFO org.myorg.quickstart.util.MapUtil - SensorReading{id='sensor_4', timestamp=1547718215, temperature=34.1}
2021-04-15 16:42:10,456 INFO org.myorg.quickstart.util.MapUtil - sensor_4,1547718218,11.89
2021-04-15 16:42:10,456 INFO org.myorg.quickstart.util.MapUtil - SensorReading{id='sensor_4', timestamp=1547718218, temperature=11.89}
2021-04-15 16:42:10,457 INFO org.myorg.quickstart.util.MapUtil - sensor_10,1547718220,32.1
2021-04-15 16:42:10,457 INFO org.myorg.quickstart.util.MapUtil - SensorReading{id='sensor_10', timestamp=1547718220, temperature=32.1}
2021-04-15 16:42:10,457 INFO org.myorg.quickstart.util.MapUtil - sensor_7,1547718223,33.6
2021-04-15 16:42:10,457 INFO org.myorg.quickstart.util.MapUtil - SensorReading{id='sensor_7', timestamp=1547718223, temperature=33.6}
2021-04-15 16:42:10,457 INFO org.myorg.quickstart.util.MapUtil - sensor_6,1547718225,23.22
2021-04-15 16:42:10,457 INFO org.myorg.quickstart.util.MapUtil - SensorReading{id='sensor_6', timestamp=1547718225, temperature=23.22}
2021-04-15 16:42:10,459 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - split 1 processed: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 16:42:10,459 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: CLOSING -> CLOSED
2021-04-15 16:42:10,459 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - cleanup, state=CLOSED
2021-04-15 16:42:10,460 WARN o.a.f.s.a.functions.source.ContinuousFileReaderOperator - not processing any records while closed
2021-04-15 16:42:10,462 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task Split Reader: Custom File Source -> Map (1/1)#0
2021-04-15 16:42:10,466 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3): Finished PipelinedSubpartition#0 [number of buffers: 2 (423 bytes), number of buffers in backlog: 1, finished? true, read view? true].
2021-04-15 16:42:10,467 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3): Finished PipelinedSubpartition#0 [number of buffers: 2 (423 bytes), number of buffers in backlog: 1, finished? true, read view? true].
2021-04-15 16:42:10,467 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3): Finished PipelinedSubpartition#0 [number of buffers: 2 (376 bytes), number of buffers in backlog: 1, finished? true, read view? true].
2021-04-15 16:42:10,467 INFO org.apache.flink.runtime.taskmanager.Task - Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3) switched from RUNNING to FINISHED.
2021-04-15 16:42:10,467 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3).
2021-04-15 16:42:10,467 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task Split Reader: Custom File Source -> Map (1/1)#0 network resources (state: FINISHED).
2021-04-15 16:42:10,467 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - unregistering f983f0475270ec4e11b8992d4f8a2d9f#0@4858412eecdb3f6d113d8ebe3691c6c3
2021-04-15 16:42:10,467 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - unregistering 0c01a5a4416986f051aeabdae995fd4e#0@4858412eecdb3f6d113d8ebe3691c6c3
2021-04-15 16:42:10,467 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - unregistering e946045e7ef045c8c954e9d67e3df3c9#0@4858412eecdb3f6d113d8ebe3691c6c3
2021-04-15 16:42:10,467 DEBUG o.a.f.r.io.network.partition.consumer.SingleInputGate - Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3): Releasing SingleInputGate{owningTaskName='Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3)', gateIndex=0}.
2021-04-15 16:42:10,468 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3) [FINISHED]
2021-04-15 16:42:10,469 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - PipelinedResultPartition e946045e7ef045c8c954e9d67e3df3c9#0@4858412eecdb3f6d113d8ebe3691c6c3 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
2021-04-15 16:42:10,470 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Received consume notification from PipelinedResultPartition e946045e7ef045c8c954e9d67e3df3c9#0@4858412eecdb3f6d113d8ebe3691c6c3 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 16:42:10,470 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3): Releasing PipelinedResultPartition e946045e7ef045c8c954e9d67e3df3c9#0@4858412eecdb3f6d113d8ebe3691c6c3 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 16:42:10,470 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3): Released PipelinedSubpartition#0 [number of buffers: 2 (380 bytes), number of buffers in backlog: 0, finished? true, read view? false].
2021-04-15 16:42:10,470 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Released partition e946045e7ef045c8c954e9d67e3df3c9#0 produced by 4858412eecdb3f6d113d8ebe3691c6c3.
2021-04-15 16:42:10,470 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task Sink: Print to Std. Out (1/1)#0
2021-04-15 16:42:10,470 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task Sink: Print to Std. Out (1/1)#0
2021-04-15 16:42:10,471 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - PipelinedResultPartition f983f0475270ec4e11b8992d4f8a2d9f#0@4858412eecdb3f6d113d8ebe3691c6c3 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
2021-04-15 16:42:10,471 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Received consume notification from PipelinedResultPartition f983f0475270ec4e11b8992d4f8a2d9f#0@4858412eecdb3f6d113d8ebe3691c6c3 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 16:42:10,471 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3): Releasing PipelinedResultPartition f983f0475270ec4e11b8992d4f8a2d9f#0@4858412eecdb3f6d113d8ebe3691c6c3 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 16:42:10,471 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - PipelinedResultPartition 0c01a5a4416986f051aeabdae995fd4e#0@4858412eecdb3f6d113d8ebe3691c6c3 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
2021-04-15 16:42:10,471 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Received consume notification from PipelinedResultPartition 0c01a5a4416986f051aeabdae995fd4e#0@4858412eecdb3f6d113d8ebe3691c6c3 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 16:42:10,471 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3): Released PipelinedSubpartition#0 [number of buffers: 2 (427 bytes), number of buffers in backlog: 0, finished? true, read view? false].
2021-04-15 16:42:10,471 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Released partition f983f0475270ec4e11b8992d4f8a2d9f#0 produced by 4858412eecdb3f6d113d8ebe3691c6c3.
2021-04-15 16:42:10,471 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3): Releasing PipelinedResultPartition 0c01a5a4416986f051aeabdae995fd4e#0@4858412eecdb3f6d113d8ebe3691c6c3 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 16:42:10,471 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task Sink: Print to Std. Out (1/1)#0
2021-04-15 16:42:10,471 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Split Reader: Custom File Source -> Map (1/1)#0 (4858412eecdb3f6d113d8ebe3691c6c3): Released PipelinedSubpartition#0 [number of buffers: 2 (427 bytes), number of buffers in backlog: 0, finished? true, read view? false].
2021-04-15 16:42:10,471 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task Sink: Print to Std. Out (1/1)#0
2021-04-15 16:42:10,471 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Released partition 0c01a5a4416986f051aeabdae995fd4e#0 produced by 4858412eecdb3f6d113d8ebe3691c6c3.
2021-04-15 16:42:10,472 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task Sink: Print to Std. Out (1/1)#0
2021-04-15 16:42:10,473 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task Sink: Print to Std. Out (1/1)#0
2021-04-15 16:42:10,469 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task Split Reader: Custom File Source -> Map (1/1)#0 4858412eecdb3f6d113d8ebe3691c6c3.
2021-04-15 16:42:10,470 INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (1/1)#0 (0e60cf60924bc9f09119be8d3a72649b) switched from RUNNING to FINISHED.
2021-04-15 16:42:10,473 INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (1/1)#0 (c877f0a4be6a5b3336617e6a51c4a60a) switched from RUNNING to FINISHED.
2021-04-15 16:42:10,473 INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (1/1)#0 (f2397a8d6677164c2ff2a2b7e938a507) switched from RUNNING to FINISHED.
2021-04-15 16:42:10,473 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Sink: Print to Std. Out (1/1)#0 (0e60cf60924bc9f09119be8d3a72649b).
2021-04-15 16:42:10,473 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task Sink: Print to Std. Out (1/1)#0 network resources (state: FINISHED).
2021-04-15 16:42:10,473 DEBUG o.a.f.r.io.network.partition.consumer.SingleInputGate - Sink: Print to Std. Out (1/1)#0 (0e60cf60924bc9f09119be8d3a72649b): Releasing SingleInputGate{owningTaskName='Sink: Print to Std. Out (1/1)#0 (0e60cf60924bc9f09119be8d3a72649b)', gateIndex=0}.
2021-04-15 16:42:10,475 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Sink: Print to Std. Out (1/1)#0 (0e60cf60924bc9f09119be8d3a72649b) [FINISHED]
2021-04-15 16:42:10,473 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Sink: Print to Std. Out (1/1)#0 (c877f0a4be6a5b3336617e6a51c4a60a).
2021-04-15 16:42:10,480 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task Sink: Print to Std. Out (1/1)#0 network resources (state: FINISHED).
2021-04-15 16:42:10,480 DEBUG o.a.f.r.io.network.partition.consumer.SingleInputGate - Sink: Print to Std. Out (1/1)#0 (c877f0a4be6a5b3336617e6a51c4a60a): Releasing SingleInputGate{owningTaskName='Sink: Print to Std. Out (1/1)#0 (c877f0a4be6a5b3336617e6a51c4a60a)', gateIndex=0}.
2021-04-15 16:42:10,480 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Sink: Print to Std. Out (1/1)#0 (c877f0a4be6a5b3336617e6a51c4a60a) [FINISHED]
2021-04-15 16:42:10,473 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Sink: Print to Std. Out (1/1)#0 (f2397a8d6677164c2ff2a2b7e938a507).
2021-04-15 16:42:10,480 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task Sink: Print to Std. Out (1/1)#0 network resources (state: FINISHED).
2021-04-15 16:42:10,480 DEBUG o.a.f.r.io.network.partition.consumer.SingleInputGate - Sink: Print to Std. Out (1/1)#0 (f2397a8d6677164c2ff2a2b7e938a507): Releasing SingleInputGate{owningTaskName='Sink: Print to Std. Out (1/1)#0 (f2397a8d6677164c2ff2a2b7e938a507)', gateIndex=0}.
2021-04-15 16:42:10,481 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Sink: Print to Std. Out (1/1)#0 (f2397a8d6677164c2ff2a2b7e938a507) [FINISHED]
2021-04-15 16:42:10,475 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Split Reader: Custom File Source -> Map (1/1) (4858412eecdb3f6d113d8ebe3691c6c3) switched from RUNNING to FINISHED.
2021-04-15 16:42:10,482 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Split Reader: Custom File Source -> Map (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 16:42:10,482 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{5983cf90d537d97243a6fde044f804e7}) for execution vertex (id 20ba6b65f97481d5570070de90e4e791_0) from the physical slot (SlotRequestId{684829b4e2028009ff1e3e6261ffb834})
2021-04-15 16:42:10,476 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task Sink: Print to Std. Out (1/1)#0 0e60cf60924bc9f09119be8d3a72649b.
2021-04-15 16:42:10,483 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task Sink: Print to Std. Out (1/1)#0 c877f0a4be6a5b3336617e6a51c4a60a.
2021-04-15 16:42:10,484 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task Sink: Print to Std. Out (1/1)#0 f2397a8d6677164c2ff2a2b7e938a507.
2021-04-15 16:42:10,485 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (1/1) (0e60cf60924bc9f09119be8d3a72649b) switched from RUNNING to FINISHED.
2021-04-15 16:42:10,488 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Sink: Print to Std. Out (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 16:42:10,488 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{81bb6e24a61070ed3e8de65185e111cd}) for execution vertex (id a7ff31a2a262e9bd1fe62e920ca466b3_0) from the physical slot (SlotRequestId{684829b4e2028009ff1e3e6261ffb834})
2021-04-15 16:42:10,490 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (1/1) (c877f0a4be6a5b3336617e6a51c4a60a) switched from RUNNING to FINISHED.
2021-04-15 16:42:10,490 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Sink: Print to Std. Out (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 16:42:10,491 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{afa28cb278b682e95be54efef81386db}) for execution vertex (id 5bd02938c768711b3149e43f99433bdd_0) from the physical slot (SlotRequestId{684829b4e2028009ff1e3e6261ffb834})
2021-04-15 16:42:10,492 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (1/1) (f2397a8d6677164c2ff2a2b7e938a507) switched from RUNNING to FINISHED.
2021-04-15 16:42:10,495 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Sink: Print to Std. Out (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 16:42:10,496 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{8a297e254da69e779776532d07e0da75}) for execution vertex (id 700e2d9c0374125bac8dd259c7728377_0) from the physical slot (SlotRequestId{684829b4e2028009ff1e3e6261ffb834})
2021-04-15 16:42:10,496 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Release shared slot externally (SlotRequestId{684829b4e2028009ff1e3e6261ffb834})
2021-04-15 16:42:10,496 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Releasing slot [SlotRequestId{684829b4e2028009ff1e3e6261ffb834}] because: Slot is being returned from SlotSharingExecutionSlotAllocator.
2021-04-15 16:42:10,496 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Release shared slot (SlotRequestId{684829b4e2028009ff1e3e6261ffb834})
2021-04-15 16:42:10,497 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Adding slot [e008f7508b8d125944a51f400364fa60] to available slots
2021-04-15 16:42:10,499 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Job Flink Streaming Job (3faa797a88435b0ef0677b9294a4ce7c) switched from state RUNNING to FINISHED.
2021-04-15 16:42:10,500 INFO o.apache.flink.runtime.checkpoint.CheckpointCoordinator - Stopping checkpoint coordinator for job 3faa797a88435b0ef0677b9294a4ce7c.
2021-04-15 16:42:10,505 INFO o.a.f.r.checkpoint.StandaloneCompletedCheckpointStore - Shutting down
2021-04-15 16:42:10,513 INFO org.apache.flink.runtime.minicluster.MiniCluster - Shutting down Flink Mini Cluster
2021-04-15 16:42:10,513 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Job 3faa797a88435b0ef0677b9294a4ce7c reached globally terminal state FINISHED.
2021-04-15 16:42:10,513 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Shutting down rest endpoint.
2021-04-15 16:42:10,514 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Stopping TaskExecutor akka://flink/user/rpc/taskmanager_0.
2021-04-15 16:42:10,514 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Close ResourceManager connection 8cce6b975b0f95c142096ee1040d9aaa.
org.apache.flink.util.FlinkException: The TaskExecutor is shutting down.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:424) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:214) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:563) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:186) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 16:42:10,515 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Closing TaskExecutor connection 0e8cf66e-9f5e-4007-a2c2-5069242a0468 because: The TaskExecutor is shutting down.
2021-04-15 16:42:10,515 DEBUG o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Unregister TaskManager 5d75443d3996fd611e2245b958ea7d56 from the SlotManager.
2021-04-15 16:42:10,515 DEBUG o.a.f.r.i.n.p.ResourceManagerPartitionTrackerImpl - Processing shutdown of task executor 0e8cf66e-9f5e-4007-a2c2-5069242a0468.
2021-04-15 16:42:10,519 INFO org.apache.flink.runtime.jobmaster.JobMaster - Stopping the JobMaster for job Flink Streaming Job(3faa797a88435b0ef0677b9294a4ce7c).
2021-04-15 16:42:10,519 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Close JobManager connection for job 3faa797a88435b0ef0677b9294a4ce7c.
org.apache.flink.util.FlinkException: The TaskExecutor is shutting down.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:424) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:214) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:563) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:186) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 16:42:10,523 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Disconnect TaskExecutor 0e8cf66e-9f5e-4007-a2c2-5069242a0468 because: Stopping JobMaster for job Flink Streaming Job(3faa797a88435b0ef0677b9294a4ce7c).
2021-04-15 16:42:10,522 DEBUG o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Free slot TaskSlot(index:0, state:ALLOCATED, resource profile: ResourceProfile{managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}, allocationId: e008f7508b8d125944a51f400364fa60, jobId: 3faa797a88435b0ef0677b9294a4ce7c).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:169) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:441) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:214) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:563) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:186) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 16:42:10,523 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Suspending SlotPool.
2021-04-15 16:42:10,530 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Close ResourceManager connection 8cce6b975b0f95c142096ee1040d9aaa.
org.apache.flink.util.FlinkException: Stopping JobMaster for job Flink Streaming Job(3faa797a88435b0ef0677b9294a4ce7c).
	at org.apache.flink.runtime.jobmaster.JobMaster.onStop(JobMaster.java:416) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:214) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:563) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:186) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 16:42:10,531 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Stopping SlotPool.
2021-04-15 16:42:10,534 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Disconnect job manager a927ba8199e461cd59eb5d4568a14ddb@akka://flink/user/rpc/jobmanager_3 for job 3faa797a88435b0ef0677b9294a4ce7c from the resource manager.
2021-04-15 16:42:10,552 DEBUG org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor - The RpcEndpoint jobmanager_3 terminated successfully.
2021-04-15 16:42:10,554 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Free slot with allocation id e008f7508b8d125944a51f400364fa60 because: Stopping JobMaster for job Flink Streaming Job(3faa797a88435b0ef0677b9294a4ce7c).
2021-04-15 16:42:10,556 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Could not free slot for allocation id e008f7508b8d125944a51f400364fa60.
org.apache.flink.runtime.taskexecutor.slot.SlotNotFoundException: Could not find slot for e008f7508b8d125944a51f400364fa60.
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.freeSlot(TaskSlotTableImpl.java:409) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlotInternal(TaskExecutor.java:1798) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlot(TaskExecutor.java:1105) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:566) ~[na:na]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:305) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:212) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:158) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 16:42:10,556 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Releasing local state under allocation id e008f7508b8d125944a51f400364fa60.
2021-04-15 16:42:10,577 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - AkkaRpcActor akka://flink/user/rpc/jobmanager_3 has terminated.
2021-04-15 16:42:10,578 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Stop job leader service.
2021-04-15 16:42:10,578 INFO o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Shutting down TaskExecutorLocalStateStoresManager.
2021-04-15 16:42:10,578 DEBUG org.apache.flink.runtime.io.disk.iomanager.IOManager - Shutting down I/O manager.
2021-04-15 16:42:10,582 DEBUG o.a.flink.runtime.resourcemanager.JobLeaderIdService - Found a new job leader null@null.
2021-04-15 16:42:10,583 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Discard job leader lost leadership for outdated leader a927ba8199e461cd59eb5d4568a14ddb for job 3faa797a88435b0ef0677b9294a4ce7c.
2021-04-15 16:42:10,587 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Removing cache directory C:\Users\ccy\AppData\Local\Temp\flink-web-ui
2021-04-15 16:42:10,587 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Shut down complete.
2021-04-15 16:42:10,587 INFO org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager removed spill file directory C:\Users\ccy\AppData\Local\Temp\flink-io-415d0b00-2748-42de-b954-b4e19fb54776
2021-04-15 16:42:10,588 INFO o.a.flink.runtime.io.network.NettyShuffleEnvironment - Shutting down the network environment and its components.
2021-04-15 16:42:10,588 DEBUG o.a.flink.runtime.io.network.NettyShuffleEnvironment - Shutting down network connection manager
2021-04-15 16:42:10,588 DEBUG o.a.flink.runtime.io.network.NettyShuffleEnvironment - Shutting down intermediate result partition manager
2021-04-15 16:42:10,589 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Releasing 0 partitions because of shutdown.
2021-04-15 16:42:10,589 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Successful shutdown.
2021-04-15 16:42:10,593 INFO org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager removed spill file directory C:\Users\ccy\AppData\Local\Temp\flink-netty-shuffle-e1981eed-e920-4a35-a7c1-b7c53850034c
2021-04-15 16:42:10,593 INFO org.apache.flink.runtime.taskexecutor.KvStateService - Shutting down the kvState service and its components.
2021-04-15 16:42:10,593 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Stop job leader service.
2021-04-15 16:42:10,596 INFO org.apache.flink.runtime.filecache.FileCache - removed file cache directory C:\Users\ccy\AppData\Local\Temp\flink-dist-cache-d076b5c5-e939-4ba7-9de0-a727be8b5d0a
2021-04-15 16:42:10,598 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Stopped TaskExecutor akka://flink/user/rpc/taskmanager_0.
2021-04-15 16:42:10,598 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcActor - The RpcEndpoint taskmanager_0 terminated successfully.
2021-04-15 16:42:10,599 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - AkkaRpcActor akka://flink/user/rpc/taskmanager_0 has terminated.
2021-04-15 16:42:10,601 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..
2021-04-15 16:42:10,602 INFO o.a.f.r.e.component.DispatcherResourceManagerComponent - Closing components.
2021-04-15 16:42:10,603 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Stopping SessionDispatcherLeaderProcess.
2021-04-15 16:42:10,603 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Stopping dispatcher akka://flink/user/rpc/dispatcher_2.
2021-04-15 16:42:10,603 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Stopping all currently running jobs of dispatcher akka://flink/user/rpc/dispatcher_2.
2021-04-15 16:42:10,604 INFO o.a.f.r.r.h.l.b.BackPressureRequestCoordinator - Shutting down back pressure request coordinator.
2021-04-15 16:42:10,605 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Stopped dispatcher akka://flink/user/rpc/dispatcher_2.
2021-04-15 16:42:10,605 DEBUG org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor - The RpcEndpoint dispatcher_2 terminated successfully.
2021-04-15 16:42:10,606 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - AkkaRpcActor akka://flink/user/rpc/dispatcher_2 has terminated.
2021-04-15 16:42:10,609 INFO o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Closing the SlotManager.
2021-04-15 16:42:10,609 INFO o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Suspending the SlotManager.
2021-04-15 16:42:10,610 DEBUG org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor - The RpcEndpoint resourcemanager_1 terminated successfully.
2021-04-15 16:42:10,610 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - AkkaRpcActor akka://flink/user/rpc/resourcemanager_1 has terminated.
2021-04-15 16:42:10,613 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Stopping Akka RPC service.
2021-04-15 16:42:10,620 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcActor - The RpcEndpoint MetricQueryService terminated successfully.
2021-04-15 16:42:10,623 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - AkkaRpcActor akka://flink-metrics/user/rpc/MetricQueryService has terminated.
2021-04-15 16:42:10,633 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Stopping supervisor actor.
2021-04-15 16:42:10,670 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Stopping Akka RPC service.
2021-04-15 16:42:10,671 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Stopped Akka RPC service.
2021-04-15 16:42:10,671 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Stopping supervisor actor.
2021-04-15 16:42:10,673 DEBUG akka.event.EventStream - shutting down: StandardOutLogger
2021-04-15 16:42:10,681 INFO org.apache.flink.runtime.blob.PermanentBlobCache - Shutting down BLOB cache
2021-04-15 16:42:10,683 INFO org.apache.flink.runtime.blob.TransientBlobCache - Shutting down BLOB cache
2021-04-15 16:42:10,687 INFO org.apache.flink.runtime.blob.BlobServer - Stopped BLOB server at 0.0.0.0:60745
2021-04-15 16:42:10,687 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Stopped Akka RPC service.
2021-04-15 17:19:53,059 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:19:53,064 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.util.Random
2021-04-15 17:19:53,170 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.java.typeutils.runtime.PojoComparator
2021-04-15 17:19:53,172 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:19:53,172 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [Ljava.lang.Object;
2021-04-15 17:19:53,216 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.java.typeutils.runtime.PojoComparator
2021-04-15 17:19:53,217 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:19:53,217 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [Ljava.lang.Object;
2021-04-15 17:19:53,251 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.java.typeutils.runtime.PojoComparator
2021-04-15 17:19:53,251 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:19:53,251 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [Ljava.lang.Object;
2021-04-15 17:19:53,253 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.java.typeutils.runtime.PojoComparator
2021-04-15 17:19:53,253 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:19:53,253 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [Ljava.lang.Object;
2021-04-15 17:28:52,567 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:28:52,573 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.util.Random
2021-04-15 17:28:52,715 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.java.typeutils.runtime.PojoComparator
2021-04-15 17:28:52,717 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:28:52,718 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [Ljava.lang.Object;
2021-04-15 17:28:52,806 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.java.typeutils.runtime.PojoComparator
2021-04-15 17:28:52,807 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:28:52,808 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [Ljava.lang.Object;
2021-04-15 17:28:52,874 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
2021-04-15 17:28:52,875 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:28:52,875 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:28:52,877 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:28:52,878 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:28:52,879 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:28:52,893 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.java.typeutils.runtime.PojoComparator
2021-04-15 17:28:52,893 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:28:52,893 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [Ljava.lang.Object;
2021-04-15 17:28:52,895 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.java.typeutils.runtime.PojoComparator
2021-04-15 17:28:52,895 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:28:52,895 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [Ljava.lang.Object;
2021-04-15 17:28:52,937 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.streaming.util.typeutils.FieldAccessor$PojoFieldAccessor
2021-04-15 17:28:52,938 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.streaming.api.functions.aggregation.SumFunction$DoubleSum
2021-04-15 17:28:52,940 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.java.typeutils.runtime.PojoSerializer
2021-04-15 17:28:52,940 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:28:52,946 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.streaming.util.typeutils.FieldAccessor$PojoFieldAccessor
2021-04-15 17:28:52,947 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.streaming.api.functions.aggregation.SumFunction$DoubleSum
2021-04-15 17:28:52,947 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.java.typeutils.runtime.PojoSerializer
2021-04-15 17:28:52,947 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:28:52,949 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
2021-04-15 17:28:52,950 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:28:52,950 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:28:52,950 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:28:52,950 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:28:52,950 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:28:52,980 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=3, name='Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction)', outputType=Integer, parallelism=4}
2021-04-15 17:28:52,984 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming PartitionTransformation{id=2, name='Partition', outputType=PojoType<org.myorg.quickstart.dto.SensorReading, fields = [id: String, temperature: Double, timestamp: Long]>, parallelism=1}
2021-04-15 17:28:52,985 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySourceTransformation{id=1, name='sensor', outputType=PojoType<org.myorg.quickstart.dto.SensorReading, fields = [id: String, temperature: Double, timestamp: Long]>, parallelism=1}
2021-04-15 17:28:52,993 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 1
2021-04-15 17:28:52,995 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 3
2021-04-15 17:28:52,996 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySinkTransformation{id=4, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=4}
2021-04-15 17:28:52,996 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 4
2021-04-15 17:28:52,996 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=6, name='Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction)', outputType=PojoType<org.myorg.quickstart.dto.SensorReading, fields = [id: String, temperature: Double, timestamp: Long]>, parallelism=4}
2021-04-15 17:28:52,997 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming PartitionTransformation{id=5, name='Partition', outputType=PojoType<org.myorg.quickstart.dto.SensorReading, fields = [id: String, temperature: Double, timestamp: Long]>, parallelism=1}
2021-04-15 17:28:52,997 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 6
2021-04-15 17:28:52,997 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySinkTransformation{id=8, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=4}
2021-04-15 17:28:52,997 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming SideOutputTransformation{id=7, name='SideOutput', outputType=PojoType<org.myorg.quickstart.dto.SensorReading, fields = [id: String, temperature: Double, timestamp: Long]>, parallelism=4}
2021-04-15 17:28:52,997 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 8
2021-04-15 17:28:53,065 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'bc764cd8ddf7a0cff126f51c16239658' for node 'Source: sensor-1' {id: 1, parallelism: 1, user function: org.myorg.quickstart.util.SourceUtil}
2021-04-15 17:28:53,065 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '20ba6b65f97481d5570070de90e4e791' for node 'Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction)-3' {id: 3, parallelism: 4, user function: org.apache.flink.streaming.runtime.operators.windowing.functions.InternalSingleValueWindowFunction}
2021-04-15 17:28:53,065 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '51397532e2d9c7a21097a30d590b3114' for node 'Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction)-6' {id: 6, parallelism: 4, user function: org.apache.flink.streaming.runtime.operators.windowing.functions.InternalSingleValueWindowFunction}
2021-04-15 17:28:53,065 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'a7ff31a2a262e9bd1fe62e920ca466b3' for node 'Sink: Print to Std. Out-4' {id: 4, parallelism: 4, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
2021-04-15 17:28:53,065 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'e1aa9a3f1b74e8aee21b292597024e03' for node 'Sink: Print to Std. Out-8' {id: 8, parallelism: 4, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
2021-04-15 17:28:53,132 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 4 for 3
2021-04-15 17:28:53,172 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 4 for 6
2021-04-15 17:28:53,178 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 1
2021-04-15 17:28:53,190 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - CONNECTED: KeyGroupStreamPartitioner - 1 -> 3
2021-04-15 17:28:53,190 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - CONNECTED: KeyGroupStreamPartitioner - 1 -> 6
2021-04-15 17:28:53,252 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.
2021-04-15 17:28:53,253 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.
2021-04-15 17:28:53,253 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.
2021-04-15 17:28:53,254 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.min required for local execution is not set, setting it to its default value 64 mb.
2021-04-15 17:28:53,255 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.max required for local execution is not set, setting it to its default value 64 mb.
2021-04-15 17:28:53,255 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.
2021-04-15 17:28:53,297 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting Flink Mini Cluster
2021-04-15 17:28:53,298 DEBUG org.apache.flink.runtime.minicluster.MiniCluster - Using configuration MiniClusterConfiguration {singleRpcService=SHARED, numTaskManagers=1, commonBindAddress='null', config={taskmanager.memory.network.min=64 mb, taskmanager.cpu.cores=1.7976931348623157E308, taskmanager.memory.task.off-heap.size=9223372036854775807 bytes, execution.target=local, rest.bind-port=0, taskmanager.memory.network.max=64 mb, execution.attached=true, taskmanager.memory.managed.size=128 mb, parallelism.default=4, taskmanager.numberOfTaskSlots=4, taskmanager.memory.task.heap.size=9223372036854775807 bytes, rest.address=localhost}}
2021-04-15 17:28:53,302 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting Metrics Registry
2021-04-15 17:28:53,388 INFO org.apache.flink.runtime.metrics.MetricRegistryImpl - No metrics reporter configured, no metrics will be exposed/reported.
2021-04-15 17:28:53,388 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting RPC Service(s)
2021-04-15 17:28:53,684 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
2021-04-15 17:28:53,692 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Using akka configuration
 Config(SimpleConfigObject({"akka":{"actor":{"default-dispatcher":{"executor":"fork-join-executor","fork-join-executor":{"parallelism-factor":1,"parallelism-max":4,"parallelism-min":2},"throughput":15},"guardian-supervisor-strategy":"org.apache.flink.runtime.akka.EscalatingSupervisorStrategy","supervisor-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"type":"Dispatcher"},"warn-about-java-serializer-usage":"off"},"daemonic":"off","jvm-exit-on-fatal-error":"on","log-config-on-start":"off","log-dead-letters":"off","log-dead-letters-during-shutdown":"off","logger-startup-timeout":"30s","loggers":["akka.event.slf4j.Slf4jLogger"],"logging-filter":"akka.event.slf4j.Slf4jLoggingFilter","loglevel":"DEBUG","serialize-messages":"off","stdout-loglevel":"OFF"}}))
2021-04-15 17:28:54,552 INFO akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2021-04-15 17:28:54,581 DEBUG akka.event.EventStream - logger log1-Slf4jLogger started
2021-04-15 17:28:54,588 DEBUG akka.event.EventStream - Default Loggers started
2021-04-15 17:28:55,244 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink
2021-04-15 17:28:55,273 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
2021-04-15 17:28:55,275 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Using akka configuration
 Config(SimpleConfigObject({"akka":{"actor":{"default-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"thread-priority":1,"throughput":15,"type":"akka.dispatch.PriorityThreadsDispatcher"},"guardian-supervisor-strategy":"org.apache.flink.runtime.akka.EscalatingSupervisorStrategy","supervisor-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"type":"Dispatcher"},"warn-about-java-serializer-usage":"off"},"daemonic":"off","jvm-exit-on-fatal-error":"on","log-config-on-start":"off","log-dead-letters":"off","log-dead-letters-during-shutdown":"off","logger-startup-timeout":"30s","loggers":["akka.event.slf4j.Slf4jLogger"],"logging-filter":"akka.event.slf4j.Slf4jLoggingFilter","loglevel":"DEBUG","serialize-messages":"off","stdout-loglevel":"OFF"}}))
2021-04-15 17:28:55,311 INFO akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2021-04-15 17:28:55,395 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink-metrics
2021-04-15 17:28:55,401 DEBUG akka.event.EventStream - logger log1-Slf4jLogger started
2021-04-15 17:28:55,402 DEBUG akka.event.EventStream - Default Loggers started
2021-04-15 17:28:55,420 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting AkkaRpcActor with name MetricQueryService.
2021-04-15 17:28:55,428 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
2021-04-15 17:28:55,687 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting high-availability services
2021-04-15 17:28:56,460 INFO org.apache.flink.runtime.blob.BlobServer - Created BLOB server storage directory C:\Users\ccy\AppData\Local\Temp\blobStore-e957eeb3-27ba-4556-b955-8427663cbdc6
2021-04-15 17:28:56,469 DEBUG org.apache.flink.util.NetUtils - Trying to open socket on port 0
2021-04-15 17:28:56,472 INFO org.apache.flink.runtime.blob.BlobServer - Started BLOB server at 0.0.0.0:61582 - max concurrent requests: 50 - max backlog: 1000
2021-04-15 17:28:56,477 INFO org.apache.flink.runtime.blob.PermanentBlobCache - Created BLOB cache storage directory C:\Users\ccy\AppData\Local\Temp\blobStore-3bfd06c3-40ed-4d01-acb1-35dc901abfef
2021-04-15 17:28:56,480 INFO org.apache.flink.runtime.blob.TransientBlobCache - Created BLOB cache storage directory C:\Users\ccy\AppData\Local\Temp\blobStore-5d965b9c-b223-4929-91c5-d8ce50c0ee6a
2021-04-15 17:28:56,481 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting 1 TaskManger(s)
2021-04-15 17:28:56,487 INFO org.apache.flink.runtime.taskexecutor.TaskManagerRunner - Starting TaskManager with ResourceID: ef6044cc-9b73-466f-adb2-51c3fede0ecb
2021-04-15 17:28:56,526 INFO o.apache.flink.runtime.taskexecutor.TaskManagerServices - Temporary file directory 'C:\Users\ccy\AppData\Local\Temp': total 137 GB, usable 24 GB (17.52% usable)
2021-04-15 17:28:56,532 INFO org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\ccy\AppData\Local\Temp\flink-io-ba4ad1b3-43e0-481a-8e0d-6343ad3178b4 for spill files.
2021-04-15 17:28:56,541 INFO org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\ccy\AppData\Local\Temp\flink-netty-shuffle-3f62f909-24a2-4d5a-953f-536d5cbab833 for spill files.
2021-04-15 17:28:56,589 INFO o.a.flink.runtime.io.network.buffer.NetworkBufferPool - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2021-04-15 17:28:56,605 INFO o.a.flink.runtime.io.network.NettyShuffleEnvironment - Starting the network environment and its components.
2021-04-15 17:28:56,605 DEBUG o.a.flink.runtime.io.network.NettyShuffleEnvironment - Starting network connection manager
2021-04-15 17:28:56,607 INFO org.apache.flink.runtime.taskexecutor.KvStateService - Starting the kvState service and its components.
2021-04-15 17:28:56,621 DEBUG o.a.flink.runtime.taskexecutor.TaskManagerConfiguration - Messages have a max timeout of 10000 ms
2021-04-15 17:28:56,634 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting AkkaRpcActor with name taskmanager_0.
2021-04-15 17:28:56,635 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2021-04-15 17:28:56,650 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Start job leader service.
2021-04-15 17:28:56,652 INFO org.apache.flink.runtime.filecache.FileCache - User file cache uses directory C:\Users\ccy\AppData\Local\Temp\flink-dist-cache-09a4c3bd-7ec2-40f4-8d91-ba56e1dd077f
2021-04-15 17:28:56,719 DEBUG o.a.f.r.e.c.DefaultDispatcherResourceManagerComponentFactory - Starting Dispatcher REST endpoint.
2021-04-15 17:28:56,719 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Starting rest endpoint.
2021-04-15 17:28:56,732 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Failed to load web based job submission extension.
org.apache.flink.util.FlinkException: The module flink-runtime-web could not be found in the class path. Please add this jar in order to enable web based job submission.
	at org.apache.flink.runtime.webmonitor.WebMonitorUtils.loadWebSubmissionExtension(WebMonitorUtils.java:199) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint.initializeWebSubmissionHandlers(DispatcherRestEndpoint.java:112) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.webmonitor.WebMonitorEndpoint.initializeHandlers(WebMonitorEndpoint.java:228) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint.initializeHandlers(DispatcherRestEndpoint.java:89) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:144) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:172) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:463) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:422) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:366) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.program.PerJobMiniClusterFactory.submitJob(PerJobMiniClusterFactory.java:75) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:85) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1905) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1796) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:69) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1782) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1765) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.myorg.quickstart.other.EWindow.Window1.main(Window1.java:81) ~[classes/:na]
2021-04-15 17:28:56,981 DEBUG o.a.f.s.n.i.n.u.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
2021-04-15 17:28:56,981 DEBUG o.a.f.s.n.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2021-04-15 17:28:56,982 DEBUG o.a.f.s.n.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2021-04-15 17:28:57,073 WARN org.apache.flink.runtime.webmonitor.WebMonitorUtils - Log file environment variable 'log.file' is not set.
2021-04-15 17:28:57,073 WARN org.apache.flink.runtime.webmonitor.WebMonitorUtils - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'web.log.path'.
2021-04-15 17:28:57,111 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - Platform: Windows
2021-04-15 17:28:57,114 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
2021-04-15 17:28:57,114 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - Java version: 11
2021-04-15 17:28:57,115 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
2021-04-15 17:28:57,116 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
2021-04-15 17:28:57,117 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
2021-04-15 17:28:57,118 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: unavailable
java.lang.UnsupportedOperationException: Reflective setAccessible(true) disabled
	at org.apache.flink.shaded.netty4.io.netty.util.internal.ReflectionUtil.trySetAccessible(ReflectionUtil.java:31) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0$4.run(PlatformDependent0.java:233) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at java.base/java.security.AccessController.doPrivileged(Native Method) ~[na:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:227) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.isAndroid(PlatformDependent.java:289) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:92) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:223) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:210) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.cached(AsciiString.java:1401) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<clinit>(AsciiString.java:48) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<init>(HttpMethod.java:135) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<clinit>(HttpMethod.java:36) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.runtime.rest.HttpMethodWrapper.<clinit>(HttpMethodWrapper.java:27) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.messages.cluster.ShutdownHeaders.getHttpMethod(ShutdownHeaders.java:57) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.checkAllEndpointsAndHandlersAreUnique(RestServerEndpoint.java:572) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:155) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:172) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:463) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:422) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:366) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.program.PerJobMiniClusterFactory.submitJob(PerJobMiniClusterFactory.java:75) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:85) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1905) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1796) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:69) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1782) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1765) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.myorg.quickstart.other.EWindow.Window1.main(Window1.java:81) ~[classes/:na]
2021-04-15 17:28:57,119 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
2021-04-15 17:28:57,120 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable
java.lang.IllegalAccessException: class org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0$6 cannot access class jdk.internal.misc.Unsafe (in module java.base) because module java.base does not export jdk.internal.misc to unnamed module @127a7a2e
	at java.base/jdk.internal.reflect.Reflection.newIllegalAccessException(Reflection.java:361) ~[na:na]
	at java.base/java.lang.reflect.AccessibleObject.checkAccess(AccessibleObject.java:591) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:558) ~[na:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0$6.run(PlatformDependent0.java:347) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at java.base/java.security.AccessController.doPrivileged(Native Method) ~[na:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:338) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.isAndroid(PlatformDependent.java:289) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:92) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:223) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:210) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.cached(AsciiString.java:1401) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<clinit>(AsciiString.java:48) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<init>(HttpMethod.java:135) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<clinit>(HttpMethod.java:36) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.runtime.rest.HttpMethodWrapper.<clinit>(HttpMethodWrapper.java:27) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.messages.cluster.ShutdownHeaders.getHttpMethod(ShutdownHeaders.java:57) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.checkAllEndpointsAndHandlersAreUnique(RestServerEndpoint.java:572) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:155) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:172) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:463) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:422) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:366) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.program.PerJobMiniClusterFactory.submitJob(PerJobMiniClusterFactory.java:75) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:85) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1905) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1796) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:69) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1782) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1765) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.myorg.quickstart.other.EWindow.Window1.main(Window1.java:81) ~[classes/:na]
2021-04-15 17:28:57,121 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): unavailable
2021-04-15 17:28:57,121 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
2021-04-15 17:28:57,122 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - maxDirectMemory: 2122317824 bytes (maybe)
2021-04-15 17:28:57,122 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\ccy\AppData\Local\Temp (java.io.tmpdir)
2021-04-15 17:28:57,122 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
2021-04-15 17:28:57,124 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: -1 bytes
2021-04-15 17:28:57,124 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
2021-04-15 17:28:57,125 DEBUG o.a.f.shaded.netty4.io.netty.util.internal.CleanerJava9 - java.nio.ByteBuffer.cleaner(): available
2021-04-15 17:28:57,126 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
2021-04-15 17:28:57,131 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@1e12a5a6 under DELETE@/v1/cluster.
2021-04-15 17:28:57,132 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@1e12a5a6 under DELETE@/cluster.
2021-04-15 17:28:57,132 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@195580ba under GET@/v1/config.
2021-04-15 17:28:57,132 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@195580ba under GET@/config.
2021-04-15 17:28:57,132 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetListHandler@3c25cfe1 under GET@/v1/datasets.
2021-04-15 17:28:57,132 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetListHandler@3c25cfe1 under GET@/datasets.
2021-04-15 17:28:57,132 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteStatusHandler@1d3c112a under GET@/v1/datasets/delete/:triggerid.
2021-04-15 17:28:57,132 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteStatusHandler@1d3c112a under GET@/datasets/delete/:triggerid.
2021-04-15 17:28:57,132 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteTriggerHandler@2a140ce5 under DELETE@/v1/datasets/:datasetid.
2021-04-15 17:28:57,133 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteTriggerHandler@2a140ce5 under DELETE@/datasets/:datasetid.
2021-04-15 17:28:57,133 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@1f71194d under GET@/v1/jobmanager/config.
2021-04-15 17:28:57,133 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@1f71194d under GET@/jobmanager/config.
2021-04-15 17:28:57,133 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@db99785 under GET@/v1/jobmanager/log.
2021-04-15 17:28:57,133 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@db99785 under GET@/jobmanager/log.
2021-04-15 17:28:57,133 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogListHandler@70716259 under GET@/v1/jobmanager/logs.
2021-04-15 17:28:57,133 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogListHandler@70716259 under GET@/jobmanager/logs.
2021-04-15 17:28:57,133 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerCustomLogHandler@7a083b96 under GET@/v1/jobmanager/logs/:filename.
2021-04-15 17:28:57,133 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerCustomLogHandler@7a083b96 under GET@/jobmanager/logs/:filename.
2021-04-15 17:28:57,133 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@6da4feeb under GET@/v1/jobmanager/metrics.
2021-04-15 17:28:57,133 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@6da4feeb under GET@/jobmanager/metrics.
2021-04-15 17:28:57,133 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@2c604965 under GET@/v1/jobmanager/stdout.
2021-04-15 17:28:57,133 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@2c604965 under GET@/jobmanager/stdout.
2021-04-15 17:28:57,133 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@57f8951a under GET@/v1/jobs.
2021-04-15 17:28:57,133 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@57f8951a under GET@/jobs.
2021-04-15 17:28:57,133 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@6c17c0f8 under POST@/v1/jobs.
2021-04-15 17:28:57,133 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@6c17c0f8 under POST@/jobs.
2021-04-15 17:28:57,133 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@260e3837 under GET@/v1/jobs/metrics.
2021-04-15 17:28:57,133 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@260e3837 under GET@/jobs/metrics.
2021-04-15 17:28:57,134 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@88b76f2 under GET@/v1/jobs/overview.
2021-04-15 17:28:57,134 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@88b76f2 under GET@/jobs/overview.
2021-04-15 17:28:57,134 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@1b4872bc under GET@/v1/jobs/:jobid.
2021-04-15 17:28:57,134 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@1b4872bc under GET@/jobs/:jobid.
2021-04-15 17:28:57,134 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@498a612d under PATCH@/v1/jobs/:jobid.
2021-04-15 17:28:57,134 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@498a612d under PATCH@/jobs/:jobid.
2021-04-15 17:28:57,134 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@1e1237ab under GET@/v1/jobs/:jobid/accumulators.
2021-04-15 17:28:57,134 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@1e1237ab under GET@/jobs/:jobid/accumulators.
2021-04-15 17:28:57,134 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@4dfdfe7d under GET@/v1/jobs/:jobid/checkpoints.
2021-04-15 17:28:57,134 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@4dfdfe7d under GET@/jobs/:jobid/checkpoints.
2021-04-15 17:28:57,134 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@1578b8ec under GET@/v1/jobs/:jobid/checkpoints/config.
2021-04-15 17:28:57,135 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@1578b8ec under GET@/jobs/:jobid/checkpoints/config.
2021-04-15 17:28:57,135 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@f613067 under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid.
2021-04-15 17:28:57,135 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@f613067 under GET@/jobs/:jobid/checkpoints/details/:checkpointid.
2021-04-15 17:28:57,135 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@c1e14f under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
2021-04-15 17:28:57,135 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@c1e14f under GET@/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
2021-04-15 17:28:57,135 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@226de93c under GET@/v1/jobs/:jobid/config.
2021-04-15 17:28:57,135 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@226de93c under GET@/jobs/:jobid/config.
2021-04-15 17:28:57,135 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.coordination.ClientCoordinationHandler@72028a45 under POST@/v1/jobs/:jobid/coordinators/:operatorid.
2021-04-15 17:28:57,135 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.coordination.ClientCoordinationHandler@72028a45 under POST@/jobs/:jobid/coordinators/:operatorid.
2021-04-15 17:28:57,135 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@74667e6a under GET@/v1/jobs/:jobid/exceptions.
2021-04-15 17:28:57,136 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@74667e6a under GET@/jobs/:jobid/exceptions.
2021-04-15 17:28:57,136 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@7b222230 under GET@/v1/jobs/:jobid/execution-result.
2021-04-15 17:28:57,136 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@7b222230 under GET@/jobs/:jobid/execution-result.
2021-04-15 17:28:57,136 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@364b1061 under GET@/v1/jobs/:jobid/metrics.
2021-04-15 17:28:57,136 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@364b1061 under GET@/jobs/:jobid/metrics.
2021-04-15 17:28:57,136 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@50fdf44f under GET@/v1/jobs/:jobid/plan.
2021-04-15 17:28:57,136 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@50fdf44f under GET@/jobs/:jobid/plan.
2021-04-15 17:28:57,136 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@172f4514 under PATCH@/v1/jobs/:jobid/rescaling.
2021-04-15 17:28:57,136 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@172f4514 under PATCH@/jobs/:jobid/rescaling.
2021-04-15 17:28:57,136 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@7df6d663 under GET@/v1/jobs/:jobid/rescaling/:triggerid.
2021-04-15 17:28:57,136 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@7df6d663 under GET@/jobs/:jobid/rescaling/:triggerid.
2021-04-15 17:28:57,137 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@13d019a4 under POST@/v1/jobs/:jobid/savepoints.
2021-04-15 17:28:57,137 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@13d019a4 under POST@/jobs/:jobid/savepoints.
2021-04-15 17:28:57,137 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@2c30c81d under GET@/v1/jobs/:jobid/savepoints/:triggerid.
2021-04-15 17:28:57,137 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@2c30c81d under GET@/jobs/:jobid/savepoints/:triggerid.
2021-04-15 17:28:57,137 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@415a3f6a under POST@/v1/jobs/:jobid/stop.
2021-04-15 17:28:57,137 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@415a3f6a under POST@/jobs/:jobid/stop.
2021-04-15 17:28:57,137 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@a54acec under GET@/v1/jobs/:jobid/vertices/:vertexid.
2021-04-15 17:28:57,137 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@a54acec under GET@/jobs/:jobid/vertices/:vertexid.
2021-04-15 17:28:57,137 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@19da993b under GET@/v1/jobs/:jobid/vertices/:vertexid/accumulators.
2021-04-15 17:28:57,137 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@19da993b under GET@/jobs/:jobid/vertices/:vertexid/accumulators.
2021-04-15 17:28:57,137 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@3380ca3d under GET@/v1/jobs/:jobid/vertices/:vertexid/backpressure.
2021-04-15 17:28:57,137 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@3380ca3d under GET@/jobs/:jobid/vertices/:vertexid/backpressure.
2021-04-15 17:28:57,137 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@23310248 under GET@/v1/jobs/:jobid/vertices/:vertexid/metrics.
2021-04-15 17:28:57,138 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@23310248 under GET@/jobs/:jobid/vertices/:vertexid/metrics.
2021-04-15 17:28:57,138 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@c2df90e under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
2021-04-15 17:28:57,138 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@c2df90e under GET@/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
2021-04-15 17:28:57,138 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@41f3aaf1 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
2021-04-15 17:28:57,138 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@41f3aaf1 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
2021-04-15 17:28:57,138 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@741741d0 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
2021-04-15 17:28:57,138 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@741741d0 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
2021-04-15 17:28:57,138 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@5f9f3e58 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
2021-04-15 17:28:57,138 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@5f9f3e58 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
2021-04-15 17:28:57,138 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@3c19592c under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
2021-04-15 17:28:57,138 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@3c19592c under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
2021-04-15 17:28:57,138 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@60e1d87c under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
2021-04-15 17:28:57,138 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@60e1d87c under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
2021-04-15 17:28:57,139 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@2eb60c71 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasktimes.
2021-04-15 17:28:57,139 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@2eb60c71 under GET@/jobs/:jobid/vertices/:vertexid/subtasktimes.
2021-04-15 17:28:57,139 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@87d9a01 under GET@/v1/jobs/:jobid/vertices/:vertexid/taskmanagers.
2021-04-15 17:28:57,139 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@87d9a01 under GET@/jobs/:jobid/vertices/:vertexid/taskmanagers.
2021-04-15 17:28:57,139 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@7e5b621b under GET@/v1/jobs/:jobid/vertices/:vertexid/watermarks.
2021-04-15 17:28:57,139 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@7e5b621b under GET@/jobs/:jobid/vertices/:vertexid/watermarks.
2021-04-15 17:28:57,139 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@10177794 under GET@/v1/jobs/:jobid/yarn-cancel.
2021-04-15 17:28:57,139 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@10177794 under GET@/jobs/:jobid/yarn-cancel.
2021-04-15 17:28:57,139 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@e5c2463 under GET@/v1/jobs/:jobid/yarn-stop.
2021-04-15 17:28:57,139 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@e5c2463 under GET@/jobs/:jobid/yarn-stop.
2021-04-15 17:28:57,139 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@6a950a3b under GET@/v1/overview.
2021-04-15 17:28:57,139 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@6a950a3b under GET@/overview.
2021-04-15 17:28:57,140 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@4f7be6c8 under POST@/v1/savepoint-disposal.
2021-04-15 17:28:57,140 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@4f7be6c8 under POST@/savepoint-disposal.
2021-04-15 17:28:57,140 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@647b9364 under GET@/v1/savepoint-disposal/:triggerid.
2021-04-15 17:28:57,140 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@647b9364 under GET@/savepoint-disposal/:triggerid.
2021-04-15 17:28:57,140 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@b6bccb4 under GET@/v1/taskmanagers.
2021-04-15 17:28:57,140 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@b6bccb4 under GET@/taskmanagers.
2021-04-15 17:28:57,141 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@49edcb30 under GET@/v1/taskmanagers/metrics.
2021-04-15 17:28:57,141 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@49edcb30 under GET@/taskmanagers/metrics.
2021-04-15 17:28:57,141 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@59303963 under GET@/v1/taskmanagers/:taskmanagerid.
2021-04-15 17:28:57,141 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@59303963 under GET@/taskmanagers/:taskmanagerid.
2021-04-15 17:28:57,141 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@61e86192 under GET@/v1/taskmanagers/:taskmanagerid/log.
2021-04-15 17:28:57,141 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@61e86192 under GET@/taskmanagers/:taskmanagerid/log.
2021-04-15 17:28:57,141 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogListHandler@34330f77 under GET@/v1/taskmanagers/:taskmanagerid/logs.
2021-04-15 17:28:57,141 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogListHandler@34330f77 under GET@/taskmanagers/:taskmanagerid/logs.
2021-04-15 17:28:57,141 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerCustomLogHandler@1320e68a under GET@/v1/taskmanagers/:taskmanagerid/logs/:filename.
2021-04-15 17:28:57,141 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerCustomLogHandler@1320e68a under GET@/taskmanagers/:taskmanagerid/logs/:filename.
2021-04-15 17:28:57,141 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@4b033eac under GET@/v1/taskmanagers/:taskmanagerid/metrics.
2021-04-15 17:28:57,141 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@4b033eac under GET@/taskmanagers/:taskmanagerid/metrics.
2021-04-15 17:28:57,142 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@69c532af under GET@/v1/taskmanagers/:taskmanagerid/stdout.
2021-04-15 17:28:57,142 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@69c532af under GET@/taskmanagers/:taskmanagerid/stdout.
2021-04-15 17:28:57,142 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerThreadDumpHandler@45a1d057 under GET@/v1/taskmanagers/:taskmanagerid/thread-dump.
2021-04-15 17:28:57,142 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerThreadDumpHandler@45a1d057 under GET@/taskmanagers/:taskmanagerid/thread-dump.
2021-04-15 17:28:57,151 DEBUG o.a.f.s.n.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 8
2021-04-15 17:28:57,181 DEBUG o.a.f.shaded.netty4.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
2021-04-15 17:28:57,181 DEBUG o.a.f.shaded.netty4.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
2021-04-15 17:28:57,190 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
2021-04-15 17:28:57,246 DEBUG o.a.f.shaded.netty4.io.netty.channel.DefaultChannelId - -Dio.netty.processId: 11044 (auto-detected)
2021-04-15 17:28:57,249 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
2021-04-15 17:28:57,249 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
2021-04-15 17:28:58,026 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
2021-04-15 17:28:58,027 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
2021-04-15 17:28:58,733 DEBUG o.a.f.shaded.netty4.io.netty.channel.DefaultChannelId - -Dio.netty.machineId: 2c:6f:c9:ff:fe:1c:21:83 (auto-detected)
2021-04-15 17:28:58,750 DEBUG o.a.f.shaded.netty4.io.netty.util.ResourceLeakDetector - -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.level: simple
2021-04-15 17:28:58,750 DEBUG o.a.f.shaded.netty4.io.netty.util.ResourceLeakDetector - -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.targetRecords: 4
2021-04-15 17:28:58,785 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 8
2021-04-15 17:28:58,785 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 8
2021-04-15 17:28:58,785 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
2021-04-15 17:28:58,785 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 11
2021-04-15 17:28:58,786 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 16777216
2021-04-15 17:28:58,786 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.tinyCacheSize: 512
2021-04-15 17:28:58,786 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
2021-04-15 17:28:58,786 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
2021-04-15 17:28:58,786 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2021-04-15 17:28:58,786 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
2021-04-15 17:28:58,786 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2021-04-15 17:28:58,786 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: true
2021-04-15 17:28:58,786 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2021-04-15 17:28:58,794 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
2021-04-15 17:28:58,795 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 0
2021-04-15 17:28:58,795 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
2021-04-15 17:28:58,809 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Binding rest endpoint to null:0.
2021-04-15 17:28:58,809 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Rest endpoint listening at localhost:61601
2021-04-15 17:28:58,811 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender http://localhost:61601
2021-04-15 17:28:58,815 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - http://localhost:61601 was granted leadership with leaderSessionID=c1fe49c1-7eea-4230-b5fb-6dbb4f11b4df
2021-04-15 17:28:58,815 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader http://localhost:61601 , session=c1fe49c1-7eea-4230-b5fb-6dbb4f11b4df
2021-04-15 17:28:58,833 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting FencedAkkaRpcActor with name resourcemanager_1.
2021-04-15 17:28:58,833 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_1 .
2021-04-15 17:28:58,849 DEBUG o.a.f.r.e.c.DefaultDispatcherResourceManagerComponentFactory - Starting Dispatcher.
2021-04-15 17:28:58,852 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
2021-04-15 17:28:58,853 DEBUG o.a.f.r.e.c.DefaultDispatcherResourceManagerComponentFactory - Starting ResourceManager.
2021-04-15 17:28:58,853 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: StandaloneResourceManager
2021-04-15 17:28:58,856 DEBUG o.a.f.runtime.dispatcher.runner.DefaultDispatcherRunner - Create new DispatcherLeaderProcess with leader session id 59fd287b-87cc-46ed-b047-62e85ff7fd11.
2021-04-15 17:28:58,859 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - ResourceManager akka://flink/user/rpc/resourcemanager_1 was granted leadership with fencing token ab7d8ac3598dccd6c7def97a7d8f4869
2021-04-15 17:28:58,868 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Start SessionDispatcherLeaderProcess.
2021-04-15 17:28:58,868 INFO o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Starting the SlotManager.
2021-04-15 17:28:58,870 INFO org.apache.flink.runtime.minicluster.MiniCluster - Flink Mini Cluster started successfully
2021-04-15 17:28:58,873 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:28:58,873 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:28:58,876 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/resourcemanager_1 , session=c7def97a-7d8f-4869-ab7d-8ac3598dccd6
2021-04-15 17:28:58,876 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Recover all persisted job graphs.
2021-04-15 17:28:58,877 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Successfully recovered 0 persisted job graphs.
2021-04-15 17:28:58,884 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:28:58,885 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(ab7d8ac3598dccd6c7def97a7d8f4869).
2021-04-15 17:28:58,887 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting FencedAkkaRpcActor with name dispatcher_2.
2021-04-15 17:28:58,887 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:28:58,891 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_2 .
2021-04-15 17:28:58,897 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:28:58,908 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/dispatcher_2 , session=59fd287b-87cc-46ed-b047-62e85ff7fd11
2021-04-15 17:28:58,910 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/dispatcher_2. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
2021-04-15 17:28:58,911 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/dispatcher_2. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
2021-04-15 17:28:58,914 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Resolved ResourceManager address, beginning registration
2021-04-15 17:28:58,915 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Registration at ResourceManager attempt 1 (timeout=100ms)
2021-04-15 17:28:58,918 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
2021-04-15 17:28:58,924 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Registering TaskManager with ResourceID ef6044cc-9b73-466f-adb2-51c3fede0ecb (akka://flink/user/rpc/taskmanager_0) at ResourceManager
2021-04-15 17:28:58,929 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Successful registration at resource manager akka://flink/user/rpc/resourcemanager_1 under registration id 6952b71a1cb3afec877a0dbde6f12488.
2021-04-15 17:28:58,933 DEBUG o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Registering TaskManager ef6044cc-9b73-466f-adb2-51c3fede0ecb under 6952b71a1cb3afec877a0dbde6f12488 at the SlotManager.
2021-04-15 17:28:58,938 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Received JobGraph submission d8718395ee2b28f55a0cfaf6a66b2e05 (Flink Streaming Job).
2021-04-15 17:28:58,938 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Submitting job d8718395ee2b28f55a0cfaf6a66b2e05 (Flink Streaming Job).
2021-04-15 17:28:58,958 DEBUG org.apache.flink.client.ClientUtils - Wait until job initialization is finished
2021-04-15 17:28:58,963 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: JobManagerRunnerImpl
2021-04-15 17:28:58,971 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting FencedAkkaRpcActor with name jobmanager_3.
2021-04-15 17:28:58,972 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
2021-04-15 17:28:58,982 INFO org.apache.flink.runtime.jobmaster.JobMaster - Initializing job Flink Streaming Job (d8718395ee2b28f55a0cfaf6a66b2e05).
2021-04-15 17:28:59,003 INFO org.apache.flink.runtime.jobmaster.JobMaster - Using restart back off time strategy NoRestartBackoffTimeStrategy for Flink Streaming Job (d8718395ee2b28f55a0cfaf6a66b2e05).
2021-04-15 17:28:59,056 INFO org.apache.flink.runtime.jobmaster.JobMaster - Running initialization on master for job Flink Streaming Job (d8718395ee2b28f55a0cfaf6a66b2e05).
2021-04-15 17:28:59,056 INFO org.apache.flink.runtime.jobmaster.JobMaster - Successfully ran initialization on master in 0 ms.
2021-04-15 17:28:59,056 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Adding 3 vertices from job graph Flink Streaming Job (d8718395ee2b28f55a0cfaf6a66b2e05).
2021-04-15 17:28:59,056 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Attaching 3 topologically sorted vertices to existing job graph with 0 vertices and 0 intermediate results.
2021-04-15 17:28:59,070 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex bc764cd8ddf7a0cff126f51c16239658 (Source: sensor) to 0 predecessors.
2021-04-15 17:28:59,072 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex 20ba6b65f97481d5570070de90e4e791 (Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out) to 1 predecessors.
2021-04-15 17:28:59,072 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting input 0 of vertex 20ba6b65f97481d5570070de90e4e791 (Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out) to intermediate result referenced via predecessor bc764cd8ddf7a0cff126f51c16239658 (Source: sensor).
2021-04-15 17:28:59,073 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex 51397532e2d9c7a21097a30d590b3114 (Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out) to 1 predecessors.
2021-04-15 17:28:59,073 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting input 0 of vertex 51397532e2d9c7a21097a30d590b3114 (Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out) to intermediate result referenced via predecessor bc764cd8ddf7a0cff126f51c16239658 (Source: sensor).
2021-04-15 17:28:59,083 INFO o.a.f.r.scheduler.adapter.DefaultExecutionTopology - Built 1 pipelined regions in 1 ms
2021-04-15 17:28:59,086 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Successfully created execution graph from job graph Flink Streaming Job (d8718395ee2b28f55a0cfaf6a66b2e05).
2021-04-15 17:28:59,103 INFO org.apache.flink.runtime.jobmaster.JobMaster - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:28:59,120 DEBUG o.apache.flink.runtime.checkpoint.CheckpointCoordinator - Status of the shared state registry of job d8718395ee2b28f55a0cfaf6a66b2e05 after restore: SharedStateRegistry{registeredStates={}}.
2021-04-15 17:28:59,120 INFO o.apache.flink.runtime.checkpoint.CheckpointCoordinator - No checkpoint found during restore.
2021-04-15 17:28:59,123 INFO org.apache.flink.runtime.jobmaster.JobMaster - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@323ece5d for Flink Streaming Job (d8718395ee2b28f55a0cfaf6a66b2e05).
2021-04-15 17:28:59,138 INFO org.apache.flink.runtime.jobmaster.JobManagerRunnerImpl - JobManager runner for job Flink Streaming Job (d8718395ee2b28f55a0cfaf6a66b2e05) was granted leadership with session id b0f25b05-446c-42f5-add3-b7d8d2a183ff at akka://flink/user/rpc/jobmanager_3.
2021-04-15 17:28:59,141 INFO org.apache.flink.runtime.jobmaster.JobMaster - Starting execution of job Flink Streaming Job (d8718395ee2b28f55a0cfaf6a66b2e05) under job master id add3b7d8d2a183ffb0f25b05446c42f5.
2021-04-15 17:28:59,142 INFO org.apache.flink.runtime.jobmaster.JobMaster - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2021-04-15 17:28:59,143 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Job Flink Streaming Job (d8718395ee2b28f55a0cfaf6a66b2e05) switched from state CREATED to RUNNING.
2021-04-15 17:28:59,148 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: sensor (1/1) (66d7423dc3838d85e58caf33ce5d5263) switched from CREATED to SCHEDULED.
2021-04-15 17:28:59,148 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4) (bf9a83bbf9e37b72a60cb03c1b019c6f) switched from CREATED to SCHEDULED.
2021-04-15 17:28:59,149 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4) (3d4ed64e692ffae832219227e639362b) switched from CREATED to SCHEDULED.
2021-04-15 17:28:59,149 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4) (3ef01f533787fc90d59ba1b0dea6e401) switched from CREATED to SCHEDULED.
2021-04-15 17:28:59,149 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4) (ae52a459d391bf1e41e481dde8b0dd7a) switched from CREATED to SCHEDULED.
2021-04-15 17:28:59,149 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4) (af65f5e91794dcc4e71d1e622436d9d0) switched from CREATED to SCHEDULED.
2021-04-15 17:28:59,149 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4) (8e75427985233be7213de041d1c3d1c1) switched from CREATED to SCHEDULED.
2021-04-15 17:28:59,149 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4) (91eb55c4f793d71472f308bade398aa6) switched from CREATED to SCHEDULED.
2021-04-15 17:28:59,149 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4) (1fc0c843d84d9035cf29566105413ec3) switched from CREATED to SCHEDULED.
2021-04-15 17:28:59,157 DEBUG o.a.f.r.jobmaster.slotpool.PhysicalSlotProviderImpl - Received slot request [SlotRequestId{a41f22f3d50f82ffcadd588ae3adf6df}] with resource requirements: ResourceProfile{UNKNOWN}
2021-04-15 17:28:59,159 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{a41f22f3d50f82ffcadd588ae3adf6df}]
2021-04-15 17:28:59,161 DEBUG o.a.f.r.jobmaster.slotpool.PhysicalSlotProviderImpl - Received slot request [SlotRequestId{ae2bfb57e9478aaead0214ede0b26917}] with resource requirements: ResourceProfile{UNKNOWN}
2021-04-15 17:28:59,162 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{ae2bfb57e9478aaead0214ede0b26917}]
2021-04-15 17:28:59,162 DEBUG o.a.f.r.jobmaster.slotpool.PhysicalSlotProviderImpl - Received slot request [SlotRequestId{e59b4bc1bf5eeef4c879e386809570ef}] with resource requirements: ResourceProfile{UNKNOWN}
2021-04-15 17:28:59,162 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{e59b4bc1bf5eeef4c879e386809570ef}]
2021-04-15 17:28:59,162 DEBUG o.a.f.r.jobmaster.slotpool.PhysicalSlotProviderImpl - Received slot request [SlotRequestId{6fd88bd4c0f06c2e9666a4bdcaad74a9}] with resource requirements: ResourceProfile{UNKNOWN}
2021-04-15 17:28:59,163 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{6fd88bd4c0f06c2e9666a4bdcaad74a9}]
2021-04-15 17:28:59,163 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{7a8a4d44cc5a0ad843c4b5c7d01c4bd9}) for execution vertex (id 20ba6b65f97481d5570070de90e4e791_3) from the physical slot (SlotRequestId{a41f22f3d50f82ffcadd588ae3adf6df})
2021-04-15 17:28:59,165 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{532c60e056507a431696474bc64a7b39}) for execution vertex (id 51397532e2d9c7a21097a30d590b3114_3) from the physical slot (SlotRequestId{a41f22f3d50f82ffcadd588ae3adf6df})
2021-04-15 17:28:59,166 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{64b8c7d19640e2845b1afa4958b9d9b9}) for execution vertex (id 20ba6b65f97481d5570070de90e4e791_1) from the physical slot (SlotRequestId{ae2bfb57e9478aaead0214ede0b26917})
2021-04-15 17:28:59,166 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{d517f52447a961afbae9e735eeb4f2da}) for execution vertex (id 51397532e2d9c7a21097a30d590b3114_1) from the physical slot (SlotRequestId{ae2bfb57e9478aaead0214ede0b26917})
2021-04-15 17:28:59,166 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{40952385085fa845a482736a53e1ba3c}) for execution vertex (id 20ba6b65f97481d5570070de90e4e791_2) from the physical slot (SlotRequestId{e59b4bc1bf5eeef4c879e386809570ef})
2021-04-15 17:28:59,166 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{321bc34c9f4068ea144a98be04136475}) for execution vertex (id 51397532e2d9c7a21097a30d590b3114_2) from the physical slot (SlotRequestId{e59b4bc1bf5eeef4c879e386809570ef})
2021-04-15 17:28:59,166 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{afcf44bda7398f5bd637836fe4207923}) for execution vertex (id bc764cd8ddf7a0cff126f51c16239658_0) from the physical slot (SlotRequestId{6fd88bd4c0f06c2e9666a4bdcaad74a9})
2021-04-15 17:28:59,166 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{44dec28b934c729e93c7aa49603f7244}) for execution vertex (id 20ba6b65f97481d5570070de90e4e791_0) from the physical slot (SlotRequestId{6fd88bd4c0f06c2e9666a4bdcaad74a9})
2021-04-15 17:28:59,166 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{df8a509e9044767a72c3c5023dbd7cc4}) for execution vertex (id 51397532e2d9c7a21097a30d590b3114_0) from the physical slot (SlotRequestId{6fd88bd4c0f06c2e9666a4bdcaad74a9})
2021-04-15 17:28:59,172 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/jobmanager_3 , session=b0f25b05-446c-42f5-add3-b7d8d2a183ff
2021-04-15 17:28:59,173 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
2021-04-15 17:28:59,174 INFO org.apache.flink.runtime.jobmaster.JobMaster - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(ab7d8ac3598dccd6c7def97a7d8f4869)
2021-04-15 17:28:59,176 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:28:59,176 INFO org.apache.flink.runtime.jobmaster.JobMaster - Resolved ResourceManager address, beginning registration
2021-04-15 17:28:59,177 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Registration at ResourceManager attempt 1 (timeout=100ms)
2021-04-15 17:28:59,177 DEBUG o.a.flink.runtime.resourcemanager.JobLeaderIdService - Add job d8718395ee2b28f55a0cfaf6a66b2e05 to job leader id monitoring.
2021-04-15 17:28:59,179 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Registering job manager add3b7d8d2a183ffb0f25b05446c42f5@akka://flink/user/rpc/jobmanager_3 for job d8718395ee2b28f55a0cfaf6a66b2e05.
2021-04-15 17:28:59,179 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/jobmanager_3. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2021-04-15 17:28:59,182 DEBUG o.a.flink.runtime.resourcemanager.JobLeaderIdService - Found a new job leader b0f25b05-446c-42f5-add3-b7d8d2a183ff@akka://flink/user/rpc/jobmanager_3.
2021-04-15 17:28:59,186 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Registered job manager add3b7d8d2a183ffb0f25b05446c42f5@akka://flink/user/rpc/jobmanager_3 for job d8718395ee2b28f55a0cfaf6a66b2e05.
2021-04-15 17:28:59,188 INFO org.apache.flink.runtime.jobmaster.JobMaster - JobManager successfully registered at ResourceManager, leader id: ab7d8ac3598dccd6c7def97a7d8f4869.
2021-04-15 17:28:59,190 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{a41f22f3d50f82ffcadd588ae3adf6df}] and profile ResourceProfile{UNKNOWN} with allocation id 2d67f315f3b1d02910ae44e43f082e57 from resource manager.
2021-04-15 17:28:59,190 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job d8718395ee2b28f55a0cfaf6a66b2e05 with allocation id 2d67f315f3b1d02910ae44e43f082e57.
2021-04-15 17:28:59,191 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{ae2bfb57e9478aaead0214ede0b26917}] and profile ResourceProfile{UNKNOWN} with allocation id a452818f247f624c8b1f33ad6f3c4488 from resource manager.
2021-04-15 17:28:59,191 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{e59b4bc1bf5eeef4c879e386809570ef}] and profile ResourceProfile{UNKNOWN} with allocation id 6c4cfaa4e375e41e70c49cba42f8c112 from resource manager.
2021-04-15 17:28:59,192 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{6fd88bd4c0f06c2e9666a4bdcaad74a9}] and profile ResourceProfile{UNKNOWN} with allocation id fa490bb8b06dc7ecb79de4620856f76e from resource manager.
2021-04-15 17:28:59,194 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 2d67f315f3b1d02910ae44e43f082e57 for job d8718395ee2b28f55a0cfaf6a66b2e05 from resource manager with leader id ab7d8ac3598dccd6c7def97a7d8f4869.
2021-04-15 17:28:59,195 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job d8718395ee2b28f55a0cfaf6a66b2e05 with allocation id a452818f247f624c8b1f33ad6f3c4488.
2021-04-15 17:28:59,198 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job d8718395ee2b28f55a0cfaf6a66b2e05 with allocation id 6c4cfaa4e375e41e70c49cba42f8c112.
2021-04-15 17:28:59,199 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job d8718395ee2b28f55a0cfaf6a66b2e05 with allocation id fa490bb8b06dc7ecb79de4620856f76e.
2021-04-15 17:28:59,203 DEBUG org.apache.flink.runtime.memory.MemoryManager - Initialized MemoryManager with total memory size 33554432 and page size 32768.
2021-04-15 17:28:59,204 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 2d67f315f3b1d02910ae44e43f082e57.
2021-04-15 17:28:59,205 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Add job d8718395ee2b28f55a0cfaf6a66b2e05 for job leader monitoring.
2021-04-15 17:28:59,206 DEBUG o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - New leader information for job d8718395ee2b28f55a0cfaf6a66b2e05. Address: akka://flink/user/rpc/jobmanager_3, leader id: add3b7d8d2a183ffb0f25b05446c42f5.
2021-04-15 17:28:59,207 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Try to register at job manager akka://flink/user/rpc/jobmanager_3 with leader id b0f25b05-446c-42f5-add3-b7d8d2a183ff.
2021-04-15 17:28:59,207 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/jobmanager_3. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2021-04-15 17:28:59,208 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request a452818f247f624c8b1f33ad6f3c4488 for job d8718395ee2b28f55a0cfaf6a66b2e05 from resource manager with leader id ab7d8ac3598dccd6c7def97a7d8f4869.
2021-04-15 17:28:59,208 DEBUG org.apache.flink.runtime.memory.MemoryManager - Initialized MemoryManager with total memory size 33554432 and page size 32768.
2021-04-15 17:28:59,208 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for a452818f247f624c8b1f33ad6f3c4488.
2021-04-15 17:28:59,209 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 6c4cfaa4e375e41e70c49cba42f8c112 for job d8718395ee2b28f55a0cfaf6a66b2e05 from resource manager with leader id ab7d8ac3598dccd6c7def97a7d8f4869.
2021-04-15 17:28:59,209 DEBUG org.apache.flink.runtime.memory.MemoryManager - Initialized MemoryManager with total memory size 33554432 and page size 32768.
2021-04-15 17:28:59,210 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Resolved JobManager address, beginning registration
2021-04-15 17:28:59,210 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 6c4cfaa4e375e41e70c49cba42f8c112.
2021-04-15 17:28:59,210 DEBUG o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Registration at JobManager attempt 1 (timeout=100ms)
2021-04-15 17:28:59,210 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request fa490bb8b06dc7ecb79de4620856f76e for job d8718395ee2b28f55a0cfaf6a66b2e05 from resource manager with leader id ab7d8ac3598dccd6c7def97a7d8f4869.
2021-04-15 17:28:59,210 DEBUG org.apache.flink.runtime.memory.MemoryManager - Initialized MemoryManager with total memory size 33554432 and page size 32768.
2021-04-15 17:28:59,210 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for fa490bb8b06dc7ecb79de4620856f76e.
2021-04-15 17:28:59,212 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
2021-04-15 17:28:59,214 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Register new TaskExecutor ef6044cc-9b73-466f-adb2-51c3fede0ecb.
2021-04-15 17:28:59,214 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Successful registration at job manager akka://flink/user/rpc/jobmanager_3 for job d8718395ee2b28f55a0cfaf6a66b2e05.
2021-04-15 17:28:59,215 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Establish JobManager connection for job d8718395ee2b28f55a0cfaf6a66b2e05.
2021-04-15 17:28:59,218 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Offer reserved slots to the leader of job d8718395ee2b28f55a0cfaf6a66b2e05.
2021-04-15 17:28:59,221 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Fulfilling pending slot request [SlotRequestId{a41f22f3d50f82ffcadd588ae3adf6df}] with slot [a452818f247f624c8b1f33ad6f3c4488]
2021-04-15 17:28:59,222 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{7a8a4d44cc5a0ad843c4b5c7d01c4bd9}) for execution vertex (id 20ba6b65f97481d5570070de90e4e791_3) from the physical slot (SlotRequestId{a41f22f3d50f82ffcadd588ae3adf6df})
2021-04-15 17:28:59,225 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{532c60e056507a431696474bc64a7b39}) for execution vertex (id 51397532e2d9c7a21097a30d590b3114_3) from the physical slot (SlotRequestId{a41f22f3d50f82ffcadd588ae3adf6df})
2021-04-15 17:28:59,225 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Fulfilling pending slot request [SlotRequestId{ae2bfb57e9478aaead0214ede0b26917}] with slot [2d67f315f3b1d02910ae44e43f082e57]
2021-04-15 17:28:59,226 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{64b8c7d19640e2845b1afa4958b9d9b9}) for execution vertex (id 20ba6b65f97481d5570070de90e4e791_1) from the physical slot (SlotRequestId{ae2bfb57e9478aaead0214ede0b26917})
2021-04-15 17:28:59,226 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{d517f52447a961afbae9e735eeb4f2da}) for execution vertex (id 51397532e2d9c7a21097a30d590b3114_1) from the physical slot (SlotRequestId{ae2bfb57e9478aaead0214ede0b26917})
2021-04-15 17:28:59,226 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Fulfilling pending slot request [SlotRequestId{e59b4bc1bf5eeef4c879e386809570ef}] with slot [6c4cfaa4e375e41e70c49cba42f8c112]
2021-04-15 17:28:59,226 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{40952385085fa845a482736a53e1ba3c}) for execution vertex (id 20ba6b65f97481d5570070de90e4e791_2) from the physical slot (SlotRequestId{e59b4bc1bf5eeef4c879e386809570ef})
2021-04-15 17:28:59,226 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{321bc34c9f4068ea144a98be04136475}) for execution vertex (id 51397532e2d9c7a21097a30d590b3114_2) from the physical slot (SlotRequestId{e59b4bc1bf5eeef4c879e386809570ef})
2021-04-15 17:28:59,226 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Fulfilling pending slot request [SlotRequestId{6fd88bd4c0f06c2e9666a4bdcaad74a9}] with slot [fa490bb8b06dc7ecb79de4620856f76e]
2021-04-15 17:28:59,226 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{afcf44bda7398f5bd637836fe4207923}) for execution vertex (id bc764cd8ddf7a0cff126f51c16239658_0) from the physical slot (SlotRequestId{6fd88bd4c0f06c2e9666a4bdcaad74a9})
2021-04-15 17:28:59,231 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{44dec28b934c729e93c7aa49603f7244}) for execution vertex (id 20ba6b65f97481d5570070de90e4e791_0) from the physical slot (SlotRequestId{6fd88bd4c0f06c2e9666a4bdcaad74a9})
2021-04-15 17:28:59,231 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{df8a509e9044767a72c3c5023dbd7cc4}) for execution vertex (id 51397532e2d9c7a21097a30d590b3114_0) from the physical slot (SlotRequestId{6fd88bd4c0f06c2e9666a4bdcaad74a9})
2021-04-15 17:28:59,232 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: sensor (1/1) (66d7423dc3838d85e58caf33ce5d5263) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:28:59,232 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: sensor (1/1) (attempt #0) with attempt id 66d7423dc3838d85e58caf33ce5d5263 to ef6044cc-9b73-466f-adb2-51c3fede0ecb @ server1 (dataPort=-1) with allocation id fa490bb8b06dc7ecb79de4620856f76e
2021-04-15 17:28:59,241 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4) (bf9a83bbf9e37b72a60cb03c1b019c6f) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:28:59,241 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4) (attempt #0) with attempt id bf9a83bbf9e37b72a60cb03c1b019c6f to ef6044cc-9b73-466f-adb2-51c3fede0ecb @ server1 (dataPort=-1) with allocation id fa490bb8b06dc7ecb79de4620856f76e
2021-04-15 17:28:59,241 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot fa490bb8b06dc7ecb79de4620856f76e.
2021-04-15 17:28:59,242 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4) (3d4ed64e692ffae832219227e639362b) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:28:59,242 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4) (attempt #0) with attempt id 3d4ed64e692ffae832219227e639362b to ef6044cc-9b73-466f-adb2-51c3fede0ecb @ server1 (dataPort=-1) with allocation id 2d67f315f3b1d02910ae44e43f082e57
2021-04-15 17:28:59,243 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4) (3ef01f533787fc90d59ba1b0dea6e401) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:28:59,243 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4) (attempt #0) with attempt id 3ef01f533787fc90d59ba1b0dea6e401 to ef6044cc-9b73-466f-adb2-51c3fede0ecb @ server1 (dataPort=-1) with allocation id 6c4cfaa4e375e41e70c49cba42f8c112
2021-04-15 17:28:59,243 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4) (ae52a459d391bf1e41e481dde8b0dd7a) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:28:59,243 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4) (attempt #0) with attempt id ae52a459d391bf1e41e481dde8b0dd7a to ef6044cc-9b73-466f-adb2-51c3fede0ecb @ server1 (dataPort=-1) with allocation id a452818f247f624c8b1f33ad6f3c4488
2021-04-15 17:28:59,243 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4) (af65f5e91794dcc4e71d1e622436d9d0) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:28:59,243 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4) (attempt #0) with attempt id af65f5e91794dcc4e71d1e622436d9d0 to ef6044cc-9b73-466f-adb2-51c3fede0ecb @ server1 (dataPort=-1) with allocation id fa490bb8b06dc7ecb79de4620856f76e
2021-04-15 17:28:59,244 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4) (8e75427985233be7213de041d1c3d1c1) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:28:59,244 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4) (attempt #0) with attempt id 8e75427985233be7213de041d1c3d1c1 to ef6044cc-9b73-466f-adb2-51c3fede0ecb @ server1 (dataPort=-1) with allocation id 2d67f315f3b1d02910ae44e43f082e57
2021-04-15 17:28:59,244 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4) (91eb55c4f793d71472f308bade398aa6) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:28:59,244 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4) (attempt #0) with attempt id 91eb55c4f793d71472f308bade398aa6 to ef6044cc-9b73-466f-adb2-51c3fede0ecb @ server1 (dataPort=-1) with allocation id 6c4cfaa4e375e41e70c49cba42f8c112
2021-04-15 17:28:59,244 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4) (1fc0c843d84d9035cf29566105413ec3) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:28:59,244 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4) (attempt #0) with attempt id 1fc0c843d84d9035cf29566105413ec3 to ef6044cc-9b73-466f-adb2-51c3fede0ecb @ server1 (dataPort=-1) with allocation id a452818f247f624c8b1f33ad6f3c4488
2021-04-15 17:28:59,250 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new allocation id fa490bb8b06dc7ecb79de4620856f76e for local state stores for job d8718395ee2b28f55a0cfaf6a66b2e05.
2021-04-15 17:28:59,252 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_fa490bb8b06dc7ecb79de4620856f76e], jobID=d8718395ee2b28f55a0cfaf6a66b2e05, jobVertexID=bc764cd8ddf7a0cff126f51c16239658, subtaskIndex=0}} for d8718395ee2b28f55a0cfaf6a66b2e05 - bc764cd8ddf7a0cff126f51c16239658 - 0 under allocation id fa490bb8b06dc7ecb79de4620856f76e.
2021-04-15 17:28:59,270 DEBUG o.a.f.r.io.network.partition.ResultPartitionFactory - Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@6a7493a5
2021-04-15 17:28:59,270 DEBUG o.a.f.r.io.network.partition.ResultPartitionFactory - Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@6a7493a5
2021-04-15 17:28:59,278 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263), deploy into slot with allocation id fa490bb8b06dc7ecb79de4620856f76e.
2021-04-15 17:28:59,279 INFO org.apache.flink.runtime.taskmanager.Task - Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263) switched from CREATED to DEPLOYING.
2021-04-15 17:28:59,280 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263) [DEPLOYING]
2021-04-15 17:28:59,282 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot fa490bb8b06dc7ecb79de4620856f76e.
2021-04-15 17:28:59,284 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_fa490bb8b06dc7ecb79de4620856f76e], jobID=d8718395ee2b28f55a0cfaf6a66b2e05, jobVertexID=20ba6b65f97481d5570070de90e4e791, subtaskIndex=0}} for d8718395ee2b28f55a0cfaf6a66b2e05 - 20ba6b65f97481d5570070de90e4e791 - 0 under allocation id fa490bb8b06dc7ecb79de4620856f76e.
2021-04-15 17:28:59,291 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263) [DEPLOYING].
2021-04-15 17:28:59,291 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 66d7423dc3838d85e58caf33ce5d5263 at library cache manager took 0 milliseconds
2021-04-15 17:28:59,294 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263) [DEPLOYING].
2021-04-15 17:28:59,303 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 5-16 buffers
2021-04-15 17:28:59,303 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Registered PipelinedResultPartition 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263 [PIPELINED_BOUNDED, 4 subpartitions, 4 pending consumptions].
2021-04-15 17:28:59,304 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 5-16 buffers
2021-04-15 17:28:59,304 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Registered PipelinedResultPartition de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263 [PIPELINED_BOUNDED, 4 subpartitions, 4 pending consumptions].
2021-04-15 17:28:59,304 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - registering 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263
2021-04-15 17:28:59,306 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (bf9a83bbf9e37b72a60cb03c1b019c6f): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:28:59,321 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - registering de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263
2021-04-15 17:28:59,326 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (bf9a83bbf9e37b72a60cb03c1b019c6f), deploy into slot with allocation id fa490bb8b06dc7ecb79de4620856f76e.
2021-04-15 17:28:59,337 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 2d67f315f3b1d02910ae44e43f082e57.
2021-04-15 17:28:59,343 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new allocation id 2d67f315f3b1d02910ae44e43f082e57 for local state stores for job d8718395ee2b28f55a0cfaf6a66b2e05.
2021-04-15 17:28:59,371 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_2d67f315f3b1d02910ae44e43f082e57], jobID=d8718395ee2b28f55a0cfaf6a66b2e05, jobVertexID=20ba6b65f97481d5570070de90e4e791, subtaskIndex=1}} for d8718395ee2b28f55a0cfaf6a66b2e05 - 20ba6b65f97481d5570070de90e4e791 - 1 under allocation id 2d67f315f3b1d02910ae44e43f082e57.
2021-04-15 17:28:59,374 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Using partitioner HASH for output 0 of task Source: sensor
2021-04-15 17:28:59,376 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (3d4ed64e692ffae832219227e639362b): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:28:59,379 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (3d4ed64e692ffae832219227e639362b), deploy into slot with allocation id 2d67f315f3b1d02910ae44e43f082e57.
2021-04-15 17:28:59,380 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 6c4cfaa4e375e41e70c49cba42f8c112.
2021-04-15 17:28:59,381 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Using partitioner HASH for output 1 of task Source: sensor
2021-04-15 17:28:59,387 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new allocation id 6c4cfaa4e375e41e70c49cba42f8c112 for local state stores for job d8718395ee2b28f55a0cfaf6a66b2e05.
2021-04-15 17:28:59,388 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:28:59,400 INFO org.apache.flink.runtime.taskmanager.Task - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (bf9a83bbf9e37b72a60cb03c1b019c6f) switched from CREATED to DEPLOYING.
2021-04-15 17:28:59,400 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (bf9a83bbf9e37b72a60cb03c1b019c6f) [DEPLOYING]
2021-04-15 17:28:59,401 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (bf9a83bbf9e37b72a60cb03c1b019c6f) [DEPLOYING].
2021-04-15 17:28:59,402 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task bf9a83bbf9e37b72a60cb03c1b019c6f at library cache manager took 0 milliseconds
2021-04-15 17:28:59,404 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (bf9a83bbf9e37b72a60cb03c1b019c6f) [DEPLOYING].
2021-04-15 17:28:59,404 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:28:59,404 INFO org.apache.flink.runtime.taskmanager.Task - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (3d4ed64e692ffae832219227e639362b) switched from CREATED to DEPLOYING.
2021-04-15 17:28:59,405 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_6c4cfaa4e375e41e70c49cba42f8c112], jobID=d8718395ee2b28f55a0cfaf6a66b2e05, jobVertexID=20ba6b65f97481d5570070de90e4e791, subtaskIndex=2}} for d8718395ee2b28f55a0cfaf6a66b2e05 - 20ba6b65f97481d5570070de90e4e791 - 2 under allocation id 6c4cfaa4e375e41e70c49cba42f8c112.
2021-04-15 17:28:59,405 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (3d4ed64e692ffae832219227e639362b) [DEPLOYING]
2021-04-15 17:28:59,406 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (3ef01f533787fc90d59ba1b0dea6e401): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:28:59,406 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (3d4ed64e692ffae832219227e639362b) [DEPLOYING].
2021-04-15 17:28:59,407 INFO org.apache.flink.runtime.taskmanager.Task - Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263) switched from DEPLOYING to RUNNING.
2021-04-15 17:28:59,409 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (3ef01f533787fc90d59ba1b0dea6e401), deploy into slot with allocation id 6c4cfaa4e375e41e70c49cba42f8c112.
2021-04-15 17:28:59,409 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:28:59,410 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 3d4ed64e692ffae832219227e639362b at library cache manager took 0 milliseconds
2021-04-15 17:28:59,411 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Source: sensor (1/1)#0.
2021-04-15 17:28:59,412 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot a452818f247f624c8b1f33ad6f3c4488.
2021-04-15 17:28:59,414 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: sensor (1/1) (66d7423dc3838d85e58caf33ce5d5263) switched from DEPLOYING to RUNNING.
2021-04-15 17:28:59,414 INFO org.apache.flink.runtime.taskmanager.Task - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (bf9a83bbf9e37b72a60cb03c1b019c6f) switched from DEPLOYING to RUNNING.
2021-04-15 17:28:59,415 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (3d4ed64e692ffae832219227e639362b) [DEPLOYING].
2021-04-15 17:28:59,416 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0.
2021-04-15 17:28:59,417 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new allocation id a452818f247f624c8b1f33ad6f3c4488 for local state stores for job d8718395ee2b28f55a0cfaf6a66b2e05.
2021-04-15 17:28:59,418 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4) (bf9a83bbf9e37b72a60cb03c1b019c6f) switched from DEPLOYING to RUNNING.
2021-04-15 17:28:59,419 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:28:59,428 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_a452818f247f624c8b1f33ad6f3c4488], jobID=d8718395ee2b28f55a0cfaf6a66b2e05, jobVertexID=20ba6b65f97481d5570070de90e4e791, subtaskIndex=3}} for d8718395ee2b28f55a0cfaf6a66b2e05 - 20ba6b65f97481d5570070de90e4e791 - 3 under allocation id a452818f247f624c8b1f33ad6f3c4488.
2021-04-15 17:28:59,428 INFO org.apache.flink.runtime.taskmanager.Task - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (3ef01f533787fc90d59ba1b0dea6e401) switched from CREATED to DEPLOYING.
2021-04-15 17:28:59,433 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:28:59,435 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (3ef01f533787fc90d59ba1b0dea6e401) [DEPLOYING]
2021-04-15 17:28:59,435 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (ae52a459d391bf1e41e481dde8b0dd7a): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:28:59,442 INFO org.apache.flink.runtime.taskmanager.Task - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (3d4ed64e692ffae832219227e639362b) switched from DEPLOYING to RUNNING.
2021-04-15 17:28:59,443 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (3ef01f533787fc90d59ba1b0dea6e401) [DEPLOYING].
2021-04-15 17:28:59,444 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (ae52a459d391bf1e41e481dde8b0dd7a), deploy into slot with allocation id a452818f247f624c8b1f33ad6f3c4488.
2021-04-15 17:28:59,445 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4) (3d4ed64e692ffae832219227e639362b) switched from DEPLOYING to RUNNING.
2021-04-15 17:28:59,445 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 3ef01f533787fc90d59ba1b0dea6e401 at library cache manager took 0 milliseconds
2021-04-15 17:28:59,444 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0.
2021-04-15 17:28:59,447 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot fa490bb8b06dc7ecb79de4620856f76e.
2021-04-15 17:28:59,452 INFO org.apache.flink.runtime.taskmanager.Task - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (ae52a459d391bf1e41e481dde8b0dd7a) switched from CREATED to DEPLOYING.
2021-04-15 17:28:59,452 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (3ef01f533787fc90d59ba1b0dea6e401) [DEPLOYING].
2021-04-15 17:28:59,453 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:28:59,452 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (ae52a459d391bf1e41e481dde8b0dd7a) [DEPLOYING]
2021-04-15 17:28:59,453 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:28:59,453 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (ae52a459d391bf1e41e481dde8b0dd7a) [DEPLOYING].
2021-04-15 17:28:59,459 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task ae52a459d391bf1e41e481dde8b0dd7a at library cache manager took 0 milliseconds
2021-04-15 17:28:59,459 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_fa490bb8b06dc7ecb79de4620856f76e], jobID=d8718395ee2b28f55a0cfaf6a66b2e05, jobVertexID=51397532e2d9c7a21097a30d590b3114, subtaskIndex=0}} for d8718395ee2b28f55a0cfaf6a66b2e05 - 51397532e2d9c7a21097a30d590b3114 - 0 under allocation id fa490bb8b06dc7ecb79de4620856f76e.
2021-04-15 17:28:59,453 INFO org.apache.flink.runtime.taskmanager.Task - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (3ef01f533787fc90d59ba1b0dea6e401) switched from DEPLOYING to RUNNING.
2021-04-15 17:28:59,461 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (af65f5e91794dcc4e71d1e622436d9d0): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:28:59,459 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (ae52a459d391bf1e41e481dde8b0dd7a) [DEPLOYING].
2021-04-15 17:28:59,463 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0.
2021-04-15 17:28:59,464 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (af65f5e91794dcc4e71d1e622436d9d0), deploy into slot with allocation id fa490bb8b06dc7ecb79de4620856f76e.
2021-04-15 17:28:59,468 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:28:59,475 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Source: sensor (1/1)#0
2021-04-15 17:28:59,476 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 2d67f315f3b1d02910ae44e43f082e57.
2021-04-15 17:28:59,477 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_2d67f315f3b1d02910ae44e43f082e57], jobID=d8718395ee2b28f55a0cfaf6a66b2e05, jobVertexID=51397532e2d9c7a21097a30d590b3114, subtaskIndex=1}} for d8718395ee2b28f55a0cfaf6a66b2e05 - 51397532e2d9c7a21097a30d590b3114 - 1 under allocation id 2d67f315f3b1d02910ae44e43f082e57.
2021-04-15 17:28:59,477 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (8e75427985233be7213de041d1c3d1c1): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:28:59,478 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (8e75427985233be7213de041d1c3d1c1), deploy into slot with allocation id 2d67f315f3b1d02910ae44e43f082e57.
2021-04-15 17:28:59,478 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 6c4cfaa4e375e41e70c49cba42f8c112.
2021-04-15 17:28:59,480 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_6c4cfaa4e375e41e70c49cba42f8c112], jobID=d8718395ee2b28f55a0cfaf6a66b2e05, jobVertexID=51397532e2d9c7a21097a30d590b3114, subtaskIndex=2}} for d8718395ee2b28f55a0cfaf6a66b2e05 - 51397532e2d9c7a21097a30d590b3114 - 2 under allocation id 6c4cfaa4e375e41e70c49cba42f8c112.
2021-04-15 17:28:59,481 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (91eb55c4f793d71472f308bade398aa6): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:28:59,481 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (91eb55c4f793d71472f308bade398aa6), deploy into slot with allocation id 6c4cfaa4e375e41e70c49cba42f8c112.
2021-04-15 17:28:59,481 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot a452818f247f624c8b1f33ad6f3c4488.
2021-04-15 17:28:59,482 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_a452818f247f624c8b1f33ad6f3c4488], jobID=d8718395ee2b28f55a0cfaf6a66b2e05, jobVertexID=51397532e2d9c7a21097a30d590b3114, subtaskIndex=3}} for d8718395ee2b28f55a0cfaf6a66b2e05 - 51397532e2d9c7a21097a30d590b3114 - 3 under allocation id a452818f247f624c8b1f33ad6f3c4488.
2021-04-15 17:28:59,483 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (1fc0c843d84d9035cf29566105413ec3): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:28:59,483 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (1fc0c843d84d9035cf29566105413ec3), deploy into slot with allocation id a452818f247f624c8b1f33ad6f3c4488.
2021-04-15 17:28:59,484 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot a452818f247f624c8b1f33ad6f3c4488.
2021-04-15 17:28:59,485 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 2d67f315f3b1d02910ae44e43f082e57.
2021-04-15 17:28:59,485 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 6c4cfaa4e375e41e70c49cba42f8c112.
2021-04-15 17:28:59,485 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot fa490bb8b06dc7ecb79de4620856f76e.
2021-04-15 17:28:59,508 INFO org.apache.flink.runtime.taskmanager.Task - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (af65f5e91794dcc4e71d1e622436d9d0) switched from CREATED to DEPLOYING.
2021-04-15 17:28:59,508 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (af65f5e91794dcc4e71d1e622436d9d0) [DEPLOYING]
2021-04-15 17:28:59,509 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (af65f5e91794dcc4e71d1e622436d9d0) [DEPLOYING].
2021-04-15 17:28:59,512 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task af65f5e91794dcc4e71d1e622436d9d0 at library cache manager took 0 milliseconds
2021-04-15 17:28:59,515 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (af65f5e91794dcc4e71d1e622436d9d0) [DEPLOYING].
2021-04-15 17:28:59,516 INFO org.apache.flink.runtime.taskmanager.Task - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (8e75427985233be7213de041d1c3d1c1) switched from CREATED to DEPLOYING.
2021-04-15 17:28:59,517 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (8e75427985233be7213de041d1c3d1c1) [DEPLOYING]
2021-04-15 17:28:59,518 INFO org.apache.flink.runtime.taskmanager.Task - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (91eb55c4f793d71472f308bade398aa6) switched from CREATED to DEPLOYING.
2021-04-15 17:28:59,518 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (8e75427985233be7213de041d1c3d1c1) [DEPLOYING].
2021-04-15 17:28:59,519 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (91eb55c4f793d71472f308bade398aa6) [DEPLOYING]
2021-04-15 17:28:59,519 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 8e75427985233be7213de041d1c3d1c1 at library cache manager took 0 milliseconds
2021-04-15 17:28:59,519 INFO org.apache.flink.runtime.taskmanager.Task - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (1fc0c843d84d9035cf29566105413ec3) switched from CREATED to DEPLOYING.
2021-04-15 17:28:59,520 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (1fc0c843d84d9035cf29566105413ec3) [DEPLOYING]
2021-04-15 17:28:59,519 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (91eb55c4f793d71472f308bade398aa6) [DEPLOYING].
2021-04-15 17:28:59,521 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 91eb55c4f793d71472f308bade398aa6 at library cache manager took 0 milliseconds
2021-04-15 17:28:59,520 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (8e75427985233be7213de041d1c3d1c1) [DEPLOYING].
2021-04-15 17:28:59,520 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (1fc0c843d84d9035cf29566105413ec3) [DEPLOYING].
2021-04-15 17:28:59,521 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 1fc0c843d84d9035cf29566105413ec3 at library cache manager took 0 milliseconds
2021-04-15 17:28:59,521 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (91eb55c4f793d71472f308bade398aa6) [DEPLOYING].
2021-04-15 17:28:59,522 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (1fc0c843d84d9035cf29566105413ec3) [DEPLOYING].
2021-04-15 17:28:59,544 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSource_bc764cd8ddf7a0cff126f51c16239658_(1/1) with empty state.
2021-04-15 17:28:59,545 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:28:59,545 INFO org.apache.flink.runtime.taskmanager.Task - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (ae52a459d391bf1e41e481dde8b0dd7a) switched from DEPLOYING to RUNNING.
2021-04-15 17:28:59,546 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0.
2021-04-15 17:28:59,573 WARN org.apache.flink.metrics.MetricGroup - The operator name Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:28:59,583 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:28:59,583 WARN org.apache.flink.metrics.MetricGroup - The operator name Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:28:59,587 WARN org.apache.flink.metrics.MetricGroup - The operator name Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:28:59,588 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:28:59,588 INFO org.apache.flink.runtime.taskmanager.Task - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (1fc0c843d84d9035cf29566105413ec3) switched from DEPLOYING to RUNNING.
2021-04-15 17:28:59,589 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0.
2021-04-15 17:28:59,608 WARN org.apache.flink.metrics.MetricGroup - The operator name Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:28:59,612 WARN org.apache.flink.metrics.MetricGroup - The operator name Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:28:59,616 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:28:59,628 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:28:59,628 INFO org.apache.flink.runtime.taskmanager.Task - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (91eb55c4f793d71472f308bade398aa6) switched from DEPLOYING to RUNNING.
2021-04-15 17:28:59,629 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0.
2021-04-15 17:28:59,631 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4) (3ef01f533787fc90d59ba1b0dea6e401) switched from DEPLOYING to RUNNING.
2021-04-15 17:28:59,632 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4) (ae52a459d391bf1e41e481dde8b0dd7a) switched from DEPLOYING to RUNNING.
2021-04-15 17:28:59,632 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:28:59,633 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4) (1fc0c843d84d9035cf29566105413ec3) switched from DEPLOYING to RUNNING.
2021-04-15 17:28:59,633 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4) (91eb55c4f793d71472f308bade398aa6) switched from DEPLOYING to RUNNING.
2021-04-15 17:28:59,634 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:28:59,634 INFO org.apache.flink.runtime.taskmanager.Task - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (8e75427985233be7213de041d1c3d1c1) switched from DEPLOYING to RUNNING.
2021-04-15 17:28:59,634 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0.
2021-04-15 17:28:59,634 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4) (8e75427985233be7213de041d1c3d1c1) switched from DEPLOYING to RUNNING.
2021-04-15 17:28:59,640 WARN org.apache.flink.metrics.MetricGroup - The operator name Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:28:59,643 WARN org.apache.flink.metrics.MetricGroup - The operator name Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:28:59,661 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:28:59,662 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:28:59,662 INFO org.apache.flink.runtime.taskmanager.Task - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (af65f5e91794dcc4e71d1e622436d9d0) switched from DEPLOYING to RUNNING.
2021-04-15 17:28:59,662 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0.
2021-04-15 17:28:59,662 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4) (af65f5e91794dcc4e71d1e622436d9d0) switched from DEPLOYING to RUNNING.
2021-04-15 17:28:59,666 WARN org.apache.flink.metrics.MetricGroup - The operator name Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:28:59,674 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0
2021-04-15 17:28:59,674 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_a7ff31a2a262e9bd1fe62e920ca466b3_(3/4) with empty state.
2021-04-15 17:28:59,675 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0
2021-04-15 17:28:59,675 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_e1aa9a3f1b74e8aee21b292597024e03_(3/4) with empty state.
2021-04-15 17:28:59,678 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0
2021-04-15 17:28:59,678 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_a7ff31a2a262e9bd1fe62e920ca466b3_(2/4) with empty state.
2021-04-15 17:28:59,678 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0
2021-04-15 17:28:59,679 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_e1aa9a3f1b74e8aee21b292597024e03_(1/4) with empty state.
2021-04-15 17:28:59,679 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating keyed state backend for WindowOperator_20ba6b65f97481d5570070de90e4e791_(2/4) with empty state.
2021-04-15 17:28:59,679 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0
2021-04-15 17:28:59,679 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating keyed state backend for WindowOperator_51397532e2d9c7a21097a30d590b3114_(1/4) with empty state.
2021-04-15 17:28:59,679 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0
2021-04-15 17:28:59,680 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_e1aa9a3f1b74e8aee21b292597024e03_(2/4) with empty state.
2021-04-15 17:28:59,680 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0
2021-04-15 17:28:59,681 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_a7ff31a2a262e9bd1fe62e920ca466b3_(4/4) with empty state.
2021-04-15 17:28:59,681 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating keyed state backend for WindowOperator_51397532e2d9c7a21097a30d590b3114_(2/4) with empty state.
2021-04-15 17:28:59,683 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_a7ff31a2a262e9bd1fe62e920ca466b3_(1/4) with empty state.
2021-04-15 17:28:59,685 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating keyed state backend for WindowOperator_20ba6b65f97481d5570070de90e4e791_(4/4) with empty state.
2021-04-15 17:28:59,686 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating keyed state backend for WindowOperator_20ba6b65f97481d5570070de90e4e791_(1/4) with empty state.
2021-04-15 17:28:59,714 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0
2021-04-15 17:28:59,715 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_e1aa9a3f1b74e8aee21b292597024e03_(4/4) with empty state.
2021-04-15 17:28:59,715 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating keyed state backend for WindowOperator_20ba6b65f97481d5570070de90e4e791_(3/4) with empty state.
2021-04-15 17:28:59,716 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating keyed state backend for WindowOperator_51397532e2d9c7a21097a30d590b3114_(3/4) with empty state.
2021-04-15 17:28:59,716 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating keyed state backend for WindowOperator_51397532e2d9c7a21097a30d590b3114_(4/4) with empty state.
2021-04-15 17:28:59,716 INFO o.a.f.runtime.state.heap.HeapKeyedStateBackendBuilder - Finished to build heap keyed state-backend.
2021-04-15 17:28:59,719 INFO o.a.f.runtime.state.heap.HeapKeyedStateBackendBuilder - Finished to build heap keyed state-backend.
2021-04-15 17:28:59,719 INFO o.a.f.runtime.state.heap.HeapKeyedStateBackendBuilder - Finished to build heap keyed state-backend.
2021-04-15 17:28:59,720 INFO o.a.f.runtime.state.heap.HeapKeyedStateBackendBuilder - Finished to build heap keyed state-backend.
2021-04-15 17:28:59,720 INFO o.a.f.runtime.state.heap.HeapKeyedStateBackendBuilder - Finished to build heap keyed state-backend.
2021-04-15 17:28:59,722 INFO o.a.f.runtime.state.heap.HeapKeyedStateBackendBuilder - Finished to build heap keyed state-backend.
2021-04-15 17:28:59,722 INFO o.a.f.runtime.state.heap.HeapKeyedStateBackendBuilder - Finished to build heap keyed state-backend.
2021-04-15 17:28:59,722 INFO o.a.f.runtime.state.heap.HeapKeyedStateBackendBuilder - Finished to build heap keyed state-backend.
2021-04-15 17:28:59,736 INFO o.apache.flink.runtime.state.heap.HeapKeyedStateBackend - Initializing heap keyed state backend with stream factory.
2021-04-15 17:28:59,737 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for WindowOperator_51397532e2d9c7a21097a30d590b3114_(2/4) with empty state.
2021-04-15 17:28:59,739 INFO o.apache.flink.runtime.state.heap.HeapKeyedStateBackend - Initializing heap keyed state backend with stream factory.
2021-04-15 17:28:59,743 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for WindowOperator_20ba6b65f97481d5570070de90e4e791_(2/4) with empty state.
2021-04-15 17:28:59,743 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf - -Dorg.apache.flink.shaded.netty4.io.netty.buffer.checkAccessible: true
2021-04-15 17:28:59,743 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf - -Dorg.apache.flink.shaded.netty4.io.netty.buffer.checkBounds: true
2021-04-15 17:28:59,745 DEBUG o.a.f.s.n.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.flink.shaded.netty4.io.netty.util.ResourceLeakDetector@92059c1
2021-04-15 17:28:59,747 INFO o.apache.flink.runtime.state.heap.HeapKeyedStateBackend - Initializing heap keyed state backend with stream factory.
2021-04-15 17:28:59,747 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for WindowOperator_20ba6b65f97481d5570070de90e4e791_(1/4) with empty state.
2021-04-15 17:28:59,748 INFO o.apache.flink.runtime.state.heap.HeapKeyedStateBackend - Initializing heap keyed state backend with stream factory.
2021-04-15 17:28:59,748 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for WindowOperator_20ba6b65f97481d5570070de90e4e791_(4/4) with empty state.
2021-04-15 17:28:59,748 INFO o.apache.flink.runtime.state.heap.HeapKeyedStateBackend - Initializing heap keyed state backend with stream factory.
2021-04-15 17:28:59,749 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for WindowOperator_51397532e2d9c7a21097a30d590b3114_(1/4) with empty state.
2021-04-15 17:28:59,749 INFO o.apache.flink.runtime.state.heap.HeapKeyedStateBackend - Initializing heap keyed state backend with stream factory.
2021-04-15 17:28:59,749 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for WindowOperator_20ba6b65f97481d5570070de90e4e791_(3/4) with empty state.
2021-04-15 17:28:59,749 INFO o.apache.flink.runtime.state.heap.HeapKeyedStateBackend - Initializing heap keyed state backend with stream factory.
2021-04-15 17:28:59,749 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for WindowOperator_51397532e2d9c7a21097a30d590b3114_(4/4) with empty state.
2021-04-15 17:28:59,749 INFO o.apache.flink.runtime.state.heap.HeapKeyedStateBackend - Initializing heap keyed state backend with stream factory.
2021-04-15 17:28:59,749 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for WindowOperator_51397532e2d9c7a21097a30d590b3114_(3/4) with empty state.
2021-04-15 17:28:59,824 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (ae52a459d391bf1e41e481dde8b0dd7a)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:28:59,825 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (3d4ed64e692ffae832219227e639362b)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:28:59,827 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (8e75427985233be7213de041d1c3d1c1)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:28:59,827 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (1fc0c843d84d9035cf29566105413ec3)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:28:59,827 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (91eb55c4f793d71472f308bade398aa6)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:28:59,828 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (bf9a83bbf9e37b72a60cb03c1b019c6f)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:28:59,830 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:28:59,831 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (af65f5e91794dcc4e71d1e622436d9d0)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:28:59,832 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:28:59,832 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:28:59,833 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:28:59,833 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:28:59,836 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:28:59,837 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (3ef01f533787fc90d59ba1b0dea6e401)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:28:59,838 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:28:59,840 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:28:59,841 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:28:59,841 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:28:59,841 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:28:59,841 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:28:59,841 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:28:59,841 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:28:59,842 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:28:59,842 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:28:59,842 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263]: Requesting LOCAL subpartition 3 of partition de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:28:59,841 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263]: Requesting LOCAL subpartition 3 of partition 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:28:59,842 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263]: Requesting LOCAL subpartition 1 of partition 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:28:59,842 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263]: Requesting LOCAL subpartition 2 of partition de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:28:59,842 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263]: Requesting LOCAL subpartition 1 of partition de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:28:59,843 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263]: Requesting LOCAL subpartition 0 of partition 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:28:59,843 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263]: Requesting LOCAL subpartition 0 of partition de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:28:59,843 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263]: Requesting LOCAL subpartition 2 of partition 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:28:59,844 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 3 of PipelinedResultPartition de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263 [PIPELINED_BOUNDED, 4 subpartitions, 4 pending consumptions].
2021-04-15 17:28:59,849 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263): Creating read view for subpartition 3 of partition de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263.
2021-04-15 17:28:59,850 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 3) of ResultPartition de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263
2021-04-15 17:28:59,870 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 2 of PipelinedResultPartition 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263 [PIPELINED_BOUNDED, 4 subpartitions, 4 pending consumptions].
2021-04-15 17:28:59,870 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263): Creating read view for subpartition 2 of partition 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263.
2021-04-15 17:28:59,870 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 2) of ResultPartition 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263
2021-04-15 17:28:59,870 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 3 of PipelinedResultPartition 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263 [PIPELINED_BOUNDED, 4 subpartitions, 4 pending consumptions].
2021-04-15 17:28:59,870 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263): Creating read view for subpartition 3 of partition 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263.
2021-04-15 17:28:59,870 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 3) of ResultPartition 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263
2021-04-15 17:28:59,873 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 0 of PipelinedResultPartition de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263 [PIPELINED_BOUNDED, 4 subpartitions, 4 pending consumptions].
2021-04-15 17:28:59,873 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263): Creating read view for subpartition 0 of partition de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263.
2021-04-15 17:28:59,873 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 0) of ResultPartition de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263
2021-04-15 17:28:59,875 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 0 of PipelinedResultPartition 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263 [PIPELINED_BOUNDED, 4 subpartitions, 4 pending consumptions].
2021-04-15 17:28:59,875 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263): Creating read view for subpartition 0 of partition 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263.
2021-04-15 17:28:59,875 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 0) of ResultPartition 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263
2021-04-15 17:28:59,877 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 1 of PipelinedResultPartition de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263 [PIPELINED_BOUNDED, 4 subpartitions, 4 pending consumptions].
2021-04-15 17:28:59,877 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263): Creating read view for subpartition 1 of partition de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263.
2021-04-15 17:28:59,877 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 1) of ResultPartition de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263
2021-04-15 17:28:59,881 WARN org.apache.flink.runtime.taskmanager.Task - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (8e75427985233be7213de041d1c3d1c1) switched from RUNNING to FAILED.
java.lang.RuntimeException: Record has Long.MIN_VALUE timestamp (= no timestamp marker). Is the time characteristic set to 'ProcessingTime', or did you forget to call 'DataStream.assignTimestampsAndWatermarks(...)'?
	at org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows.assignWindows(TumblingEventTimeWindows.java:83) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.processElement(WindowOperator.java:302) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:191) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.processElement(StreamTaskNetworkInput.java:204) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.emitNext(StreamTaskNetworkInput.java:174) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:396) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:191) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:617) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:581) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:755) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:570) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at java.base/java.lang.Thread.run(Thread.java:834) ~[na:na]
2021-04-15 17:28:59,882 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 2 of PipelinedResultPartition de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263 [PIPELINED_BOUNDED, 4 subpartitions, 4 pending consumptions].
2021-04-15 17:28:59,882 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263): Creating read view for subpartition 2 of partition de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263.
2021-04-15 17:28:59,882 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 2) of ResultPartition de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263
2021-04-15 17:28:59,881 WARN org.apache.flink.runtime.taskmanager.Task - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (bf9a83bbf9e37b72a60cb03c1b019c6f) switched from RUNNING to FAILED.
java.lang.RuntimeException: Record has Long.MIN_VALUE timestamp (= no timestamp marker). Is the time characteristic set to 'ProcessingTime', or did you forget to call 'DataStream.assignTimestampsAndWatermarks(...)'?
	at org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows.assignWindows(TumblingEventTimeWindows.java:83) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.processElement(WindowOperator.java:302) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:191) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.processElement(StreamTaskNetworkInput.java:204) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.emitNext(StreamTaskNetworkInput.java:174) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:396) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:191) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:617) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:581) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:755) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:570) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at java.base/java.lang.Thread.run(Thread.java:834) ~[na:na]
2021-04-15 17:28:59,886 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 1 of PipelinedResultPartition 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263 [PIPELINED_BOUNDED, 4 subpartitions, 4 pending consumptions].
2021-04-15 17:28:59,886 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263): Creating read view for subpartition 1 of partition 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263.
2021-04-15 17:28:59,886 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 1) of ResultPartition 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263
2021-04-15 17:28:59,882 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (8e75427985233be7213de041d1c3d1c1).
2021-04-15 17:28:59,889 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 network resources (state: FAILED).
2021-04-15 17:28:59,889 DEBUG o.a.f.r.io.network.partition.consumer.SingleInputGate - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (8e75427985233be7213de041d1c3d1c1): Releasing SingleInputGate{owningTaskName='Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (8e75427985233be7213de041d1c3d1c1)', gateIndex=0}.
2021-04-15 17:28:59,889 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - PipelinedResultPartition de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263 [PIPELINED_BOUNDED, 4 subpartitions, 3 pending consumptions]: Received consumed notification for subpartition 1.
2021-04-15 17:28:59,886 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (bf9a83bbf9e37b72a60cb03c1b019c6f).
2021-04-15 17:28:59,891 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 network resources (state: FAILED).
2021-04-15 17:28:59,891 DEBUG o.a.f.r.io.network.partition.consumer.SingleInputGate - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (bf9a83bbf9e37b72a60cb03c1b019c6f): Releasing SingleInputGate{owningTaskName='Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (bf9a83bbf9e37b72a60cb03c1b019c6f)', gateIndex=0}.
2021-04-15 17:28:59,882 WARN org.apache.flink.runtime.taskmanager.Task - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (ae52a459d391bf1e41e481dde8b0dd7a) switched from RUNNING to FAILED.
java.lang.RuntimeException: Record has Long.MIN_VALUE timestamp (= no timestamp marker). Is the time characteristic set to 'ProcessingTime', or did you forget to call 'DataStream.assignTimestampsAndWatermarks(...)'?
	at org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows.assignWindows(TumblingEventTimeWindows.java:83) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.processElement(WindowOperator.java:302) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:191) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.processElement(StreamTaskNetworkInput.java:204) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.emitNext(StreamTaskNetworkInput.java:174) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:396) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:191) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:617) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:581) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:755) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:570) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at java.base/java.lang.Thread.run(Thread.java:834) ~[na:na]
2021-04-15 17:28:59,891 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - PipelinedResultPartition 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263 [PIPELINED_BOUNDED, 4 subpartitions, 3 pending consumptions]: Received consumed notification for subpartition 0.
2021-04-15 17:28:59,886 WARN org.apache.flink.runtime.taskmanager.Task - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (91eb55c4f793d71472f308bade398aa6) switched from RUNNING to FAILED.
java.lang.RuntimeException: Record has Long.MIN_VALUE timestamp (= no timestamp marker). Is the time characteristic set to 'ProcessingTime', or did you forget to call 'DataStream.assignTimestampsAndWatermarks(...)'?
	at org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows.assignWindows(TumblingEventTimeWindows.java:83) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.processElement(WindowOperator.java:302) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:191) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.processElement(StreamTaskNetworkInput.java:204) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.emitNext(StreamTaskNetworkInput.java:174) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:396) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:191) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:617) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:581) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:755) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:570) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at java.base/java.lang.Thread.run(Thread.java:834) ~[na:na]
2021-04-15 17:28:59,897 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (8e75427985233be7213de041d1c3d1c1) [FAILED]
2021-04-15 17:28:59,886 WARN org.apache.flink.runtime.taskmanager.Task - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (1fc0c843d84d9035cf29566105413ec3) switched from RUNNING to FAILED.
java.lang.RuntimeException: Record has Long.MIN_VALUE timestamp (= no timestamp marker). Is the time characteristic set to 'ProcessingTime', or did you forget to call 'DataStream.assignTimestampsAndWatermarks(...)'?
	at org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows.assignWindows(TumblingEventTimeWindows.java:83) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.processElement(WindowOperator.java:302) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:191) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.processElement(StreamTaskNetworkInput.java:204) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.emitNext(StreamTaskNetworkInput.java:174) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:396) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:191) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:617) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:581) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:755) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:570) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at java.base/java.lang.Thread.run(Thread.java:834) ~[na:na]
2021-04-15 17:28:59,887 WARN org.apache.flink.runtime.taskmanager.Task - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (3d4ed64e692ffae832219227e639362b) switched from RUNNING to FAILED.
java.lang.RuntimeException: Record has Long.MIN_VALUE timestamp (= no timestamp marker). Is the time characteristic set to 'ProcessingTime', or did you forget to call 'DataStream.assignTimestampsAndWatermarks(...)'?
	at org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows.assignWindows(TumblingEventTimeWindows.java:83) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.processElement(WindowOperator.java:302) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:191) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.processElement(StreamTaskNetworkInput.java:204) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.emitNext(StreamTaskNetworkInput.java:174) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:396) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:191) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:617) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:581) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:755) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:570) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at java.base/java.lang.Thread.run(Thread.java:834) ~[na:na]
2021-04-15 17:28:59,901 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (bf9a83bbf9e37b72a60cb03c1b019c6f) [FAILED]
2021-04-15 17:28:59,888 WARN org.apache.flink.runtime.taskmanager.Task - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (3ef01f533787fc90d59ba1b0dea6e401) switched from RUNNING to FAILED.
java.lang.RuntimeException: Record has Long.MIN_VALUE timestamp (= no timestamp marker). Is the time characteristic set to 'ProcessingTime', or did you forget to call 'DataStream.assignTimestampsAndWatermarks(...)'?
	at org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows.assignWindows(TumblingEventTimeWindows.java:83) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.processElement(WindowOperator.java:302) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:191) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.processElement(StreamTaskNetworkInput.java:204) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.emitNext(StreamTaskNetworkInput.java:174) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:396) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:191) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:617) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:581) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:755) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:570) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at java.base/java.lang.Thread.run(Thread.java:834) ~[na:na]
2021-04-15 17:28:59,888 WARN org.apache.flink.runtime.taskmanager.Task - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (af65f5e91794dcc4e71d1e622436d9d0) switched from RUNNING to FAILED.
java.lang.RuntimeException: Record has Long.MIN_VALUE timestamp (= no timestamp marker). Is the time characteristic set to 'ProcessingTime', or did you forget to call 'DataStream.assignTimestampsAndWatermarks(...)'?
	at org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows.assignWindows(TumblingEventTimeWindows.java:83) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.processElement(WindowOperator.java:302) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:191) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.processElement(StreamTaskNetworkInput.java:204) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.emitNext(StreamTaskNetworkInput.java:174) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:396) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:191) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:617) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:581) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:755) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:570) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at java.base/java.lang.Thread.run(Thread.java:834) ~[na:na]
2021-04-15 17:28:59,891 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (ae52a459d391bf1e41e481dde8b0dd7a).
2021-04-15 17:28:59,908 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 network resources (state: FAILED).
2021-04-15 17:28:59,908 DEBUG o.a.f.r.io.network.partition.consumer.SingleInputGate - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (ae52a459d391bf1e41e481dde8b0dd7a): Releasing SingleInputGate{owningTaskName='Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (ae52a459d391bf1e41e481dde8b0dd7a)', gateIndex=0}.
2021-04-15 17:28:59,898 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (1fc0c843d84d9035cf29566105413ec3).
2021-04-15 17:28:59,908 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - PipelinedResultPartition 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263 [PIPELINED_BOUNDED, 4 subpartitions, 2 pending consumptions]: Received consumed notification for subpartition 3.
2021-04-15 17:28:59,895 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (91eb55c4f793d71472f308bade398aa6).
2021-04-15 17:28:59,908 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 network resources (state: FAILED).
2021-04-15 17:28:59,900 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (3d4ed64e692ffae832219227e639362b).
2021-04-15 17:28:59,904 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (3ef01f533787fc90d59ba1b0dea6e401).
2021-04-15 17:28:59,911 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (ae52a459d391bf1e41e481dde8b0dd7a) [FAILED]
2021-04-15 17:28:59,906 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (af65f5e91794dcc4e71d1e622436d9d0).
2021-04-15 17:28:59,914 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 network resources (state: FAILED).
2021-04-15 17:28:59,914 DEBUG o.a.f.r.io.network.partition.consumer.SingleInputGate - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (1fc0c843d84d9035cf29566105413ec3): Releasing SingleInputGate{owningTaskName='Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (1fc0c843d84d9035cf29566105413ec3)', gateIndex=0}.
2021-04-15 17:28:59,915 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 network resources (state: FAILED).
2021-04-15 17:28:59,915 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 network resources (state: FAILED).
2021-04-15 17:28:59,907 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FAILED to JobManager for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 bf9a83bbf9e37b72a60cb03c1b019c6f.
2021-04-15 17:28:59,935 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 network resources (state: FAILED).
2021-04-15 17:28:59,938 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - PipelinedResultPartition de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263 [PIPELINED_BOUNDED, 4 subpartitions, 2 pending consumptions]: Received consumed notification for subpartition 3.
2021-04-15 17:28:59,938 DEBUG o.a.f.r.io.network.partition.consumer.SingleInputGate - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (3ef01f533787fc90d59ba1b0dea6e401): Releasing SingleInputGate{owningTaskName='Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (3ef01f533787fc90d59ba1b0dea6e401)', gateIndex=0}.
2021-04-15 17:28:59,938 DEBUG o.a.f.r.io.network.partition.consumer.SingleInputGate - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (3d4ed64e692ffae832219227e639362b): Releasing SingleInputGate{owningTaskName='Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (3d4ed64e692ffae832219227e639362b)', gateIndex=0}.
2021-04-15 17:28:59,938 DEBUG o.a.f.r.io.network.partition.consumer.SingleInputGate - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (91eb55c4f793d71472f308bade398aa6): Releasing SingleInputGate{owningTaskName='Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (91eb55c4f793d71472f308bade398aa6)', gateIndex=0}.
2021-04-15 17:28:59,996 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FAILED to JobManager for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 8e75427985233be7213de041d1c3d1c1.
2021-04-15 17:28:59,996 DEBUG o.a.f.r.io.network.partition.consumer.SingleInputGate - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (af65f5e91794dcc4e71d1e622436d9d0): Releasing SingleInputGate{owningTaskName='Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (af65f5e91794dcc4e71d1e622436d9d0)', gateIndex=0}.
2021-04-15 17:29:00,031 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4) (bf9a83bbf9e37b72a60cb03c1b019c6f) switched from RUNNING to FAILED on ef6044cc-9b73-466f-adb2-51c3fede0ecb @ server1 (dataPort=-1).
java.lang.RuntimeException: Record has Long.MIN_VALUE timestamp (= no timestamp marker). Is the time characteristic set to 'ProcessingTime', or did you forget to call 'DataStream.assignTimestampsAndWatermarks(...)'?
	at org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows.assignWindows(TumblingEventTimeWindows.java:83) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.processElement(WindowOperator.java:302) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:191) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.processElement(StreamTaskNetworkInput.java:204) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.emitNext(StreamTaskNetworkInput.java:174) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:396) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:191) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:617) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:581) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:755) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:570) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at java.base/java.lang.Thread.run(Thread.java:834) ~[na:na]
2021-04-15 17:29:00,032 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 (1fc0c843d84d9035cf29566105413ec3) [FAILED]
2021-04-15 17:29:00,033 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - PipelinedResultPartition 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263 [PIPELINED_BOUNDED, 4 subpartitions, 1 pending consumptions]: Received consumed notification for subpartition 2.
2021-04-15 17:29:00,034 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - PipelinedResultPartition 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263 [PIPELINED_BOUNDED, 4 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 1.
2021-04-15 17:29:00,035 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - PipelinedResultPartition de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263 [PIPELINED_BOUNDED, 4 subpartitions, 1 pending consumptions]: Received consumed notification for subpartition 2.
2021-04-15 17:29:00,038 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FAILED to JobManager for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 ae52a459d391bf1e41e481dde8b0dd7a.
2021-04-15 17:29:00,038 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - PipelinedResultPartition de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263 [PIPELINED_BOUNDED, 4 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
2021-04-15 17:29:00,040 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{44dec28b934c729e93c7aa49603f7244}) for execution vertex (id 20ba6b65f97481d5570070de90e4e791_0) from the physical slot (SlotRequestId{6fd88bd4c0f06c2e9666a4bdcaad74a9})
2021-04-15 17:29:00,043 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (3ef01f533787fc90d59ba1b0dea6e401) [FAILED]
2021-04-15 17:29:00,043 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Received consume notification from PipelinedResultPartition 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263 [PIPELINED_BOUNDED, 4 subpartitions, 0 pending consumptions].
2021-04-15 17:29:00,043 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 (91eb55c4f793d71472f308bade398aa6) [FAILED]
2021-04-15 17:29:00,044 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FAILED to JobManager for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4)#0 1fc0c843d84d9035cf29566105413ec3.
2021-04-15 17:29:00,045 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Received consume notification from PipelinedResultPartition de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263 [PIPELINED_BOUNDED, 4 subpartitions, 0 pending consumptions].
2021-04-15 17:29:00,049 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263): Releasing PipelinedResultPartition 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263 [PIPELINED_BOUNDED, 4 subpartitions, 0 pending consumptions].
2021-04-15 17:29:00,051 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FAILED to JobManager for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 3ef01f533787fc90d59ba1b0dea6e401.
2021-04-15 17:29:00,051 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263): Released PipelinedSubpartition#0 [number of buffers: 6 (32768 bytes), number of buffers in backlog: 5, finished? false, read view? false].
2021-04-15 17:29:00,053 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FAILED to JobManager for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4)#0 91eb55c4f793d71472f308bade398aa6.
2021-04-15 17:29:00,052 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263): Released PipelinedSubpartition#1 [number of buffers: 2 (25024 bytes), number of buffers in backlog: 2, finished? false, read view? false].
2021-04-15 17:29:00,054 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263): Released PipelinedSubpartition#2 [number of buffers: 6 (32768 bytes), number of buffers in backlog: 5, finished? false, read view? false].
2021-04-15 17:29:00,054 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263): Released PipelinedSubpartition#3 [number of buffers: 5 (32768 bytes), number of buffers in backlog: 4, finished? false, read view? false].
2021-04-15 17:29:00,055 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Released partition 0c19b5667f8c6e6f97ba20631ce4684a#0 produced by 66d7423dc3838d85e58caf33ce5d5263.
2021-04-15 17:29:00,055 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263): Releasing PipelinedResultPartition de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263 [PIPELINED_BOUNDED, 4 subpartitions, 0 pending consumptions].
2021-04-15 17:29:00,055 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 (3d4ed64e692ffae832219227e639362b) [FAILED]
2021-04-15 17:29:00,055 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263): Released PipelinedSubpartition#0 [number of buffers: 6 (32768 bytes), number of buffers in backlog: 5, finished? false, read view? false].
2021-04-15 17:29:00,056 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263): Released PipelinedSubpartition#1 [number of buffers: 2 (25024 bytes), number of buffers in backlog: 2, finished? false, read view? false].
2021-04-15 17:29:00,057 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263): Released PipelinedSubpartition#2 [number of buffers: 6 (32768 bytes), number of buffers in backlog: 5, finished? false, read view? false].
2021-04-15 17:29:00,057 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263): Released PipelinedSubpartition#3 [number of buffers: 5 (32768 bytes), number of buffers in backlog: 4, finished? false, read view? false].
2021-04-15 17:29:00,058 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Released partition de6cfc2767aee2878e4bd5659a97a073#0 produced by 66d7423dc3838d85e58caf33ce5d5263.
2021-04-15 17:29:00,058 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 (af65f5e91794dcc4e71d1e622436d9d0) [FAILED]
2021-04-15 17:29:00,059 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FAILED to JobManager for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4)#0 3d4ed64e692ffae832219227e639362b.
2021-04-15 17:29:00,060 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FAILED to JobManager for task Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4)#0 af65f5e91794dcc4e71d1e622436d9d0.
2021-04-15 17:29:00,098 INFO o.a.f.r.e.f.f.RestartPipelinedRegionFailoverStrategy - Calculating tasks to restart to recover the failed task 20ba6b65f97481d5570070de90e4e791_0.
2021-04-15 17:29:00,098 INFO o.a.f.r.e.f.f.RestartPipelinedRegionFailoverStrategy - 9 tasks should be restarted to recover the failed task 20ba6b65f97481d5570070de90e4e791_0. 
2021-04-15 17:29:00,101 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Job Flink Streaming Job (d8718395ee2b28f55a0cfaf6a66b2e05) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:118) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:80) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:233) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeHandleTaskFailure(DefaultScheduler.java:224) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.updateTaskExecutionStateInternal(DefaultScheduler.java:215) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:669) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:89) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:447) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:566) ~[na:na]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:305) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:212) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:77) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:158) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
Caused by: java.lang.RuntimeException: Record has Long.MIN_VALUE timestamp (= no timestamp marker). Is the time characteristic set to 'ProcessingTime', or did you forget to call 'DataStream.assignTimestampsAndWatermarks(...)'?
	at org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows.assignWindows(TumblingEventTimeWindows.java:83) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.processElement(WindowOperator.java:302) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:191) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.processElement(StreamTaskNetworkInput.java:204) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.emitNext(StreamTaskNetworkInput.java:174) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:396) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:191) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:617) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:581) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:755) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:570) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at java.base/java.lang.Thread.run(Thread.java:834) ~[na:na]
2021-04-15 17:29:00,107 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: sensor (1/1) (66d7423dc3838d85e58caf33ce5d5263) switched from RUNNING to CANCELING.
2021-04-15 17:29:00,110 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4) (3d4ed64e692ffae832219227e639362b) switched from RUNNING to CANCELING.
2021-04-15 17:29:00,111 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4) (3ef01f533787fc90d59ba1b0dea6e401) switched from RUNNING to CANCELING.
2021-04-15 17:29:00,112 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4) (ae52a459d391bf1e41e481dde8b0dd7a) switched from RUNNING to CANCELING.
2021-04-15 17:29:00,112 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4) (af65f5e91794dcc4e71d1e622436d9d0) switched from RUNNING to CANCELING.
2021-04-15 17:29:00,112 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4) (8e75427985233be7213de041d1c3d1c1) switched from RUNNING to CANCELING.
2021-04-15 17:29:00,113 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4) (91eb55c4f793d71472f308bade398aa6) switched from RUNNING to CANCELING.
2021-04-15 17:29:00,113 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4) (1fc0c843d84d9035cf29566105413ec3) switched from RUNNING to CANCELING.
2021-04-15 17:29:00,114 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4) (8e75427985233be7213de041d1c3d1c1) switched from CANCELING to CANCELED.
2021-04-15 17:29:00,115 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4) - execution #0 to FAILED while being CANCELED.
2021-04-15 17:29:00,115 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{d517f52447a961afbae9e735eeb4f2da}) for execution vertex (id 51397532e2d9c7a21097a30d590b3114_1) from the physical slot (SlotRequestId{ae2bfb57e9478aaead0214ede0b26917})
2021-04-15 17:29:00,115 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Discarding the results produced by task execution 8e75427985233be7213de041d1c3d1c1.
2021-04-15 17:29:00,117 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4) (ae52a459d391bf1e41e481dde8b0dd7a) switched from CANCELING to CANCELED.
2021-04-15 17:29:00,117 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4) - execution #0 to FAILED while being CANCELED.
2021-04-15 17:29:00,118 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{7a8a4d44cc5a0ad843c4b5c7d01c4bd9}) for execution vertex (id 20ba6b65f97481d5570070de90e4e791_3) from the physical slot (SlotRequestId{a41f22f3d50f82ffcadd588ae3adf6df})
2021-04-15 17:29:00,118 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Discarding the results produced by task execution ae52a459d391bf1e41e481dde8b0dd7a.
2021-04-15 17:29:00,118 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4) (1fc0c843d84d9035cf29566105413ec3) switched from CANCELING to CANCELED.
2021-04-15 17:29:00,118 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4) - execution #0 to FAILED while being CANCELED.
2021-04-15 17:29:00,118 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{532c60e056507a431696474bc64a7b39}) for execution vertex (id 51397532e2d9c7a21097a30d590b3114_3) from the physical slot (SlotRequestId{a41f22f3d50f82ffcadd588ae3adf6df})
2021-04-15 17:29:00,118 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Release shared slot externally (SlotRequestId{a41f22f3d50f82ffcadd588ae3adf6df})
2021-04-15 17:29:00,118 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Releasing slot [SlotRequestId{a41f22f3d50f82ffcadd588ae3adf6df}] because: Slot is being returned from SlotSharingExecutionSlotAllocator.
2021-04-15 17:29:00,119 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Release shared slot (SlotRequestId{a41f22f3d50f82ffcadd588ae3adf6df})
2021-04-15 17:29:00,119 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Adding slot [a452818f247f624c8b1f33ad6f3c4488] to available slots
2021-04-15 17:29:00,120 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Discarding the results produced by task execution 1fc0c843d84d9035cf29566105413ec3.
2021-04-15 17:29:00,121 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4) (3ef01f533787fc90d59ba1b0dea6e401) switched from CANCELING to CANCELED.
2021-04-15 17:29:00,121 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4) - execution #0 to FAILED while being CANCELED.
2021-04-15 17:29:00,121 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{40952385085fa845a482736a53e1ba3c}) for execution vertex (id 20ba6b65f97481d5570070de90e4e791_2) from the physical slot (SlotRequestId{e59b4bc1bf5eeef4c879e386809570ef})
2021-04-15 17:29:00,122 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Discarding the results produced by task execution 3ef01f533787fc90d59ba1b0dea6e401.
2021-04-15 17:29:00,122 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4) (91eb55c4f793d71472f308bade398aa6) switched from CANCELING to CANCELED.
2021-04-15 17:29:00,122 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4) - execution #0 to FAILED while being CANCELED.
2021-04-15 17:29:00,123 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{321bc34c9f4068ea144a98be04136475}) for execution vertex (id 51397532e2d9c7a21097a30d590b3114_2) from the physical slot (SlotRequestId{e59b4bc1bf5eeef4c879e386809570ef})
2021-04-15 17:29:00,123 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Release shared slot externally (SlotRequestId{e59b4bc1bf5eeef4c879e386809570ef})
2021-04-15 17:29:00,123 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Releasing slot [SlotRequestId{e59b4bc1bf5eeef4c879e386809570ef}] because: Slot is being returned from SlotSharingExecutionSlotAllocator.
2021-04-15 17:29:00,123 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Release shared slot (SlotRequestId{e59b4bc1bf5eeef4c879e386809570ef})
2021-04-15 17:29:00,123 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Adding slot [6c4cfaa4e375e41e70c49cba42f8c112] to available slots
2021-04-15 17:29:00,123 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Discarding the results produced by task execution 91eb55c4f793d71472f308bade398aa6.
2021-04-15 17:29:00,124 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4) (3d4ed64e692ffae832219227e639362b) switched from CANCELING to CANCELED.
2021-04-15 17:29:00,128 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4) - execution #0 to FAILED while being CANCELED.
2021-04-15 17:29:00,128 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{64b8c7d19640e2845b1afa4958b9d9b9}) for execution vertex (id 20ba6b65f97481d5570070de90e4e791_1) from the physical slot (SlotRequestId{ae2bfb57e9478aaead0214ede0b26917})
2021-04-15 17:29:00,128 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Release shared slot externally (SlotRequestId{ae2bfb57e9478aaead0214ede0b26917})
2021-04-15 17:29:00,128 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Releasing slot [SlotRequestId{ae2bfb57e9478aaead0214ede0b26917}] because: Slot is being returned from SlotSharingExecutionSlotAllocator.
2021-04-15 17:29:00,128 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Release shared slot (SlotRequestId{ae2bfb57e9478aaead0214ede0b26917})
2021-04-15 17:29:00,128 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Adding slot [2d67f315f3b1d02910ae44e43f082e57] to available slots
2021-04-15 17:29:00,125 INFO org.apache.flink.runtime.taskmanager.Task - Attempting to cancel task Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263).
2021-04-15 17:29:00,129 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Discarding the results produced by task execution 3d4ed64e692ffae832219227e639362b.
2021-04-15 17:29:00,130 INFO org.apache.flink.runtime.taskmanager.Task - Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263) switched from RUNNING to CANCELING.
2021-04-15 17:29:00,131 INFO org.apache.flink.runtime.taskmanager.Task - Triggering cancellation of task code Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263).
2021-04-15 17:29:00,134 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4) (af65f5e91794dcc4e71d1e622436d9d0) switched from CANCELING to CANCELED.
2021-04-15 17:29:00,134 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4) - execution #0 to FAILED while being CANCELED.
2021-04-15 17:29:00,134 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{df8a509e9044767a72c3c5023dbd7cc4}) for execution vertex (id 51397532e2d9c7a21097a30d590b3114_0) from the physical slot (SlotRequestId{6fd88bd4c0f06c2e9666a4bdcaad74a9})
2021-04-15 17:29:00,134 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Discarding the results produced by task execution af65f5e91794dcc4e71d1e622436d9d0.
2021-04-15 17:29:00,135 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution 3d4ed64e692ffae832219227e639362b.
2021-04-15 17:29:00,135 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution 3ef01f533787fc90d59ba1b0dea6e401.
2021-04-15 17:29:00,135 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution ae52a459d391bf1e41e481dde8b0dd7a.
2021-04-15 17:29:00,135 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution af65f5e91794dcc4e71d1e622436d9d0.
2021-04-15 17:29:00,136 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution 8e75427985233be7213de041d1c3d1c1.
2021-04-15 17:29:00,136 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution 91eb55c4f793d71472f308bade398aa6.
2021-04-15 17:29:00,137 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution 1fc0c843d84d9035cf29566105413ec3.
2021-04-15 17:29:00,137 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution 3d4ed64e692ffae832219227e639362b.
2021-04-15 17:29:00,137 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution 3ef01f533787fc90d59ba1b0dea6e401.
2021-04-15 17:29:00,138 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution ae52a459d391bf1e41e481dde8b0dd7a.
2021-04-15 17:29:00,139 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution af65f5e91794dcc4e71d1e622436d9d0.
2021-04-15 17:29:00,139 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution 8e75427985233be7213de041d1c3d1c1.
2021-04-15 17:29:00,139 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution 91eb55c4f793d71472f308bade398aa6.
2021-04-15 17:29:00,139 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution 1fc0c843d84d9035cf29566105413ec3.
2021-04-15 17:29:00,143 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution 3d4ed64e692ffae832219227e639362b.
2021-04-15 17:29:00,143 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution 3ef01f533787fc90d59ba1b0dea6e401.
2021-04-15 17:29:00,144 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution ae52a459d391bf1e41e481dde8b0dd7a.
2021-04-15 17:29:00,144 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution af65f5e91794dcc4e71d1e622436d9d0.
2021-04-15 17:29:00,144 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution 8e75427985233be7213de041d1c3d1c1.
2021-04-15 17:29:00,144 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution 91eb55c4f793d71472f308bade398aa6.
2021-04-15 17:29:00,144 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution 1fc0c843d84d9035cf29566105413ec3.
2021-04-15 17:29:00,146 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution 3d4ed64e692ffae832219227e639362b.
2021-04-15 17:29:00,146 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution 3ef01f533787fc90d59ba1b0dea6e401.
2021-04-15 17:29:00,146 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution ae52a459d391bf1e41e481dde8b0dd7a.
2021-04-15 17:29:00,146 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution af65f5e91794dcc4e71d1e622436d9d0.
2021-04-15 17:29:00,146 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution 8e75427985233be7213de041d1c3d1c1.
2021-04-15 17:29:00,146 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution 91eb55c4f793d71472f308bade398aa6.
2021-04-15 17:29:00,146 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Cannot find task to stop for execution 1fc0c843d84d9035cf29566105413ec3.
2021-04-15 17:29:00,150 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4) - execution #0 to FAILED while being CANCELED.
2021-04-15 17:29:00,151 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4) - execution #0 to FAILED while being CANCELED.
2021-04-15 17:29:00,151 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Window(TumblingEventTimeWindows(15000), EventTimeTrigger, AggregateFunction$1, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4) - execution #0 to FAILED while being CANCELED.
2021-04-15 17:29:00,151 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/4) - execution #0 to FAILED while being CANCELED.
2021-04-15 17:29:00,151 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/4) - execution #0 to FAILED while being CANCELED.
2021-04-15 17:29:00,151 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/4) - execution #0 to FAILED while being CANCELED.
2021-04-15 17:29:00,151 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Window(TumblingEventTimeWindows(15000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/4) - execution #0 to FAILED while being CANCELED.
2021-04-15 17:29:00,156 DEBUG o.a.f.streaming.runtime.tasks.mailbox.MailboxProcessor - Closing the mailbox dropped mails [poison mail].
2021-04-15 17:29:00,158 INFO org.apache.flink.runtime.taskmanager.Task - Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263) switched from CANCELING to CANCELED.
2021-04-15 17:29:00,158 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263).
2021-04-15 17:29:00,159 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task Source: sensor (1/1)#0 network resources (state: CANCELED).
2021-04-15 17:29:00,159 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - unregistering 0c19b5667f8c6e6f97ba20631ce4684a#0@66d7423dc3838d85e58caf33ce5d5263
2021-04-15 17:29:00,159 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - unregistering de6cfc2767aee2878e4bd5659a97a073#0@66d7423dc3838d85e58caf33ce5d5263
2021-04-15 17:29:00,159 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Source: sensor (1/1)#0 (66d7423dc3838d85e58caf33ce5d5263) [CANCELED]
2021-04-15 17:29:00,160 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state CANCELED to JobManager for task Source: sensor (1/1)#0 66d7423dc3838d85e58caf33ce5d5263.
2021-04-15 17:29:00,161 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: sensor (1/1) (66d7423dc3838d85e58caf33ce5d5263) switched from CANCELING to CANCELED.
2021-04-15 17:29:00,161 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Source: sensor (1/1) - execution #0 to FAILED while being CANCELED.
2021-04-15 17:29:00,161 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{afcf44bda7398f5bd637836fe4207923}) for execution vertex (id bc764cd8ddf7a0cff126f51c16239658_0) from the physical slot (SlotRequestId{6fd88bd4c0f06c2e9666a4bdcaad74a9})
2021-04-15 17:29:00,161 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Release shared slot externally (SlotRequestId{6fd88bd4c0f06c2e9666a4bdcaad74a9})
2021-04-15 17:29:00,161 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Releasing slot [SlotRequestId{6fd88bd4c0f06c2e9666a4bdcaad74a9}] because: Slot is being returned from SlotSharingExecutionSlotAllocator.
2021-04-15 17:29:00,161 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Release shared slot (SlotRequestId{6fd88bd4c0f06c2e9666a4bdcaad74a9})
2021-04-15 17:29:00,161 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Adding slot [fa490bb8b06dc7ecb79de4620856f76e] to available slots
2021-04-15 17:29:00,163 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Job Flink Streaming Job (d8718395ee2b28f55a0cfaf6a66b2e05) switched from state FAILING to FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:118) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:80) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:233) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeHandleTaskFailure(DefaultScheduler.java:224) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.updateTaskExecutionStateInternal(DefaultScheduler.java:215) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:669) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:89) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:447) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:566) ~[na:na]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:305) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:212) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:77) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:158) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
Caused by: java.lang.RuntimeException: Record has Long.MIN_VALUE timestamp (= no timestamp marker). Is the time characteristic set to 'ProcessingTime', or did you forget to call 'DataStream.assignTimestampsAndWatermarks(...)'?
	at org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows.assignWindows(TumblingEventTimeWindows.java:83) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.processElement(WindowOperator.java:302) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:191) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.processElement(StreamTaskNetworkInput.java:204) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.emitNext(StreamTaskNetworkInput.java:174) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:396) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:191) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:617) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:581) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:755) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:570) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at java.base/java.lang.Thread.run(Thread.java:834) ~[na:na]
2021-04-15 17:29:00,168 INFO o.apache.flink.runtime.checkpoint.CheckpointCoordinator - Stopping checkpoint coordinator for job d8718395ee2b28f55a0cfaf6a66b2e05.
2021-04-15 17:29:00,173 INFO o.a.f.r.checkpoint.StandaloneCompletedCheckpointStore - Shutting down
2021-04-15 17:29:00,181 INFO org.apache.flink.runtime.minicluster.MiniCluster - Shutting down Flink Mini Cluster
2021-04-15 17:29:00,182 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Shutting down rest endpoint.
2021-04-15 17:29:00,183 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Job d8718395ee2b28f55a0cfaf6a66b2e05 reached globally terminal state FAILED.
2021-04-15 17:29:00,185 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Stopping TaskExecutor akka://flink/user/rpc/taskmanager_0.
2021-04-15 17:29:00,186 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Close ResourceManager connection e9f26642f0390994af4a8d488e229fc0.
org.apache.flink.util.FlinkException: The TaskExecutor is shutting down.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:424) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:214) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:563) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:186) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 17:29:00,188 INFO org.apache.flink.runtime.jobmaster.JobMaster - Stopping the JobMaster for job Flink Streaming Job(d8718395ee2b28f55a0cfaf6a66b2e05).
2021-04-15 17:29:00,190 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Disconnect TaskExecutor ef6044cc-9b73-466f-adb2-51c3fede0ecb because: Stopping JobMaster for job Flink Streaming Job(d8718395ee2b28f55a0cfaf6a66b2e05).
2021-04-15 17:29:00,190 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Closing TaskExecutor connection ef6044cc-9b73-466f-adb2-51c3fede0ecb because: The TaskExecutor is shutting down.
2021-04-15 17:29:00,190 DEBUG o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Unregister TaskManager 6952b71a1cb3afec877a0dbde6f12488 from the SlotManager.
2021-04-15 17:29:00,190 DEBUG o.a.f.r.i.n.p.ResourceManagerPartitionTrackerImpl - Processing shutdown of task executor ef6044cc-9b73-466f-adb2-51c3fede0ecb.
2021-04-15 17:29:00,191 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Suspending SlotPool.
2021-04-15 17:29:00,191 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Close ResourceManager connection e9f26642f0390994af4a8d488e229fc0.
org.apache.flink.util.FlinkException: Stopping JobMaster for job Flink Streaming Job(d8718395ee2b28f55a0cfaf6a66b2e05).
	at org.apache.flink.runtime.jobmaster.JobMaster.onStop(JobMaster.java:416) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:214) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:563) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:186) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 17:29:00,192 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Stopping SlotPool.
2021-04-15 17:29:00,196 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Disconnect job manager add3b7d8d2a183ffb0f25b05446c42f5@akka://flink/user/rpc/jobmanager_3 for job d8718395ee2b28f55a0cfaf6a66b2e05 from the resource manager.
2021-04-15 17:29:00,197 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Close JobManager connection for job d8718395ee2b28f55a0cfaf6a66b2e05.
org.apache.flink.util.FlinkException: The TaskExecutor is shutting down.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:424) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:214) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:563) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:186) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 17:29:00,202 DEBUG o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Free slot TaskSlot(index:1, state:ALLOCATED, resource profile: ResourceProfile{managedMemory=32.000mb (33554432 bytes), networkMemory=16.000mb (16777216 bytes)}, allocationId: a452818f247f624c8b1f33ad6f3c4488, jobId: d8718395ee2b28f55a0cfaf6a66b2e05).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:169) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:441) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:214) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:563) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:186) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 17:29:00,205 DEBUG o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Free slot TaskSlot(index:0, state:ALLOCATED, resource profile: ResourceProfile{managedMemory=32.000mb (33554432 bytes), networkMemory=16.000mb (16777216 bytes)}, allocationId: 2d67f315f3b1d02910ae44e43f082e57, jobId: d8718395ee2b28f55a0cfaf6a66b2e05).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:169) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:441) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:214) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:563) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:186) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 17:29:00,206 DEBUG o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Free slot TaskSlot(index:2, state:ALLOCATED, resource profile: ResourceProfile{managedMemory=32.000mb (33554432 bytes), networkMemory=16.000mb (16777216 bytes)}, allocationId: 6c4cfaa4e375e41e70c49cba42f8c112, jobId: d8718395ee2b28f55a0cfaf6a66b2e05).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:169) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:441) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:214) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:563) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:186) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 17:29:00,207 DEBUG o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Free slot TaskSlot(index:3, state:ALLOCATED, resource profile: ResourceProfile{managedMemory=32.000mb (33554432 bytes), networkMemory=16.000mb (16777216 bytes)}, allocationId: fa490bb8b06dc7ecb79de4620856f76e, jobId: d8718395ee2b28f55a0cfaf6a66b2e05).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:169) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:441) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:214) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:563) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:186) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 17:29:00,208 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Free slot with allocation id 6c4cfaa4e375e41e70c49cba42f8c112 because: Stopping JobMaster for job Flink Streaming Job(d8718395ee2b28f55a0cfaf6a66b2e05).
2021-04-15 17:29:00,209 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Could not free slot for allocation id 6c4cfaa4e375e41e70c49cba42f8c112.
org.apache.flink.runtime.taskexecutor.slot.SlotNotFoundException: Could not find slot for 6c4cfaa4e375e41e70c49cba42f8c112.
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.freeSlot(TaskSlotTableImpl.java:409) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlotInternal(TaskExecutor.java:1798) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlot(TaskExecutor.java:1105) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:566) ~[na:na]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:305) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:212) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:158) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 17:29:00,209 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Releasing local state under allocation id 6c4cfaa4e375e41e70c49cba42f8c112.
2021-04-15 17:29:00,227 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Free slot with allocation id fa490bb8b06dc7ecb79de4620856f76e because: Stopping JobMaster for job Flink Streaming Job(d8718395ee2b28f55a0cfaf6a66b2e05).
2021-04-15 17:29:00,227 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Could not free slot for allocation id fa490bb8b06dc7ecb79de4620856f76e.
org.apache.flink.runtime.taskexecutor.slot.SlotNotFoundException: Could not find slot for fa490bb8b06dc7ecb79de4620856f76e.
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.freeSlot(TaskSlotTableImpl.java:409) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlotInternal(TaskExecutor.java:1798) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlot(TaskExecutor.java:1105) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:566) ~[na:na]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:305) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:212) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:158) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 17:29:00,227 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Releasing local state under allocation id fa490bb8b06dc7ecb79de4620856f76e.
2021-04-15 17:29:00,230 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Free slot with allocation id a452818f247f624c8b1f33ad6f3c4488 because: Stopping JobMaster for job Flink Streaming Job(d8718395ee2b28f55a0cfaf6a66b2e05).
2021-04-15 17:29:00,232 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Could not free slot for allocation id a452818f247f624c8b1f33ad6f3c4488.
org.apache.flink.runtime.taskexecutor.slot.SlotNotFoundException: Could not find slot for a452818f247f624c8b1f33ad6f3c4488.
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.freeSlot(TaskSlotTableImpl.java:409) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlotInternal(TaskExecutor.java:1798) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlot(TaskExecutor.java:1105) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:566) ~[na:na]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:305) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:212) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:158) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 17:29:00,238 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Releasing local state under allocation id a452818f247f624c8b1f33ad6f3c4488.
2021-04-15 17:29:00,248 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Free slot with allocation id 2d67f315f3b1d02910ae44e43f082e57 because: Stopping JobMaster for job Flink Streaming Job(d8718395ee2b28f55a0cfaf6a66b2e05).
2021-04-15 17:29:00,252 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Could not free slot for allocation id 2d67f315f3b1d02910ae44e43f082e57.
org.apache.flink.runtime.taskexecutor.slot.SlotNotFoundException: Could not find slot for 2d67f315f3b1d02910ae44e43f082e57.
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.freeSlot(TaskSlotTableImpl.java:409) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlotInternal(TaskExecutor.java:1798) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlot(TaskExecutor.java:1105) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:566) ~[na:na]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:305) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:212) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:158) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 17:29:00,252 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Releasing local state under allocation id 2d67f315f3b1d02910ae44e43f082e57.
2021-04-15 17:29:00,263 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Stop job leader service.
2021-04-15 17:29:00,263 INFO o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Shutting down TaskExecutorLocalStateStoresManager.
2021-04-15 17:29:00,264 DEBUG org.apache.flink.runtime.io.disk.iomanager.IOManager - Shutting down I/O manager.
2021-04-15 17:29:00,271 DEBUG org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor - The RpcEndpoint jobmanager_3 terminated successfully.
2021-04-15 17:29:00,312 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - AkkaRpcActor akka://flink/user/rpc/jobmanager_3 has terminated.
2021-04-15 17:29:00,318 INFO org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager removed spill file directory C:\Users\ccy\AppData\Local\Temp\flink-io-ba4ad1b3-43e0-481a-8e0d-6343ad3178b4
2021-04-15 17:29:00,318 INFO o.a.flink.runtime.io.network.NettyShuffleEnvironment - Shutting down the network environment and its components.
2021-04-15 17:29:00,318 DEBUG o.a.flink.runtime.io.network.NettyShuffleEnvironment - Shutting down network connection manager
2021-04-15 17:29:00,318 DEBUG o.a.flink.runtime.io.network.NettyShuffleEnvironment - Shutting down intermediate result partition manager
2021-04-15 17:29:00,318 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Releasing 0 partitions because of shutdown.
2021-04-15 17:29:00,318 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Successful shutdown.
2021-04-15 17:29:00,328 INFO org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager removed spill file directory C:\Users\ccy\AppData\Local\Temp\flink-netty-shuffle-3f62f909-24a2-4d5a-953f-536d5cbab833
2021-04-15 17:29:00,328 INFO org.apache.flink.runtime.taskexecutor.KvStateService - Shutting down the kvState service and its components.
2021-04-15 17:29:00,328 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Stop job leader service.
2021-04-15 17:29:00,332 DEBUG o.a.flink.runtime.resourcemanager.JobLeaderIdService - Found a new job leader null@null.
2021-04-15 17:29:00,334 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Discard job leader lost leadership for outdated leader add3b7d8d2a183ffb0f25b05446c42f5 for job d8718395ee2b28f55a0cfaf6a66b2e05.
2021-04-15 17:29:00,338 INFO org.apache.flink.runtime.filecache.FileCache - removed file cache directory C:\Users\ccy\AppData\Local\Temp\flink-dist-cache-09a4c3bd-7ec2-40f4-8d91-ba56e1dd077f
2021-04-15 17:29:00,338 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Stopped TaskExecutor akka://flink/user/rpc/taskmanager_0.
2021-04-15 17:29:00,339 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcActor - The RpcEndpoint taskmanager_0 terminated successfully.
2021-04-15 17:29:00,339 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - AkkaRpcActor akka://flink/user/rpc/taskmanager_0 has terminated.
2021-04-15 17:29:00,343 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Removing cache directory C:\Users\ccy\AppData\Local\Temp\flink-web-ui
2021-04-15 17:29:00,344 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Shut down complete.
2021-04-15 17:29:00,367 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..
2021-04-15 17:29:00,369 INFO o.a.f.r.e.component.DispatcherResourceManagerComponent - Closing components.
2021-04-15 17:29:00,370 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Stopping SessionDispatcherLeaderProcess.
2021-04-15 17:29:00,370 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Stopping dispatcher akka://flink/user/rpc/dispatcher_2.
2021-04-15 17:29:00,370 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Stopping all currently running jobs of dispatcher akka://flink/user/rpc/dispatcher_2.
2021-04-15 17:29:00,371 INFO o.a.f.r.r.h.l.b.BackPressureRequestCoordinator - Shutting down back pressure request coordinator.
2021-04-15 17:29:00,371 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Stopped dispatcher akka://flink/user/rpc/dispatcher_2.
2021-04-15 17:29:00,371 DEBUG org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor - The RpcEndpoint dispatcher_2 terminated successfully.
2021-04-15 17:29:00,372 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - AkkaRpcActor akka://flink/user/rpc/dispatcher_2 has terminated.
2021-04-15 17:29:00,375 INFO o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Closing the SlotManager.
2021-04-15 17:29:00,375 INFO o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Suspending the SlotManager.
2021-04-15 17:29:00,376 DEBUG org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor - The RpcEndpoint resourcemanager_1 terminated successfully.
2021-04-15 17:29:00,376 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - AkkaRpcActor akka://flink/user/rpc/resourcemanager_1 has terminated.
2021-04-15 17:29:00,377 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Stopping Akka RPC service.
2021-04-15 17:29:00,389 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcActor - The RpcEndpoint MetricQueryService terminated successfully.
2021-04-15 17:29:00,390 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - AkkaRpcActor akka://flink-metrics/user/rpc/MetricQueryService has terminated.
2021-04-15 17:29:00,419 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Stopping supervisor actor.
2021-04-15 17:29:00,445 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Stopping Akka RPC service.
2021-04-15 17:29:00,445 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Stopped Akka RPC service.
2021-04-15 17:29:00,446 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Stopping supervisor actor.
2021-04-15 17:29:00,446 DEBUG akka.event.EventStream - shutting down: StandardOutLogger
2021-04-15 17:29:00,455 INFO org.apache.flink.runtime.blob.PermanentBlobCache - Shutting down BLOB cache
2021-04-15 17:29:00,456 INFO org.apache.flink.runtime.blob.TransientBlobCache - Shutting down BLOB cache
2021-04-15 17:29:00,459 INFO org.apache.flink.runtime.blob.BlobServer - Stopped BLOB server at 0.0.0.0:61582
2021-04-15 17:29:00,459 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Stopped Akka RPC service.
2021-04-15 17:32:10,279 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:32:10,283 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.util.Random
2021-04-15 17:32:10,335 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
2021-04-15 17:32:10,336 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:32:10,336 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:32:10,338 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:32:10,338 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:32:10,339 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:32:10,408 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySinkTransformation{id=2, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=4}
2021-04-15 17:32:10,421 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySourceTransformation{id=1, name='sensor', outputType=PojoType<org.myorg.quickstart.dto.SensorReading, fields = [id: String, temperature: Double, timestamp: Long]>, parallelism=1}
2021-04-15 17:32:10,451 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 1
2021-04-15 17:32:10,453 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 2
2021-04-15 17:32:10,555 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'bc764cd8ddf7a0cff126f51c16239658' for node 'Source: sensor-1' {id: 1, parallelism: 1, user function: org.myorg.quickstart.util.SourceUtil}
2021-04-15 17:32:10,556 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '0a448493b4782967b150582570326227' for node 'Sink: Print to Std. Out-2' {id: 2, parallelism: 4, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
2021-04-15 17:32:10,582 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 4 for 2
2021-04-15 17:32:10,631 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 1
2021-04-15 17:32:10,647 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - CONNECTED: RebalancePartitioner - 1 -> 2
2021-04-15 17:32:10,696 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.
2021-04-15 17:32:10,697 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.
2021-04-15 17:32:10,697 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.
2021-04-15 17:32:10,698 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.min required for local execution is not set, setting it to its default value 64 mb.
2021-04-15 17:32:10,699 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.max required for local execution is not set, setting it to its default value 64 mb.
2021-04-15 17:32:10,699 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.
2021-04-15 17:32:10,730 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting Flink Mini Cluster
2021-04-15 17:32:10,730 DEBUG org.apache.flink.runtime.minicluster.MiniCluster - Using configuration MiniClusterConfiguration {singleRpcService=SHARED, numTaskManagers=1, commonBindAddress='null', config={taskmanager.memory.network.min=64 mb, taskmanager.cpu.cores=1.7976931348623157E308, taskmanager.memory.task.off-heap.size=9223372036854775807 bytes, execution.target=local, rest.bind-port=0, taskmanager.memory.network.max=64 mb, execution.attached=true, taskmanager.memory.managed.size=128 mb, parallelism.default=4, taskmanager.numberOfTaskSlots=4, taskmanager.memory.task.heap.size=9223372036854775807 bytes, rest.address=localhost}}
2021-04-15 17:32:10,733 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting Metrics Registry
2021-04-15 17:32:10,801 INFO org.apache.flink.runtime.metrics.MetricRegistryImpl - No metrics reporter configured, no metrics will be exposed/reported.
2021-04-15 17:32:10,802 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting RPC Service(s)
2021-04-15 17:32:10,988 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
2021-04-15 17:32:11,000 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Using akka configuration
 Config(SimpleConfigObject({"akka":{"actor":{"default-dispatcher":{"executor":"fork-join-executor","fork-join-executor":{"parallelism-factor":1,"parallelism-max":4,"parallelism-min":2},"throughput":15},"guardian-supervisor-strategy":"org.apache.flink.runtime.akka.EscalatingSupervisorStrategy","supervisor-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"type":"Dispatcher"},"warn-about-java-serializer-usage":"off"},"daemonic":"off","jvm-exit-on-fatal-error":"on","log-config-on-start":"off","log-dead-letters":"off","log-dead-letters-during-shutdown":"off","logger-startup-timeout":"30s","loggers":["akka.event.slf4j.Slf4jLogger"],"logging-filter":"akka.event.slf4j.Slf4jLoggingFilter","loglevel":"DEBUG","serialize-messages":"off","stdout-loglevel":"OFF"}}))
2021-04-15 17:32:11,630 INFO akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2021-04-15 17:32:11,642 DEBUG akka.event.EventStream - logger log1-Slf4jLogger started
2021-04-15 17:32:11,645 DEBUG akka.event.EventStream - Default Loggers started
2021-04-15 17:32:12,374 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink
2021-04-15 17:32:12,410 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
2021-04-15 17:32:12,414 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Using akka configuration
 Config(SimpleConfigObject({"akka":{"actor":{"default-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"thread-priority":1,"throughput":15,"type":"akka.dispatch.PriorityThreadsDispatcher"},"guardian-supervisor-strategy":"org.apache.flink.runtime.akka.EscalatingSupervisorStrategy","supervisor-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"type":"Dispatcher"},"warn-about-java-serializer-usage":"off"},"daemonic":"off","jvm-exit-on-fatal-error":"on","log-config-on-start":"off","log-dead-letters":"off","log-dead-letters-during-shutdown":"off","logger-startup-timeout":"30s","loggers":["akka.event.slf4j.Slf4jLogger"],"logging-filter":"akka.event.slf4j.Slf4jLoggingFilter","loglevel":"DEBUG","serialize-messages":"off","stdout-loglevel":"OFF"}}))
2021-04-15 17:32:12,446 INFO akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2021-04-15 17:32:12,539 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink-metrics
2021-04-15 17:32:12,603 DEBUG akka.event.EventStream - logger log1-Slf4jLogger started
2021-04-15 17:32:12,605 DEBUG akka.event.EventStream - Default Loggers started
2021-04-15 17:32:12,611 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting AkkaRpcActor with name MetricQueryService.
2021-04-15 17:32:12,620 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
2021-04-15 17:32:13,116 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting high-availability services
2021-04-15 17:32:14,127 INFO org.apache.flink.runtime.blob.BlobServer - Created BLOB server storage directory C:\Users\ccy\AppData\Local\Temp\blobStore-eac5cbc1-db3e-4460-992e-5052e19185c3
2021-04-15 17:32:14,136 DEBUG org.apache.flink.util.NetUtils - Trying to open socket on port 0
2021-04-15 17:32:14,138 INFO org.apache.flink.runtime.blob.BlobServer - Started BLOB server at 0.0.0.0:61659 - max concurrent requests: 50 - max backlog: 1000
2021-04-15 17:32:14,142 INFO org.apache.flink.runtime.blob.PermanentBlobCache - Created BLOB cache storage directory C:\Users\ccy\AppData\Local\Temp\blobStore-9348da7e-23a4-4b0b-ba97-186323488fa9
2021-04-15 17:32:14,144 INFO org.apache.flink.runtime.blob.TransientBlobCache - Created BLOB cache storage directory C:\Users\ccy\AppData\Local\Temp\blobStore-94ed4399-665d-425b-aaf6-f586aa0e3c46
2021-04-15 17:32:14,145 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting 1 TaskManger(s)
2021-04-15 17:32:14,149 INFO org.apache.flink.runtime.taskexecutor.TaskManagerRunner - Starting TaskManager with ResourceID: 150961bf-a51f-4fb1-8d0d-be97ee0834aa
2021-04-15 17:32:14,181 INFO o.apache.flink.runtime.taskexecutor.TaskManagerServices - Temporary file directory 'C:\Users\ccy\AppData\Local\Temp': total 137 GB, usable 24 GB (17.52% usable)
2021-04-15 17:32:14,185 INFO org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\ccy\AppData\Local\Temp\flink-io-4df13810-bb54-4b50-aa72-bd145567e6c7 for spill files.
2021-04-15 17:32:14,196 INFO org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\ccy\AppData\Local\Temp\flink-netty-shuffle-dc9bad2f-1df5-4c3b-9140-542aef38fe79 for spill files.
2021-04-15 17:32:14,242 INFO o.a.flink.runtime.io.network.buffer.NetworkBufferPool - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2021-04-15 17:32:14,252 INFO o.a.flink.runtime.io.network.NettyShuffleEnvironment - Starting the network environment and its components.
2021-04-15 17:32:14,252 DEBUG o.a.flink.runtime.io.network.NettyShuffleEnvironment - Starting network connection manager
2021-04-15 17:32:14,254 INFO org.apache.flink.runtime.taskexecutor.KvStateService - Starting the kvState service and its components.
2021-04-15 17:32:14,266 DEBUG o.a.flink.runtime.taskexecutor.TaskManagerConfiguration - Messages have a max timeout of 10000 ms
2021-04-15 17:32:14,277 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting AkkaRpcActor with name taskmanager_0.
2021-04-15 17:32:14,277 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2021-04-15 17:32:14,291 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Start job leader service.
2021-04-15 17:32:14,293 INFO org.apache.flink.runtime.filecache.FileCache - User file cache uses directory C:\Users\ccy\AppData\Local\Temp\flink-dist-cache-89b2c05a-586c-4b73-90dc-e2615deae69a
2021-04-15 17:32:14,332 DEBUG o.a.f.r.e.c.DefaultDispatcherResourceManagerComponentFactory - Starting Dispatcher REST endpoint.
2021-04-15 17:32:14,333 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Starting rest endpoint.
2021-04-15 17:32:14,347 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Failed to load web based job submission extension.
org.apache.flink.util.FlinkException: The module flink-runtime-web could not be found in the class path. Please add this jar in order to enable web based job submission.
	at org.apache.flink.runtime.webmonitor.WebMonitorUtils.loadWebSubmissionExtension(WebMonitorUtils.java:199) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint.initializeWebSubmissionHandlers(DispatcherRestEndpoint.java:112) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.webmonitor.WebMonitorEndpoint.initializeHandlers(WebMonitorEndpoint.java:228) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint.initializeHandlers(DispatcherRestEndpoint.java:89) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:144) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:172) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:463) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:422) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:366) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.program.PerJobMiniClusterFactory.submitJob(PerJobMiniClusterFactory.java:75) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:85) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1905) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1796) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:69) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1782) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1765) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.myorg.quickstart.other.EWindow.Window1.main(Window1.java:81) ~[classes/:na]
2021-04-15 17:32:14,625 DEBUG o.a.f.s.n.i.n.u.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
2021-04-15 17:32:14,626 DEBUG o.a.f.s.n.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2021-04-15 17:32:14,626 DEBUG o.a.f.s.n.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2021-04-15 17:32:14,698 WARN org.apache.flink.runtime.webmonitor.WebMonitorUtils - Log file environment variable 'log.file' is not set.
2021-04-15 17:32:14,699 WARN org.apache.flink.runtime.webmonitor.WebMonitorUtils - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'web.log.path'.
2021-04-15 17:32:14,736 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - Platform: Windows
2021-04-15 17:32:14,737 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
2021-04-15 17:32:14,737 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - Java version: 11
2021-04-15 17:32:14,738 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
2021-04-15 17:32:14,739 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
2021-04-15 17:32:14,740 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
2021-04-15 17:32:14,741 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: unavailable
java.lang.UnsupportedOperationException: Reflective setAccessible(true) disabled
	at org.apache.flink.shaded.netty4.io.netty.util.internal.ReflectionUtil.trySetAccessible(ReflectionUtil.java:31) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0$4.run(PlatformDependent0.java:233) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at java.base/java.security.AccessController.doPrivileged(Native Method) ~[na:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:227) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.isAndroid(PlatformDependent.java:289) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:92) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:223) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:210) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.cached(AsciiString.java:1401) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<clinit>(AsciiString.java:48) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<init>(HttpMethod.java:135) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<clinit>(HttpMethod.java:36) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.runtime.rest.HttpMethodWrapper.<clinit>(HttpMethodWrapper.java:27) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.messages.cluster.ShutdownHeaders.getHttpMethod(ShutdownHeaders.java:57) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.checkAllEndpointsAndHandlersAreUnique(RestServerEndpoint.java:572) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:155) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:172) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:463) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:422) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:366) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.program.PerJobMiniClusterFactory.submitJob(PerJobMiniClusterFactory.java:75) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:85) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1905) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1796) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:69) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1782) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1765) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.myorg.quickstart.other.EWindow.Window1.main(Window1.java:81) ~[classes/:na]
2021-04-15 17:32:14,742 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
2021-04-15 17:32:14,744 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable
java.lang.IllegalAccessException: class org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0$6 cannot access class jdk.internal.misc.Unsafe (in module java.base) because module java.base does not export jdk.internal.misc to unnamed module @475c9c31
	at java.base/jdk.internal.reflect.Reflection.newIllegalAccessException(Reflection.java:361) ~[na:na]
	at java.base/java.lang.reflect.AccessibleObject.checkAccess(AccessibleObject.java:591) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:558) ~[na:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0$6.run(PlatformDependent0.java:347) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at java.base/java.security.AccessController.doPrivileged(Native Method) ~[na:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:338) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.isAndroid(PlatformDependent.java:289) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:92) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:223) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:210) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.cached(AsciiString.java:1401) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<clinit>(AsciiString.java:48) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<init>(HttpMethod.java:135) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<clinit>(HttpMethod.java:36) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.runtime.rest.HttpMethodWrapper.<clinit>(HttpMethodWrapper.java:27) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.messages.cluster.ShutdownHeaders.getHttpMethod(ShutdownHeaders.java:57) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.checkAllEndpointsAndHandlersAreUnique(RestServerEndpoint.java:572) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:155) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:172) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:463) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:422) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:366) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.program.PerJobMiniClusterFactory.submitJob(PerJobMiniClusterFactory.java:75) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:85) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1905) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1796) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:69) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1782) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1765) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.myorg.quickstart.other.EWindow.Window1.main(Window1.java:81) ~[classes/:na]
2021-04-15 17:32:14,744 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): unavailable
2021-04-15 17:32:14,744 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
2021-04-15 17:32:14,745 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - maxDirectMemory: 2122317824 bytes (maybe)
2021-04-15 17:32:14,745 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\ccy\AppData\Local\Temp (java.io.tmpdir)
2021-04-15 17:32:14,745 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
2021-04-15 17:32:14,746 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: -1 bytes
2021-04-15 17:32:14,746 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
2021-04-15 17:32:14,747 DEBUG o.a.f.shaded.netty4.io.netty.util.internal.CleanerJava9 - java.nio.ByteBuffer.cleaner(): available
2021-04-15 17:32:14,747 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
2021-04-15 17:32:14,752 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@14168e1 under DELETE@/v1/cluster.
2021-04-15 17:32:14,753 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@14168e1 under DELETE@/cluster.
2021-04-15 17:32:14,753 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@2251b3bc under GET@/v1/config.
2021-04-15 17:32:14,753 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@2251b3bc under GET@/config.
2021-04-15 17:32:14,753 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetListHandler@3fbe503c under GET@/v1/datasets.
2021-04-15 17:32:14,754 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetListHandler@3fbe503c under GET@/datasets.
2021-04-15 17:32:14,754 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteStatusHandler@3c232051 under GET@/v1/datasets/delete/:triggerid.
2021-04-15 17:32:14,754 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteStatusHandler@3c232051 under GET@/datasets/delete/:triggerid.
2021-04-15 17:32:14,754 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteTriggerHandler@15d0d6c9 under DELETE@/v1/datasets/:datasetid.
2021-04-15 17:32:14,754 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteTriggerHandler@15d0d6c9 under DELETE@/datasets/:datasetid.
2021-04-15 17:32:14,754 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@3ab35b9c under GET@/v1/jobmanager/config.
2021-04-15 17:32:14,754 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@3ab35b9c under GET@/jobmanager/config.
2021-04-15 17:32:14,754 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@7741d346 under GET@/v1/jobmanager/log.
2021-04-15 17:32:14,754 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@7741d346 under GET@/jobmanager/log.
2021-04-15 17:32:14,754 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogListHandler@52454457 under GET@/v1/jobmanager/logs.
2021-04-15 17:32:14,754 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogListHandler@52454457 under GET@/jobmanager/logs.
2021-04-15 17:32:14,754 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerCustomLogHandler@4130a648 under GET@/v1/jobmanager/logs/:filename.
2021-04-15 17:32:14,754 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerCustomLogHandler@4130a648 under GET@/jobmanager/logs/:filename.
2021-04-15 17:32:14,755 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@61ff6a49 under GET@/v1/jobmanager/metrics.
2021-04-15 17:32:14,755 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@61ff6a49 under GET@/jobmanager/metrics.
2021-04-15 17:32:14,755 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@18dd5ed3 under GET@/v1/jobmanager/stdout.
2021-04-15 17:32:14,755 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@18dd5ed3 under GET@/jobmanager/stdout.
2021-04-15 17:32:14,755 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@6042d663 under GET@/v1/jobs.
2021-04-15 17:32:14,755 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@6042d663 under GET@/jobs.
2021-04-15 17:32:14,755 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@24043ec5 under POST@/v1/jobs.
2021-04-15 17:32:14,755 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@24043ec5 under POST@/jobs.
2021-04-15 17:32:14,755 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@3e33b52e under GET@/v1/jobs/metrics.
2021-04-15 17:32:14,755 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@3e33b52e under GET@/jobs/metrics.
2021-04-15 17:32:14,755 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@4c6a4ffd under GET@/v1/jobs/overview.
2021-04-15 17:32:14,755 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@4c6a4ffd under GET@/jobs/overview.
2021-04-15 17:32:14,755 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@3aed69dd under GET@/v1/jobs/:jobid.
2021-04-15 17:32:14,755 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@3aed69dd under GET@/jobs/:jobid.
2021-04-15 17:32:14,755 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@3f1a9a53 under PATCH@/v1/jobs/:jobid.
2021-04-15 17:32:14,755 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@3f1a9a53 under PATCH@/jobs/:jobid.
2021-04-15 17:32:14,755 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@1ca3d25b under GET@/v1/jobs/:jobid/accumulators.
2021-04-15 17:32:14,756 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@1ca3d25b under GET@/jobs/:jobid/accumulators.
2021-04-15 17:32:14,756 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@2287395 under GET@/v1/jobs/:jobid/checkpoints.
2021-04-15 17:32:14,756 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@2287395 under GET@/jobs/:jobid/checkpoints.
2021-04-15 17:32:14,756 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@535a518c under GET@/v1/jobs/:jobid/checkpoints/config.
2021-04-15 17:32:14,756 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@535a518c under GET@/jobs/:jobid/checkpoints/config.
2021-04-15 17:32:14,756 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@38f981b6 under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid.
2021-04-15 17:32:14,756 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@38f981b6 under GET@/jobs/:jobid/checkpoints/details/:checkpointid.
2021-04-15 17:32:14,757 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@3a4aadf8 under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
2021-04-15 17:32:14,757 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@3a4aadf8 under GET@/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
2021-04-15 17:32:14,757 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@7bbfc5ff under GET@/v1/jobs/:jobid/config.
2021-04-15 17:32:14,757 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@7bbfc5ff under GET@/jobs/:jobid/config.
2021-04-15 17:32:14,757 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.coordination.ClientCoordinationHandler@7a682d35 under POST@/v1/jobs/:jobid/coordinators/:operatorid.
2021-04-15 17:32:14,757 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.coordination.ClientCoordinationHandler@7a682d35 under POST@/jobs/:jobid/coordinators/:operatorid.
2021-04-15 17:32:14,757 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@ee8e7ff under GET@/v1/jobs/:jobid/exceptions.
2021-04-15 17:32:14,757 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@ee8e7ff under GET@/jobs/:jobid/exceptions.
2021-04-15 17:32:14,757 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@61a2aeb7 under GET@/v1/jobs/:jobid/execution-result.
2021-04-15 17:32:14,757 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@61a2aeb7 under GET@/jobs/:jobid/execution-result.
2021-04-15 17:32:14,757 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@64b70f41 under GET@/v1/jobs/:jobid/metrics.
2021-04-15 17:32:14,757 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@64b70f41 under GET@/jobs/:jobid/metrics.
2021-04-15 17:32:14,757 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@5f8d9767 under GET@/v1/jobs/:jobid/plan.
2021-04-15 17:32:14,757 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@5f8d9767 under GET@/jobs/:jobid/plan.
2021-04-15 17:32:14,757 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@16134476 under PATCH@/v1/jobs/:jobid/rescaling.
2021-04-15 17:32:14,758 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@16134476 under PATCH@/jobs/:jobid/rescaling.
2021-04-15 17:32:14,758 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@62b09715 under GET@/v1/jobs/:jobid/rescaling/:triggerid.
2021-04-15 17:32:14,758 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@62b09715 under GET@/jobs/:jobid/rescaling/:triggerid.
2021-04-15 17:32:14,758 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@3e214105 under POST@/v1/jobs/:jobid/savepoints.
2021-04-15 17:32:14,758 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@3e214105 under POST@/jobs/:jobid/savepoints.
2021-04-15 17:32:14,758 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@da4cf09 under GET@/v1/jobs/:jobid/savepoints/:triggerid.
2021-04-15 17:32:14,758 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@da4cf09 under GET@/jobs/:jobid/savepoints/:triggerid.
2021-04-15 17:32:14,758 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@1980a3f under POST@/v1/jobs/:jobid/stop.
2021-04-15 17:32:14,758 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@1980a3f under POST@/jobs/:jobid/stop.
2021-04-15 17:32:14,758 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@67f63d26 under GET@/v1/jobs/:jobid/vertices/:vertexid.
2021-04-15 17:32:14,758 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@67f63d26 under GET@/jobs/:jobid/vertices/:vertexid.
2021-04-15 17:32:14,758 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@536b71b4 under GET@/v1/jobs/:jobid/vertices/:vertexid/accumulators.
2021-04-15 17:32:14,758 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@536b71b4 under GET@/jobs/:jobid/vertices/:vertexid/accumulators.
2021-04-15 17:32:14,759 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@789c3057 under GET@/v1/jobs/:jobid/vertices/:vertexid/backpressure.
2021-04-15 17:32:14,759 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@789c3057 under GET@/jobs/:jobid/vertices/:vertexid/backpressure.
2021-04-15 17:32:14,759 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@39941489 under GET@/v1/jobs/:jobid/vertices/:vertexid/metrics.
2021-04-15 17:32:14,759 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@39941489 under GET@/jobs/:jobid/vertices/:vertexid/metrics.
2021-04-15 17:32:14,759 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@6f5d0190 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
2021-04-15 17:32:14,759 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@6f5d0190 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
2021-04-15 17:32:14,759 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@67332b1e under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
2021-04-15 17:32:14,759 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@67332b1e under GET@/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
2021-04-15 17:32:14,759 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@7e34b127 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
2021-04-15 17:32:14,759 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@7e34b127 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
2021-04-15 17:32:14,759 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@679dd234 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
2021-04-15 17:32:14,759 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@679dd234 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
2021-04-15 17:32:14,759 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@60cb1ed6 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
2021-04-15 17:32:14,759 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@60cb1ed6 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
2021-04-15 17:32:14,760 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@1e5eb20a under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
2021-04-15 17:32:14,760 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@1e5eb20a under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
2021-04-15 17:32:14,760 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@4538856f under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasktimes.
2021-04-15 17:32:14,760 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@4538856f under GET@/jobs/:jobid/vertices/:vertexid/subtasktimes.
2021-04-15 17:32:14,760 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@4c3de38e under GET@/v1/jobs/:jobid/vertices/:vertexid/taskmanagers.
2021-04-15 17:32:14,760 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@4c3de38e under GET@/jobs/:jobid/vertices/:vertexid/taskmanagers.
2021-04-15 17:32:14,760 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@74b86971 under GET@/v1/jobs/:jobid/vertices/:vertexid/watermarks.
2021-04-15 17:32:14,760 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@74b86971 under GET@/jobs/:jobid/vertices/:vertexid/watermarks.
2021-04-15 17:32:14,760 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@1f9d4b0e under GET@/v1/jobs/:jobid/yarn-cancel.
2021-04-15 17:32:14,760 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@1f9d4b0e under GET@/jobs/:jobid/yarn-cancel.
2021-04-15 17:32:14,760 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@1e8fb66f under GET@/v1/jobs/:jobid/yarn-stop.
2021-04-15 17:32:14,760 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@1e8fb66f under GET@/jobs/:jobid/yarn-stop.
2021-04-15 17:32:14,760 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@3d8d17a3 under GET@/v1/overview.
2021-04-15 17:32:14,761 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@3d8d17a3 under GET@/overview.
2021-04-15 17:32:14,761 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@ac91282 under POST@/v1/savepoint-disposal.
2021-04-15 17:32:14,761 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@ac91282 under POST@/savepoint-disposal.
2021-04-15 17:32:14,761 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@7f79edee under GET@/v1/savepoint-disposal/:triggerid.
2021-04-15 17:32:14,761 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@7f79edee under GET@/savepoint-disposal/:triggerid.
2021-04-15 17:32:14,761 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@1ca610a0 under GET@/v1/taskmanagers.
2021-04-15 17:32:14,761 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@1ca610a0 under GET@/taskmanagers.
2021-04-15 17:32:14,761 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@49433c98 under GET@/v1/taskmanagers/metrics.
2021-04-15 17:32:14,761 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@49433c98 under GET@/taskmanagers/metrics.
2021-04-15 17:32:14,761 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@b5c6a30 under GET@/v1/taskmanagers/:taskmanagerid.
2021-04-15 17:32:14,761 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@b5c6a30 under GET@/taskmanagers/:taskmanagerid.
2021-04-15 17:32:14,761 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@3bfae028 under GET@/v1/taskmanagers/:taskmanagerid/log.
2021-04-15 17:32:14,761 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@3bfae028 under GET@/taskmanagers/:taskmanagerid/log.
2021-04-15 17:32:14,761 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogListHandler@1775c4e7 under GET@/v1/taskmanagers/:taskmanagerid/logs.
2021-04-15 17:32:14,761 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogListHandler@1775c4e7 under GET@/taskmanagers/:taskmanagerid/logs.
2021-04-15 17:32:14,761 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerCustomLogHandler@47829d6d under GET@/v1/taskmanagers/:taskmanagerid/logs/:filename.
2021-04-15 17:32:14,761 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerCustomLogHandler@47829d6d under GET@/taskmanagers/:taskmanagerid/logs/:filename.
2021-04-15 17:32:14,761 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@2f677247 under GET@/v1/taskmanagers/:taskmanagerid/metrics.
2021-04-15 17:32:14,762 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@2f677247 under GET@/taskmanagers/:taskmanagerid/metrics.
2021-04-15 17:32:14,762 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@43f03c23 under GET@/v1/taskmanagers/:taskmanagerid/stdout.
2021-04-15 17:32:14,762 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@43f03c23 under GET@/taskmanagers/:taskmanagerid/stdout.
2021-04-15 17:32:14,762 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerThreadDumpHandler@7a1b8a46 under GET@/v1/taskmanagers/:taskmanagerid/thread-dump.
2021-04-15 17:32:14,762 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerThreadDumpHandler@7a1b8a46 under GET@/taskmanagers/:taskmanagerid/thread-dump.
2021-04-15 17:32:14,768 DEBUG o.a.f.s.n.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 8
2021-04-15 17:32:14,790 DEBUG o.a.f.shaded.netty4.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
2021-04-15 17:32:14,790 DEBUG o.a.f.shaded.netty4.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
2021-04-15 17:32:14,797 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
2021-04-15 17:32:14,846 DEBUG o.a.f.shaded.netty4.io.netty.channel.DefaultChannelId - -Dio.netty.processId: 1328 (auto-detected)
2021-04-15 17:32:14,849 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
2021-04-15 17:32:14,849 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
2021-04-15 17:32:15,578 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
2021-04-15 17:32:15,579 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
2021-04-15 17:32:16,316 DEBUG o.a.f.shaded.netty4.io.netty.channel.DefaultChannelId - -Dio.netty.machineId: 2c:6f:c9:ff:fe:1c:21:83 (auto-detected)
2021-04-15 17:32:16,326 DEBUG o.a.f.shaded.netty4.io.netty.util.ResourceLeakDetector - -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.level: simple
2021-04-15 17:32:16,326 DEBUG o.a.f.shaded.netty4.io.netty.util.ResourceLeakDetector - -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.targetRecords: 4
2021-04-15 17:32:16,353 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 8
2021-04-15 17:32:16,353 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 8
2021-04-15 17:32:16,353 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
2021-04-15 17:32:16,353 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 11
2021-04-15 17:32:16,353 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 16777216
2021-04-15 17:32:16,354 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.tinyCacheSize: 512
2021-04-15 17:32:16,354 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
2021-04-15 17:32:16,354 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
2021-04-15 17:32:16,354 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2021-04-15 17:32:16,354 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
2021-04-15 17:32:16,354 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2021-04-15 17:32:16,354 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: true
2021-04-15 17:32:16,354 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2021-04-15 17:32:16,361 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
2021-04-15 17:32:16,361 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 0
2021-04-15 17:32:16,361 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
2021-04-15 17:32:16,376 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Binding rest endpoint to null:0.
2021-04-15 17:32:16,376 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Rest endpoint listening at localhost:61682
2021-04-15 17:32:16,379 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender http://localhost:61682
2021-04-15 17:32:16,383 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - http://localhost:61682 was granted leadership with leaderSessionID=f67412a2-d491-415d-a825-a43e0e6edff3
2021-04-15 17:32:16,383 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader http://localhost:61682 , session=f67412a2-d491-415d-a825-a43e0e6edff3
2021-04-15 17:32:16,399 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting FencedAkkaRpcActor with name resourcemanager_1.
2021-04-15 17:32:16,400 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_1 .
2021-04-15 17:32:16,416 DEBUG o.a.f.r.e.c.DefaultDispatcherResourceManagerComponentFactory - Starting Dispatcher.
2021-04-15 17:32:16,420 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
2021-04-15 17:32:16,420 DEBUG o.a.f.r.e.c.DefaultDispatcherResourceManagerComponentFactory - Starting ResourceManager.
2021-04-15 17:32:16,420 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: StandaloneResourceManager
2021-04-15 17:32:16,422 DEBUG o.a.f.runtime.dispatcher.runner.DefaultDispatcherRunner - Create new DispatcherLeaderProcess with leader session id 169e40fd-8280-45c3-a69b-bb98bc9a474c.
2021-04-15 17:32:16,424 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - ResourceManager akka://flink/user/rpc/resourcemanager_1 was granted leadership with fencing token 899c42556446f023b3b49168e2e54930
2021-04-15 17:32:16,428 INFO org.apache.flink.runtime.minicluster.MiniCluster - Flink Mini Cluster started successfully
2021-04-15 17:32:16,428 INFO o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Starting the SlotManager.
2021-04-15 17:32:16,429 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Start SessionDispatcherLeaderProcess.
2021-04-15 17:32:16,434 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:32:16,434 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:32:16,437 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Recover all persisted job graphs.
2021-04-15 17:32:16,437 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/resourcemanager_1 , session=b3b49168-e2e5-4930-899c-42556446f023
2021-04-15 17:32:16,437 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Successfully recovered 0 persisted job graphs.
2021-04-15 17:32:16,441 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:32:16,446 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting FencedAkkaRpcActor with name dispatcher_2.
2021-04-15 17:32:16,447 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:32:16,449 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(899c42556446f023b3b49168e2e54930).
2021-04-15 17:32:16,452 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_2 .
2021-04-15 17:32:16,465 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:32:16,468 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/dispatcher_2 , session=169e40fd-8280-45c3-a69b-bb98bc9a474c
2021-04-15 17:32:16,470 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/dispatcher_2. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
2021-04-15 17:32:16,471 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/dispatcher_2. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
2021-04-15 17:32:16,482 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Resolved ResourceManager address, beginning registration
2021-04-15 17:32:16,483 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Registration at ResourceManager attempt 1 (timeout=100ms)
2021-04-15 17:32:16,487 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
2021-04-15 17:32:16,496 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Registering TaskManager with ResourceID 150961bf-a51f-4fb1-8d0d-be97ee0834aa (akka://flink/user/rpc/taskmanager_0) at ResourceManager
2021-04-15 17:32:16,497 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Received JobGraph submission e9de8518a465d07297845be1a7d2e0c9 (Flink Streaming Job).
2021-04-15 17:32:16,498 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Submitting job e9de8518a465d07297845be1a7d2e0c9 (Flink Streaming Job).
2021-04-15 17:32:16,499 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Successful registration at resource manager akka://flink/user/rpc/resourcemanager_1 under registration id 34cd7b6e571fc5fd19948b820eb8271f.
2021-04-15 17:32:16,504 DEBUG o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Registering TaskManager 150961bf-a51f-4fb1-8d0d-be97ee0834aa under 34cd7b6e571fc5fd19948b820eb8271f at the SlotManager.
2021-04-15 17:32:16,514 DEBUG org.apache.flink.client.ClientUtils - Wait until job initialization is finished
2021-04-15 17:32:16,524 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: JobManagerRunnerImpl
2021-04-15 17:32:16,535 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting FencedAkkaRpcActor with name jobmanager_3.
2021-04-15 17:32:16,536 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
2021-04-15 17:32:16,549 INFO org.apache.flink.runtime.jobmaster.JobMaster - Initializing job Flink Streaming Job (e9de8518a465d07297845be1a7d2e0c9).
2021-04-15 17:32:16,569 INFO org.apache.flink.runtime.jobmaster.JobMaster - Using restart back off time strategy NoRestartBackoffTimeStrategy for Flink Streaming Job (e9de8518a465d07297845be1a7d2e0c9).
2021-04-15 17:32:16,611 INFO org.apache.flink.runtime.jobmaster.JobMaster - Running initialization on master for job Flink Streaming Job (e9de8518a465d07297845be1a7d2e0c9).
2021-04-15 17:32:16,611 INFO org.apache.flink.runtime.jobmaster.JobMaster - Successfully ran initialization on master in 0 ms.
2021-04-15 17:32:16,611 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Adding 2 vertices from job graph Flink Streaming Job (e9de8518a465d07297845be1a7d2e0c9).
2021-04-15 17:32:16,611 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Attaching 2 topologically sorted vertices to existing job graph with 0 vertices and 0 intermediate results.
2021-04-15 17:32:16,622 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex bc764cd8ddf7a0cff126f51c16239658 (Source: sensor) to 0 predecessors.
2021-04-15 17:32:16,623 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex 0a448493b4782967b150582570326227 (Sink: Print to Std. Out) to 1 predecessors.
2021-04-15 17:32:16,623 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting input 0 of vertex 0a448493b4782967b150582570326227 (Sink: Print to Std. Out) to intermediate result referenced via predecessor bc764cd8ddf7a0cff126f51c16239658 (Source: sensor).
2021-04-15 17:32:16,635 INFO o.a.f.r.scheduler.adapter.DefaultExecutionTopology - Built 1 pipelined regions in 0 ms
2021-04-15 17:32:16,636 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Successfully created execution graph from job graph Flink Streaming Job (e9de8518a465d07297845be1a7d2e0c9).
2021-04-15 17:32:16,654 INFO org.apache.flink.runtime.jobmaster.JobMaster - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:32:16,671 DEBUG o.apache.flink.runtime.checkpoint.CheckpointCoordinator - Status of the shared state registry of job e9de8518a465d07297845be1a7d2e0c9 after restore: SharedStateRegistry{registeredStates={}}.
2021-04-15 17:32:16,671 INFO o.apache.flink.runtime.checkpoint.CheckpointCoordinator - No checkpoint found during restore.
2021-04-15 17:32:16,674 INFO org.apache.flink.runtime.jobmaster.JobMaster - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@405c07d3 for Flink Streaming Job (e9de8518a465d07297845be1a7d2e0c9).
2021-04-15 17:32:16,693 INFO org.apache.flink.runtime.jobmaster.JobManagerRunnerImpl - JobManager runner for job Flink Streaming Job (e9de8518a465d07297845be1a7d2e0c9) was granted leadership with session id 13b8462c-7e5f-41cd-9916-b0c8751b8a4d at akka://flink/user/rpc/jobmanager_3.
2021-04-15 17:32:16,697 INFO org.apache.flink.runtime.jobmaster.JobMaster - Starting execution of job Flink Streaming Job (e9de8518a465d07297845be1a7d2e0c9) under job master id 9916b0c8751b8a4d13b8462c7e5f41cd.
2021-04-15 17:32:16,700 INFO org.apache.flink.runtime.jobmaster.JobMaster - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2021-04-15 17:32:16,701 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Job Flink Streaming Job (e9de8518a465d07297845be1a7d2e0c9) switched from state CREATED to RUNNING.
2021-04-15 17:32:16,707 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: sensor (1/1) (450b30e9c07df83514b84b34ad804ae3) switched from CREATED to SCHEDULED.
2021-04-15 17:32:16,707 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (1/4) (91f1e72fb3c553acd4846f4cc9d13aee) switched from CREATED to SCHEDULED.
2021-04-15 17:32:16,707 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (2/4) (cb92e5ff57ec617806463ab320025499) switched from CREATED to SCHEDULED.
2021-04-15 17:32:16,707 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (3/4) (3f24e477fb8841194487a8eb8d4c0ab7) switched from CREATED to SCHEDULED.
2021-04-15 17:32:16,707 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (4/4) (c820ba6aa6fbbce775d0d6a096a64ae2) switched from CREATED to SCHEDULED.
2021-04-15 17:32:16,722 DEBUG o.a.f.r.jobmaster.slotpool.PhysicalSlotProviderImpl - Received slot request [SlotRequestId{adde56d93776d845152a45c95aa7d8d3}] with resource requirements: ResourceProfile{UNKNOWN}
2021-04-15 17:32:16,726 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{adde56d93776d845152a45c95aa7d8d3}]
2021-04-15 17:32:16,728 DEBUG o.a.f.r.jobmaster.slotpool.PhysicalSlotProviderImpl - Received slot request [SlotRequestId{552c1ab39ca48d17cc3cc00742af8af4}] with resource requirements: ResourceProfile{UNKNOWN}
2021-04-15 17:32:16,728 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{552c1ab39ca48d17cc3cc00742af8af4}]
2021-04-15 17:32:16,728 DEBUG o.a.f.r.jobmaster.slotpool.PhysicalSlotProviderImpl - Received slot request [SlotRequestId{ebba9be7e6726c71e9a27b50498c3c33}] with resource requirements: ResourceProfile{UNKNOWN}
2021-04-15 17:32:16,728 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{ebba9be7e6726c71e9a27b50498c3c33}]
2021-04-15 17:32:16,729 DEBUG o.a.f.r.jobmaster.slotpool.PhysicalSlotProviderImpl - Received slot request [SlotRequestId{2853149d8ee51690e11364d01bd18719}] with resource requirements: ResourceProfile{UNKNOWN}
2021-04-15 17:32:16,729 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{2853149d8ee51690e11364d01bd18719}]
2021-04-15 17:32:16,729 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{fd6f02be43a7be0d1950b60e22549e1a}) for execution vertex (id 0a448493b4782967b150582570326227_1) from the physical slot (SlotRequestId{adde56d93776d845152a45c95aa7d8d3})
2021-04-15 17:32:16,732 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{802bbbb643342a4f6352384cc32dd52e}) for execution vertex (id bc764cd8ddf7a0cff126f51c16239658_0) from the physical slot (SlotRequestId{552c1ab39ca48d17cc3cc00742af8af4})
2021-04-15 17:32:16,732 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{23fcf879bd53ed41c179da34b650b0a0}) for execution vertex (id 0a448493b4782967b150582570326227_0) from the physical slot (SlotRequestId{552c1ab39ca48d17cc3cc00742af8af4})
2021-04-15 17:32:16,733 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{e02d9dcb1592c044bab87bb229958d25}) for execution vertex (id 0a448493b4782967b150582570326227_2) from the physical slot (SlotRequestId{ebba9be7e6726c71e9a27b50498c3c33})
2021-04-15 17:32:16,733 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{7f6e44ba23453c678ed9141bea2d352f}) for execution vertex (id 0a448493b4782967b150582570326227_3) from the physical slot (SlotRequestId{2853149d8ee51690e11364d01bd18719})
2021-04-15 17:32:16,739 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
2021-04-15 17:32:16,739 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/jobmanager_3 , session=13b8462c-7e5f-41cd-9916-b0c8751b8a4d
2021-04-15 17:32:16,739 INFO org.apache.flink.runtime.jobmaster.JobMaster - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(899c42556446f023b3b49168e2e54930)
2021-04-15 17:32:16,741 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:32:16,742 INFO org.apache.flink.runtime.jobmaster.JobMaster - Resolved ResourceManager address, beginning registration
2021-04-15 17:32:16,742 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Registration at ResourceManager attempt 1 (timeout=100ms)
2021-04-15 17:32:16,742 DEBUG o.a.flink.runtime.resourcemanager.JobLeaderIdService - Add job e9de8518a465d07297845be1a7d2e0c9 to job leader id monitoring.
2021-04-15 17:32:16,744 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Registering job manager 9916b0c8751b8a4d13b8462c7e5f41cd@akka://flink/user/rpc/jobmanager_3 for job e9de8518a465d07297845be1a7d2e0c9.
2021-04-15 17:32:16,744 DEBUG o.a.flink.runtime.resourcemanager.JobLeaderIdService - Found a new job leader 13b8462c-7e5f-41cd-9916-b0c8751b8a4d@akka://flink/user/rpc/jobmanager_3.
2021-04-15 17:32:16,744 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/jobmanager_3. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2021-04-15 17:32:16,749 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Registered job manager 9916b0c8751b8a4d13b8462c7e5f41cd@akka://flink/user/rpc/jobmanager_3 for job e9de8518a465d07297845be1a7d2e0c9.
2021-04-15 17:32:16,751 INFO org.apache.flink.runtime.jobmaster.JobMaster - JobManager successfully registered at ResourceManager, leader id: 899c42556446f023b3b49168e2e54930.
2021-04-15 17:32:16,752 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{adde56d93776d845152a45c95aa7d8d3}] and profile ResourceProfile{UNKNOWN} with allocation id 9fa5476ec54661d5dcd59697c027f783 from resource manager.
2021-04-15 17:32:16,753 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job e9de8518a465d07297845be1a7d2e0c9 with allocation id 9fa5476ec54661d5dcd59697c027f783.
2021-04-15 17:32:16,753 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{552c1ab39ca48d17cc3cc00742af8af4}] and profile ResourceProfile{UNKNOWN} with allocation id 312c56263ac1a28eec6b38bd513f1309 from resource manager.
2021-04-15 17:32:16,753 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{ebba9be7e6726c71e9a27b50498c3c33}] and profile ResourceProfile{UNKNOWN} with allocation id 3ce3d87985866459f759ff7a03a88be2 from resource manager.
2021-04-15 17:32:16,754 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{2853149d8ee51690e11364d01bd18719}] and profile ResourceProfile{UNKNOWN} with allocation id 90449ee5b0bd2df9cf15b63595aabdbf from resource manager.
2021-04-15 17:32:16,757 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 9fa5476ec54661d5dcd59697c027f783 for job e9de8518a465d07297845be1a7d2e0c9 from resource manager with leader id 899c42556446f023b3b49168e2e54930.
2021-04-15 17:32:16,763 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job e9de8518a465d07297845be1a7d2e0c9 with allocation id 312c56263ac1a28eec6b38bd513f1309.
2021-04-15 17:32:16,764 DEBUG org.apache.flink.runtime.memory.MemoryManager - Initialized MemoryManager with total memory size 33554432 and page size 32768.
2021-04-15 17:32:16,764 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job e9de8518a465d07297845be1a7d2e0c9 with allocation id 3ce3d87985866459f759ff7a03a88be2.
2021-04-15 17:32:16,765 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 9fa5476ec54661d5dcd59697c027f783.
2021-04-15 17:32:16,766 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job e9de8518a465d07297845be1a7d2e0c9 with allocation id 90449ee5b0bd2df9cf15b63595aabdbf.
2021-04-15 17:32:16,770 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Add job e9de8518a465d07297845be1a7d2e0c9 for job leader monitoring.
2021-04-15 17:32:16,772 DEBUG o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - New leader information for job e9de8518a465d07297845be1a7d2e0c9. Address: akka://flink/user/rpc/jobmanager_3, leader id: 9916b0c8751b8a4d13b8462c7e5f41cd.
2021-04-15 17:32:16,773 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Try to register at job manager akka://flink/user/rpc/jobmanager_3 with leader id 13b8462c-7e5f-41cd-9916-b0c8751b8a4d.
2021-04-15 17:32:16,773 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/jobmanager_3. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2021-04-15 17:32:16,773 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 312c56263ac1a28eec6b38bd513f1309 for job e9de8518a465d07297845be1a7d2e0c9 from resource manager with leader id 899c42556446f023b3b49168e2e54930.
2021-04-15 17:32:16,774 DEBUG org.apache.flink.runtime.memory.MemoryManager - Initialized MemoryManager with total memory size 33554432 and page size 32768.
2021-04-15 17:32:16,775 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 312c56263ac1a28eec6b38bd513f1309.
2021-04-15 17:32:16,775 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 3ce3d87985866459f759ff7a03a88be2 for job e9de8518a465d07297845be1a7d2e0c9 from resource manager with leader id 899c42556446f023b3b49168e2e54930.
2021-04-15 17:32:16,775 DEBUG org.apache.flink.runtime.memory.MemoryManager - Initialized MemoryManager with total memory size 33554432 and page size 32768.
2021-04-15 17:32:16,776 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 3ce3d87985866459f759ff7a03a88be2.
2021-04-15 17:32:16,776 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 90449ee5b0bd2df9cf15b63595aabdbf for job e9de8518a465d07297845be1a7d2e0c9 from resource manager with leader id 899c42556446f023b3b49168e2e54930.
2021-04-15 17:32:16,777 DEBUG org.apache.flink.runtime.memory.MemoryManager - Initialized MemoryManager with total memory size 33554432 and page size 32768.
2021-04-15 17:32:16,777 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 90449ee5b0bd2df9cf15b63595aabdbf.
2021-04-15 17:32:16,777 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Resolved JobManager address, beginning registration
2021-04-15 17:32:16,778 DEBUG o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Registration at JobManager attempt 1 (timeout=100ms)
2021-04-15 17:32:16,781 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
2021-04-15 17:32:16,782 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Register new TaskExecutor 150961bf-a51f-4fb1-8d0d-be97ee0834aa.
2021-04-15 17:32:16,783 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Successful registration at job manager akka://flink/user/rpc/jobmanager_3 for job e9de8518a465d07297845be1a7d2e0c9.
2021-04-15 17:32:16,784 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Establish JobManager connection for job e9de8518a465d07297845be1a7d2e0c9.
2021-04-15 17:32:16,789 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Offer reserved slots to the leader of job e9de8518a465d07297845be1a7d2e0c9.
2021-04-15 17:32:16,792 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Fulfilling pending slot request [SlotRequestId{adde56d93776d845152a45c95aa7d8d3}] with slot [90449ee5b0bd2df9cf15b63595aabdbf]
2021-04-15 17:32:16,793 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{fd6f02be43a7be0d1950b60e22549e1a}) for execution vertex (id 0a448493b4782967b150582570326227_1) from the physical slot (SlotRequestId{adde56d93776d845152a45c95aa7d8d3})
2021-04-15 17:32:16,797 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Fulfilling pending slot request [SlotRequestId{552c1ab39ca48d17cc3cc00742af8af4}] with slot [3ce3d87985866459f759ff7a03a88be2]
2021-04-15 17:32:16,798 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{802bbbb643342a4f6352384cc32dd52e}) for execution vertex (id bc764cd8ddf7a0cff126f51c16239658_0) from the physical slot (SlotRequestId{552c1ab39ca48d17cc3cc00742af8af4})
2021-04-15 17:32:16,804 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{23fcf879bd53ed41c179da34b650b0a0}) for execution vertex (id 0a448493b4782967b150582570326227_0) from the physical slot (SlotRequestId{552c1ab39ca48d17cc3cc00742af8af4})
2021-04-15 17:32:16,804 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Fulfilling pending slot request [SlotRequestId{ebba9be7e6726c71e9a27b50498c3c33}] with slot [312c56263ac1a28eec6b38bd513f1309]
2021-04-15 17:32:16,804 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{e02d9dcb1592c044bab87bb229958d25}) for execution vertex (id 0a448493b4782967b150582570326227_2) from the physical slot (SlotRequestId{ebba9be7e6726c71e9a27b50498c3c33})
2021-04-15 17:32:16,804 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Fulfilling pending slot request [SlotRequestId{2853149d8ee51690e11364d01bd18719}] with slot [9fa5476ec54661d5dcd59697c027f783]
2021-04-15 17:32:16,804 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{7f6e44ba23453c678ed9141bea2d352f}) for execution vertex (id 0a448493b4782967b150582570326227_3) from the physical slot (SlotRequestId{2853149d8ee51690e11364d01bd18719})
2021-04-15 17:32:16,805 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: sensor (1/1) (450b30e9c07df83514b84b34ad804ae3) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:32:16,805 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: sensor (1/1) (attempt #0) with attempt id 450b30e9c07df83514b84b34ad804ae3 to 150961bf-a51f-4fb1-8d0d-be97ee0834aa @ server1 (dataPort=-1) with allocation id 3ce3d87985866459f759ff7a03a88be2
2021-04-15 17:32:16,827 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (1/4) (91f1e72fb3c553acd4846f4cc9d13aee) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:32:16,827 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Sink: Print to Std. Out (1/4) (attempt #0) with attempt id 91f1e72fb3c553acd4846f4cc9d13aee to 150961bf-a51f-4fb1-8d0d-be97ee0834aa @ server1 (dataPort=-1) with allocation id 3ce3d87985866459f759ff7a03a88be2
2021-04-15 17:32:16,831 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (2/4) (cb92e5ff57ec617806463ab320025499) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:32:16,831 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Sink: Print to Std. Out (2/4) (attempt #0) with attempt id cb92e5ff57ec617806463ab320025499 to 150961bf-a51f-4fb1-8d0d-be97ee0834aa @ server1 (dataPort=-1) with allocation id 90449ee5b0bd2df9cf15b63595aabdbf
2021-04-15 17:32:16,831 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (3/4) (3f24e477fb8841194487a8eb8d4c0ab7) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:32:16,831 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Sink: Print to Std. Out (3/4) (attempt #0) with attempt id 3f24e477fb8841194487a8eb8d4c0ab7 to 150961bf-a51f-4fb1-8d0d-be97ee0834aa @ server1 (dataPort=-1) with allocation id 312c56263ac1a28eec6b38bd513f1309
2021-04-15 17:32:16,831 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (4/4) (c820ba6aa6fbbce775d0d6a096a64ae2) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:32:16,831 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Sink: Print to Std. Out (4/4) (attempt #0) with attempt id c820ba6aa6fbbce775d0d6a096a64ae2 to 150961bf-a51f-4fb1-8d0d-be97ee0834aa @ server1 (dataPort=-1) with allocation id 9fa5476ec54661d5dcd59697c027f783
2021-04-15 17:32:16,836 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 3ce3d87985866459f759ff7a03a88be2.
2021-04-15 17:32:16,849 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new allocation id 3ce3d87985866459f759ff7a03a88be2 for local state stores for job e9de8518a465d07297845be1a7d2e0c9.
2021-04-15 17:32:16,853 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_3ce3d87985866459f759ff7a03a88be2], jobID=e9de8518a465d07297845be1a7d2e0c9, jobVertexID=bc764cd8ddf7a0cff126f51c16239658, subtaskIndex=0}} for e9de8518a465d07297845be1a7d2e0c9 - bc764cd8ddf7a0cff126f51c16239658 - 0 under allocation id 3ce3d87985866459f759ff7a03a88be2.
2021-04-15 17:32:16,901 DEBUG o.a.f.r.io.network.partition.ResultPartitionFactory - Source: sensor (1/1)#0 (450b30e9c07df83514b84b34ad804ae3): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@1bda9629
2021-04-15 17:32:16,913 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: sensor (1/1)#0 (450b30e9c07df83514b84b34ad804ae3), deploy into slot with allocation id 3ce3d87985866459f759ff7a03a88be2.
2021-04-15 17:32:16,920 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 90449ee5b0bd2df9cf15b63595aabdbf.
2021-04-15 17:32:16,921 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 3ce3d87985866459f759ff7a03a88be2.
2021-04-15 17:32:16,921 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 312c56263ac1a28eec6b38bd513f1309.
2021-04-15 17:32:16,921 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 9fa5476ec54661d5dcd59697c027f783.
2021-04-15 17:32:16,922 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 3ce3d87985866459f759ff7a03a88be2.
2021-04-15 17:32:16,935 INFO org.apache.flink.runtime.taskmanager.Task - Source: sensor (1/1)#0 (450b30e9c07df83514b84b34ad804ae3) switched from CREATED to DEPLOYING.
2021-04-15 17:32:16,936 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_3ce3d87985866459f759ff7a03a88be2], jobID=e9de8518a465d07297845be1a7d2e0c9, jobVertexID=0a448493b4782967b150582570326227, subtaskIndex=0}} for e9de8518a465d07297845be1a7d2e0c9 - 0a448493b4782967b150582570326227 - 0 under allocation id 3ce3d87985866459f759ff7a03a88be2.
2021-04-15 17:32:16,939 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Source: sensor (1/1)#0 (450b30e9c07df83514b84b34ad804ae3) [DEPLOYING]
2021-04-15 17:32:16,950 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: sensor (1/1)#0 (450b30e9c07df83514b84b34ad804ae3) [DEPLOYING].
2021-04-15 17:32:16,955 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 450b30e9c07df83514b84b34ad804ae3 at library cache manager took 1 milliseconds
2021-04-15 17:32:16,961 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: sensor (1/1)#0 (450b30e9c07df83514b84b34ad804ae3) [DEPLOYING].
2021-04-15 17:32:16,962 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - Sink: Print to Std. Out (1/4)#0 (91f1e72fb3c553acd4846f4cc9d13aee): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:32:16,964 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 5-16 buffers
2021-04-15 17:32:16,964 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Registered PipelinedResultPartition 8c5d465939db86ffd156b06321db3698#0@450b30e9c07df83514b84b34ad804ae3 [PIPELINED_BOUNDED, 4 subpartitions, 4 pending consumptions].
2021-04-15 17:32:16,965 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - registering 8c5d465939db86ffd156b06321db3698#0@450b30e9c07df83514b84b34ad804ae3
2021-04-15 17:32:16,967 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Sink: Print to Std. Out (1/4)#0 (91f1e72fb3c553acd4846f4cc9d13aee), deploy into slot with allocation id 3ce3d87985866459f759ff7a03a88be2.
2021-04-15 17:32:16,968 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 90449ee5b0bd2df9cf15b63595aabdbf.
2021-04-15 17:32:16,973 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new allocation id 90449ee5b0bd2df9cf15b63595aabdbf for local state stores for job e9de8518a465d07297845be1a7d2e0c9.
2021-04-15 17:32:16,977 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_90449ee5b0bd2df9cf15b63595aabdbf], jobID=e9de8518a465d07297845be1a7d2e0c9, jobVertexID=0a448493b4782967b150582570326227, subtaskIndex=1}} for e9de8518a465d07297845be1a7d2e0c9 - 0a448493b4782967b150582570326227 - 1 under allocation id 90449ee5b0bd2df9cf15b63595aabdbf.
2021-04-15 17:32:16,977 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - Sink: Print to Std. Out (2/4)#0 (cb92e5ff57ec617806463ab320025499): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:32:16,982 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Sink: Print to Std. Out (2/4)#0 (cb92e5ff57ec617806463ab320025499), deploy into slot with allocation id 90449ee5b0bd2df9cf15b63595aabdbf.
2021-04-15 17:32:16,983 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 312c56263ac1a28eec6b38bd513f1309.
2021-04-15 17:32:16,988 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new allocation id 312c56263ac1a28eec6b38bd513f1309 for local state stores for job e9de8518a465d07297845be1a7d2e0c9.
2021-04-15 17:32:16,992 INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (1/4)#0 (91f1e72fb3c553acd4846f4cc9d13aee) switched from CREATED to DEPLOYING.
2021-04-15 17:32:16,992 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (1/4)#0 (91f1e72fb3c553acd4846f4cc9d13aee) [DEPLOYING]
2021-04-15 17:32:16,992 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Sink: Print to Std. Out (1/4)#0 (91f1e72fb3c553acd4846f4cc9d13aee) [DEPLOYING].
2021-04-15 17:32:16,995 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 91f1e72fb3c553acd4846f4cc9d13aee at library cache manager took 2 milliseconds
2021-04-15 17:32:16,997 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Sink: Print to Std. Out (1/4)#0 (91f1e72fb3c553acd4846f4cc9d13aee) [DEPLOYING].
2021-04-15 17:32:16,999 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:32:17,000 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Using partitioner REBALANCE for output 0 of task Source: sensor
2021-04-15 17:32:17,000 INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (2/4)#0 (cb92e5ff57ec617806463ab320025499) switched from CREATED to DEPLOYING.
2021-04-15 17:32:17,001 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_312c56263ac1a28eec6b38bd513f1309], jobID=e9de8518a465d07297845be1a7d2e0c9, jobVertexID=0a448493b4782967b150582570326227, subtaskIndex=2}} for e9de8518a465d07297845be1a7d2e0c9 - 0a448493b4782967b150582570326227 - 2 under allocation id 312c56263ac1a28eec6b38bd513f1309.
2021-04-15 17:32:17,001 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (2/4)#0 (cb92e5ff57ec617806463ab320025499) [DEPLOYING]
2021-04-15 17:32:17,005 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Sink: Print to Std. Out (2/4)#0 (cb92e5ff57ec617806463ab320025499) [DEPLOYING].
2021-04-15 17:32:17,006 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task cb92e5ff57ec617806463ab320025499 at library cache manager took 0 milliseconds
2021-04-15 17:32:17,006 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Sink: Print to Std. Out (2/4)#0 (cb92e5ff57ec617806463ab320025499) [DEPLOYING].
2021-04-15 17:32:17,007 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:32:17,009 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - Sink: Print to Std. Out (3/4)#0 (3f24e477fb8841194487a8eb8d4c0ab7): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:32:17,010 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Sink: Print to Std. Out (3/4)#0 (3f24e477fb8841194487a8eb8d4c0ab7), deploy into slot with allocation id 312c56263ac1a28eec6b38bd513f1309.
2021-04-15 17:32:17,010 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 9fa5476ec54661d5dcd59697c027f783.
2021-04-15 17:32:17,014 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new allocation id 9fa5476ec54661d5dcd59697c027f783 for local state stores for job e9de8518a465d07297845be1a7d2e0c9.
2021-04-15 17:32:17,014 INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (3/4)#0 (3f24e477fb8841194487a8eb8d4c0ab7) switched from CREATED to DEPLOYING.
2021-04-15 17:32:17,015 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (3/4)#0 (3f24e477fb8841194487a8eb8d4c0ab7) [DEPLOYING]
2021-04-15 17:32:17,015 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Sink: Print to Std. Out (3/4)#0 (3f24e477fb8841194487a8eb8d4c0ab7) [DEPLOYING].
2021-04-15 17:32:17,015 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 3f24e477fb8841194487a8eb8d4c0ab7 at library cache manager took 0 milliseconds
2021-04-15 17:32:17,018 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Sink: Print to Std. Out (3/4)#0 (3f24e477fb8841194487a8eb8d4c0ab7) [DEPLOYING].
2021-04-15 17:32:17,018 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:32:17,019 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_9fa5476ec54661d5dcd59697c027f783], jobID=e9de8518a465d07297845be1a7d2e0c9, jobVertexID=0a448493b4782967b150582570326227, subtaskIndex=3}} for e9de8518a465d07297845be1a7d2e0c9 - 0a448493b4782967b150582570326227 - 3 under allocation id 9fa5476ec54661d5dcd59697c027f783.
2021-04-15 17:32:17,020 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - Sink: Print to Std. Out (4/4)#0 (c820ba6aa6fbbce775d0d6a096a64ae2): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:32:17,020 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Sink: Print to Std. Out (4/4)#0 (c820ba6aa6fbbce775d0d6a096a64ae2), deploy into slot with allocation id 9fa5476ec54661d5dcd59697c027f783.
2021-04-15 17:32:17,020 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:32:17,022 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:32:17,022 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:32:17,023 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:32:17,024 INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (4/4)#0 (c820ba6aa6fbbce775d0d6a096a64ae2) switched from CREATED to DEPLOYING.
2021-04-15 17:32:17,025 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (4/4)#0 (c820ba6aa6fbbce775d0d6a096a64ae2) [DEPLOYING]
2021-04-15 17:32:17,030 INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (3/4)#0 (3f24e477fb8841194487a8eb8d4c0ab7) switched from DEPLOYING to RUNNING.
2021-04-15 17:32:17,031 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Sink: Print to Std. Out (3/4)#0.
2021-04-15 17:32:17,031 INFO org.apache.flink.runtime.taskmanager.Task - Source: sensor (1/1)#0 (450b30e9c07df83514b84b34ad804ae3) switched from DEPLOYING to RUNNING.
2021-04-15 17:32:17,032 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Source: sensor (1/1)#0.
2021-04-15 17:32:17,031 INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (2/4)#0 (cb92e5ff57ec617806463ab320025499) switched from DEPLOYING to RUNNING.
2021-04-15 17:32:17,055 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Sink: Print to Std. Out (2/4)#0.
2021-04-15 17:32:17,031 INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (1/4)#0 (91f1e72fb3c553acd4846f4cc9d13aee) switched from DEPLOYING to RUNNING.
2021-04-15 17:32:17,066 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Sink: Print to Std. Out (1/4)#0.
2021-04-15 17:32:17,065 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (3/4) (3f24e477fb8841194487a8eb8d4c0ab7) switched from DEPLOYING to RUNNING.
2021-04-15 17:32:17,067 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: sensor (1/1) (450b30e9c07df83514b84b34ad804ae3) switched from DEPLOYING to RUNNING.
2021-04-15 17:32:17,067 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (2/4) (cb92e5ff57ec617806463ab320025499) switched from DEPLOYING to RUNNING.
2021-04-15 17:32:17,067 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (1/4) (91f1e72fb3c553acd4846f4cc9d13aee) switched from DEPLOYING to RUNNING.
2021-04-15 17:32:17,028 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Sink: Print to Std. Out (4/4)#0 (c820ba6aa6fbbce775d0d6a096a64ae2) [DEPLOYING].
2021-04-15 17:32:17,069 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task c820ba6aa6fbbce775d0d6a096a64ae2 at library cache manager took 0 milliseconds
2021-04-15 17:32:17,070 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Sink: Print to Std. Out (4/4)#0 (c820ba6aa6fbbce775d0d6a096a64ae2) [DEPLOYING].
2021-04-15 17:32:17,073 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:32:17,093 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:32:17,093 INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (4/4)#0 (c820ba6aa6fbbce775d0d6a096a64ae2) switched from DEPLOYING to RUNNING.
2021-04-15 17:32:17,094 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Sink: Print to Std. Out (4/4)#0.
2021-04-15 17:32:17,103 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (4/4) (c820ba6aa6fbbce775d0d6a096a64ae2) switched from DEPLOYING to RUNNING.
2021-04-15 17:32:17,115 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Source: sensor (1/1)#0
2021-04-15 17:32:17,169 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSource_bc764cd8ddf7a0cff126f51c16239658_(1/1) with empty state.
2021-04-15 17:32:17,171 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Sink: Print to Std. Out (3/4)#0
2021-04-15 17:32:17,172 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_0a448493b4782967b150582570326227_(3/4) with empty state.
2021-04-15 17:32:17,172 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Sink: Print to Std. Out (2/4)#0
2021-04-15 17:32:17,172 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_0a448493b4782967b150582570326227_(2/4) with empty state.
2021-04-15 17:32:17,172 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Sink: Print to Std. Out (4/4)#0
2021-04-15 17:32:17,173 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_0a448493b4782967b150582570326227_(4/4) with empty state.
2021-04-15 17:32:17,176 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Sink: Print to Std. Out (1/4)#0
2021-04-15 17:32:17,177 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_0a448493b4782967b150582570326227_(1/4) with empty state.
2021-04-15 17:32:17,209 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf - -Dorg.apache.flink.shaded.netty4.io.netty.buffer.checkAccessible: true
2021-04-15 17:32:17,209 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf - -Dorg.apache.flink.shaded.netty4.io.netty.buffer.checkBounds: true
2021-04-15 17:32:17,210 DEBUG o.a.f.s.n.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.flink.shaded.netty4.io.netty.util.ResourceLeakDetector@30ceac1b
2021-04-15 17:32:17,215 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - Sink: Print to Std. Out (1/4)#0 (91f1e72fb3c553acd4846f4cc9d13aee)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:32:17,215 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - Sink: Print to Std. Out (2/4)#0 (cb92e5ff57ec617806463ab320025499)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:32:17,216 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - Sink: Print to Std. Out (4/4)#0 (c820ba6aa6fbbce775d0d6a096a64ae2)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:32:17,217 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:32:17,219 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:32:17,218 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - Sink: Print to Std. Out (3/4)#0 (3f24e477fb8841194487a8eb8d4c0ab7)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:32:17,221 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:32:17,222 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:32:17,223 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:32:17,223 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:32:17,223 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:32:17,223 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:32:17,223 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [8c5d465939db86ffd156b06321db3698#0@450b30e9c07df83514b84b34ad804ae3]: Requesting LOCAL subpartition 0 of partition 8c5d465939db86ffd156b06321db3698#0@450b30e9c07df83514b84b34ad804ae3. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:32:17,224 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [8c5d465939db86ffd156b06321db3698#0@450b30e9c07df83514b84b34ad804ae3]: Requesting LOCAL subpartition 2 of partition 8c5d465939db86ffd156b06321db3698#0@450b30e9c07df83514b84b34ad804ae3. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:32:17,224 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [8c5d465939db86ffd156b06321db3698#0@450b30e9c07df83514b84b34ad804ae3]: Requesting LOCAL subpartition 3 of partition 8c5d465939db86ffd156b06321db3698#0@450b30e9c07df83514b84b34ad804ae3. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:32:17,224 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 0 of PipelinedResultPartition 8c5d465939db86ffd156b06321db3698#0@450b30e9c07df83514b84b34ad804ae3 [PIPELINED_BOUNDED, 4 subpartitions, 4 pending consumptions].
2021-04-15 17:32:17,224 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [8c5d465939db86ffd156b06321db3698#0@450b30e9c07df83514b84b34ad804ae3]: Requesting LOCAL subpartition 1 of partition 8c5d465939db86ffd156b06321db3698#0@450b30e9c07df83514b84b34ad804ae3. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:32:17,224 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: sensor (1/1)#0 (450b30e9c07df83514b84b34ad804ae3): Creating read view for subpartition 0 of partition 8c5d465939db86ffd156b06321db3698#0@450b30e9c07df83514b84b34ad804ae3.
2021-04-15 17:32:17,225 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 0) of ResultPartition 8c5d465939db86ffd156b06321db3698#0@450b30e9c07df83514b84b34ad804ae3
2021-04-15 17:32:17,229 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 2 of PipelinedResultPartition 8c5d465939db86ffd156b06321db3698#0@450b30e9c07df83514b84b34ad804ae3 [PIPELINED_BOUNDED, 4 subpartitions, 4 pending consumptions].
2021-04-15 17:32:17,229 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: sensor (1/1)#0 (450b30e9c07df83514b84b34ad804ae3): Creating read view for subpartition 2 of partition 8c5d465939db86ffd156b06321db3698#0@450b30e9c07df83514b84b34ad804ae3.
2021-04-15 17:32:17,229 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 2) of ResultPartition 8c5d465939db86ffd156b06321db3698#0@450b30e9c07df83514b84b34ad804ae3
2021-04-15 17:32:17,229 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 1 of PipelinedResultPartition 8c5d465939db86ffd156b06321db3698#0@450b30e9c07df83514b84b34ad804ae3 [PIPELINED_BOUNDED, 4 subpartitions, 4 pending consumptions].
2021-04-15 17:32:17,229 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: sensor (1/1)#0 (450b30e9c07df83514b84b34ad804ae3): Creating read view for subpartition 1 of partition 8c5d465939db86ffd156b06321db3698#0@450b30e9c07df83514b84b34ad804ae3.
2021-04-15 17:32:17,229 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 1) of ResultPartition 8c5d465939db86ffd156b06321db3698#0@450b30e9c07df83514b84b34ad804ae3
2021-04-15 17:32:17,231 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 3 of PipelinedResultPartition 8c5d465939db86ffd156b06321db3698#0@450b30e9c07df83514b84b34ad804ae3 [PIPELINED_BOUNDED, 4 subpartitions, 4 pending consumptions].
2021-04-15 17:32:17,231 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: sensor (1/1)#0 (450b30e9c07df83514b84b34ad804ae3): Creating read view for subpartition 3 of partition 8c5d465939db86ffd156b06321db3698#0@450b30e9c07df83514b84b34ad804ae3.
2021-04-15 17:32:17,231 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 3) of ResultPartition 8c5d465939db86ffd156b06321db3698#0@450b30e9c07df83514b84b34ad804ae3
2021-04-15 17:35:09,667 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:35:09,671 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.util.Random
2021-04-15 17:35:09,759 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.myorg.quickstart.other.DTransform.MultiStream$1
2021-04-15 17:35:09,803 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.myorg.quickstart.other.DTransform.MultiStream$3
2021-04-15 17:35:09,805 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.myorg.quickstart.other.DTransform.MultiStream$2
2021-04-15 17:35:09,837 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
2021-04-15 17:35:09,838 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:35:09,839 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:35:09,840 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:35:09,842 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:35:09,843 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:35:09,851 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
2021-04-15 17:35:09,851 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:35:09,852 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:35:09,852 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:35:09,852 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:35:09,853 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:35:09,854 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
2021-04-15 17:35:09,854 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:35:09,854 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:35:09,854 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:35:09,854 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:35:09,854 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:35:09,870 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
2021-04-15 17:35:09,870 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:35:09,870 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:35:09,870 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:35:09,870 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:35:09,870 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:35:09,892 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=2, name='Process', outputType=GenericType<java.lang.Object>, parallelism=1}
2021-04-15 17:35:09,897 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySourceTransformation{id=1, name='sensor', outputType=PojoType<org.myorg.quickstart.dto.SensorReading, fields = [id: String, temperature: Double, timestamp: Long]>, parallelism=1}
2021-04-15 17:35:09,907 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 1
2021-04-15 17:35:09,920 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 2
2021-04-15 17:35:09,921 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySinkTransformation{id=6, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=1}
2021-04-15 17:35:09,921 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming SideOutputTransformation{id=3, name='SideOutput', outputType=PojoType<org.myorg.quickstart.dto.SensorReading, fields = [id: String, temperature: Double, timestamp: Long]>, parallelism=1}
2021-04-15 17:35:09,930 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 6
2021-04-15 17:35:09,931 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySinkTransformation{id=7, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=1}
2021-04-15 17:35:09,931 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming SideOutputTransformation{id=5, name='SideOutput', outputType=PojoType<org.myorg.quickstart.dto.SensorReading, fields = [id: String, temperature: Double, timestamp: Long]>, parallelism=1}
2021-04-15 17:35:09,931 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 7
2021-04-15 17:35:09,931 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySinkTransformation{id=8, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=1}
2021-04-15 17:35:09,932 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming SideOutputTransformation{id=4, name='SideOutput', outputType=PojoType<org.myorg.quickstart.dto.SensorReading, fields = [id: String, temperature: Double, timestamp: Long]>, parallelism=1}
2021-04-15 17:35:09,932 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 8
2021-04-15 17:35:09,932 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySinkTransformation{id=10, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=1}
2021-04-15 17:35:09,932 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming UnionTransformation{id=9, name='Union', outputType=PojoType<org.myorg.quickstart.dto.SensorReading, fields = [id: String, temperature: Double, timestamp: Long]>, parallelism=1}
2021-04-15 17:35:09,933 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 10
2021-04-15 17:35:10,019 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'cbc357ccb763df2852fee8c4fc7d55f2' for node 'Source: sensor-1' {id: 1, parallelism: 1, user function: org.myorg.quickstart.util.SourceUtil}
2021-04-15 17:35:10,019 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '864ae8de554cc248475790a298b480bf' for node 'Process-2' {id: 2, parallelism: 1, user function: org.myorg.quickstart.other.DTransform.MultiStream$4}
2021-04-15 17:35:10,021 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '666d412a56e17eca4e56b80d012b9b4e' for node 'Sink: Print to Std. Out-6' {id: 6, parallelism: 1, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
2021-04-15 17:35:10,021 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '010fb2190e5aaa200fb1ceee04f4019d' for node 'Sink: Print to Std. Out-7' {id: 7, parallelism: 1, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
2021-04-15 17:35:10,021 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '36d907d3ace1ed44b5db1a8a56bdffa8' for node 'Sink: Print to Std. Out-8' {id: 8, parallelism: 1, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
2021-04-15 17:35:10,021 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'f5c76b9f24bd1684ec0becd4e81cafd6' for node 'Sink: Print to Std. Out-10' {id: 10, parallelism: 1, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
2021-04-15 17:35:10,101 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 10
2021-04-15 17:35:10,133 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 1
2021-04-15 17:35:10,143 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - CONNECTED: ForwardPartitioner - 1 -> 10
2021-04-15 17:35:10,143 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - CONNECTED: ForwardPartitioner - 1 -> 10
2021-04-15 17:35:10,143 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - CONNECTED: ForwardPartitioner - 1 -> 10
2021-04-15 17:35:10,194 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.
2021-04-15 17:35:10,195 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.
2021-04-15 17:35:10,195 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.
2021-04-15 17:35:10,196 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.min required for local execution is not set, setting it to its default value 64 mb.
2021-04-15 17:35:10,196 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.max required for local execution is not set, setting it to its default value 64 mb.
2021-04-15 17:35:10,196 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.
2021-04-15 17:35:10,218 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting Flink Mini Cluster
2021-04-15 17:35:10,219 DEBUG org.apache.flink.runtime.minicluster.MiniCluster - Using configuration MiniClusterConfiguration {singleRpcService=SHARED, numTaskManagers=1, commonBindAddress='null', config={taskmanager.memory.network.min=64 mb, taskmanager.cpu.cores=1.7976931348623157E308, taskmanager.memory.task.off-heap.size=9223372036854775807 bytes, execution.target=local, rest.bind-port=0, taskmanager.memory.network.max=64 mb, execution.attached=true, taskmanager.memory.managed.size=128 mb, parallelism.default=4, taskmanager.numberOfTaskSlots=1, taskmanager.memory.task.heap.size=9223372036854775807 bytes, rest.address=localhost}}
2021-04-15 17:35:10,223 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting Metrics Registry
2021-04-15 17:35:10,302 INFO org.apache.flink.runtime.metrics.MetricRegistryImpl - No metrics reporter configured, no metrics will be exposed/reported.
2021-04-15 17:35:10,302 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting RPC Service(s)
2021-04-15 17:35:10,504 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
2021-04-15 17:35:10,518 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Using akka configuration
 Config(SimpleConfigObject({"akka":{"actor":{"default-dispatcher":{"executor":"fork-join-executor","fork-join-executor":{"parallelism-factor":1,"parallelism-max":4,"parallelism-min":2},"throughput":15},"guardian-supervisor-strategy":"org.apache.flink.runtime.akka.EscalatingSupervisorStrategy","supervisor-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"type":"Dispatcher"},"warn-about-java-serializer-usage":"off"},"daemonic":"off","jvm-exit-on-fatal-error":"on","log-config-on-start":"off","log-dead-letters":"off","log-dead-letters-during-shutdown":"off","logger-startup-timeout":"30s","loggers":["akka.event.slf4j.Slf4jLogger"],"logging-filter":"akka.event.slf4j.Slf4jLoggingFilter","loglevel":"DEBUG","serialize-messages":"off","stdout-loglevel":"OFF"}}))
2021-04-15 17:35:11,271 INFO akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2021-04-15 17:35:11,294 DEBUG akka.event.EventStream - logger log1-Slf4jLogger started
2021-04-15 17:35:11,300 DEBUG akka.event.EventStream - Default Loggers started
2021-04-15 17:35:12,379 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink
2021-04-15 17:35:12,464 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
2021-04-15 17:35:12,466 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Using akka configuration
 Config(SimpleConfigObject({"akka":{"actor":{"default-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"thread-priority":1,"throughput":15,"type":"akka.dispatch.PriorityThreadsDispatcher"},"guardian-supervisor-strategy":"org.apache.flink.runtime.akka.EscalatingSupervisorStrategy","supervisor-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"type":"Dispatcher"},"warn-about-java-serializer-usage":"off"},"daemonic":"off","jvm-exit-on-fatal-error":"on","log-config-on-start":"off","log-dead-letters":"off","log-dead-letters-during-shutdown":"off","logger-startup-timeout":"30s","loggers":["akka.event.slf4j.Slf4jLogger"],"logging-filter":"akka.event.slf4j.Slf4jLoggingFilter","loglevel":"DEBUG","serialize-messages":"off","stdout-loglevel":"OFF"}}))
2021-04-15 17:35:12,539 INFO akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2021-04-15 17:35:12,544 DEBUG akka.event.EventStream - logger log1-Slf4jLogger started
2021-04-15 17:35:12,617 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink-metrics
2021-04-15 17:35:12,545 DEBUG akka.event.EventStream - Default Loggers started
2021-04-15 17:35:12,649 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting AkkaRpcActor with name MetricQueryService.
2021-04-15 17:35:12,660 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
2021-04-15 17:35:12,897 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting high-availability services
2021-04-15 17:35:13,656 INFO org.apache.flink.runtime.blob.BlobServer - Created BLOB server storage directory C:\Users\ccy\AppData\Local\Temp\blobStore-7a53f6a9-bf6c-4e6c-acee-40bf01ee878c
2021-04-15 17:35:13,665 DEBUG org.apache.flink.util.NetUtils - Trying to open socket on port 0
2021-04-15 17:35:13,667 INFO org.apache.flink.runtime.blob.BlobServer - Started BLOB server at 0.0.0.0:61747 - max concurrent requests: 50 - max backlog: 1000
2021-04-15 17:35:13,673 INFO org.apache.flink.runtime.blob.PermanentBlobCache - Created BLOB cache storage directory C:\Users\ccy\AppData\Local\Temp\blobStore-d5d026d3-c746-4a10-a45e-e0c9a51a813b
2021-04-15 17:35:13,675 INFO org.apache.flink.runtime.blob.TransientBlobCache - Created BLOB cache storage directory C:\Users\ccy\AppData\Local\Temp\blobStore-d89bc07d-183f-4817-b734-3634ef026e3d
2021-04-15 17:35:13,676 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting 1 TaskManger(s)
2021-04-15 17:35:13,680 INFO org.apache.flink.runtime.taskexecutor.TaskManagerRunner - Starting TaskManager with ResourceID: e030c6b3-5674-4e7a-8d41-83390b0a053c
2021-04-15 17:35:13,713 INFO o.apache.flink.runtime.taskexecutor.TaskManagerServices - Temporary file directory 'C:\Users\ccy\AppData\Local\Temp': total 137 GB, usable 24 GB (17.52% usable)
2021-04-15 17:35:13,716 INFO org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\ccy\AppData\Local\Temp\flink-io-406ae3c7-ce64-4e8d-9ac6-d69f312feb99 for spill files.
2021-04-15 17:35:13,725 INFO org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\ccy\AppData\Local\Temp\flink-netty-shuffle-2b4cfb7e-f85a-4e19-a0c9-6b9f3b5f3c72 for spill files.
2021-04-15 17:35:13,774 INFO o.a.flink.runtime.io.network.buffer.NetworkBufferPool - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2021-04-15 17:35:13,785 INFO o.a.flink.runtime.io.network.NettyShuffleEnvironment - Starting the network environment and its components.
2021-04-15 17:35:13,786 DEBUG o.a.flink.runtime.io.network.NettyShuffleEnvironment - Starting network connection manager
2021-04-15 17:35:13,788 INFO org.apache.flink.runtime.taskexecutor.KvStateService - Starting the kvState service and its components.
2021-04-15 17:35:13,802 DEBUG o.a.flink.runtime.taskexecutor.TaskManagerConfiguration - Messages have a max timeout of 10000 ms
2021-04-15 17:35:13,814 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting AkkaRpcActor with name taskmanager_0.
2021-04-15 17:35:13,815 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2021-04-15 17:35:13,828 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Start job leader service.
2021-04-15 17:35:13,830 INFO org.apache.flink.runtime.filecache.FileCache - User file cache uses directory C:\Users\ccy\AppData\Local\Temp\flink-dist-cache-decda7d4-b39d-4ee8-9042-417a0dbb3d2f
2021-04-15 17:35:13,887 DEBUG o.a.f.r.e.c.DefaultDispatcherResourceManagerComponentFactory - Starting Dispatcher REST endpoint.
2021-04-15 17:35:13,888 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Starting rest endpoint.
2021-04-15 17:35:13,899 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Failed to load web based job submission extension.
org.apache.flink.util.FlinkException: The module flink-runtime-web could not be found in the class path. Please add this jar in order to enable web based job submission.
	at org.apache.flink.runtime.webmonitor.WebMonitorUtils.loadWebSubmissionExtension(WebMonitorUtils.java:199) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint.initializeWebSubmissionHandlers(DispatcherRestEndpoint.java:112) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.webmonitor.WebMonitorEndpoint.initializeHandlers(WebMonitorEndpoint.java:228) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint.initializeHandlers(DispatcherRestEndpoint.java:89) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:144) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:172) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:463) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:422) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:366) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.program.PerJobMiniClusterFactory.submitJob(PerJobMiniClusterFactory.java:75) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:85) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1905) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1796) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:69) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1782) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1765) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.myorg.quickstart.other.DTransform.MultiStream.main(MultiStream.java:63) ~[classes/:na]
2021-04-15 17:35:14,139 DEBUG o.a.f.s.n.i.n.u.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
2021-04-15 17:35:14,139 DEBUG o.a.f.s.n.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2021-04-15 17:35:14,140 DEBUG o.a.f.s.n.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2021-04-15 17:35:14,218 WARN org.apache.flink.runtime.webmonitor.WebMonitorUtils - Log file environment variable 'log.file' is not set.
2021-04-15 17:35:14,218 WARN org.apache.flink.runtime.webmonitor.WebMonitorUtils - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'web.log.path'.
2021-04-15 17:35:14,257 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - Platform: Windows
2021-04-15 17:35:14,259 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
2021-04-15 17:35:14,260 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - Java version: 11
2021-04-15 17:35:14,261 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
2021-04-15 17:35:14,262 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
2021-04-15 17:35:14,262 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
2021-04-15 17:35:14,264 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: unavailable
java.lang.UnsupportedOperationException: Reflective setAccessible(true) disabled
	at org.apache.flink.shaded.netty4.io.netty.util.internal.ReflectionUtil.trySetAccessible(ReflectionUtil.java:31) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0$4.run(PlatformDependent0.java:233) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at java.base/java.security.AccessController.doPrivileged(Native Method) ~[na:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:227) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.isAndroid(PlatformDependent.java:289) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:92) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:223) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:210) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.cached(AsciiString.java:1401) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<clinit>(AsciiString.java:48) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<init>(HttpMethod.java:135) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<clinit>(HttpMethod.java:36) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.runtime.rest.HttpMethodWrapper.<clinit>(HttpMethodWrapper.java:27) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.messages.cluster.ShutdownHeaders.getHttpMethod(ShutdownHeaders.java:57) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.checkAllEndpointsAndHandlersAreUnique(RestServerEndpoint.java:572) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:155) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:172) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:463) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:422) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:366) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.program.PerJobMiniClusterFactory.submitJob(PerJobMiniClusterFactory.java:75) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:85) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1905) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1796) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:69) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1782) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1765) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.myorg.quickstart.other.DTransform.MultiStream.main(MultiStream.java:63) ~[classes/:na]
2021-04-15 17:35:14,265 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
2021-04-15 17:35:14,267 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable
java.lang.IllegalAccessException: class org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0$6 cannot access class jdk.internal.misc.Unsafe (in module java.base) because module java.base does not export jdk.internal.misc to unnamed module @3cce57c7
	at java.base/jdk.internal.reflect.Reflection.newIllegalAccessException(Reflection.java:361) ~[na:na]
	at java.base/java.lang.reflect.AccessibleObject.checkAccess(AccessibleObject.java:591) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:558) ~[na:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0$6.run(PlatformDependent0.java:347) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at java.base/java.security.AccessController.doPrivileged(Native Method) ~[na:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:338) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.isAndroid(PlatformDependent.java:289) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:92) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:223) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:210) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.cached(AsciiString.java:1401) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<clinit>(AsciiString.java:48) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<init>(HttpMethod.java:135) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<clinit>(HttpMethod.java:36) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.runtime.rest.HttpMethodWrapper.<clinit>(HttpMethodWrapper.java:27) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.messages.cluster.ShutdownHeaders.getHttpMethod(ShutdownHeaders.java:57) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.checkAllEndpointsAndHandlersAreUnique(RestServerEndpoint.java:572) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:155) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:172) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:463) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:422) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:366) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.program.PerJobMiniClusterFactory.submitJob(PerJobMiniClusterFactory.java:75) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:85) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1905) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1796) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:69) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1782) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1765) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.myorg.quickstart.other.DTransform.MultiStream.main(MultiStream.java:63) ~[classes/:na]
2021-04-15 17:35:14,267 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): unavailable
2021-04-15 17:35:14,267 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
2021-04-15 17:35:14,268 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - maxDirectMemory: 2122317824 bytes (maybe)
2021-04-15 17:35:14,269 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\ccy\AppData\Local\Temp (java.io.tmpdir)
2021-04-15 17:35:14,269 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
2021-04-15 17:35:14,270 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: -1 bytes
2021-04-15 17:35:14,277 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
2021-04-15 17:35:14,278 DEBUG o.a.f.shaded.netty4.io.netty.util.internal.CleanerJava9 - java.nio.ByteBuffer.cleaner(): available
2021-04-15 17:35:14,278 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
2021-04-15 17:35:14,283 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@523a7801 under DELETE@/v1/cluster.
2021-04-15 17:35:14,284 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@523a7801 under DELETE@/cluster.
2021-04-15 17:35:14,284 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@79a13920 under GET@/v1/config.
2021-04-15 17:35:14,284 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@79a13920 under GET@/config.
2021-04-15 17:35:14,285 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetListHandler@182e7eda under GET@/v1/datasets.
2021-04-15 17:35:14,285 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetListHandler@182e7eda under GET@/datasets.
2021-04-15 17:35:14,285 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteStatusHandler@5f61371d under GET@/v1/datasets/delete/:triggerid.
2021-04-15 17:35:14,285 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteStatusHandler@5f61371d under GET@/datasets/delete/:triggerid.
2021-04-15 17:35:14,285 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteTriggerHandler@420a8042 under DELETE@/v1/datasets/:datasetid.
2021-04-15 17:35:14,285 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteTriggerHandler@420a8042 under DELETE@/datasets/:datasetid.
2021-04-15 17:35:14,285 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@3292d91a under GET@/v1/jobmanager/config.
2021-04-15 17:35:14,285 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@3292d91a under GET@/jobmanager/config.
2021-04-15 17:35:14,286 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@5921b93c under GET@/v1/jobmanager/log.
2021-04-15 17:35:14,286 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@5921b93c under GET@/jobmanager/log.
2021-04-15 17:35:14,286 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogListHandler@faea4da under GET@/v1/jobmanager/logs.
2021-04-15 17:35:14,286 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogListHandler@faea4da under GET@/jobmanager/logs.
2021-04-15 17:35:14,286 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerCustomLogHandler@19b02dfd under GET@/v1/jobmanager/logs/:filename.
2021-04-15 17:35:14,286 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerCustomLogHandler@19b02dfd under GET@/jobmanager/logs/:filename.
2021-04-15 17:35:14,286 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@3dce6dd8 under GET@/v1/jobmanager/metrics.
2021-04-15 17:35:14,286 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@3dce6dd8 under GET@/jobmanager/metrics.
2021-04-15 17:35:14,286 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@69f2cb04 under GET@/v1/jobmanager/stdout.
2021-04-15 17:35:14,286 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@69f2cb04 under GET@/jobmanager/stdout.
2021-04-15 17:35:14,286 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@13803a94 under GET@/v1/jobs.
2021-04-15 17:35:14,286 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@13803a94 under GET@/jobs.
2021-04-15 17:35:14,286 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@b4732dc under POST@/v1/jobs.
2021-04-15 17:35:14,286 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@b4732dc under POST@/jobs.
2021-04-15 17:35:14,286 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@45292ec1 under GET@/v1/jobs/metrics.
2021-04-15 17:35:14,286 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@45292ec1 under GET@/jobs/metrics.
2021-04-15 17:35:14,286 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@3a7c678b under GET@/v1/jobs/overview.
2021-04-15 17:35:14,286 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@3a7c678b under GET@/jobs/overview.
2021-04-15 17:35:14,286 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@28babeca under GET@/v1/jobs/:jobid.
2021-04-15 17:35:14,287 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@28babeca under GET@/jobs/:jobid.
2021-04-15 17:35:14,287 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@1ad9b8d3 under PATCH@/v1/jobs/:jobid.
2021-04-15 17:35:14,287 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@1ad9b8d3 under PATCH@/jobs/:jobid.
2021-04-15 17:35:14,287 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@168ad26f under GET@/v1/jobs/:jobid/accumulators.
2021-04-15 17:35:14,287 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@168ad26f under GET@/jobs/:jobid/accumulators.
2021-04-15 17:35:14,287 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@4f93bf0a under GET@/v1/jobs/:jobid/checkpoints.
2021-04-15 17:35:14,287 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@4f93bf0a under GET@/jobs/:jobid/checkpoints.
2021-04-15 17:35:14,287 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@322204dc under GET@/v1/jobs/:jobid/checkpoints/config.
2021-04-15 17:35:14,287 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@322204dc under GET@/jobs/:jobid/checkpoints/config.
2021-04-15 17:35:14,287 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@656a3d6b under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid.
2021-04-15 17:35:14,287 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@656a3d6b under GET@/jobs/:jobid/checkpoints/details/:checkpointid.
2021-04-15 17:35:14,287 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@25b38203 under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
2021-04-15 17:35:14,287 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@25b38203 under GET@/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
2021-04-15 17:35:14,287 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@778a1250 under GET@/v1/jobs/:jobid/config.
2021-04-15 17:35:14,288 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@778a1250 under GET@/jobs/:jobid/config.
2021-04-15 17:35:14,288 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.coordination.ClientCoordinationHandler@55acec99 under POST@/v1/jobs/:jobid/coordinators/:operatorid.
2021-04-15 17:35:14,288 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.coordination.ClientCoordinationHandler@55acec99 under POST@/jobs/:jobid/coordinators/:operatorid.
2021-04-15 17:35:14,288 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@61191222 under GET@/v1/jobs/:jobid/exceptions.
2021-04-15 17:35:14,288 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@61191222 under GET@/jobs/:jobid/exceptions.
2021-04-15 17:35:14,288 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@58833798 under GET@/v1/jobs/:jobid/execution-result.
2021-04-15 17:35:14,288 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@58833798 under GET@/jobs/:jobid/execution-result.
2021-04-15 17:35:14,288 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@7f3ca64a under GET@/v1/jobs/:jobid/metrics.
2021-04-15 17:35:14,289 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@7f3ca64a under GET@/jobs/:jobid/metrics.
2021-04-15 17:35:14,289 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@4d464510 under GET@/v1/jobs/:jobid/plan.
2021-04-15 17:35:14,289 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@4d464510 under GET@/jobs/:jobid/plan.
2021-04-15 17:35:14,289 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@64e7d698 under PATCH@/v1/jobs/:jobid/rescaling.
2021-04-15 17:35:14,289 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@64e7d698 under PATCH@/jobs/:jobid/rescaling.
2021-04-15 17:35:14,289 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@2519026b under GET@/v1/jobs/:jobid/rescaling/:triggerid.
2021-04-15 17:35:14,289 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@2519026b under GET@/jobs/:jobid/rescaling/:triggerid.
2021-04-15 17:35:14,289 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@3f8dfe74 under POST@/v1/jobs/:jobid/savepoints.
2021-04-15 17:35:14,289 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@3f8dfe74 under POST@/jobs/:jobid/savepoints.
2021-04-15 17:35:14,289 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@401c4250 under GET@/v1/jobs/:jobid/savepoints/:triggerid.
2021-04-15 17:35:14,289 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@401c4250 under GET@/jobs/:jobid/savepoints/:triggerid.
2021-04-15 17:35:14,289 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@1a950fdd under POST@/v1/jobs/:jobid/stop.
2021-04-15 17:35:14,289 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@1a950fdd under POST@/jobs/:jobid/stop.
2021-04-15 17:35:14,289 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@77724cbe under GET@/v1/jobs/:jobid/vertices/:vertexid.
2021-04-15 17:35:14,289 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@77724cbe under GET@/jobs/:jobid/vertices/:vertexid.
2021-04-15 17:35:14,289 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@27dc627a under GET@/v1/jobs/:jobid/vertices/:vertexid/accumulators.
2021-04-15 17:35:14,289 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@27dc627a under GET@/jobs/:jobid/vertices/:vertexid/accumulators.
2021-04-15 17:35:14,290 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@570ba13 under GET@/v1/jobs/:jobid/vertices/:vertexid/backpressure.
2021-04-15 17:35:14,290 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@570ba13 under GET@/jobs/:jobid/vertices/:vertexid/backpressure.
2021-04-15 17:35:14,290 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@37a9b687 under GET@/v1/jobs/:jobid/vertices/:vertexid/metrics.
2021-04-15 17:35:14,290 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@37a9b687 under GET@/jobs/:jobid/vertices/:vertexid/metrics.
2021-04-15 17:35:14,290 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@525b1b70 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
2021-04-15 17:35:14,290 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@525b1b70 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
2021-04-15 17:35:14,290 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@16d07cf3 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
2021-04-15 17:35:14,290 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@16d07cf3 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
2021-04-15 17:35:14,290 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@16f0ec18 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
2021-04-15 17:35:14,290 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@16f0ec18 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
2021-04-15 17:35:14,290 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@6c977dcf under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
2021-04-15 17:35:14,290 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@6c977dcf under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
2021-04-15 17:35:14,290 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@661d6bb6 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
2021-04-15 17:35:14,291 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@661d6bb6 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
2021-04-15 17:35:14,291 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@733fb462 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
2021-04-15 17:35:14,291 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@733fb462 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
2021-04-15 17:35:14,291 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@623e0631 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasktimes.
2021-04-15 17:35:14,291 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@623e0631 under GET@/jobs/:jobid/vertices/:vertexid/subtasktimes.
2021-04-15 17:35:14,291 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@359066bc under GET@/v1/jobs/:jobid/vertices/:vertexid/taskmanagers.
2021-04-15 17:35:14,291 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@359066bc under GET@/jobs/:jobid/vertices/:vertexid/taskmanagers.
2021-04-15 17:35:14,291 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@385dfb63 under GET@/v1/jobs/:jobid/vertices/:vertexid/watermarks.
2021-04-15 17:35:14,291 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@385dfb63 under GET@/jobs/:jobid/vertices/:vertexid/watermarks.
2021-04-15 17:35:14,291 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@364fd4ae under GET@/v1/jobs/:jobid/yarn-cancel.
2021-04-15 17:35:14,291 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@364fd4ae under GET@/jobs/:jobid/yarn-cancel.
2021-04-15 17:35:14,292 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@245253d8 under GET@/v1/jobs/:jobid/yarn-stop.
2021-04-15 17:35:14,292 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@245253d8 under GET@/jobs/:jobid/yarn-stop.
2021-04-15 17:35:14,292 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@12417468 under GET@/v1/overview.
2021-04-15 17:35:14,292 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@12417468 under GET@/overview.
2021-04-15 17:35:14,292 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@459003a0 under POST@/v1/savepoint-disposal.
2021-04-15 17:35:14,292 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@459003a0 under POST@/savepoint-disposal.
2021-04-15 17:35:14,292 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@d325518 under GET@/v1/savepoint-disposal/:triggerid.
2021-04-15 17:35:14,292 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@d325518 under GET@/savepoint-disposal/:triggerid.
2021-04-15 17:35:14,292 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@3b481bf5 under GET@/v1/taskmanagers.
2021-04-15 17:35:14,292 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@3b481bf5 under GET@/taskmanagers.
2021-04-15 17:35:14,292 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@2233cac0 under GET@/v1/taskmanagers/metrics.
2021-04-15 17:35:14,292 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@2233cac0 under GET@/taskmanagers/metrics.
2021-04-15 17:35:14,292 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@67fb5025 under GET@/v1/taskmanagers/:taskmanagerid.
2021-04-15 17:35:14,293 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@67fb5025 under GET@/taskmanagers/:taskmanagerid.
2021-04-15 17:35:14,293 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@787e4357 under GET@/v1/taskmanagers/:taskmanagerid/log.
2021-04-15 17:35:14,293 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@787e4357 under GET@/taskmanagers/:taskmanagerid/log.
2021-04-15 17:35:14,293 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogListHandler@392781e under GET@/v1/taskmanagers/:taskmanagerid/logs.
2021-04-15 17:35:14,293 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogListHandler@392781e under GET@/taskmanagers/:taskmanagerid/logs.
2021-04-15 17:35:14,293 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerCustomLogHandler@3fcbc766 under GET@/v1/taskmanagers/:taskmanagerid/logs/:filename.
2021-04-15 17:35:14,293 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerCustomLogHandler@3fcbc766 under GET@/taskmanagers/:taskmanagerid/logs/:filename.
2021-04-15 17:35:14,293 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@28cd2c2 under GET@/v1/taskmanagers/:taskmanagerid/metrics.
2021-04-15 17:35:14,293 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@28cd2c2 under GET@/taskmanagers/:taskmanagerid/metrics.
2021-04-15 17:35:14,293 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@8e25d3f under GET@/v1/taskmanagers/:taskmanagerid/stdout.
2021-04-15 17:35:14,293 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@8e25d3f under GET@/taskmanagers/:taskmanagerid/stdout.
2021-04-15 17:35:14,293 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerThreadDumpHandler@18a096b5 under GET@/v1/taskmanagers/:taskmanagerid/thread-dump.
2021-04-15 17:35:14,293 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerThreadDumpHandler@18a096b5 under GET@/taskmanagers/:taskmanagerid/thread-dump.
2021-04-15 17:35:14,298 DEBUG o.a.f.s.n.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 8
2021-04-15 17:35:14,326 DEBUG o.a.f.shaded.netty4.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
2021-04-15 17:35:14,326 DEBUG o.a.f.shaded.netty4.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
2021-04-15 17:35:14,335 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
2021-04-15 17:35:14,394 DEBUG o.a.f.shaded.netty4.io.netty.channel.DefaultChannelId - -Dio.netty.processId: 13804 (auto-detected)
2021-04-15 17:35:14,397 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
2021-04-15 17:35:14,397 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
2021-04-15 17:35:15,166 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
2021-04-15 17:35:15,167 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
2021-04-15 17:35:15,889 DEBUG o.a.f.shaded.netty4.io.netty.channel.DefaultChannelId - -Dio.netty.machineId: 2c:6f:c9:ff:fe:1c:21:83 (auto-detected)
2021-04-15 17:35:15,901 DEBUG o.a.f.shaded.netty4.io.netty.util.ResourceLeakDetector - -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.level: simple
2021-04-15 17:35:15,902 DEBUG o.a.f.shaded.netty4.io.netty.util.ResourceLeakDetector - -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.targetRecords: 4
2021-04-15 17:35:15,925 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 8
2021-04-15 17:35:15,925 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 8
2021-04-15 17:35:15,925 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
2021-04-15 17:35:15,925 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 11
2021-04-15 17:35:15,925 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 16777216
2021-04-15 17:35:15,925 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.tinyCacheSize: 512
2021-04-15 17:35:15,925 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
2021-04-15 17:35:15,925 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
2021-04-15 17:35:15,925 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2021-04-15 17:35:15,925 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
2021-04-15 17:35:15,925 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2021-04-15 17:35:15,925 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: true
2021-04-15 17:35:15,925 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2021-04-15 17:35:15,932 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
2021-04-15 17:35:15,933 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 0
2021-04-15 17:35:15,933 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
2021-04-15 17:35:15,949 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Binding rest endpoint to null:0.
2021-04-15 17:35:15,949 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Rest endpoint listening at localhost:61766
2021-04-15 17:35:15,951 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender http://localhost:61766
2021-04-15 17:35:15,955 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - http://localhost:61766 was granted leadership with leaderSessionID=0eb8c2f3-f7ed-4580-9580-3f62288d3126
2021-04-15 17:35:15,956 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader http://localhost:61766 , session=0eb8c2f3-f7ed-4580-9580-3f62288d3126
2021-04-15 17:35:15,974 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting FencedAkkaRpcActor with name resourcemanager_1.
2021-04-15 17:35:15,975 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_1 .
2021-04-15 17:35:15,988 DEBUG o.a.f.r.e.c.DefaultDispatcherResourceManagerComponentFactory - Starting Dispatcher.
2021-04-15 17:35:15,992 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
2021-04-15 17:35:15,992 DEBUG o.a.f.r.e.c.DefaultDispatcherResourceManagerComponentFactory - Starting ResourceManager.
2021-04-15 17:35:15,992 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: StandaloneResourceManager
2021-04-15 17:35:15,993 DEBUG o.a.f.runtime.dispatcher.runner.DefaultDispatcherRunner - Create new DispatcherLeaderProcess with leader session id 77cda3d9-839d-40bd-a4bf-c5b25e899d1a.
2021-04-15 17:35:15,995 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - ResourceManager akka://flink/user/rpc/resourcemanager_1 was granted leadership with fencing token a6061ea247a36bbaa4d839adf21c4f16
2021-04-15 17:35:15,996 INFO org.apache.flink.runtime.minicluster.MiniCluster - Flink Mini Cluster started successfully
2021-04-15 17:35:15,999 INFO o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Starting the SlotManager.
2021-04-15 17:35:16,000 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Start SessionDispatcherLeaderProcess.
2021-04-15 17:35:16,003 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Recover all persisted job graphs.
2021-04-15 17:35:16,003 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Successfully recovered 0 persisted job graphs.
2021-04-15 17:35:16,004 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:35:16,004 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:35:16,006 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/resourcemanager_1 , session=a4d839ad-f21c-4f16-a606-1ea247a36bba
2021-04-15 17:35:16,010 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:35:16,013 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting FencedAkkaRpcActor with name dispatcher_2.
2021-04-15 17:35:16,013 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:35:16,014 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(a6061ea247a36bbaa4d839adf21c4f16).
2021-04-15 17:35:16,019 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_2 .
2021-04-15 17:35:16,024 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:35:16,035 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/dispatcher_2 , session=77cda3d9-839d-40bd-a4bf-c5b25e899d1a
2021-04-15 17:35:16,036 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/dispatcher_2. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
2021-04-15 17:35:16,037 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/dispatcher_2. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
2021-04-15 17:35:16,050 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Resolved ResourceManager address, beginning registration
2021-04-15 17:35:16,051 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Registration at ResourceManager attempt 1 (timeout=100ms)
2021-04-15 17:35:16,058 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
2021-04-15 17:35:16,072 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Registering TaskManager with ResourceID e030c6b3-5674-4e7a-8d41-83390b0a053c (akka://flink/user/rpc/taskmanager_0) at ResourceManager
2021-04-15 17:35:16,075 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Successful registration at resource manager akka://flink/user/rpc/resourcemanager_1 under registration id 8aa22bd1935c0bed825541c80ecf2bce.
2021-04-15 17:35:16,079 DEBUG o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Registering TaskManager e030c6b3-5674-4e7a-8d41-83390b0a053c under 8aa22bd1935c0bed825541c80ecf2bce at the SlotManager.
2021-04-15 17:35:16,086 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Received JobGraph submission 9d1409a665da0496f2932c71f6a847a1 (Flink Streaming Job).
2021-04-15 17:35:16,087 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Submitting job 9d1409a665da0496f2932c71f6a847a1 (Flink Streaming Job).
2021-04-15 17:35:16,101 DEBUG org.apache.flink.client.ClientUtils - Wait until job initialization is finished
2021-04-15 17:35:16,107 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: JobManagerRunnerImpl
2021-04-15 17:35:16,114 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting FencedAkkaRpcActor with name jobmanager_3.
2021-04-15 17:35:16,114 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
2021-04-15 17:35:16,126 INFO org.apache.flink.runtime.jobmaster.JobMaster - Initializing job Flink Streaming Job (9d1409a665da0496f2932c71f6a847a1).
2021-04-15 17:35:16,144 INFO org.apache.flink.runtime.jobmaster.JobMaster - Using restart back off time strategy NoRestartBackoffTimeStrategy for Flink Streaming Job (9d1409a665da0496f2932c71f6a847a1).
2021-04-15 17:35:16,188 INFO org.apache.flink.runtime.jobmaster.JobMaster - Running initialization on master for job Flink Streaming Job (9d1409a665da0496f2932c71f6a847a1).
2021-04-15 17:35:16,188 INFO org.apache.flink.runtime.jobmaster.JobMaster - Successfully ran initialization on master in 0 ms.
2021-04-15 17:35:16,188 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Adding 2 vertices from job graph Flink Streaming Job (9d1409a665da0496f2932c71f6a847a1).
2021-04-15 17:35:16,189 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Attaching 2 topologically sorted vertices to existing job graph with 0 vertices and 0 intermediate results.
2021-04-15 17:35:16,204 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex cbc357ccb763df2852fee8c4fc7d55f2 (Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out)) to 0 predecessors.
2021-04-15 17:35:16,204 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex f5c76b9f24bd1684ec0becd4e81cafd6 (Sink: Print to Std. Out) to 3 predecessors.
2021-04-15 17:35:16,204 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting input 0 of vertex f5c76b9f24bd1684ec0becd4e81cafd6 (Sink: Print to Std. Out) to intermediate result referenced via predecessor cbc357ccb763df2852fee8c4fc7d55f2 (Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out)).
2021-04-15 17:35:16,205 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting input 1 of vertex f5c76b9f24bd1684ec0becd4e81cafd6 (Sink: Print to Std. Out) to intermediate result referenced via predecessor cbc357ccb763df2852fee8c4fc7d55f2 (Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out)).
2021-04-15 17:35:16,205 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting input 2 of vertex f5c76b9f24bd1684ec0becd4e81cafd6 (Sink: Print to Std. Out) to intermediate result referenced via predecessor cbc357ccb763df2852fee8c4fc7d55f2 (Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out)).
2021-04-15 17:35:16,215 INFO o.a.f.r.scheduler.adapter.DefaultExecutionTopology - Built 1 pipelined regions in 1 ms
2021-04-15 17:35:16,217 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Successfully created execution graph from job graph Flink Streaming Job (9d1409a665da0496f2932c71f6a847a1).
2021-04-15 17:35:16,235 INFO org.apache.flink.runtime.jobmaster.JobMaster - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:35:16,254 DEBUG o.apache.flink.runtime.checkpoint.CheckpointCoordinator - Status of the shared state registry of job 9d1409a665da0496f2932c71f6a847a1 after restore: SharedStateRegistry{registeredStates={}}.
2021-04-15 17:35:16,254 INFO o.apache.flink.runtime.checkpoint.CheckpointCoordinator - No checkpoint found during restore.
2021-04-15 17:35:16,256 INFO org.apache.flink.runtime.jobmaster.JobMaster - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@1ca780cd for Flink Streaming Job (9d1409a665da0496f2932c71f6a847a1).
2021-04-15 17:35:16,274 INFO org.apache.flink.runtime.jobmaster.JobManagerRunnerImpl - JobManager runner for job Flink Streaming Job (9d1409a665da0496f2932c71f6a847a1) was granted leadership with session id b4f3e53a-f2ed-4f97-b1df-49b5b9c9e663 at akka://flink/user/rpc/jobmanager_3.
2021-04-15 17:35:16,281 INFO org.apache.flink.runtime.jobmaster.JobMaster - Starting execution of job Flink Streaming Job (9d1409a665da0496f2932c71f6a847a1) under job master id b1df49b5b9c9e663b4f3e53af2ed4f97.
2021-04-15 17:35:16,283 INFO org.apache.flink.runtime.jobmaster.JobMaster - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2021-04-15 17:35:16,284 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Job Flink Streaming Job (9d1409a665da0496f2932c71f6a847a1) switched from state CREATED to RUNNING.
2021-04-15 17:35:16,289 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1) (f23daafaedd8cee3f74cd54bc39000dd) switched from CREATED to SCHEDULED.
2021-04-15 17:35:16,289 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (1/1) (6feafd3d5c8ae65013b100fa3a7611d0) switched from CREATED to SCHEDULED.
2021-04-15 17:35:16,299 DEBUG o.a.f.r.jobmaster.slotpool.PhysicalSlotProviderImpl - Received slot request [SlotRequestId{bf40a17fdc197c276c7e614d64dbd207}] with resource requirements: ResourceProfile{UNKNOWN}
2021-04-15 17:35:16,303 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{bf40a17fdc197c276c7e614d64dbd207}]
2021-04-15 17:35:16,306 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{da9ca1d54e12134e5ecd5b6d742c7a5f}) for execution vertex (id cbc357ccb763df2852fee8c4fc7d55f2_0) from the physical slot (SlotRequestId{bf40a17fdc197c276c7e614d64dbd207})
2021-04-15 17:35:16,308 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{41b19784e557196cb5951b71c78b04a4}) for execution vertex (id f5c76b9f24bd1684ec0becd4e81cafd6_0) from the physical slot (SlotRequestId{bf40a17fdc197c276c7e614d64dbd207})
2021-04-15 17:35:16,315 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
2021-04-15 17:35:16,316 INFO org.apache.flink.runtime.jobmaster.JobMaster - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(a6061ea247a36bbaa4d839adf21c4f16)
2021-04-15 17:35:16,315 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/jobmanager_3 , session=b4f3e53a-f2ed-4f97-b1df-49b5b9c9e663
2021-04-15 17:35:16,318 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:35:16,320 INFO org.apache.flink.runtime.jobmaster.JobMaster - Resolved ResourceManager address, beginning registration
2021-04-15 17:35:16,320 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Registration at ResourceManager attempt 1 (timeout=100ms)
2021-04-15 17:35:16,320 DEBUG o.a.flink.runtime.resourcemanager.JobLeaderIdService - Add job 9d1409a665da0496f2932c71f6a847a1 to job leader id monitoring.
2021-04-15 17:35:16,322 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Registering job manager b1df49b5b9c9e663b4f3e53af2ed4f97@akka://flink/user/rpc/jobmanager_3 for job 9d1409a665da0496f2932c71f6a847a1.
2021-04-15 17:35:16,323 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/jobmanager_3. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2021-04-15 17:35:16,323 DEBUG o.a.flink.runtime.resourcemanager.JobLeaderIdService - Found a new job leader b4f3e53a-f2ed-4f97-b1df-49b5b9c9e663@akka://flink/user/rpc/jobmanager_3.
2021-04-15 17:35:16,330 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Registered job manager b1df49b5b9c9e663b4f3e53af2ed4f97@akka://flink/user/rpc/jobmanager_3 for job 9d1409a665da0496f2932c71f6a847a1.
2021-04-15 17:35:16,333 INFO org.apache.flink.runtime.jobmaster.JobMaster - JobManager successfully registered at ResourceManager, leader id: a6061ea247a36bbaa4d839adf21c4f16.
2021-04-15 17:35:16,335 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{bf40a17fdc197c276c7e614d64dbd207}] and profile ResourceProfile{UNKNOWN} with allocation id 56af020fbe2a8b9be41d6d05061ec16a from resource manager.
2021-04-15 17:35:16,336 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 9d1409a665da0496f2932c71f6a847a1 with allocation id 56af020fbe2a8b9be41d6d05061ec16a.
2021-04-15 17:35:16,341 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 56af020fbe2a8b9be41d6d05061ec16a for job 9d1409a665da0496f2932c71f6a847a1 from resource manager with leader id a6061ea247a36bbaa4d839adf21c4f16.
2021-04-15 17:35:16,350 DEBUG org.apache.flink.runtime.memory.MemoryManager - Initialized MemoryManager with total memory size 134217728 and page size 32768.
2021-04-15 17:35:16,351 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 56af020fbe2a8b9be41d6d05061ec16a.
2021-04-15 17:35:16,352 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Add job 9d1409a665da0496f2932c71f6a847a1 for job leader monitoring.
2021-04-15 17:35:16,354 DEBUG o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - New leader information for job 9d1409a665da0496f2932c71f6a847a1. Address: akka://flink/user/rpc/jobmanager_3, leader id: b1df49b5b9c9e663b4f3e53af2ed4f97.
2021-04-15 17:35:16,356 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Try to register at job manager akka://flink/user/rpc/jobmanager_3 with leader id b4f3e53a-f2ed-4f97-b1df-49b5b9c9e663.
2021-04-15 17:35:16,356 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/jobmanager_3. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2021-04-15 17:35:16,358 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Resolved JobManager address, beginning registration
2021-04-15 17:35:16,358 DEBUG o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Registration at JobManager attempt 1 (timeout=100ms)
2021-04-15 17:35:16,361 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
2021-04-15 17:35:16,362 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Register new TaskExecutor e030c6b3-5674-4e7a-8d41-83390b0a053c.
2021-04-15 17:35:16,363 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Successful registration at job manager akka://flink/user/rpc/jobmanager_3 for job 9d1409a665da0496f2932c71f6a847a1.
2021-04-15 17:35:16,365 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Establish JobManager connection for job 9d1409a665da0496f2932c71f6a847a1.
2021-04-15 17:35:16,371 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Offer reserved slots to the leader of job 9d1409a665da0496f2932c71f6a847a1.
2021-04-15 17:35:16,375 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Fulfilling pending slot request [SlotRequestId{bf40a17fdc197c276c7e614d64dbd207}] with slot [56af020fbe2a8b9be41d6d05061ec16a]
2021-04-15 17:35:16,377 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{da9ca1d54e12134e5ecd5b6d742c7a5f}) for execution vertex (id cbc357ccb763df2852fee8c4fc7d55f2_0) from the physical slot (SlotRequestId{bf40a17fdc197c276c7e614d64dbd207})
2021-04-15 17:35:16,387 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{41b19784e557196cb5951b71c78b04a4}) for execution vertex (id f5c76b9f24bd1684ec0becd4e81cafd6_0) from the physical slot (SlotRequestId{bf40a17fdc197c276c7e614d64dbd207})
2021-04-15 17:35:16,387 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1) (f23daafaedd8cee3f74cd54bc39000dd) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:35:16,388 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1) (attempt #0) with attempt id f23daafaedd8cee3f74cd54bc39000dd to e030c6b3-5674-4e7a-8d41-83390b0a053c @ server1 (dataPort=-1) with allocation id 56af020fbe2a8b9be41d6d05061ec16a
2021-04-15 17:35:16,402 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (1/1) (6feafd3d5c8ae65013b100fa3a7611d0) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:35:16,403 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Sink: Print to Std. Out (1/1) (attempt #0) with attempt id 6feafd3d5c8ae65013b100fa3a7611d0 to e030c6b3-5674-4e7a-8d41-83390b0a053c @ server1 (dataPort=-1) with allocation id 56af020fbe2a8b9be41d6d05061ec16a
2021-04-15 17:35:16,406 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 56af020fbe2a8b9be41d6d05061ec16a.
2021-04-15 17:35:16,409 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 56af020fbe2a8b9be41d6d05061ec16a.
2021-04-15 17:35:16,420 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new allocation id 56af020fbe2a8b9be41d6d05061ec16a for local state stores for job 9d1409a665da0496f2932c71f6a847a1.
2021-04-15 17:35:16,423 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_56af020fbe2a8b9be41d6d05061ec16a], jobID=9d1409a665da0496f2932c71f6a847a1, jobVertexID=cbc357ccb763df2852fee8c4fc7d55f2, subtaskIndex=0}} for 9d1409a665da0496f2932c71f6a847a1 - cbc357ccb763df2852fee8c4fc7d55f2 - 0 under allocation id 56af020fbe2a8b9be41d6d05061ec16a.
2021-04-15 17:35:16,453 DEBUG o.a.f.r.io.network.partition.ResultPartitionFactory - Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1)#0 (f23daafaedd8cee3f74cd54bc39000dd): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@7465b37d
2021-04-15 17:35:16,453 DEBUG o.a.f.r.io.network.partition.ResultPartitionFactory - Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1)#0 (f23daafaedd8cee3f74cd54bc39000dd): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@7465b37d
2021-04-15 17:35:16,453 DEBUG o.a.f.r.io.network.partition.ResultPartitionFactory - Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1)#0 (f23daafaedd8cee3f74cd54bc39000dd): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@7465b37d
2021-04-15 17:35:16,467 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1)#0 (f23daafaedd8cee3f74cd54bc39000dd), deploy into slot with allocation id 56af020fbe2a8b9be41d6d05061ec16a.
2021-04-15 17:35:16,469 INFO org.apache.flink.runtime.taskmanager.Task - Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1)#0 (f23daafaedd8cee3f74cd54bc39000dd) switched from CREATED to DEPLOYING.
2021-04-15 17:35:16,469 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1)#0 (f23daafaedd8cee3f74cd54bc39000dd) [DEPLOYING]
2021-04-15 17:35:16,472 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 56af020fbe2a8b9be41d6d05061ec16a.
2021-04-15 17:35:16,479 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_56af020fbe2a8b9be41d6d05061ec16a], jobID=9d1409a665da0496f2932c71f6a847a1, jobVertexID=f5c76b9f24bd1684ec0becd4e81cafd6, subtaskIndex=0}} for 9d1409a665da0496f2932c71f6a847a1 - f5c76b9f24bd1684ec0becd4e81cafd6 - 0 under allocation id 56af020fbe2a8b9be41d6d05061ec16a.
2021-04-15 17:35:16,509 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1)#0 (f23daafaedd8cee3f74cd54bc39000dd) [DEPLOYING].
2021-04-15 17:35:16,510 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task f23daafaedd8cee3f74cd54bc39000dd at library cache manager took 0 milliseconds
2021-04-15 17:35:16,514 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1)#0 (f23daafaedd8cee3f74cd54bc39000dd) [DEPLOYING].
2021-04-15 17:35:16,518 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 2-10 buffers
2021-04-15 17:35:16,519 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - Sink: Print to Std. Out (1/1)#0 (6feafd3d5c8ae65013b100fa3a7611d0): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:35:16,519 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Registered PipelinedResultPartition b8e12b549987799d1b36ea7f3b9001a3#0@f23daafaedd8cee3f74cd54bc39000dd [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:35:16,519 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 2-10 buffers
2021-04-15 17:35:16,519 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Registered PipelinedResultPartition 3bdcd2615e393cd9a2a48f093e2d9714#0@f23daafaedd8cee3f74cd54bc39000dd [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:35:16,519 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 2-10 buffers
2021-04-15 17:35:16,519 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Registered PipelinedResultPartition e5ee35cabeaac687783938d6579b3d15#0@f23daafaedd8cee3f74cd54bc39000dd [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:35:16,519 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - registering b8e12b549987799d1b36ea7f3b9001a3#0@f23daafaedd8cee3f74cd54bc39000dd
2021-04-15 17:35:16,520 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - Sink: Print to Std. Out (1/1)#0 (6feafd3d5c8ae65013b100fa3a7611d0): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:35:16,520 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - Sink: Print to Std. Out (1/1)#0 (6feafd3d5c8ae65013b100fa3a7611d0): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:35:16,521 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Sink: Print to Std. Out (1/1)#0 (6feafd3d5c8ae65013b100fa3a7611d0), deploy into slot with allocation id 56af020fbe2a8b9be41d6d05061ec16a.
2021-04-15 17:35:16,522 INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (1/1)#0 (6feafd3d5c8ae65013b100fa3a7611d0) switched from CREATED to DEPLOYING.
2021-04-15 17:35:16,522 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (1/1)#0 (6feafd3d5c8ae65013b100fa3a7611d0) [DEPLOYING]
2021-04-15 17:35:16,522 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Sink: Print to Std. Out (1/1)#0 (6feafd3d5c8ae65013b100fa3a7611d0) [DEPLOYING].
2021-04-15 17:35:16,523 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 6feafd3d5c8ae65013b100fa3a7611d0 at library cache manager took 0 milliseconds
2021-04-15 17:35:16,525 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Sink: Print to Std. Out (1/1)#0 (6feafd3d5c8ae65013b100fa3a7611d0) [DEPLOYING].
2021-04-15 17:35:16,525 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:35:16,528 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:35:16,528 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:35:16,529 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - registering 3bdcd2615e393cd9a2a48f093e2d9714#0@f23daafaedd8cee3f74cd54bc39000dd
2021-04-15 17:35:16,530 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - registering e5ee35cabeaac687783938d6579b3d15#0@f23daafaedd8cee3f74cd54bc39000dd
2021-04-15 17:35:16,544 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Using partitioner FORWARD for output 0 of task Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out)
2021-04-15 17:35:16,546 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:35:16,547 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Using partitioner FORWARD for output 1 of task Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out)
2021-04-15 17:35:16,548 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Using partitioner FORWARD for output 2 of task Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out)
2021-04-15 17:35:16,550 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:35:16,555 INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (1/1)#0 (6feafd3d5c8ae65013b100fa3a7611d0) switched from DEPLOYING to RUNNING.
2021-04-15 17:35:16,555 INFO org.apache.flink.runtime.taskmanager.Task - Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1)#0 (f23daafaedd8cee3f74cd54bc39000dd) switched from DEPLOYING to RUNNING.
2021-04-15 17:35:16,556 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1)#0.
2021-04-15 17:35:16,556 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Sink: Print to Std. Out (1/1)#0.
2021-04-15 17:35:16,557 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (1/1) (6feafd3d5c8ae65013b100fa3a7611d0) switched from DEPLOYING to RUNNING.
2021-04-15 17:35:16,557 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1) (f23daafaedd8cee3f74cd54bc39000dd) switched from DEPLOYING to RUNNING.
2021-04-15 17:35:16,645 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1)#0
2021-04-15 17:35:16,697 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_666d412a56e17eca4e56b80d012b9b4e_(1/1) with empty state.
2021-04-15 17:35:16,713 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Sink: Print to Std. Out (1/1)#0
2021-04-15 17:35:16,714 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_f5c76b9f24bd1684ec0becd4e81cafd6_(1/1) with empty state.
2021-04-15 17:35:16,728 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_010fb2190e5aaa200fb1ceee04f4019d_(1/1) with empty state.
2021-04-15 17:35:16,729 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_36d907d3ace1ed44b5db1a8a56bdffa8_(1/1) with empty state.
2021-04-15 17:35:16,729 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for ProcessOperator_864ae8de554cc248475790a298b480bf_(1/1) with empty state.
2021-04-15 17:35:16,730 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSource_cbc357ccb763df2852fee8c4fc7d55f2_(1/1) with empty state.
2021-04-15 17:35:16,744 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf - -Dorg.apache.flink.shaded.netty4.io.netty.buffer.checkAccessible: true
2021-04-15 17:35:16,744 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf - -Dorg.apache.flink.shaded.netty4.io.netty.buffer.checkBounds: true
2021-04-15 17:35:16,745 DEBUG o.a.f.s.n.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.flink.shaded.netty4.io.netty.util.ResourceLeakDetector@27165ef8
2021-04-15 17:35:16,749 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - Sink: Print to Std. Out (1/1)#0 (6feafd3d5c8ae65013b100fa3a7611d0)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:35:16,751 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - Sink: Print to Std. Out (1/1)#0 (6feafd3d5c8ae65013b100fa3a7611d0)/InputChannelInfo{gateIdx=1, inputChannelIdx=0} finished recovering input.
2021-04-15 17:35:16,751 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:35:16,751 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - Sink: Print to Std. Out (1/1)#0 (6feafd3d5c8ae65013b100fa3a7611d0)/InputChannelInfo{gateIdx=2, inputChannelIdx=0} finished recovering input.
2021-04-15 17:35:16,753 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:35:16,754 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [b8e12b549987799d1b36ea7f3b9001a3#0@f23daafaedd8cee3f74cd54bc39000dd]: Requesting LOCAL subpartition 0 of partition b8e12b549987799d1b36ea7f3b9001a3#0@f23daafaedd8cee3f74cd54bc39000dd. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:35:16,754 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 0 of PipelinedResultPartition b8e12b549987799d1b36ea7f3b9001a3#0@f23daafaedd8cee3f74cd54bc39000dd [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:35:16,754 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1)#0 (f23daafaedd8cee3f74cd54bc39000dd): Creating read view for subpartition 0 of partition b8e12b549987799d1b36ea7f3b9001a3#0@f23daafaedd8cee3f74cd54bc39000dd.
2021-04-15 17:35:16,755 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 0) of ResultPartition b8e12b549987799d1b36ea7f3b9001a3#0@f23daafaedd8cee3f74cd54bc39000dd
2021-04-15 17:35:16,756 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:35:16,756 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=1, inputChannelIdx=0}
2021-04-15 17:35:16,757 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [3bdcd2615e393cd9a2a48f093e2d9714#0@f23daafaedd8cee3f74cd54bc39000dd]: Requesting LOCAL subpartition 0 of partition 3bdcd2615e393cd9a2a48f093e2d9714#0@f23daafaedd8cee3f74cd54bc39000dd. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:35:16,757 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 0 of PipelinedResultPartition 3bdcd2615e393cd9a2a48f093e2d9714#0@f23daafaedd8cee3f74cd54bc39000dd [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:35:16,757 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1)#0 (f23daafaedd8cee3f74cd54bc39000dd): Creating read view for subpartition 0 of partition 3bdcd2615e393cd9a2a48f093e2d9714#0@f23daafaedd8cee3f74cd54bc39000dd.
2021-04-15 17:35:16,757 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 0) of ResultPartition 3bdcd2615e393cd9a2a48f093e2d9714#0@f23daafaedd8cee3f74cd54bc39000dd
2021-04-15 17:35:16,757 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:35:16,757 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=2, inputChannelIdx=0}
2021-04-15 17:35:16,757 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [e5ee35cabeaac687783938d6579b3d15#0@f23daafaedd8cee3f74cd54bc39000dd]: Requesting LOCAL subpartition 0 of partition e5ee35cabeaac687783938d6579b3d15#0@f23daafaedd8cee3f74cd54bc39000dd. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:35:16,758 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 0 of PipelinedResultPartition e5ee35cabeaac687783938d6579b3d15#0@f23daafaedd8cee3f74cd54bc39000dd [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:35:16,758 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1)#0 (f23daafaedd8cee3f74cd54bc39000dd): Creating read view for subpartition 0 of partition e5ee35cabeaac687783938d6579b3d15#0@f23daafaedd8cee3f74cd54bc39000dd.
2021-04-15 17:35:16,758 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 0) of ResultPartition e5ee35cabeaac687783938d6579b3d15#0@f23daafaedd8cee3f74cd54bc39000dd
2021-04-15 17:35:26,019 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:35:26,020 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:35:26,020 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from aca703268e121b7e13cddc02b8a127bd.
2021-04-15 17:35:26,021 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat request from aca703268e121b7e13cddc02b8a127bd.
2021-04-15 17:35:26,022 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 3fbc8113f4421c44abbae9a3d0ea86ae.
2021-04-15 17:35:26,023 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from e030c6b3-5674-4e7a-8d41-83390b0a053c.
2021-04-15 17:35:26,024 DEBUG o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Received slot report from instance 8aa22bd1935c0bed825541c80ecf2bce: SlotReport{SlotStatus{slotID=e030c6b3-5674-4e7a-8d41-83390b0a053c_0, allocationID=56af020fbe2a8b9be41d6d05061ec16a, jobID=9d1409a665da0496f2932c71f6a847a1, resourceProfile=ResourceProfile{managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}}}.
2021-04-15 17:35:26,028 DEBUG o.a.f.r.i.n.p.ResourceManagerPartitionTrackerImpl - Processing cluster partition report from task executor e030c6b3-5674-4e7a-8d41-83390b0a053c: PartitionReport{entries=[]}.
2021-04-15 17:35:26,329 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
2021-04-15 17:35:26,330 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from 3fbc8113f4421c44abbae9a3d0ea86ae.
2021-04-15 17:35:26,350 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat from e030c6b3-5674-4e7a-8d41-83390b0a053c.
2021-04-15 17:35:36,041 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:35:36,042 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:35:36,042 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat request from aca703268e121b7e13cddc02b8a127bd.
2021-04-15 17:35:36,042 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from aca703268e121b7e13cddc02b8a127bd.
2021-04-15 17:35:36,042 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 3fbc8113f4421c44abbae9a3d0ea86ae.
2021-04-15 17:35:36,042 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from e030c6b3-5674-4e7a-8d41-83390b0a053c.
2021-04-15 17:35:36,042 DEBUG o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Received slot report from instance 8aa22bd1935c0bed825541c80ecf2bce: SlotReport{SlotStatus{slotID=e030c6b3-5674-4e7a-8d41-83390b0a053c_0, allocationID=56af020fbe2a8b9be41d6d05061ec16a, jobID=9d1409a665da0496f2932c71f6a847a1, resourceProfile=ResourceProfile{managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}}}.
2021-04-15 17:35:36,042 DEBUG o.a.f.r.i.n.p.ResourceManagerPartitionTrackerImpl - Processing cluster partition report from task executor e030c6b3-5674-4e7a-8d41-83390b0a053c: PartitionReport{entries=[]}.
2021-04-15 17:35:36,349 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
2021-04-15 17:35:36,350 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from 3fbc8113f4421c44abbae9a3d0ea86ae.
2021-04-15 17:35:36,350 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat from e030c6b3-5674-4e7a-8d41-83390b0a053c.
2021-04-15 17:36:14,668 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:36:14,673 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.util.Random
2021-04-15 17:36:14,741 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.myorg.quickstart.other.DTransform.MultiStream$1
2021-04-15 17:36:14,802 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.myorg.quickstart.other.DTransform.MultiStream$3
2021-04-15 17:36:14,805 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.myorg.quickstart.other.DTransform.MultiStream$2
2021-04-15 17:36:14,830 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
2021-04-15 17:36:14,830 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:36:14,833 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:36:14,838 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:36:14,839 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:36:14,840 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:36:14,846 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
2021-04-15 17:36:14,847 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:36:14,849 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:36:14,849 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:36:14,850 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:36:14,850 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:36:14,851 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
2021-04-15 17:36:14,851 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:36:14,851 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:36:14,851 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:36:14,852 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:36:14,852 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:36:14,886 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=2, name='Process', outputType=GenericType<java.lang.Object>, parallelism=1}
2021-04-15 17:36:14,890 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySourceTransformation{id=1, name='sensor', outputType=PojoType<org.myorg.quickstart.dto.SensorReading, fields = [id: String, temperature: Double, timestamp: Long]>, parallelism=1}
2021-04-15 17:36:14,900 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 1
2021-04-15 17:36:14,910 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 2
2021-04-15 17:36:14,912 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySinkTransformation{id=6, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=1}
2021-04-15 17:36:14,912 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming SideOutputTransformation{id=3, name='SideOutput', outputType=PojoType<org.myorg.quickstart.dto.SensorReading, fields = [id: String, temperature: Double, timestamp: Long]>, parallelism=1}
2021-04-15 17:36:14,922 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 6
2021-04-15 17:36:14,922 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySinkTransformation{id=7, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=1}
2021-04-15 17:36:14,922 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming SideOutputTransformation{id=5, name='SideOutput', outputType=PojoType<org.myorg.quickstart.dto.SensorReading, fields = [id: String, temperature: Double, timestamp: Long]>, parallelism=1}
2021-04-15 17:36:14,922 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 7
2021-04-15 17:36:14,922 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySinkTransformation{id=8, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=1}
2021-04-15 17:36:14,923 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming SideOutputTransformation{id=4, name='SideOutput', outputType=PojoType<org.myorg.quickstart.dto.SensorReading, fields = [id: String, temperature: Double, timestamp: Long]>, parallelism=1}
2021-04-15 17:36:14,923 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 8
2021-04-15 17:36:15,006 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'cbc357ccb763df2852fee8c4fc7d55f2' for node 'Source: sensor-1' {id: 1, parallelism: 1, user function: org.myorg.quickstart.util.SourceUtil}
2021-04-15 17:36:15,006 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '864ae8de554cc248475790a298b480bf' for node 'Process-2' {id: 2, parallelism: 1, user function: org.myorg.quickstart.other.DTransform.MultiStream$4}
2021-04-15 17:36:15,008 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '666d412a56e17eca4e56b80d012b9b4e' for node 'Sink: Print to Std. Out-6' {id: 6, parallelism: 1, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
2021-04-15 17:36:15,009 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '010fb2190e5aaa200fb1ceee04f4019d' for node 'Sink: Print to Std. Out-7' {id: 7, parallelism: 1, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
2021-04-15 17:36:15,009 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '36d907d3ace1ed44b5db1a8a56bdffa8' for node 'Sink: Print to Std. Out-8' {id: 8, parallelism: 1, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
2021-04-15 17:36:15,128 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 1
2021-04-15 17:36:15,205 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.
2021-04-15 17:36:15,206 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.
2021-04-15 17:36:15,207 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.
2021-04-15 17:36:15,209 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.min required for local execution is not set, setting it to its default value 64 mb.
2021-04-15 17:36:15,210 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.max required for local execution is not set, setting it to its default value 64 mb.
2021-04-15 17:36:15,211 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.
2021-04-15 17:36:15,238 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting Flink Mini Cluster
2021-04-15 17:36:15,239 DEBUG org.apache.flink.runtime.minicluster.MiniCluster - Using configuration MiniClusterConfiguration {singleRpcService=SHARED, numTaskManagers=1, commonBindAddress='null', config={taskmanager.memory.network.min=64 mb, taskmanager.cpu.cores=1.7976931348623157E308, taskmanager.memory.task.off-heap.size=9223372036854775807 bytes, execution.target=local, rest.bind-port=0, taskmanager.memory.network.max=64 mb, execution.attached=true, taskmanager.memory.managed.size=128 mb, parallelism.default=4, taskmanager.numberOfTaskSlots=1, taskmanager.memory.task.heap.size=9223372036854775807 bytes, rest.address=localhost}}
2021-04-15 17:36:15,244 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting Metrics Registry
2021-04-15 17:36:15,331 INFO org.apache.flink.runtime.metrics.MetricRegistryImpl - No metrics reporter configured, no metrics will be exposed/reported.
2021-04-15 17:36:15,331 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting RPC Service(s)
2021-04-15 17:36:15,511 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
2021-04-15 17:36:15,522 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Using akka configuration
 Config(SimpleConfigObject({"akka":{"actor":{"default-dispatcher":{"executor":"fork-join-executor","fork-join-executor":{"parallelism-factor":1,"parallelism-max":4,"parallelism-min":2},"throughput":15},"guardian-supervisor-strategy":"org.apache.flink.runtime.akka.EscalatingSupervisorStrategy","supervisor-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"type":"Dispatcher"},"warn-about-java-serializer-usage":"off"},"daemonic":"off","jvm-exit-on-fatal-error":"on","log-config-on-start":"off","log-dead-letters":"off","log-dead-letters-during-shutdown":"off","logger-startup-timeout":"30s","loggers":["akka.event.slf4j.Slf4jLogger"],"logging-filter":"akka.event.slf4j.Slf4jLoggingFilter","loglevel":"DEBUG","serialize-messages":"off","stdout-loglevel":"OFF"}}))
2021-04-15 17:36:16,101 INFO akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2021-04-15 17:36:16,112 DEBUG akka.event.EventStream - logger log1-Slf4jLogger started
2021-04-15 17:36:16,116 DEBUG akka.event.EventStream - Default Loggers started
2021-04-15 17:36:17,021 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink
2021-04-15 17:36:17,090 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
2021-04-15 17:36:17,094 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Using akka configuration
 Config(SimpleConfigObject({"akka":{"actor":{"default-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"thread-priority":1,"throughput":15,"type":"akka.dispatch.PriorityThreadsDispatcher"},"guardian-supervisor-strategy":"org.apache.flink.runtime.akka.EscalatingSupervisorStrategy","supervisor-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"type":"Dispatcher"},"warn-about-java-serializer-usage":"off"},"daemonic":"off","jvm-exit-on-fatal-error":"on","log-config-on-start":"off","log-dead-letters":"off","log-dead-letters-during-shutdown":"off","logger-startup-timeout":"30s","loggers":["akka.event.slf4j.Slf4jLogger"],"logging-filter":"akka.event.slf4j.Slf4jLoggingFilter","loglevel":"DEBUG","serialize-messages":"off","stdout-loglevel":"OFF"}}))
2021-04-15 17:36:17,263 INFO akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2021-04-15 17:36:17,266 DEBUG akka.event.EventStream - logger log1-Slf4jLogger started
2021-04-15 17:36:17,332 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink-metrics
2021-04-15 17:36:17,389 DEBUG akka.event.EventStream - Default Loggers started
2021-04-15 17:36:17,405 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting AkkaRpcActor with name MetricQueryService.
2021-04-15 17:36:17,433 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
2021-04-15 17:36:17,660 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting high-availability services
2021-04-15 17:36:18,572 INFO org.apache.flink.runtime.blob.BlobServer - Created BLOB server storage directory C:\Users\ccy\AppData\Local\Temp\blobStore-e1a0dbf0-eb5e-405e-8426-7e07d55aea27
2021-04-15 17:36:18,581 DEBUG org.apache.flink.util.NetUtils - Trying to open socket on port 0
2021-04-15 17:36:18,583 INFO org.apache.flink.runtime.blob.BlobServer - Started BLOB server at 0.0.0.0:61787 - max concurrent requests: 50 - max backlog: 1000
2021-04-15 17:36:18,587 INFO org.apache.flink.runtime.blob.PermanentBlobCache - Created BLOB cache storage directory C:\Users\ccy\AppData\Local\Temp\blobStore-f4c6aecf-f7c2-41e8-ba52-98afcf48193f
2021-04-15 17:36:18,589 INFO org.apache.flink.runtime.blob.TransientBlobCache - Created BLOB cache storage directory C:\Users\ccy\AppData\Local\Temp\blobStore-b3b5192f-4598-47b7-b4d5-9a4e10c68c2d
2021-04-15 17:36:18,589 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting 1 TaskManger(s)
2021-04-15 17:36:18,593 INFO org.apache.flink.runtime.taskexecutor.TaskManagerRunner - Starting TaskManager with ResourceID: 38b446c6-1a9f-4416-9e9d-05d916bbfe4c
2021-04-15 17:36:18,628 INFO o.apache.flink.runtime.taskexecutor.TaskManagerServices - Temporary file directory 'C:\Users\ccy\AppData\Local\Temp': total 137 GB, usable 24 GB (17.52% usable)
2021-04-15 17:36:18,633 INFO org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\ccy\AppData\Local\Temp\flink-io-c9b0ec53-c6a9-4f28-8b95-1e2a566f0548 for spill files.
2021-04-15 17:36:18,644 INFO org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\ccy\AppData\Local\Temp\flink-netty-shuffle-fc676038-a22e-453e-8135-2c5dda27d144 for spill files.
2021-04-15 17:36:18,693 INFO o.a.flink.runtime.io.network.buffer.NetworkBufferPool - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2021-04-15 17:36:18,703 INFO o.a.flink.runtime.io.network.NettyShuffleEnvironment - Starting the network environment and its components.
2021-04-15 17:36:18,703 DEBUG o.a.flink.runtime.io.network.NettyShuffleEnvironment - Starting network connection manager
2021-04-15 17:36:18,705 INFO org.apache.flink.runtime.taskexecutor.KvStateService - Starting the kvState service and its components.
2021-04-15 17:36:18,718 DEBUG o.a.flink.runtime.taskexecutor.TaskManagerConfiguration - Messages have a max timeout of 10000 ms
2021-04-15 17:36:18,731 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting AkkaRpcActor with name taskmanager_0.
2021-04-15 17:36:18,732 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2021-04-15 17:36:18,748 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Start job leader service.
2021-04-15 17:36:18,750 INFO org.apache.flink.runtime.filecache.FileCache - User file cache uses directory C:\Users\ccy\AppData\Local\Temp\flink-dist-cache-580939ef-63f9-4804-a257-19c9ebab68b3
2021-04-15 17:36:18,818 DEBUG o.a.f.r.e.c.DefaultDispatcherResourceManagerComponentFactory - Starting Dispatcher REST endpoint.
2021-04-15 17:36:18,818 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Starting rest endpoint.
2021-04-15 17:36:18,826 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Failed to load web based job submission extension.
org.apache.flink.util.FlinkException: The module flink-runtime-web could not be found in the class path. Please add this jar in order to enable web based job submission.
	at org.apache.flink.runtime.webmonitor.WebMonitorUtils.loadWebSubmissionExtension(WebMonitorUtils.java:199) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint.initializeWebSubmissionHandlers(DispatcherRestEndpoint.java:112) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.webmonitor.WebMonitorEndpoint.initializeHandlers(WebMonitorEndpoint.java:228) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint.initializeHandlers(DispatcherRestEndpoint.java:89) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:144) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:172) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:463) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:422) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:366) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.program.PerJobMiniClusterFactory.submitJob(PerJobMiniClusterFactory.java:75) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:85) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1905) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1796) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:69) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1782) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1765) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.myorg.quickstart.other.DTransform.MultiStream.main(MultiStream.java:63) ~[classes/:na]
2021-04-15 17:36:19,040 DEBUG o.a.f.s.n.i.n.u.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
2021-04-15 17:36:19,040 DEBUG o.a.f.s.n.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2021-04-15 17:36:19,040 DEBUG o.a.f.s.n.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2021-04-15 17:36:19,110 WARN org.apache.flink.runtime.webmonitor.WebMonitorUtils - Log file environment variable 'log.file' is not set.
2021-04-15 17:36:19,110 WARN org.apache.flink.runtime.webmonitor.WebMonitorUtils - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'web.log.path'.
2021-04-15 17:36:19,144 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - Platform: Windows
2021-04-15 17:36:19,146 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
2021-04-15 17:36:19,146 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - Java version: 11
2021-04-15 17:36:19,147 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
2021-04-15 17:36:19,148 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
2021-04-15 17:36:19,149 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
2021-04-15 17:36:19,149 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: unavailable
java.lang.UnsupportedOperationException: Reflective setAccessible(true) disabled
	at org.apache.flink.shaded.netty4.io.netty.util.internal.ReflectionUtil.trySetAccessible(ReflectionUtil.java:31) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0$4.run(PlatformDependent0.java:233) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at java.base/java.security.AccessController.doPrivileged(Native Method) ~[na:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:227) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.isAndroid(PlatformDependent.java:289) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:92) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:223) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:210) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.cached(AsciiString.java:1401) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<clinit>(AsciiString.java:48) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<init>(HttpMethod.java:135) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<clinit>(HttpMethod.java:36) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.runtime.rest.HttpMethodWrapper.<clinit>(HttpMethodWrapper.java:27) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.messages.cluster.ShutdownHeaders.getHttpMethod(ShutdownHeaders.java:57) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.checkAllEndpointsAndHandlersAreUnique(RestServerEndpoint.java:572) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:155) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:172) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:463) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:422) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:366) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.program.PerJobMiniClusterFactory.submitJob(PerJobMiniClusterFactory.java:75) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:85) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1905) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1796) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:69) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1782) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1765) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.myorg.quickstart.other.DTransform.MultiStream.main(MultiStream.java:63) ~[classes/:na]
2021-04-15 17:36:19,150 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
2021-04-15 17:36:19,152 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable
java.lang.IllegalAccessException: class org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0$6 cannot access class jdk.internal.misc.Unsafe (in module java.base) because module java.base does not export jdk.internal.misc to unnamed module @3cce57c7
	at java.base/jdk.internal.reflect.Reflection.newIllegalAccessException(Reflection.java:361) ~[na:na]
	at java.base/java.lang.reflect.AccessibleObject.checkAccess(AccessibleObject.java:591) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:558) ~[na:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0$6.run(PlatformDependent0.java:347) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at java.base/java.security.AccessController.doPrivileged(Native Method) ~[na:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:338) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.isAndroid(PlatformDependent.java:289) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:92) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:223) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:210) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.cached(AsciiString.java:1401) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<clinit>(AsciiString.java:48) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<init>(HttpMethod.java:135) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<clinit>(HttpMethod.java:36) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.runtime.rest.HttpMethodWrapper.<clinit>(HttpMethodWrapper.java:27) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.messages.cluster.ShutdownHeaders.getHttpMethod(ShutdownHeaders.java:57) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.checkAllEndpointsAndHandlersAreUnique(RestServerEndpoint.java:572) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:155) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:172) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:463) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:422) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:366) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.program.PerJobMiniClusterFactory.submitJob(PerJobMiniClusterFactory.java:75) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:85) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1905) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1796) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:69) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1782) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1765) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.myorg.quickstart.other.DTransform.MultiStream.main(MultiStream.java:63) ~[classes/:na]
2021-04-15 17:36:19,152 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): unavailable
2021-04-15 17:36:19,152 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
2021-04-15 17:36:19,153 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - maxDirectMemory: 2122317824 bytes (maybe)
2021-04-15 17:36:19,153 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\ccy\AppData\Local\Temp (java.io.tmpdir)
2021-04-15 17:36:19,153 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
2021-04-15 17:36:19,154 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: -1 bytes
2021-04-15 17:36:19,154 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
2021-04-15 17:36:19,155 DEBUG o.a.f.shaded.netty4.io.netty.util.internal.CleanerJava9 - java.nio.ByteBuffer.cleaner(): available
2021-04-15 17:36:19,155 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
2021-04-15 17:36:19,159 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@691124ee under DELETE@/v1/cluster.
2021-04-15 17:36:19,161 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@691124ee under DELETE@/cluster.
2021-04-15 17:36:19,161 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@6b5ab2f2 under GET@/v1/config.
2021-04-15 17:36:19,161 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@6b5ab2f2 under GET@/config.
2021-04-15 17:36:19,161 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetListHandler@315c081 under GET@/v1/datasets.
2021-04-15 17:36:19,161 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetListHandler@315c081 under GET@/datasets.
2021-04-15 17:36:19,161 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteStatusHandler@6b2dd3df under GET@/v1/datasets/delete/:triggerid.
2021-04-15 17:36:19,161 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteStatusHandler@6b2dd3df under GET@/datasets/delete/:triggerid.
2021-04-15 17:36:19,162 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteTriggerHandler@4db77402 under DELETE@/v1/datasets/:datasetid.
2021-04-15 17:36:19,162 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteTriggerHandler@4db77402 under DELETE@/datasets/:datasetid.
2021-04-15 17:36:19,162 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@73c48264 under GET@/v1/jobmanager/config.
2021-04-15 17:36:19,162 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@73c48264 under GET@/jobmanager/config.
2021-04-15 17:36:19,162 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@5ef85555 under GET@/v1/jobmanager/log.
2021-04-15 17:36:19,162 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@5ef85555 under GET@/jobmanager/log.
2021-04-15 17:36:19,162 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogListHandler@5bcec67e under GET@/v1/jobmanager/logs.
2021-04-15 17:36:19,162 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogListHandler@5bcec67e under GET@/jobmanager/logs.
2021-04-15 17:36:19,162 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerCustomLogHandler@2dafae61 under GET@/v1/jobmanager/logs/:filename.
2021-04-15 17:36:19,162 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerCustomLogHandler@2dafae61 under GET@/jobmanager/logs/:filename.
2021-04-15 17:36:19,162 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@7a2fce12 under GET@/v1/jobmanager/metrics.
2021-04-15 17:36:19,163 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@7a2fce12 under GET@/jobmanager/metrics.
2021-04-15 17:36:19,163 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@66e17eff under GET@/v1/jobmanager/stdout.
2021-04-15 17:36:19,163 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@66e17eff under GET@/jobmanager/stdout.
2021-04-15 17:36:19,163 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@4bb1b96b under GET@/v1/jobs.
2021-04-15 17:36:19,163 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@4bb1b96b under GET@/jobs.
2021-04-15 17:36:19,163 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@1bbddada under POST@/v1/jobs.
2021-04-15 17:36:19,163 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@1bbddada under POST@/jobs.
2021-04-15 17:36:19,163 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@1f66d8e1 under GET@/v1/jobs/metrics.
2021-04-15 17:36:19,163 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@1f66d8e1 under GET@/jobs/metrics.
2021-04-15 17:36:19,163 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@721d5b74 under GET@/v1/jobs/overview.
2021-04-15 17:36:19,163 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@721d5b74 under GET@/jobs/overview.
2021-04-15 17:36:19,163 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@3421debd under GET@/v1/jobs/:jobid.
2021-04-15 17:36:19,163 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@3421debd under GET@/jobs/:jobid.
2021-04-15 17:36:19,163 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@41bfa9e9 under PATCH@/v1/jobs/:jobid.
2021-04-15 17:36:19,163 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@41bfa9e9 under PATCH@/jobs/:jobid.
2021-04-15 17:36:19,163 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@68b7d0ef under GET@/v1/jobs/:jobid/accumulators.
2021-04-15 17:36:19,164 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@68b7d0ef under GET@/jobs/:jobid/accumulators.
2021-04-15 17:36:19,164 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@7069f076 under GET@/v1/jobs/:jobid/checkpoints.
2021-04-15 17:36:19,164 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@7069f076 under GET@/jobs/:jobid/checkpoints.
2021-04-15 17:36:19,164 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@4a070cf0 under GET@/v1/jobs/:jobid/checkpoints/config.
2021-04-15 17:36:19,164 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@4a070cf0 under GET@/jobs/:jobid/checkpoints/config.
2021-04-15 17:36:19,164 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@764b14b8 under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid.
2021-04-15 17:36:19,165 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@764b14b8 under GET@/jobs/:jobid/checkpoints/details/:checkpointid.
2021-04-15 17:36:19,165 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@202d9236 under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
2021-04-15 17:36:19,165 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@202d9236 under GET@/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
2021-04-15 17:36:19,165 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@1f782c05 under GET@/v1/jobs/:jobid/config.
2021-04-15 17:36:19,165 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@1f782c05 under GET@/jobs/:jobid/config.
2021-04-15 17:36:19,165 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.coordination.ClientCoordinationHandler@6d6ac396 under POST@/v1/jobs/:jobid/coordinators/:operatorid.
2021-04-15 17:36:19,165 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.coordination.ClientCoordinationHandler@6d6ac396 under POST@/jobs/:jobid/coordinators/:operatorid.
2021-04-15 17:36:19,165 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@432af457 under GET@/v1/jobs/:jobid/exceptions.
2021-04-15 17:36:19,165 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@432af457 under GET@/jobs/:jobid/exceptions.
2021-04-15 17:36:19,165 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@f5a7226 under GET@/v1/jobs/:jobid/execution-result.
2021-04-15 17:36:19,165 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@f5a7226 under GET@/jobs/:jobid/execution-result.
2021-04-15 17:36:19,165 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@519c6fcc under GET@/v1/jobs/:jobid/metrics.
2021-04-15 17:36:19,165 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@519c6fcc under GET@/jobs/:jobid/metrics.
2021-04-15 17:36:19,165 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@6ad1701a under GET@/v1/jobs/:jobid/plan.
2021-04-15 17:36:19,165 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@6ad1701a under GET@/jobs/:jobid/plan.
2021-04-15 17:36:19,166 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@7ecda95b under PATCH@/v1/jobs/:jobid/rescaling.
2021-04-15 17:36:19,166 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@7ecda95b under PATCH@/jobs/:jobid/rescaling.
2021-04-15 17:36:19,166 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@22da2fe6 under GET@/v1/jobs/:jobid/rescaling/:triggerid.
2021-04-15 17:36:19,166 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@22da2fe6 under GET@/jobs/:jobid/rescaling/:triggerid.
2021-04-15 17:36:19,166 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@100ad67e under POST@/v1/jobs/:jobid/savepoints.
2021-04-15 17:36:19,166 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@100ad67e under POST@/jobs/:jobid/savepoints.
2021-04-15 17:36:19,166 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@713a35c5 under GET@/v1/jobs/:jobid/savepoints/:triggerid.
2021-04-15 17:36:19,166 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@713a35c5 under GET@/jobs/:jobid/savepoints/:triggerid.
2021-04-15 17:36:19,166 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@62aeddc8 under POST@/v1/jobs/:jobid/stop.
2021-04-15 17:36:19,166 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@62aeddc8 under POST@/jobs/:jobid/stop.
2021-04-15 17:36:19,166 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@11787b64 under GET@/v1/jobs/:jobid/vertices/:vertexid.
2021-04-15 17:36:19,166 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@11787b64 under GET@/jobs/:jobid/vertices/:vertexid.
2021-04-15 17:36:19,166 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@5707f613 under GET@/v1/jobs/:jobid/vertices/:vertexid/accumulators.
2021-04-15 17:36:19,166 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@5707f613 under GET@/jobs/:jobid/vertices/:vertexid/accumulators.
2021-04-15 17:36:19,166 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@77b3752b under GET@/v1/jobs/:jobid/vertices/:vertexid/backpressure.
2021-04-15 17:36:19,166 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@77b3752b under GET@/jobs/:jobid/vertices/:vertexid/backpressure.
2021-04-15 17:36:19,166 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@6367a688 under GET@/v1/jobs/:jobid/vertices/:vertexid/metrics.
2021-04-15 17:36:19,166 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@6367a688 under GET@/jobs/:jobid/vertices/:vertexid/metrics.
2021-04-15 17:36:19,167 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@319642db under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
2021-04-15 17:36:19,167 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@319642db under GET@/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
2021-04-15 17:36:19,167 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@59498d94 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
2021-04-15 17:36:19,167 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@59498d94 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
2021-04-15 17:36:19,167 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@35bfa1bb under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
2021-04-15 17:36:19,167 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@35bfa1bb under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
2021-04-15 17:36:19,167 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@6b321262 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
2021-04-15 17:36:19,167 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@6b321262 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
2021-04-15 17:36:19,167 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@68b11545 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
2021-04-15 17:36:19,167 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@68b11545 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
2021-04-15 17:36:19,167 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@7d0100ea under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
2021-04-15 17:36:19,167 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@7d0100ea under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
2021-04-15 17:36:19,167 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@357bc488 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasktimes.
2021-04-15 17:36:19,167 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@357bc488 under GET@/jobs/:jobid/vertices/:vertexid/subtasktimes.
2021-04-15 17:36:19,167 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@4ea17147 under GET@/v1/jobs/:jobid/vertices/:vertexid/taskmanagers.
2021-04-15 17:36:19,167 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@4ea17147 under GET@/jobs/:jobid/vertices/:vertexid/taskmanagers.
2021-04-15 17:36:19,167 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@2eda4eeb under GET@/v1/jobs/:jobid/vertices/:vertexid/watermarks.
2021-04-15 17:36:19,168 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@2eda4eeb under GET@/jobs/:jobid/vertices/:vertexid/watermarks.
2021-04-15 17:36:19,168 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@5ba90d8a under GET@/v1/jobs/:jobid/yarn-cancel.
2021-04-15 17:36:19,168 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@5ba90d8a under GET@/jobs/:jobid/yarn-cancel.
2021-04-15 17:36:19,168 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@309dcdf3 under GET@/v1/jobs/:jobid/yarn-stop.
2021-04-15 17:36:19,168 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@309dcdf3 under GET@/jobs/:jobid/yarn-stop.
2021-04-15 17:36:19,168 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@7573b9ee under GET@/v1/overview.
2021-04-15 17:36:19,168 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@7573b9ee under GET@/overview.
2021-04-15 17:36:19,168 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@9a20cbd under POST@/v1/savepoint-disposal.
2021-04-15 17:36:19,168 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@9a20cbd under POST@/savepoint-disposal.
2021-04-15 17:36:19,168 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@1af4955e under GET@/v1/savepoint-disposal/:triggerid.
2021-04-15 17:36:19,168 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@1af4955e under GET@/savepoint-disposal/:triggerid.
2021-04-15 17:36:19,168 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@445821a6 under GET@/v1/taskmanagers.
2021-04-15 17:36:19,168 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@445821a6 under GET@/taskmanagers.
2021-04-15 17:36:19,168 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@2c0c4c0a under GET@/v1/taskmanagers/metrics.
2021-04-15 17:36:19,168 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@2c0c4c0a under GET@/taskmanagers/metrics.
2021-04-15 17:36:19,168 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@35d26ad2 under GET@/v1/taskmanagers/:taskmanagerid.
2021-04-15 17:36:19,169 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@35d26ad2 under GET@/taskmanagers/:taskmanagerid.
2021-04-15 17:36:19,169 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@bb25753 under GET@/v1/taskmanagers/:taskmanagerid/log.
2021-04-15 17:36:19,169 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@bb25753 under GET@/taskmanagers/:taskmanagerid/log.
2021-04-15 17:36:19,169 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogListHandler@ee21292 under GET@/v1/taskmanagers/:taskmanagerid/logs.
2021-04-15 17:36:19,169 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogListHandler@ee21292 under GET@/taskmanagers/:taskmanagerid/logs.
2021-04-15 17:36:19,169 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerCustomLogHandler@40c06358 under GET@/v1/taskmanagers/:taskmanagerid/logs/:filename.
2021-04-15 17:36:19,169 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerCustomLogHandler@40c06358 under GET@/taskmanagers/:taskmanagerid/logs/:filename.
2021-04-15 17:36:19,169 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@66e21568 under GET@/v1/taskmanagers/:taskmanagerid/metrics.
2021-04-15 17:36:19,169 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@66e21568 under GET@/taskmanagers/:taskmanagerid/metrics.
2021-04-15 17:36:19,169 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@7f73ce28 under GET@/v1/taskmanagers/:taskmanagerid/stdout.
2021-04-15 17:36:19,169 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@7f73ce28 under GET@/taskmanagers/:taskmanagerid/stdout.
2021-04-15 17:36:19,169 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerThreadDumpHandler@611b35d6 under GET@/v1/taskmanagers/:taskmanagerid/thread-dump.
2021-04-15 17:36:19,169 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerThreadDumpHandler@611b35d6 under GET@/taskmanagers/:taskmanagerid/thread-dump.
2021-04-15 17:36:19,174 DEBUG o.a.f.s.n.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 8
2021-04-15 17:36:19,195 DEBUG o.a.f.shaded.netty4.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
2021-04-15 17:36:19,195 DEBUG o.a.f.shaded.netty4.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
2021-04-15 17:36:19,201 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
2021-04-15 17:36:19,246 DEBUG o.a.f.shaded.netty4.io.netty.channel.DefaultChannelId - -Dio.netty.processId: 8780 (auto-detected)
2021-04-15 17:36:19,249 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
2021-04-15 17:36:19,249 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
2021-04-15 17:36:19,953 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
2021-04-15 17:36:19,953 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
2021-04-15 17:36:20,673 DEBUG o.a.f.shaded.netty4.io.netty.channel.DefaultChannelId - -Dio.netty.machineId: 2c:6f:c9:ff:fe:1c:21:83 (auto-detected)
2021-04-15 17:36:20,683 DEBUG o.a.f.shaded.netty4.io.netty.util.ResourceLeakDetector - -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.level: simple
2021-04-15 17:36:20,684 DEBUG o.a.f.shaded.netty4.io.netty.util.ResourceLeakDetector - -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.targetRecords: 4
2021-04-15 17:36:20,706 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 8
2021-04-15 17:36:20,706 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 8
2021-04-15 17:36:20,706 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
2021-04-15 17:36:20,706 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 11
2021-04-15 17:36:20,707 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 16777216
2021-04-15 17:36:20,707 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.tinyCacheSize: 512
2021-04-15 17:36:20,707 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
2021-04-15 17:36:20,707 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
2021-04-15 17:36:20,707 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2021-04-15 17:36:20,707 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
2021-04-15 17:36:20,707 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2021-04-15 17:36:20,708 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: true
2021-04-15 17:36:20,708 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2021-04-15 17:36:20,715 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
2021-04-15 17:36:20,715 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 0
2021-04-15 17:36:20,715 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
2021-04-15 17:36:20,728 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Binding rest endpoint to null:0.
2021-04-15 17:36:20,728 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Rest endpoint listening at localhost:61807
2021-04-15 17:36:20,731 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender http://localhost:61807
2021-04-15 17:36:20,733 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - http://localhost:61807 was granted leadership with leaderSessionID=78f45352-1921-493c-9f71-bd1ef6c02cf6
2021-04-15 17:36:20,734 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader http://localhost:61807 , session=78f45352-1921-493c-9f71-bd1ef6c02cf6
2021-04-15 17:36:20,747 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting FencedAkkaRpcActor with name resourcemanager_1.
2021-04-15 17:36:20,747 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_1 .
2021-04-15 17:36:20,761 DEBUG o.a.f.r.e.c.DefaultDispatcherResourceManagerComponentFactory - Starting Dispatcher.
2021-04-15 17:36:20,763 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
2021-04-15 17:36:20,764 DEBUG o.a.f.r.e.c.DefaultDispatcherResourceManagerComponentFactory - Starting ResourceManager.
2021-04-15 17:36:20,764 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: StandaloneResourceManager
2021-04-15 17:36:20,765 DEBUG o.a.f.runtime.dispatcher.runner.DefaultDispatcherRunner - Create new DispatcherLeaderProcess with leader session id 2142ac78-85a1-4185-ace4-610c1d869a0f.
2021-04-15 17:36:20,769 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - ResourceManager akka://flink/user/rpc/resourcemanager_1 was granted leadership with fencing token 9bf12184ac71006edba038496c7046fb
2021-04-15 17:36:20,771 INFO org.apache.flink.runtime.minicluster.MiniCluster - Flink Mini Cluster started successfully
2021-04-15 17:36:20,773 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Start SessionDispatcherLeaderProcess.
2021-04-15 17:36:20,775 INFO o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Starting the SlotManager.
2021-04-15 17:36:20,780 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:36:20,780 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:36:20,780 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Recover all persisted job graphs.
2021-04-15 17:36:20,781 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/resourcemanager_1 , session=dba03849-6c70-46fb-9bf1-2184ac71006e
2021-04-15 17:36:20,781 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Successfully recovered 0 persisted job graphs.
2021-04-15 17:36:20,784 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(9bf12184ac71006edba038496c7046fb).
2021-04-15 17:36:20,788 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:36:20,791 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:36:20,792 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting FencedAkkaRpcActor with name dispatcher_2.
2021-04-15 17:36:20,793 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:36:20,795 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_2 .
2021-04-15 17:36:20,811 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/dispatcher_2 , session=2142ac78-85a1-4185-ace4-610c1d869a0f
2021-04-15 17:36:20,812 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/dispatcher_2. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
2021-04-15 17:36:20,814 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/dispatcher_2. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
2021-04-15 17:36:20,833 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Resolved ResourceManager address, beginning registration
2021-04-15 17:36:20,833 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Registration at ResourceManager attempt 1 (timeout=100ms)
2021-04-15 17:36:20,842 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
2021-04-15 17:36:20,851 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Registering TaskManager with ResourceID 38b446c6-1a9f-4416-9e9d-05d916bbfe4c (akka://flink/user/rpc/taskmanager_0) at ResourceManager
2021-04-15 17:36:20,855 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Successful registration at resource manager akka://flink/user/rpc/resourcemanager_1 under registration id a3299a29ca9ac98e66879e7b1d08d81f.
2021-04-15 17:36:20,858 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Received JobGraph submission bb558677db9a98394e15445932ceb609 (Flink Streaming Job).
2021-04-15 17:36:20,859 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Submitting job bb558677db9a98394e15445932ceb609 (Flink Streaming Job).
2021-04-15 17:36:20,860 DEBUG o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Registering TaskManager 38b446c6-1a9f-4416-9e9d-05d916bbfe4c under a3299a29ca9ac98e66879e7b1d08d81f at the SlotManager.
2021-04-15 17:36:20,889 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: JobManagerRunnerImpl
2021-04-15 17:36:20,892 DEBUG org.apache.flink.client.ClientUtils - Wait until job initialization is finished
2021-04-15 17:36:20,900 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting FencedAkkaRpcActor with name jobmanager_3.
2021-04-15 17:36:20,901 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
2021-04-15 17:36:20,914 INFO org.apache.flink.runtime.jobmaster.JobMaster - Initializing job Flink Streaming Job (bb558677db9a98394e15445932ceb609).
2021-04-15 17:36:20,951 INFO org.apache.flink.runtime.jobmaster.JobMaster - Using restart back off time strategy NoRestartBackoffTimeStrategy for Flink Streaming Job (bb558677db9a98394e15445932ceb609).
2021-04-15 17:36:21,013 INFO org.apache.flink.runtime.jobmaster.JobMaster - Running initialization on master for job Flink Streaming Job (bb558677db9a98394e15445932ceb609).
2021-04-15 17:36:21,013 INFO org.apache.flink.runtime.jobmaster.JobMaster - Successfully ran initialization on master in 0 ms.
2021-04-15 17:36:21,013 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Adding 1 vertices from job graph Flink Streaming Job (bb558677db9a98394e15445932ceb609).
2021-04-15 17:36:21,013 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Attaching 1 topologically sorted vertices to existing job graph with 0 vertices and 0 intermediate results.
2021-04-15 17:36:21,028 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex cbc357ccb763df2852fee8c4fc7d55f2 (Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out)) to 0 predecessors.
2021-04-15 17:36:21,037 INFO o.a.f.r.scheduler.adapter.DefaultExecutionTopology - Built 1 pipelined regions in 0 ms
2021-04-15 17:36:21,040 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Successfully created execution graph from job graph Flink Streaming Job (bb558677db9a98394e15445932ceb609).
2021-04-15 17:36:21,057 INFO org.apache.flink.runtime.jobmaster.JobMaster - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:36:21,074 DEBUG o.apache.flink.runtime.checkpoint.CheckpointCoordinator - Status of the shared state registry of job bb558677db9a98394e15445932ceb609 after restore: SharedStateRegistry{registeredStates={}}.
2021-04-15 17:36:21,074 INFO o.apache.flink.runtime.checkpoint.CheckpointCoordinator - No checkpoint found during restore.
2021-04-15 17:36:21,077 INFO org.apache.flink.runtime.jobmaster.JobMaster - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@488aa1a for Flink Streaming Job (bb558677db9a98394e15445932ceb609).
2021-04-15 17:36:21,090 INFO org.apache.flink.runtime.jobmaster.JobManagerRunnerImpl - JobManager runner for job Flink Streaming Job (bb558677db9a98394e15445932ceb609) was granted leadership with session id c0173b2b-dffe-43a7-a627-1af9038358a5 at akka://flink/user/rpc/jobmanager_3.
2021-04-15 17:36:21,094 INFO org.apache.flink.runtime.jobmaster.JobMaster - Starting execution of job Flink Streaming Job (bb558677db9a98394e15445932ceb609) under job master id a6271af9038358a5c0173b2bdffe43a7.
2021-04-15 17:36:21,097 INFO org.apache.flink.runtime.jobmaster.JobMaster - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2021-04-15 17:36:21,098 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Job Flink Streaming Job (bb558677db9a98394e15445932ceb609) switched from state CREATED to RUNNING.
2021-04-15 17:36:21,102 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1) (dd72d27e30e461c85136a4e3e00c5a3a) switched from CREATED to SCHEDULED.
2021-04-15 17:36:21,112 DEBUG o.a.f.r.jobmaster.slotpool.PhysicalSlotProviderImpl - Received slot request [SlotRequestId{62615054e9aed1665696a081c36a88bd}] with resource requirements: ResourceProfile{UNKNOWN}
2021-04-15 17:36:21,116 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{62615054e9aed1665696a081c36a88bd}]
2021-04-15 17:36:21,119 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{6f94048d9d1665920fe6d74e2a6277ab}) for execution vertex (id cbc357ccb763df2852fee8c4fc7d55f2_0) from the physical slot (SlotRequestId{62615054e9aed1665696a081c36a88bd})
2021-04-15 17:36:21,126 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/jobmanager_3 , session=c0173b2b-dffe-43a7-a627-1af9038358a5
2021-04-15 17:36:21,127 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
2021-04-15 17:36:21,128 INFO org.apache.flink.runtime.jobmaster.JobMaster - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(9bf12184ac71006edba038496c7046fb)
2021-04-15 17:36:21,129 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:36:21,130 INFO org.apache.flink.runtime.jobmaster.JobMaster - Resolved ResourceManager address, beginning registration
2021-04-15 17:36:21,130 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Registration at ResourceManager attempt 1 (timeout=100ms)
2021-04-15 17:36:21,130 DEBUG o.a.flink.runtime.resourcemanager.JobLeaderIdService - Add job bb558677db9a98394e15445932ceb609 to job leader id monitoring.
2021-04-15 17:36:21,131 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Registering job manager a6271af9038358a5c0173b2bdffe43a7@akka://flink/user/rpc/jobmanager_3 for job bb558677db9a98394e15445932ceb609.
2021-04-15 17:36:21,131 DEBUG o.a.flink.runtime.resourcemanager.JobLeaderIdService - Found a new job leader c0173b2b-dffe-43a7-a627-1af9038358a5@akka://flink/user/rpc/jobmanager_3.
2021-04-15 17:36:21,132 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/jobmanager_3. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2021-04-15 17:36:21,138 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Registered job manager a6271af9038358a5c0173b2bdffe43a7@akka://flink/user/rpc/jobmanager_3 for job bb558677db9a98394e15445932ceb609.
2021-04-15 17:36:21,140 INFO org.apache.flink.runtime.jobmaster.JobMaster - JobManager successfully registered at ResourceManager, leader id: 9bf12184ac71006edba038496c7046fb.
2021-04-15 17:36:21,142 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{62615054e9aed1665696a081c36a88bd}] and profile ResourceProfile{UNKNOWN} with allocation id 8e5ea749e6d1178e05f89b96669f769b from resource manager.
2021-04-15 17:36:21,143 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job bb558677db9a98394e15445932ceb609 with allocation id 8e5ea749e6d1178e05f89b96669f769b.
2021-04-15 17:36:21,149 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 8e5ea749e6d1178e05f89b96669f769b for job bb558677db9a98394e15445932ceb609 from resource manager with leader id 9bf12184ac71006edba038496c7046fb.
2021-04-15 17:36:21,156 DEBUG org.apache.flink.runtime.memory.MemoryManager - Initialized MemoryManager with total memory size 134217728 and page size 32768.
2021-04-15 17:36:21,157 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 8e5ea749e6d1178e05f89b96669f769b.
2021-04-15 17:36:21,160 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Add job bb558677db9a98394e15445932ceb609 for job leader monitoring.
2021-04-15 17:36:21,164 DEBUG o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - New leader information for job bb558677db9a98394e15445932ceb609. Address: akka://flink/user/rpc/jobmanager_3, leader id: a6271af9038358a5c0173b2bdffe43a7.
2021-04-15 17:36:21,165 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Try to register at job manager akka://flink/user/rpc/jobmanager_3 with leader id c0173b2b-dffe-43a7-a627-1af9038358a5.
2021-04-15 17:36:21,165 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/jobmanager_3. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2021-04-15 17:36:21,169 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Resolved JobManager address, beginning registration
2021-04-15 17:36:21,169 DEBUG o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Registration at JobManager attempt 1 (timeout=100ms)
2021-04-15 17:36:21,172 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
2021-04-15 17:36:21,176 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Register new TaskExecutor 38b446c6-1a9f-4416-9e9d-05d916bbfe4c.
2021-04-15 17:36:21,177 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Successful registration at job manager akka://flink/user/rpc/jobmanager_3 for job bb558677db9a98394e15445932ceb609.
2021-04-15 17:36:21,179 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Establish JobManager connection for job bb558677db9a98394e15445932ceb609.
2021-04-15 17:36:21,185 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Offer reserved slots to the leader of job bb558677db9a98394e15445932ceb609.
2021-04-15 17:36:21,190 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Fulfilling pending slot request [SlotRequestId{62615054e9aed1665696a081c36a88bd}] with slot [8e5ea749e6d1178e05f89b96669f769b]
2021-04-15 17:36:21,191 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{6f94048d9d1665920fe6d74e2a6277ab}) for execution vertex (id cbc357ccb763df2852fee8c4fc7d55f2_0) from the physical slot (SlotRequestId{62615054e9aed1665696a081c36a88bd})
2021-04-15 17:36:21,202 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1) (dd72d27e30e461c85136a4e3e00c5a3a) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:36:21,202 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1) (attempt #0) with attempt id dd72d27e30e461c85136a4e3e00c5a3a to 38b446c6-1a9f-4416-9e9d-05d916bbfe4c @ server1 (dataPort=-1) with allocation id 8e5ea749e6d1178e05f89b96669f769b
2021-04-15 17:36:21,237 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 8e5ea749e6d1178e05f89b96669f769b.
2021-04-15 17:36:21,238 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 8e5ea749e6d1178e05f89b96669f769b.
2021-04-15 17:36:21,269 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new allocation id 8e5ea749e6d1178e05f89b96669f769b for local state stores for job bb558677db9a98394e15445932ceb609.
2021-04-15 17:36:21,272 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_8e5ea749e6d1178e05f89b96669f769b], jobID=bb558677db9a98394e15445932ceb609, jobVertexID=cbc357ccb763df2852fee8c4fc7d55f2, subtaskIndex=0}} for bb558677db9a98394e15445932ceb609 - cbc357ccb763df2852fee8c4fc7d55f2 - 0 under allocation id 8e5ea749e6d1178e05f89b96669f769b.
2021-04-15 17:36:21,291 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1)#0 (dd72d27e30e461c85136a4e3e00c5a3a), deploy into slot with allocation id 8e5ea749e6d1178e05f89b96669f769b.
2021-04-15 17:36:21,292 INFO org.apache.flink.runtime.taskmanager.Task - Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1)#0 (dd72d27e30e461c85136a4e3e00c5a3a) switched from CREATED to DEPLOYING.
2021-04-15 17:36:21,292 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1)#0 (dd72d27e30e461c85136a4e3e00c5a3a) [DEPLOYING]
2021-04-15 17:36:21,296 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1)#0 (dd72d27e30e461c85136a4e3e00c5a3a) [DEPLOYING].
2021-04-15 17:36:21,297 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task dd72d27e30e461c85136a4e3e00c5a3a at library cache manager took 0 milliseconds
2021-04-15 17:36:21,299 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1)#0 (dd72d27e30e461c85136a4e3e00c5a3a) [DEPLOYING].
2021-04-15 17:36:21,310 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:36:21,317 INFO org.apache.flink.runtime.taskmanager.Task - Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1)#0 (dd72d27e30e461c85136a4e3e00c5a3a) switched from DEPLOYING to RUNNING.
2021-04-15 17:36:21,317 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1)#0.
2021-04-15 17:36:21,318 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1) (dd72d27e30e461c85136a4e3e00c5a3a) switched from DEPLOYING to RUNNING.
2021-04-15 17:36:21,380 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Source: sensor -> Process -> (Sink: Print to Std. Out, Sink: Print to Std. Out, Sink: Print to Std. Out) (1/1)#0
2021-04-15 17:36:21,405 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_666d412a56e17eca4e56b80d012b9b4e_(1/1) with empty state.
2021-04-15 17:36:21,421 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_010fb2190e5aaa200fb1ceee04f4019d_(1/1) with empty state.
2021-04-15 17:36:21,422 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_36d907d3ace1ed44b5db1a8a56bdffa8_(1/1) with empty state.
2021-04-15 17:36:21,422 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for ProcessOperator_864ae8de554cc248475790a298b480bf_(1/1) with empty state.
2021-04-15 17:36:21,422 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSource_cbc357ccb763df2852fee8c4fc7d55f2_(1/1) with empty state.
2021-04-15 17:36:30,788 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:36:30,789 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat request from e4cd339946bbdd3340352a266877be5b.
2021-04-15 17:36:30,789 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:36:30,790 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from e4cd339946bbdd3340352a266877be5b.
2021-04-15 17:36:30,790 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from e03874b45d7582ee7d1ce96dc608e2f8.
2021-04-15 17:36:30,792 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 38b446c6-1a9f-4416-9e9d-05d916bbfe4c.
2021-04-15 17:36:30,793 DEBUG o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Received slot report from instance a3299a29ca9ac98e66879e7b1d08d81f: SlotReport{SlotStatus{slotID=38b446c6-1a9f-4416-9e9d-05d916bbfe4c_0, allocationID=8e5ea749e6d1178e05f89b96669f769b, jobID=bb558677db9a98394e15445932ceb609, resourceProfile=ResourceProfile{managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}}}.
2021-04-15 17:36:30,796 DEBUG o.a.f.r.i.n.p.ResourceManagerPartitionTrackerImpl - Processing cluster partition report from task executor 38b446c6-1a9f-4416-9e9d-05d916bbfe4c: PartitionReport{entries=[]}.
2021-04-15 17:36:31,140 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
2021-04-15 17:36:31,144 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from e03874b45d7582ee7d1ce96dc608e2f8.
2021-04-15 17:36:31,195 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat from 38b446c6-1a9f-4416-9e9d-05d916bbfe4c.
2021-04-15 17:47:43,866 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:47:43,869 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.util.Random
2021-04-15 17:47:46,967 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'equals' from 'core' module.
2021-04-15 17:47:47,065 DEBUG org.apache.calcite.sql.parser - Reduced `id` = 'sensor_1'
2021-04-15 17:47:47,235 DEBUG org.apache.flink.table.module.ModuleManager - Cannot find FunctionDefinition 'id' from any loaded modules.
2021-04-15 17:47:47,243 DEBUG org.apache.flink.table.module.ModuleManager - Cannot find FunctionDefinition '=' from any loaded modules.
2021-04-15 17:47:47,250 DEBUG org.apache.flink.table.module.ModuleManager - Cannot find FunctionDefinition 'id' from any loaded modules.
2021-04-15 17:47:47,251 DEBUG org.apache.flink.table.module.ModuleManager - Cannot find FunctionDefinition 'temperature' from any loaded modules.
2021-04-15 17:47:47,694 DEBUG org.apache.calcite.sql2rel - Plan after converting SqlNode to RelNode
LogicalProject(id=[$0], temperature=[$1])
  LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
    LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
      LogicalProject(id=[$0], temperature=[$1])
        LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:47,710 INFO org.apache.flink.api.java.typeutils.TypeExtractor - class org.apache.flink.types.Row is missing a default constructor so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2021-04-15 17:47:48,528 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:47:48,543 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:48,544 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:47:48,544 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#15:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#14,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:48,549 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#13:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#12,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:48,550 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#11:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#10,inputs=0..1)
2021-04-15 17:47:48,550 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#6:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
2021-04-15 17:47:48,577 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert table references before rewriting sub-queries to semi-join cost 23 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
   +- LogicalProject(id=[$0], temperature=[$1])
      +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:48,578 DEBUG org.apache.calcite.plan.RelOptPlanner - call#0: Apply rule [SimplifyFilterConditionRule:simplifySubQuery] to [rel#20:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#19,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:48,590 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:48,591 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
SimplifyFilterConditionRule:simplifySubQuery                                   1              11,169
* Total                                                                        1              11,169

2021-04-15 17:47:48,592 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#22:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#21,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:48,592 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#20:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#19,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:48,592 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#18:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#17,inputs=0..1)
2021-04-15 17:47:48,592 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#6:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
2021-04-15 17:47:48,593 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize rewrite sub-queries to semi-join cost 15 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
   +- LogicalProject(id=[$0], temperature=[$1])
      +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:48,594 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:48,594 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:47:48,594 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#29:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#28,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:48,594 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#27:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#26,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:48,594 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#25:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#24,inputs=0..1)
2021-04-15 17:47:48,597 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#6:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
2021-04-15 17:47:48,598 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize sub-queries remove cost 5 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
   +- LogicalProject(id=[$0], temperature=[$1])
      +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:48,599 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:48,599 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:47:48,599 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#36:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#35,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:48,599 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#34:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#33,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:48,599 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#32:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#31,inputs=0..1)
2021-04-15 17:47:48,599 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#6:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
2021-04-15 17:47:48,600 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert table references after sub-queries removed cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
   +- LogicalProject(id=[$0], temperature=[$1])
      +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:48,601 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize subquery_rewrite cost 76 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
   +- LogicalProject(id=[$0], temperature=[$1])
      +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:48,602 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:47:48,602 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:48,602 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:47:48,602 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#43:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#42,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:48,603 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#41:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#40,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:48,603 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#39:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#38,inputs=0..1)
2021-04-15 17:47:48,603 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#6:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
2021-04-15 17:47:48,604 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert correlate to temporal table join cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
   +- LogicalProject(id=[$0], temperature=[$1])
      +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:48,604 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:48,605 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:47:48,605 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#50:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#49,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:48,605 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#48:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#47,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:48,605 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#46:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#45,inputs=0..1)
2021-04-15 17:47:48,605 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#6:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
2021-04-15 17:47:48,606 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert enumerable table scan cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
   +- LogicalProject(id=[$0], temperature=[$1])
      +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:48,606 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize temporal_join_rewrite cost 5 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
   +- LogicalProject(id=[$0], temperature=[$1])
      +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:48,606 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:47:48,606 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:48,607 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:47:48,607 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#57:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#56,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:48,607 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#55:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#54,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:48,607 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#53:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#52,inputs=0..1)
2021-04-15 17:47:48,607 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#6:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
2021-04-15 17:47:48,609 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize pre-rewrite before decorrelation cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
   +- LogicalProject(id=[$0], temperature=[$1])
      +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:48,627 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize  cost 17 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
   +- LogicalProject(id=[$0], temperature=[$1])
      +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:48,627 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize decorrelate cost 21 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
   +- LogicalProject(id=[$0], temperature=[$1])
      +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:48,636 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize time_indicator cost 7 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
   +- LogicalProject(id=[$0], temperature=[$1])
      +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:48,636 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1: Apply rule [SimplifyFilterConditionRule] to [rel#65:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#64,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:48,638 DEBUG org.apache.calcite.plan.RelOptPlanner - call#4: Apply rule [ReduceExpressionsRule(Filter)] to [rel#65:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#64,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:48,692 DEBUG org.apache.calcite.plan.RelOptPlanner - call#5: Apply rule [ReduceExpressionsRule(Project)] to [rel#63:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#62,inputs=0..1)]
2021-04-15 17:47:48,694 DEBUG org.apache.calcite.plan.RelOptPlanner - call#6: Apply rule [ConvertToNotInOrInRule] to [rel#65:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#64,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:48,701 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:48,701 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
ReduceExpressionsRule(Filter)                                                  1              54,331
ConvertToNotInOrInRule                                                         1               6,086
SimplifyFilterConditionRule                                                    1                 242
ReduceExpressionsRule(Project)                                                 1                 112
* Total                                                                        4              60,771

2021-04-15 17:47:48,702 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#67:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#66,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:48,702 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#65:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#64,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:48,702 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#63:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#62,inputs=0..1)
2021-04-15 17:47:48,702 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#6:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
2021-04-15 17:47:48,702 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize default_rewrite cost 66 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
   +- LogicalProject(id=[$0], temperature=[$1])
      +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:48,703 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:47:48,703 DEBUG org.apache.calcite.plan.RelOptPlanner - call#7: Apply rule [ReduceExpressionsRule(Project)] to [rel#70:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#69,inputs=0..1)]
2021-04-15 17:47:48,704 DEBUG org.apache.calcite.plan.RelOptPlanner - call#8: Apply rule [FilterProjectTransposeRule] to [rel#72:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#71,condition==($0, _UTF-16LE'sensor_1')), rel#70:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#69,inputs=0..1)]
2021-04-15 17:47:48,706 DEBUG org.apache.calcite.plan.RelOptPlanner - call#8: Rule FilterProjectTransposeRule arguments [rel#72:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#71,condition==($0, _UTF-16LE'sensor_1')), rel#70:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#69,inputs=0..1)] produced rel#77:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=LogicalFilter#76,inputs=0..1)
2021-04-15 17:47:48,709 DEBUG org.apache.calcite.plan.RelOptPlanner - call#9: Apply rule [SimplifyFilterConditionRule] to [rel#76:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#69,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:48,709 DEBUG org.apache.calcite.plan.RelOptPlanner - call#10: Apply rule [ReduceExpressionsRule(Filter)] to [rel#76:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#69,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:48,710 DEBUG org.apache.calcite.plan.RelOptPlanner - call#11: Apply rule [ReduceExpressionsRule(Project)] to [rel#79:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#78,inputs=0..1)]
2021-04-15 17:47:48,837 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: ExpressionReducer$1 

 Code:

      public class ExpressionReducer$1
          extends org.apache.flink.api.common.functions.RichMapFunction {

        
        private final org.apache.flink.table.data.binary.BinaryStringData str$0 = org.apache.flink.table.data.binary.BinaryStringData.fromString("sensor_1");
                   
        org.apache.flink.table.data.GenericRowData out = new org.apache.flink.table.data.GenericRowData(1);

        public ExpressionReducer$1(Object[] references) throws Exception {
          
        }

        

        @Override
        public void open(org.apache.flink.configuration.Configuration parameters) throws Exception {
          
        }

        @Override
        public Object map(Object _in1) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) _in1;
          
          
          
          
          
          
          
          
          if (false) {
            out.setField(0, null);
          } else {
            out.setField(0, ((org.apache.flink.table.data.binary.BinaryStringData) str$0));
          }
                    
                  
          return out;
          
        }

        @Override
        public void close() throws Exception {
          
        }
      }
    
2021-04-15 17:47:48,857 DEBUG org.apache.calcite.plan.RelOptPlanner - call#11: Rule ReduceExpressionsRule(Project) arguments [rel#79:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#78,inputs=0..1)] produced rel#81:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#78,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])
2021-04-15 17:47:48,859 DEBUG org.apache.calcite.plan.RelOptPlanner - call#12: Apply rule [SimplifyFilterConditionRule] to [rel#76:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#69,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:48,860 DEBUG org.apache.calcite.plan.RelOptPlanner - call#13: Apply rule [ReduceExpressionsRule(Filter)] to [rel#76:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#69,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:48,861 DEBUG org.apache.calcite.plan.RelOptPlanner - call#14: Apply rule [ReduceExpressionsRule(Project)] to [rel#81:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#78,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])]
2021-04-15 17:47:48,861 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:48,864 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
ReduceExpressionsRule(Project)                                                 3             146,363
ReduceExpressionsRule(Filter)                                                  2                 974
SimplifyFilterConditionRule                                                    2                 708
FilterProjectTransposeRule                                                     1               2,275
* Total                                                                        8             150,320

2021-04-15 17:47:48,864 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#74:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#82,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:48,864 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#81:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#78,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])
2021-04-15 17:47:48,864 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#76:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#69,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:48,864 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#6:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
2021-04-15 17:47:48,865 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize filter rules cost 161 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalProject(id=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE"], temperature=[$1])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
      +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:48,867 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:48,867 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:47:48,867 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#88:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#87,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:48,867 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#86:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#85,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])
2021-04-15 17:47:48,867 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#84:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#83,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:48,868 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#6:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
2021-04-15 17:47:48,868 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize push predicate into table scan cost 3 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalProject(id=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE"], temperature=[$1])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
      +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:48,869 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:48,869 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:47:48,869 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#95:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#94,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:48,870 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#93:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#92,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])
2021-04-15 17:47:48,870 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#91:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#90,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:48,870 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#6:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
2021-04-15 17:47:48,870 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize prune empty after predicate push down cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalProject(id=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE"], temperature=[$1])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
      +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:48,871 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize predicate_pushdown cost 168 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalProject(id=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE"], temperature=[$1])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
      +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:49,080 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:49,080 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalDataStreamTableScanConverter(in:NONE,out:LOGICAL)] rels [#6]
2021-04-15 17:47:49,081 DEBUG org.apache.calcite.plan.RelOptPlanner - call#31: Apply rule [FlinkLogicalDataStreamTableScanConverter(in:NONE,out:LOGICAL)] to [rel#6:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])]
2021-04-15 17:47:49,083 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#106 via FlinkLogicalDataStreamTableScanConverter(in:NONE,out:LOGICAL)
2021-04-15 17:47:49,161 DEBUG org.apache.calcite.plan.RelOptPlanner - call#31 generated 1 successors: [rel#106:FlinkLogicalDataStreamTableScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])]
2021-04-15 17:47:49,161 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:49,161 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FilterToCalcRule] rels [#98]
2021-04-15 17:47:49,161 DEBUG org.apache.calcite.plan.RelOptPlanner - call#50: Apply rule [FilterToCalcRule] to [rel#98:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:49,168 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#108 via FilterToCalcRule
2021-04-15 17:47:49,169 DEBUG org.apache.calcite.plan.RelOptPlanner - call#50 generated 1 successors: [rel#108:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)]
2021-04-15 17:47:49,170 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:49,170 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectFilterTransposeRule] rels [#100,#98]
2021-04-15 17:47:49,170 DEBUG org.apache.calcite.plan.RelOptPlanner - call#54: Apply rule [ProjectFilterTransposeRule] to [rel#100:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#99,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#98:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:49,177 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#111 via ProjectFilterTransposeRule
2021-04-15 17:47:49,179 DEBUG org.apache.calcite.plan.RelOptPlanner - call#54 generated 1 successors: [rel#111:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=LogicalFilter#110,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])]
2021-04-15 17:47:49,179 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:49,179 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#100]
2021-04-15 17:47:49,179 DEBUG org.apache.calcite.plan.RelOptPlanner - call#75: Apply rule [ProjectToCalcRule] to [rel#100:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#99,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])]
2021-04-15 17:47:49,180 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#116 via ProjectToCalcRule
2021-04-15 17:47:49,183 DEBUG org.apache.calcite.plan.RelOptPlanner - call#75 generated 1 successors: [rel#116:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#99,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t4,1=$t1)]
2021-04-15 17:47:49,183 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:49,183 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)] rels [#102]
2021-04-15 17:47:49,191 DEBUG org.apache.calcite.plan.RelOptPlanner - call#83: Apply rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)] to [rel#102:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#101,name=DataStreamTableSink,fields=id, temperature)]
2021-04-15 17:47:49,192 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#118 via FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)
2021-04-15 17:47:49,287 DEBUG org.apache.calcite.plan.RelOptPlanner - call#83 generated 1 successors: [rel#118:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#117,name=DataStreamTableSink,fields=id, temperature)]
2021-04-15 17:47:49,287 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:49,287 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectCalcMergeRule] rels [#100,#108]
2021-04-15 17:47:49,288 DEBUG org.apache.calcite.plan.RelOptPlanner - call#102: Apply rule [ProjectCalcMergeRule] to [rel#100:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#99,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#108:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)]
2021-04-15 17:47:49,290 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#119 via ProjectCalcMergeRule
2021-04-15 17:47:49,291 DEBUG org.apache.calcite.plan.RelOptPlanner - call#102 generated 1 successors: [rel#119:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_1',expr#6==($t0, $t5),0=$t4,1=$t1,$condition=$t6)]
2021-04-15 17:47:49,291 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:49,292 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#108]
2021-04-15 17:47:49,292 DEBUG org.apache.calcite.plan.RelOptPlanner - call#106: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#108:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)]
2021-04-15 17:47:49,294 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#120 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:47:49,334 DEBUG org.apache.calcite.plan.RelOptPlanner - call#106 generated 1 successors: [rel#120:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#107,select=id, temperature, timestamp,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:49,335 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:49,335 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#109]
2021-04-15 17:47:49,335 DEBUG org.apache.calcite.plan.RelOptPlanner - call#129: Apply rule [ProjectToCalcRule] to [rel#109:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,inputs=0..1)]
2021-04-15 17:47:49,336 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#122 via ProjectToCalcRule
2021-04-15 17:47:49,336 DEBUG org.apache.calcite.plan.RelOptPlanner - call#129 generated 1 successors: [rel#122:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},proj#0..1={exprs})]
2021-04-15 17:47:49,337 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:49,337 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FilterProjectTransposeRule] rels [#113,#109]
2021-04-15 17:47:49,337 DEBUG org.apache.calcite.plan.RelOptPlanner - call#134: Apply rule [FilterProjectTransposeRule] to [rel#113:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#112,condition==($0, _UTF-16LE'sensor_1')), rel#109:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,inputs=0..1)]
2021-04-15 17:47:49,337 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#124 via FilterProjectTransposeRule
2021-04-15 17:47:49,338 DEBUG org.apache.calcite.plan.RelOptPlanner - call#134 generated 1 successors: [rel#124:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=LogicalFilter#123,inputs=0..1)]
2021-04-15 17:47:49,338 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:49,338 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FilterToCalcRule] rels [#113]
2021-04-15 17:47:49,339 DEBUG org.apache.calcite.plan.RelOptPlanner - call#149: Apply rule [FilterToCalcRule] to [rel#113:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#112,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:49,339 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#126 via FilterToCalcRule
2021-04-15 17:47:49,340 DEBUG org.apache.calcite.plan.RelOptPlanner - call#149 generated 1 successors: [rel#126:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#112,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1',expr#3==($t0, $t2),proj#0..1={exprs},$condition=$t3)]
2021-04-15 17:47:49,341 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:49,341 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectFilterTransposeRule] rels [#115,#113]
2021-04-15 17:47:49,342 DEBUG org.apache.calcite.plan.RelOptPlanner - call#153: Apply rule [ProjectFilterTransposeRule] to [rel#115:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#114,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#113:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#112,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:49,342 DEBUG org.apache.calcite.plan.RelOptPlanner - call#153 generated 0 successors.
2021-04-15 17:47:49,343 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:49,343 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#115]
2021-04-15 17:47:49,343 DEBUG org.apache.calcite.plan.RelOptPlanner - call#174: Apply rule [ProjectToCalcRule] to [rel#115:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#114,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])]
2021-04-15 17:47:49,346 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#127 via ProjectToCalcRule
2021-04-15 17:47:49,347 DEBUG org.apache.calcite.plan.RelOptPlanner - call#174 generated 1 successors: [rel#127:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#114,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t3,1=$t1)]
2021-04-15 17:47:49,347 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:49,347 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#116,#108]
2021-04-15 17:47:49,347 DEBUG org.apache.calcite.plan.RelOptPlanner - call#185: Apply rule [FlinkCalcMergeRule] to [rel#116:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#99,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t4,1=$t1), rel#108:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)]
2021-04-15 17:47:49,349 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#128 via FlinkCalcMergeRule
2021-04-15 17:47:49,349 DEBUG org.apache.calcite.plan.RelOptPlanner - call#185 generated 1 successors: [rel#128:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_1',expr#6==($t0, $t5),0=$t4,1=$t1,$condition=$t6)]
2021-04-15 17:47:49,350 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:49,350 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#116]
2021-04-15 17:47:49,350 DEBUG org.apache.calcite.plan.RelOptPlanner - call#188: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#116:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#99,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t4,1=$t1)]
2021-04-15 17:47:49,350 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#129 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:47:49,372 DEBUG org.apache.calcite.plan.RelOptPlanner - call#188 generated 1 successors: [rel#129:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#121,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature)]
2021-04-15 17:47:49,372 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.45E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,375 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#119]
2021-04-15 17:47:49,375 DEBUG org.apache.calcite.plan.RelOptPlanner - call#205: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#119:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_1',expr#6==($t0, $t5),0=$t4,1=$t1,$condition=$t6)]
2021-04-15 17:47:49,375 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#130 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:47:49,379 DEBUG org.apache.calcite.plan.RelOptPlanner - call#205 generated 1 successors: [rel#130:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#107,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:49,380 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,380 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FilterCalcMergeRule] rels [#113,#122]
2021-04-15 17:47:49,380 DEBUG org.apache.calcite.plan.RelOptPlanner - call#221: Apply rule [FilterCalcMergeRule] to [rel#113:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#112,condition==($0, _UTF-16LE'sensor_1')), rel#122:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},proj#0..1={exprs})]
2021-04-15 17:47:49,381 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#131 via FilterCalcMergeRule
2021-04-15 17:47:49,382 DEBUG org.apache.calcite.plan.RelOptPlanner - call#221 generated 1 successors: [rel#131:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..1={exprs},$condition=$t4)]
2021-04-15 17:47:49,383 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,383 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#122]
2021-04-15 17:47:49,383 DEBUG org.apache.calcite.plan.RelOptPlanner - call#226: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#122:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},proj#0..1={exprs})]
2021-04-15 17:47:49,383 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#132 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:47:49,384 DEBUG org.apache.calcite.plan.RelOptPlanner - call#226 generated 1 successors: [rel#132:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#107,select=id, temperature)]
2021-04-15 17:47:49,385 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,385 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectFilterTransposeRule] rels [#125,#98]
2021-04-15 17:47:49,386 DEBUG org.apache.calcite.plan.RelOptPlanner - call#229: Apply rule [ProjectFilterTransposeRule] to [rel#125:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#99,inputs=0..1), rel#98:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:49,386 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#135 via ProjectFilterTransposeRule
2021-04-15 17:47:49,387 DEBUG org.apache.calcite.plan.RelOptPlanner - call#229 generated 1 successors: [rel#135:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=LogicalProject#134,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:49,387 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,387 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectMergeRule] rels [#115,#125]
2021-04-15 17:47:49,387 DEBUG org.apache.calcite.plan.RelOptPlanner - call#234: Apply rule [ProjectMergeRule] to [rel#115:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#114,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#125:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#99,inputs=0..1)]
2021-04-15 17:47:49,389 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#137 via ProjectMergeRule
2021-04-15 17:47:49,389 DEBUG org.apache.calcite.plan.RelOptPlanner - call#234 generated 1 successors: [rel#137:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#99,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])]
2021-04-15 17:47:49,389 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,389 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectCalcMergeRule] rels [#125,#108]
2021-04-15 17:47:49,390 DEBUG org.apache.calcite.plan.RelOptPlanner - call#250: Apply rule [ProjectCalcMergeRule] to [rel#125:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#99,inputs=0..1), rel#108:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)]
2021-04-15 17:47:49,391 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#138 via ProjectCalcMergeRule
2021-04-15 17:47:49,391 DEBUG org.apache.calcite.plan.RelOptPlanner - call#250 generated 1 successors: [rel#138:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..1={exprs},$condition=$t4)]
2021-04-15 17:47:49,392 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,392 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#125]
2021-04-15 17:47:49,393 DEBUG org.apache.calcite.plan.RelOptPlanner - call#252: Apply rule [ProjectToCalcRule] to [rel#125:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#99,inputs=0..1)]
2021-04-15 17:47:49,393 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#139 via ProjectToCalcRule
2021-04-15 17:47:49,394 DEBUG org.apache.calcite.plan.RelOptPlanner - call#252 generated 1 successors: [rel#139:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#99,expr#0..2={inputs},proj#0..1={exprs})]
2021-04-15 17:47:49,394 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,395 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectCalcMergeRule] rels [#115,#126]
2021-04-15 17:47:49,395 DEBUG org.apache.calcite.plan.RelOptPlanner - call#262: Apply rule [ProjectCalcMergeRule] to [rel#115:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#114,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#126:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#112,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1',expr#3==($t0, $t2),proj#0..1={exprs},$condition=$t3)]
2021-04-15 17:47:49,396 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#140 via ProjectCalcMergeRule
2021-04-15 17:47:49,397 DEBUG org.apache.calcite.plan.RelOptPlanner - call#262 generated 1 successors: [rel#140:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#112,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=_UTF-16LE'sensor_1',expr#5==($t0, $t4),0=$t3,1=$t1,$condition=$t5)]
2021-04-15 17:47:49,397 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,397 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#126,#122]
2021-04-15 17:47:49,397 DEBUG org.apache.calcite.plan.RelOptPlanner - call#264: Apply rule [FlinkCalcMergeRule] to [rel#126:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#112,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1',expr#3==($t0, $t2),proj#0..1={exprs},$condition=$t3), rel#122:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},proj#0..1={exprs})]
2021-04-15 17:47:49,398 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#141 via FlinkCalcMergeRule
2021-04-15 17:47:49,399 DEBUG org.apache.calcite.plan.RelOptPlanner - call#264 generated 1 successors: [rel#141:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..1={exprs},$condition=$t4)]
2021-04-15 17:47:49,399 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,399 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#126]
2021-04-15 17:47:49,399 DEBUG org.apache.calcite.plan.RelOptPlanner - call#267: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#126:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#112,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1',expr#3==($t0, $t2),proj#0..1={exprs},$condition=$t3)]
2021-04-15 17:47:49,399 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#142 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:47:49,418 DEBUG org.apache.calcite.plan.RelOptPlanner - call#267 generated 1 successors: [rel#142:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#133,select=id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:49,418 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,418 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#127,#126]
2021-04-15 17:47:49,418 DEBUG org.apache.calcite.plan.RelOptPlanner - call#277: Apply rule [FlinkCalcMergeRule] to [rel#127:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#114,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t3,1=$t1), rel#126:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#112,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1',expr#3==($t0, $t2),proj#0..1={exprs},$condition=$t3)]
2021-04-15 17:47:49,419 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#144 via FlinkCalcMergeRule
2021-04-15 17:47:49,420 DEBUG org.apache.calcite.plan.RelOptPlanner - call#277 generated 1 successors: [rel#144:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#112,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=_UTF-16LE'sensor_1',expr#5==($t0, $t4),0=$t3,1=$t1,$condition=$t5)]
2021-04-15 17:47:49,420 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,421 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#127]
2021-04-15 17:47:49,421 DEBUG org.apache.calcite.plan.RelOptPlanner - call#280: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#127:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#114,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t3,1=$t1)]
2021-04-15 17:47:49,421 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#145 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:47:49,422 DEBUG org.apache.calcite.plan.RelOptPlanner - call#280 generated 1 successors: [rel#145:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#143,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature)]
2021-04-15 17:47:49,422 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,422 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#129,#120]
2021-04-15 17:47:49,423 DEBUG org.apache.calcite.plan.RelOptPlanner - call#288: Apply rule [FlinkCalcMergeRule] to [rel#129:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#121,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature), rel#120:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#107,select=id, temperature, timestamp,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:49,425 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#146 via FlinkCalcMergeRule
2021-04-15 17:47:49,425 DEBUG org.apache.calcite.plan.RelOptPlanner - call#288 generated 1 successors: [rel#146:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#107,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:49,426 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,426 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectCalcMergeRule] rels [#115,#131]
2021-04-15 17:47:49,426 DEBUG org.apache.calcite.plan.RelOptPlanner - call#306: Apply rule [ProjectCalcMergeRule] to [rel#115:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#114,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#131:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..1={exprs},$condition=$t4)]
2021-04-15 17:47:49,427 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#147 via ProjectCalcMergeRule
2021-04-15 17:47:49,427 DEBUG org.apache.calcite.plan.RelOptPlanner - call#306 generated 1 successors: [rel#147:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_1',expr#6==($t0, $t5),0=$t4,1=$t1,$condition=$t6)]
2021-04-15 17:47:49,427 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,427 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#127,#131]
2021-04-15 17:47:49,428 DEBUG org.apache.calcite.plan.RelOptPlanner - call#309: Apply rule [FlinkCalcMergeRule] to [rel#127:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#114,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t3,1=$t1), rel#131:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..1={exprs},$condition=$t4)]
2021-04-15 17:47:49,431 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#148 via FlinkCalcMergeRule
2021-04-15 17:47:49,434 DEBUG org.apache.calcite.plan.RelOptPlanner - call#309 generated 1 successors: [rel#148:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_1',expr#6==($t0, $t5),0=$t4,1=$t1,$condition=$t6)]
2021-04-15 17:47:49,434 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,435 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#131]
2021-04-15 17:47:49,435 DEBUG org.apache.calcite.plan.RelOptPlanner - call#311: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#131:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..1={exprs},$condition=$t4)]
2021-04-15 17:47:49,435 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#149 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:47:49,436 DEBUG org.apache.calcite.plan.RelOptPlanner - call#311 generated 1 successors: [rel#149:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#107,select=id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:49,437 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,437 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectCalcMergeRule] rels [#115,#139]
2021-04-15 17:47:49,437 DEBUG org.apache.calcite.plan.RelOptPlanner - call#328: Apply rule [ProjectCalcMergeRule] to [rel#115:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#114,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#139:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#99,expr#0..2={inputs},proj#0..1={exprs})]
2021-04-15 17:47:49,438 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#150 via ProjectCalcMergeRule
2021-04-15 17:47:49,438 DEBUG org.apache.calcite.plan.RelOptPlanner - call#328 generated 1 successors: [rel#150:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#99,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t4,1=$t1)]
2021-04-15 17:47:49,438 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,439 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#139,#108]
2021-04-15 17:47:49,439 DEBUG org.apache.calcite.plan.RelOptPlanner - call#330: Apply rule [FlinkCalcMergeRule] to [rel#139:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#99,expr#0..2={inputs},proj#0..1={exprs}), rel#108:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)]
2021-04-15 17:47:49,442 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#151 via FlinkCalcMergeRule
2021-04-15 17:47:49,442 DEBUG org.apache.calcite.plan.RelOptPlanner - call#330 generated 1 successors: [rel#151:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..1={exprs},$condition=$t4)]
2021-04-15 17:47:49,442 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,443 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#127,#139]
2021-04-15 17:47:49,443 DEBUG org.apache.calcite.plan.RelOptPlanner - call#332: Apply rule [FlinkCalcMergeRule] to [rel#127:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#114,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t3,1=$t1), rel#139:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#99,expr#0..2={inputs},proj#0..1={exprs})]
2021-04-15 17:47:49,443 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#152 via FlinkCalcMergeRule
2021-04-15 17:47:49,444 DEBUG org.apache.calcite.plan.RelOptPlanner - call#332 generated 1 successors: [rel#152:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#99,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t4,1=$t1)]
2021-04-15 17:47:49,444 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,444 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#139]
2021-04-15 17:47:49,444 DEBUG org.apache.calcite.plan.RelOptPlanner - call#334: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#139:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#99,expr#0..2={inputs},proj#0..1={exprs})]
2021-04-15 17:47:49,445 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#153 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:47:49,448 DEBUG org.apache.calcite.plan.RelOptPlanner - call#334 generated 1 successors: [rel#153:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#121,select=id, temperature)]
2021-04-15 17:47:49,449 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,449 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#140,#122]
2021-04-15 17:47:49,449 DEBUG org.apache.calcite.plan.RelOptPlanner - call#344: Apply rule [FlinkCalcMergeRule] to [rel#140:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#112,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=_UTF-16LE'sensor_1',expr#5==($t0, $t4),0=$t3,1=$t1,$condition=$t5), rel#122:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},proj#0..1={exprs})]
2021-04-15 17:47:49,451 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#154 via FlinkCalcMergeRule
2021-04-15 17:47:49,451 DEBUG org.apache.calcite.plan.RelOptPlanner - call#344 generated 1 successors: [rel#154:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_1',expr#6==($t0, $t5),0=$t4,1=$t1,$condition=$t6)]
2021-04-15 17:47:49,451 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,451 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#140]
2021-04-15 17:47:49,451 DEBUG org.apache.calcite.plan.RelOptPlanner - call#347: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#140:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#112,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=_UTF-16LE'sensor_1',expr#5==($t0, $t4),0=$t3,1=$t1,$condition=$t5)]
2021-04-15 17:47:49,452 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#155 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:47:49,453 DEBUG org.apache.calcite.plan.RelOptPlanner - call#347 generated 1 successors: [rel#155:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#133,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:49,453 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,453 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#142,#132]
2021-04-15 17:47:49,454 DEBUG org.apache.calcite.plan.RelOptPlanner - call#355: Apply rule [FlinkCalcMergeRule] to [rel#142:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#133,select=id, temperature,where==(id, _UTF-16LE'sensor_1')), rel#132:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#107,select=id, temperature)]
2021-04-15 17:47:49,456 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#156 via FlinkCalcMergeRule
2021-04-15 17:47:49,456 DEBUG org.apache.calcite.plan.RelOptPlanner - call#355 generated 1 successors: [rel#156:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#107,select=id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:49,456 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,457 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#145,#142]
2021-04-15 17:47:49,457 DEBUG org.apache.calcite.plan.RelOptPlanner - call#364: Apply rule [FlinkCalcMergeRule] to [rel#145:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#143,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature), rel#142:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#133,select=id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:49,458 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#157 via FlinkCalcMergeRule
2021-04-15 17:47:49,459 DEBUG org.apache.calcite.plan.RelOptPlanner - call#364 generated 1 successors: [rel#157:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#133,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:49,459 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,460 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#145,#149]
2021-04-15 17:47:49,460 DEBUG org.apache.calcite.plan.RelOptPlanner - call#374: Apply rule [FlinkCalcMergeRule] to [rel#145:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#143,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature), rel#149:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#107,select=id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:49,463 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#158 via FlinkCalcMergeRule
2021-04-15 17:47:49,464 DEBUG org.apache.calcite.plan.RelOptPlanner - call#374 generated 1 successors: [rel#158:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#107,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:49,464 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,464 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#153,#120]
2021-04-15 17:47:49,465 DEBUG org.apache.calcite.plan.RelOptPlanner - call#382: Apply rule [FlinkCalcMergeRule] to [rel#153:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#121,select=id, temperature), rel#120:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#107,select=id, temperature, timestamp,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:49,466 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#159 via FlinkCalcMergeRule
2021-04-15 17:47:49,467 DEBUG org.apache.calcite.plan.RelOptPlanner - call#382 generated 1 successors: [rel#159:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#107,select=id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:49,467 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,467 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#145,#153]
2021-04-15 17:47:49,467 DEBUG org.apache.calcite.plan.RelOptPlanner - call#384: Apply rule [FlinkCalcMergeRule] to [rel#145:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#143,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature), rel#153:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#121,select=id, temperature)]
2021-04-15 17:47:49,468 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#160 via FlinkCalcMergeRule
2021-04-15 17:47:49,468 DEBUG org.apache.calcite.plan.RelOptPlanner - call#384 generated 1 successors: [rel#160:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#121,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature)]
2021-04-15 17:47:49,469 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,469 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#155,#132]
2021-04-15 17:47:49,469 DEBUG org.apache.calcite.plan.RelOptPlanner - call#392: Apply rule [FlinkCalcMergeRule] to [rel#155:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#133,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1')), rel#132:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#107,select=id, temperature)]
2021-04-15 17:47:49,472 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#161 via FlinkCalcMergeRule
2021-04-15 17:47:49,472 DEBUG org.apache.calcite.plan.RelOptPlanner - call#392 generated 1 successors: [rel#161:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#107,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:49,472 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,473 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for VolcanoPlanner
2021-04-15 17:47:49,474 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
FlinkCalcMergeRule                                                            14              35,242
FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)                                 9             100,918
ProjectCalcMergeRule                                                           5              10,279
ProjectToCalcRule                                                              4              10,486
ProjectFilterTransposeRule                                                     3              10,607
FilterToCalcRule                                                               2              10,094
FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)                           1              95,923
FlinkLogicalDataStreamTableScanConverter(in:NONE,out:LOGICAL)                   1              80,337
FilterCalcMergeRule                                                            1               2,160
ProjectMergeRule                                                               1               2,119
FilterProjectTransposeRule                                                     1               1,347
* Total                                                                       42             359,512

2021-04-15 17:47:49,510 DEBUG org.apache.calcite.plan.RelOptPlanner - Cheapest plan:
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature]): rowcount = 1.5E7, cumulative cost = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 163
  FlinkLogicalCalc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[=(id, _UTF-16LE'sensor_1')]): rowcount = 1.5E7, cumulative cost = {1.15E8 rows, 1.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 162
    FlinkLogicalDataStreamTableScan(table=[[Unregistered_DataStream_1]]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 106

2021-04-15 17:47:49,514 DEBUG org.apache.calcite.plan.RelOptPlanner - Provenance:
rel#163:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=FlinkLogicalCalc#162,name=DataStreamTableSink,fields=id, temperature)
  direct
    rel#118:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#117,name=DataStreamTableSink,fields=id, temperature)
      call#83 rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)]
        rel#102:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#101,name=DataStreamTableSink,fields=id, temperature)
          no parent
rel#162:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=FlinkLogicalDataStreamTableScan#106,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))
  direct
    rel#130:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#107,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))
      call#205 rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)]
        rel#119:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_1',expr#6==($t0, $t5),0=$t4,1=$t1,$condition=$t6)
          call#102 rule [ProjectCalcMergeRule]
            rel#100:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#99,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])
              no parent
            rel#108:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)
              call#50 rule [FilterToCalcRule]
                rel#98:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#97,condition==($0, _UTF-16LE'sensor_1'))
                  no parent
rel#106:FlinkLogicalDataStreamTableScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
  call#31 rule [FlinkLogicalDataStreamTableScanConverter(in:NONE,out:LOGICAL)]
    rel#6:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
      no parent

2021-04-15 17:47:49,515 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize logical cost 642 ms.
optimize result: 
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- FlinkLogicalCalc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[=(id, _UTF-16LE'sensor_1')])
   +- FlinkLogicalDataStreamTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:49,528 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:49,528 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:47:49,528 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#167:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#166,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:49,529 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#165:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#164,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))
2021-04-15 17:47:49,529 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#106:FlinkLogicalDataStreamTableScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
2021-04-15 17:47:49,530 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize logical_rewrite cost 14 ms.
optimize result: 
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- FlinkLogicalCalc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[=(id, _UTF-16LE'sensor_1')])
   +- FlinkLogicalDataStreamTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:49,542 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:49,543 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecDataStreamScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#106]
2021-04-15 17:47:49,543 DEBUG org.apache.calcite.plan.RelOptPlanner - call#404: Apply rule [StreamExecDataStreamScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#106:FlinkLogicalDataStreamTableScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])]
2021-04-15 17:47:49,551 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#176 via StreamExecDataStreamScanRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:47:49,608 DEBUG org.apache.calcite.plan.RelOptPlanner - call#404 generated 1 successors: [rel#176:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1],fields=id, temperature, timestamp)]
2021-04-15 17:47:49,609 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:49,609 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#170]
2021-04-15 17:47:49,610 DEBUG org.apache.calcite.plan.RelOptPlanner - call#415: Apply rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#170:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#169,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:49,611 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#178 via StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:47:49,667 DEBUG org.apache.calcite.plan.RelOptPlanner - call#415 generated 1 successors: [rel#178:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#177,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:49,668 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:49,668 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#172]
2021-04-15 17:47:49,668 DEBUG org.apache.calcite.plan.RelOptPlanner - call#432: Apply rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#172:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#171,name=DataStreamTableSink,fields=id, temperature)]
2021-04-15 17:47:49,678 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#180 via StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:47:49,728 DEBUG org.apache.calcite.plan.RelOptPlanner - call#432 generated 1 successors: [rel#180:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#179,name=DataStreamTableSink,fields=id, temperature)]
2021-04-15 17:47:49,729 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:49,729 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for VolcanoPlanner
2021-04-15 17:47:49,730 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
FlinkCalcMergeRule                                                            14              35,242
FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)                                 9             100,918
ProjectCalcMergeRule                                                           5              10,279
ProjectToCalcRule                                                              4              10,486
ProjectFilterTransposeRule                                                     3              10,607
FilterToCalcRule                                                               2              10,094
FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)                           1              95,923
FlinkLogicalDataStreamTableScanConverter(in:NONE,out:LOGICAL)                   1              80,337
StreamExecDataStreamScanRule(in:LOGICAL,out:STREAM_PHYSICAL)                   1              65,537
StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)                       1              60,828
StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)                             1              57,914
FilterCalcMergeRule                                                            1               2,160
ProjectMergeRule                                                               1               2,119
FilterProjectTransposeRule                                                     1               1,347
* Total                                                                       45             543,791

2021-04-15 17:47:49,752 DEBUG org.apache.calcite.plan.RelOptPlanner - Cheapest plan:
StreamExecLegacySink(name=[DataStreamTableSink], fields=[id, temperature]): rowcount = 1.5E7, cumulative cost = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 182
  StreamExecCalc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[=(id, _UTF-16LE'sensor_1')]): rowcount = 1.5E7, cumulative cost = {1.15E8 rows, 1.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 181
    StreamExecDataStreamScan(table=[[Unregistered_DataStream_1]], fields=[id, temperature, timestamp]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 176

2021-04-15 17:47:49,753 DEBUG org.apache.calcite.plan.RelOptPlanner - Provenance:
rel#182:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=StreamExecCalc#181,name=DataStreamTableSink,fields=id, temperature)
  direct
    rel#180:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#179,name=DataStreamTableSink,fields=id, temperature)
      call#432 rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#172:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#171,name=DataStreamTableSink,fields=id, temperature)
          no parent
rel#181:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=StreamExecDataStreamScan#176,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))
  direct
    rel#178:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#177,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))
      call#415 rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#170:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#169,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))
          no parent
rel#176:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1],fields=id, temperature, timestamp)
  call#404 rule [StreamExecDataStreamScanRule(in:LOGICAL,out:STREAM_PHYSICAL)]
    rel#106:FlinkLogicalDataStreamTableScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
      no parent

2021-04-15 17:47:49,753 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize physical cost 223 ms.
optimize result: 
LegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[=(id, _UTF-16LE'sensor_1')])
   +- DataStreamScan(table=[[Unregistered_DataStream_1]], fields=[id, temperature, timestamp])

2021-04-15 17:47:49,753 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:47:49,754 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:49,754 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:47:49,754 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#186:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#185,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:49,754 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#184:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#183,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))
2021-04-15 17:47:49,754 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#176:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1],fields=id, temperature, timestamp)
2021-04-15 17:47:49,755 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize watermark transpose cost 1 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[=(id, _UTF-16LE'sensor_1')])
   +- DataStreamScan(table=[[Unregistered_DataStream_1]], fields=[id, temperature, timestamp])

2021-04-15 17:47:49,798 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize Changelog mode inference cost 43 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[=(id, _UTF-16LE'sensor_1')])
   +- DataStreamScan(table=[[Unregistered_DataStream_1]], fields=[id, temperature, timestamp])

2021-04-15 17:47:49,799 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize Initialization for mini-batch interval inference cost 0 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[=(id, _UTF-16LE'sensor_1')])
   +- DataStreamScan(table=[[Unregistered_DataStream_1]], fields=[id, temperature, timestamp])

2021-04-15 17:47:49,800 DEBUG org.apache.calcite.plan.RelOptPlanner - call#440: Apply rule [MiniBatchIntervalInferRule] to [rel#198:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#197,name=DataStreamTableSink,fields=id, temperature)]
2021-04-15 17:47:49,805 DEBUG org.apache.calcite.plan.RelOptPlanner - call#441: Apply rule [MiniBatchIntervalInferRule] to [rel#196:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[I].[NONE](input=HepRelVertex#195,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:49,805 DEBUG org.apache.calcite.plan.RelOptPlanner - call#442: Apply rule [MiniBatchIntervalInferRule] to [rel#191:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[Unregistered_DataStream_1],fields=id, temperature, timestamp)]
2021-04-15 17:47:49,805 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:49,805 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
MiniBatchIntervalInferRule                                                     3               4,527
* Total                                                                        3               4,527

2021-04-15 17:47:49,805 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#198:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#197,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:49,806 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#196:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[I].[NONE](input=HepRelVertex#195,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))
2021-04-15 17:47:49,806 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#191:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[Unregistered_DataStream_1],fields=id, temperature, timestamp)
2021-04-15 17:47:49,807 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize mini-batch interval rules cost 7 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[=(id, _UTF-16LE'sensor_1')])
   +- DataStreamScan(table=[[Unregistered_DataStream_1]], fields=[id, temperature, timestamp])

2021-04-15 17:47:49,807 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:49,808 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:47:49,808 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#203:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#202,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:49,808 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#201:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[I].[NONE](input=HepRelVertex#200,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))
2021-04-15 17:47:49,808 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#191:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[Unregistered_DataStream_1],fields=id, temperature, timestamp)
2021-04-15 17:47:49,809 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize physical rewrite cost 1 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[=(id, _UTF-16LE'sensor_1')])
   +- DataStreamScan(table=[[Unregistered_DataStream_1]], fields=[id, temperature, timestamp])

2021-04-15 17:47:49,810 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize physical_rewrite cost 56 ms.
optimize result: 
LegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[=(id, _UTF-16LE'sensor_1')])
   +- DataStreamScan(table=[[Unregistered_DataStream_1]], fields=[id, temperature, timestamp])

2021-04-15 17:47:49,910 DEBUG o.a.flink.table.planner.codegen.OperatorCodeGenerator$ - Compiling OneInputStreamOperator Code:
SourceConversion
2021-04-15 17:47:49,990 DEBUG o.a.flink.table.planner.codegen.OperatorCodeGenerator$ - Compiling OneInputStreamOperator Code:
StreamExecCalc
2021-04-15 17:47:50,002 DEBUG o.a.flink.table.planner.codegen.OperatorCodeGenerator$ - Compiling OneInputStreamOperator Code:
SinkConversion
2021-04-15 17:47:50,005 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
2021-04-15 17:47:50,006 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:47:50,006 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:47:50,009 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:47:50,011 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:47:50,012 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:47:50,026 INFO org.apache.flink.api.java.typeutils.TypeExtractor - class org.apache.flink.types.Row is missing a default constructor so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2021-04-15 17:47:50,029 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:47:50,030 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:50,034 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:47:50,034 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#215:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#214,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:50,035 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#213:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#212,inputs=0..1)
2021-04-15 17:47:50,035 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#211:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#210,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:50,035 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#209:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#208,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:50,035 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#207:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#206,inputs=0..1)
2021-04-15 17:47:50,035 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#1:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
2021-04-15 17:47:50,037 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert table references before rewriting sub-queries to semi-join cost 5 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalProject(id=[$0], temperature=[$1])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
      +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
         +- LogicalProject(id=[$0], temperature=[$1])
            +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:50,037 DEBUG org.apache.calcite.plan.RelOptPlanner - call#443: Apply rule [SimplifyFilterConditionRule:simplifySubQuery] to [rel#220:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#219,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,038 DEBUG org.apache.calcite.plan.RelOptPlanner - call#444: Apply rule [SimplifyFilterConditionRule:simplifySubQuery] to [rel#222:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#221,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,038 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:50,038 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
SimplifyFilterConditionRule:simplifySubQuery                                   2                 529
* Total                                                                        2                 529

2021-04-15 17:47:50,039 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#226:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#225,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:50,039 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#224:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#223,inputs=0..1)
2021-04-15 17:47:50,039 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#222:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#221,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:50,039 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#220:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#219,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:50,039 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#218:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#217,inputs=0..1)
2021-04-15 17:47:50,039 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#1:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
2021-04-15 17:47:50,039 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize rewrite sub-queries to semi-join cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalProject(id=[$0], temperature=[$1])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
      +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
         +- LogicalProject(id=[$0], temperature=[$1])
            +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:50,040 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:50,040 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:47:50,040 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#237:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#236,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:50,040 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#235:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#234,inputs=0..1)
2021-04-15 17:47:50,040 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#233:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#232,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:50,040 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#231:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#230,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:50,040 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#229:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#228,inputs=0..1)
2021-04-15 17:47:50,040 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#1:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
2021-04-15 17:47:50,041 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize sub-queries remove cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalProject(id=[$0], temperature=[$1])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
      +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
         +- LogicalProject(id=[$0], temperature=[$1])
            +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:50,042 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:50,042 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:47:50,042 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#248:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#247,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:50,042 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#246:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#245,inputs=0..1)
2021-04-15 17:47:50,042 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#244:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#243,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:50,042 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#242:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#241,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:50,042 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#240:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#239,inputs=0..1)
2021-04-15 17:47:50,042 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#1:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
2021-04-15 17:47:50,043 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert table references after sub-queries removed cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalProject(id=[$0], temperature=[$1])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
      +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
         +- LogicalProject(id=[$0], temperature=[$1])
            +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:50,043 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize subquery_rewrite cost 14 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalProject(id=[$0], temperature=[$1])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
      +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
         +- LogicalProject(id=[$0], temperature=[$1])
            +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:50,043 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:47:50,044 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:50,044 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:47:50,044 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#259:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#258,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:50,044 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#257:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#256,inputs=0..1)
2021-04-15 17:47:50,044 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#255:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#254,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:50,044 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#253:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#252,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:50,044 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#251:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#250,inputs=0..1)
2021-04-15 17:47:50,044 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#1:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
2021-04-15 17:47:50,045 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert correlate to temporal table join cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalProject(id=[$0], temperature=[$1])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
      +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
         +- LogicalProject(id=[$0], temperature=[$1])
            +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:50,046 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:50,046 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:47:50,046 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#270:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#269,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:50,046 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#268:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#267,inputs=0..1)
2021-04-15 17:47:50,046 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#266:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#265,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:50,046 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#264:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#263,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:50,046 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#262:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#261,inputs=0..1)
2021-04-15 17:47:50,046 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#1:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
2021-04-15 17:47:50,047 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert enumerable table scan cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalProject(id=[$0], temperature=[$1])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
      +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
         +- LogicalProject(id=[$0], temperature=[$1])
            +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:50,047 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize temporal_join_rewrite cost 4 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalProject(id=[$0], temperature=[$1])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
      +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
         +- LogicalProject(id=[$0], temperature=[$1])
            +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:50,047 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:47:50,048 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:50,049 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:47:50,049 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#281:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#280,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:50,050 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#279:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#278,inputs=0..1)
2021-04-15 17:47:50,050 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#277:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#276,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:50,050 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#275:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#274,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:50,050 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#273:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#272,inputs=0..1)
2021-04-15 17:47:50,050 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#1:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
2021-04-15 17:47:50,051 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize pre-rewrite before decorrelation cost 3 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalProject(id=[$0], temperature=[$1])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
      +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
         +- LogicalProject(id=[$0], temperature=[$1])
            +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:50,051 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize  cost 0 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalProject(id=[$0], temperature=[$1])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
      +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
         +- LogicalProject(id=[$0], temperature=[$1])
            +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:50,052 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize decorrelate cost 5 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalProject(id=[$0], temperature=[$1])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
      +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
         +- LogicalProject(id=[$0], temperature=[$1])
            +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:50,053 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize time_indicator cost 1 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalProject(id=[$0], temperature=[$1])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
      +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
         +- LogicalProject(id=[$0], temperature=[$1])
            +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:50,054 DEBUG org.apache.calcite.plan.RelOptPlanner - call#445: Apply rule [SimplifyFilterConditionRule] to [rel#291:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#290,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,054 DEBUG org.apache.calcite.plan.RelOptPlanner - call#446: Apply rule [SimplifyFilterConditionRule] to [rel#293:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#292,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,055 DEBUG org.apache.calcite.plan.RelOptPlanner - call#451: Apply rule [ReduceExpressionsRule(Filter)] to [rel#291:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#290,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,055 DEBUG org.apache.calcite.plan.RelOptPlanner - call#452: Apply rule [ReduceExpressionsRule(Filter)] to [rel#293:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#292,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,058 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: ExpressionReducer$17 

 Code:

      public class ExpressionReducer$17
          extends org.apache.flink.api.common.functions.RichMapFunction {

        
        private final org.apache.flink.table.data.binary.BinaryStringData str$14 = org.apache.flink.table.data.binary.BinaryStringData.fromString("sensor_1");
                   
        org.apache.flink.table.data.GenericRowData out = new org.apache.flink.table.data.GenericRowData(1);

        public ExpressionReducer$17(Object[] references) throws Exception {
          
        }

        

        @Override
        public void open(org.apache.flink.configuration.Configuration parameters) throws Exception {
          
        }

        @Override
        public Object map(Object _in1) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) _in1;
          
          boolean isNull$15;
          boolean result$16;
          
          
          
          
          
          
          
          
          isNull$15 = false || false;
          result$16 = false;
          if (!isNull$15) {
            
            result$16 = ((org.apache.flink.table.data.binary.BinaryStringData) str$14).equals(((org.apache.flink.table.data.binary.BinaryStringData) str$14));
            
          }
          
          if (isNull$15) {
            out.setField(0, null);
          } else {
            out.setField(0, result$16);
          }
                    
                  
          return out;
          
        }

        @Override
        public void close() throws Exception {
          
        }
      }
    
2021-04-15 17:47:50,068 DEBUG org.apache.calcite.plan.RelOptPlanner - call#452: Rule ReduceExpressionsRule(Filter) arguments [rel#293:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#292,condition==($0, _UTF-16LE'sensor_1'))] produced rel#292:HepRelVertex(rel#291:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#290,condition==($0, _UTF-16LE'sensor_1')))
2021-04-15 17:47:50,069 DEBUG org.apache.calcite.plan.RelOptPlanner - call#453: Apply rule [ReduceExpressionsRule(Filter)] to [rel#291:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#290,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,082 DEBUG org.apache.calcite.plan.RelOptPlanner - call#454: Apply rule [ReduceExpressionsRule(Project)] to [rel#289:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#288,inputs=0..1)]
2021-04-15 17:47:50,082 DEBUG org.apache.calcite.plan.RelOptPlanner - call#455: Apply rule [ReduceExpressionsRule(Project)] to [rel#295:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#292,inputs=0..1)]
2021-04-15 17:47:50,084 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: ExpressionReducer$19 

 Code:

      public class ExpressionReducer$19
          extends org.apache.flink.api.common.functions.RichMapFunction {

        
        private final org.apache.flink.table.data.binary.BinaryStringData str$18 = org.apache.flink.table.data.binary.BinaryStringData.fromString("sensor_1");
                   
        org.apache.flink.table.data.GenericRowData out = new org.apache.flink.table.data.GenericRowData(1);

        public ExpressionReducer$19(Object[] references) throws Exception {
          
        }

        

        @Override
        public void open(org.apache.flink.configuration.Configuration parameters) throws Exception {
          
        }

        @Override
        public Object map(Object _in1) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) _in1;
          
          
          
          
          
          
          
          
          if (false) {
            out.setField(0, null);
          } else {
            out.setField(0, ((org.apache.flink.table.data.binary.BinaryStringData) str$18));
          }
                    
                  
          return out;
          
        }

        @Override
        public void close() throws Exception {
          
        }
      }
    
2021-04-15 17:47:50,091 DEBUG org.apache.calcite.plan.RelOptPlanner - call#455: Rule ReduceExpressionsRule(Project) arguments [rel#295:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#292,inputs=0..1)] produced rel#299:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#292,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])
2021-04-15 17:47:50,091 DEBUG org.apache.calcite.plan.RelOptPlanner - call#456: Apply rule [ReduceExpressionsRule(Project)] to [rel#289:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#288,inputs=0..1)]
2021-04-15 17:47:50,092 DEBUG org.apache.calcite.plan.RelOptPlanner - call#457: Apply rule [ReduceExpressionsRule(Project)] to [rel#299:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#292,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])]
2021-04-15 17:47:50,092 DEBUG org.apache.calcite.plan.RelOptPlanner - call#458: Apply rule [ConvertToNotInOrInRule] to [rel#291:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#290,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,093 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:50,093 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
ReduceExpressionsRule(Project)                                                 4               8,830
ReduceExpressionsRule(Filter)                                                  3              26,296
SimplifyFilterConditionRule                                                    2                 555
ConvertToNotInOrInRule                                                         1                 259
* Total                                                                       10              35,940

2021-04-15 17:47:50,093 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#297:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#300,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:50,093 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#299:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#292,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])
2021-04-15 17:47:50,093 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#291:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#290,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:50,096 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#289:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#288,inputs=0..1)
2021-04-15 17:47:50,097 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#1:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
2021-04-15 17:47:50,098 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize default_rewrite cost 43 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalProject(id=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE"], temperature=[$1])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
      +- LogicalProject(id=[$0], temperature=[$1])
         +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:50,098 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:47:50,098 DEBUG org.apache.calcite.plan.RelOptPlanner - call#459: Apply rule [ReduceExpressionsRule(Project)] to [rel#302:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#301,inputs=0..1)]
2021-04-15 17:47:50,098 DEBUG org.apache.calcite.plan.RelOptPlanner - call#460: Apply rule [FilterProjectTransposeRule] to [rel#304:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#303,condition==($0, _UTF-16LE'sensor_1')), rel#302:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#301,inputs=0..1)]
2021-04-15 17:47:50,098 DEBUG org.apache.calcite.plan.RelOptPlanner - call#460: Rule FilterProjectTransposeRule arguments [rel#304:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#303,condition==($0, _UTF-16LE'sensor_1')), rel#302:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#301,inputs=0..1)] produced rel#311:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=LogicalFilter#310,inputs=0..1)
2021-04-15 17:47:50,099 DEBUG org.apache.calcite.plan.RelOptPlanner - call#461: Apply rule [SimplifyFilterConditionRule] to [rel#310:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#301,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,099 DEBUG org.apache.calcite.plan.RelOptPlanner - call#462: Apply rule [ReduceExpressionsRule(Filter)] to [rel#310:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#301,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,100 DEBUG org.apache.calcite.plan.RelOptPlanner - call#463: Apply rule [ReduceExpressionsRule(Project)] to [rel#313:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#312,inputs=0..1)]
2021-04-15 17:47:50,101 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: ExpressionReducer$21 

 Code:

      public class ExpressionReducer$21
          extends org.apache.flink.api.common.functions.RichMapFunction {

        
        private final org.apache.flink.table.data.binary.BinaryStringData str$20 = org.apache.flink.table.data.binary.BinaryStringData.fromString("sensor_1");
                   
        org.apache.flink.table.data.GenericRowData out = new org.apache.flink.table.data.GenericRowData(1);

        public ExpressionReducer$21(Object[] references) throws Exception {
          
        }

        

        @Override
        public void open(org.apache.flink.configuration.Configuration parameters) throws Exception {
          
        }

        @Override
        public Object map(Object _in1) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) _in1;
          
          
          
          
          
          
          
          
          if (false) {
            out.setField(0, null);
          } else {
            out.setField(0, ((org.apache.flink.table.data.binary.BinaryStringData) str$20));
          }
                    
                  
          return out;
          
        }

        @Override
        public void close() throws Exception {
          
        }
      }
    
2021-04-15 17:47:50,108 DEBUG org.apache.calcite.plan.RelOptPlanner - call#463: Rule ReduceExpressionsRule(Project) arguments [rel#313:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#312,inputs=0..1)] produced rel#315:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#312,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])
2021-04-15 17:47:50,108 DEBUG org.apache.calcite.plan.RelOptPlanner - call#464: Apply rule [SimplifyFilterConditionRule] to [rel#310:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#301,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,109 DEBUG org.apache.calcite.plan.RelOptPlanner - call#465: Apply rule [ReduceExpressionsRule(Filter)] to [rel#310:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#301,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,109 DEBUG org.apache.calcite.plan.RelOptPlanner - call#466: Apply rule [ReduceExpressionsRule(Project)] to [rel#315:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#312,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])]
2021-04-15 17:47:50,109 DEBUG org.apache.calcite.plan.RelOptPlanner - call#467: Apply rule [ReduceExpressionsRule(Project)] to [rel#306:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#316,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])]
2021-04-15 17:47:50,110 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:50,110 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
ReduceExpressionsRule(Project)                                                 4               8,312
SimplifyFilterConditionRule                                                    2                 646
ReduceExpressionsRule(Filter)                                                  2                 450
FilterProjectTransposeRule                                                     1                  85
* Total                                                                        9               9,493

2021-04-15 17:47:50,110 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#308:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#307,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:50,110 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#306:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#316,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])
2021-04-15 17:47:50,110 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#315:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#312,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])
2021-04-15 17:47:50,111 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#310:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#301,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:50,111 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#1:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
2021-04-15 17:47:50,111 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize filter rules cost 13 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalProject(id=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE"], temperature=[$1])
   +- LogicalProject(id=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE"], temperature=[$1])
      +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
         +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:50,112 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:50,112 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:47:50,112 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#324:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#323,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:50,112 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#322:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#321,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])
2021-04-15 17:47:50,112 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#320:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#319,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])
2021-04-15 17:47:50,113 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#318:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#317,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:50,113 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#1:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
2021-04-15 17:47:50,113 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize push predicate into table scan cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalProject(id=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE"], temperature=[$1])
   +- LogicalProject(id=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE"], temperature=[$1])
      +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
         +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:50,114 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:50,114 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:47:50,114 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#333:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#332,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:50,114 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#331:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#330,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])
2021-04-15 17:47:50,114 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#329:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#328,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])
2021-04-15 17:47:50,114 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#327:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#326,condition==($0, _UTF-16LE'sensor_1'))
2021-04-15 17:47:50,114 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#1:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
2021-04-15 17:47:50,115 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize prune empty after predicate push down cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalProject(id=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE"], temperature=[$1])
   +- LogicalProject(id=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE"], temperature=[$1])
      +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
         +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:50,116 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize predicate_pushdown cost 17 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- LogicalProject(id=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE"], temperature=[$1])
   +- LogicalProject(id=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE"], temperature=[$1])
      +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_1')])
         +- LogicalTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:50,126 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:50,127 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalDataStreamTableScanConverter(in:NONE,out:LOGICAL)] rels [#1]
2021-04-15 17:47:50,127 DEBUG org.apache.calcite.plan.RelOptPlanner - call#484: Apply rule [FlinkLogicalDataStreamTableScanConverter(in:NONE,out:LOGICAL)] to [rel#1:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])]
2021-04-15 17:47:50,127 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#346 via FlinkLogicalDataStreamTableScanConverter(in:NONE,out:LOGICAL)
2021-04-15 17:47:50,151 DEBUG org.apache.calcite.plan.RelOptPlanner - call#484 generated 1 successors: [rel#346:FlinkLogicalDataStreamTableScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])]
2021-04-15 17:47:50,151 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:50,151 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FilterToCalcRule] rels [#336]
2021-04-15 17:47:50,151 DEBUG org.apache.calcite.plan.RelOptPlanner - call#503: Apply rule [FilterToCalcRule] to [rel#336:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,152 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#348 via FilterToCalcRule
2021-04-15 17:47:50,152 DEBUG org.apache.calcite.plan.RelOptPlanner - call#503 generated 1 successors: [rel#348:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)]
2021-04-15 17:47:50,152 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:50,153 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectFilterTransposeRule] rels [#338,#336]
2021-04-15 17:47:50,153 DEBUG org.apache.calcite.plan.RelOptPlanner - call#507: Apply rule [ProjectFilterTransposeRule] to [rel#338:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#337,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#336:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,153 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#351 via ProjectFilterTransposeRule
2021-04-15 17:47:50,154 DEBUG org.apache.calcite.plan.RelOptPlanner - call#507 generated 1 successors: [rel#351:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=LogicalFilter#350,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])]
2021-04-15 17:47:50,154 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:50,154 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#338]
2021-04-15 17:47:50,155 DEBUG org.apache.calcite.plan.RelOptPlanner - call#528: Apply rule [ProjectToCalcRule] to [rel#338:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#337,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])]
2021-04-15 17:47:50,155 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#356 via ProjectToCalcRule
2021-04-15 17:47:50,155 DEBUG org.apache.calcite.plan.RelOptPlanner - call#528 generated 1 successors: [rel#356:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#337,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t4,1=$t1)]
2021-04-15 17:47:50,156 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:50,156 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectMergeRule] rels [#340,#338]
2021-04-15 17:47:50,156 DEBUG org.apache.calcite.plan.RelOptPlanner - call#535: Apply rule [ProjectMergeRule] to [rel#340:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#339,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#338:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#337,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])]
2021-04-15 17:47:50,156 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#357 via ProjectMergeRule
2021-04-15 17:47:50,165 DEBUG org.apache.calcite.plan.RelOptPlanner - call#535 generated 1 successors: [rel#357:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#337,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])]
2021-04-15 17:47:50,166 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:50,166 DEBUG org.apache.calcite.plan.RelOptPlanner - Skip match: rule [ProjectToCalcRule] rels [#340]
2021-04-15 17:47:50,166 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)] rels [#342]
2021-04-15 17:47:50,166 DEBUG org.apache.calcite.plan.RelOptPlanner - call#561: Apply rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)] to [rel#342:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#339,name=DataStreamTableSink,fields=id, temperature)]
2021-04-15 17:47:50,166 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#359 via FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)
2021-04-15 17:47:50,192 DEBUG org.apache.calcite.plan.RelOptPlanner - call#561 generated 1 successors: [rel#359:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#358,name=DataStreamTableSink,fields=id, temperature)]
2021-04-15 17:47:50,192 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:50,192 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectCalcMergeRule] rels [#338,#348]
2021-04-15 17:47:50,192 DEBUG org.apache.calcite.plan.RelOptPlanner - call#580: Apply rule [ProjectCalcMergeRule] to [rel#338:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#337,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#348:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)]
2021-04-15 17:47:50,194 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#360 via ProjectCalcMergeRule
2021-04-15 17:47:50,194 DEBUG org.apache.calcite.plan.RelOptPlanner - call#580 generated 1 successors: [rel#360:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_1',expr#6==($t0, $t5),0=$t4,1=$t1,$condition=$t6)]
2021-04-15 17:47:50,194 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:50,194 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#348]
2021-04-15 17:47:50,195 DEBUG org.apache.calcite.plan.RelOptPlanner - call#584: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#348:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)]
2021-04-15 17:47:50,195 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#361 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:47:50,196 DEBUG org.apache.calcite.plan.RelOptPlanner - call#584 generated 1 successors: [rel#361:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#347,select=id, temperature, timestamp,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,196 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:50,196 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#349]
2021-04-15 17:47:50,196 DEBUG org.apache.calcite.plan.RelOptPlanner - call#607: Apply rule [ProjectToCalcRule] to [rel#349:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,inputs=0..1)]
2021-04-15 17:47:50,197 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#363 via ProjectToCalcRule
2021-04-15 17:47:50,197 DEBUG org.apache.calcite.plan.RelOptPlanner - call#607 generated 1 successors: [rel#363:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},proj#0..1={exprs})]
2021-04-15 17:47:50,197 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:50,197 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FilterProjectTransposeRule] rels [#353,#349]
2021-04-15 17:47:50,197 DEBUG org.apache.calcite.plan.RelOptPlanner - call#612: Apply rule [FilterProjectTransposeRule] to [rel#353:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#352,condition==($0, _UTF-16LE'sensor_1')), rel#349:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,inputs=0..1)]
2021-04-15 17:47:50,197 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#365 via FilterProjectTransposeRule
2021-04-15 17:47:50,198 DEBUG org.apache.calcite.plan.RelOptPlanner - call#612 generated 1 successors: [rel#365:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=LogicalFilter#364,inputs=0..1)]
2021-04-15 17:47:50,198 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:50,198 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FilterToCalcRule] rels [#353]
2021-04-15 17:47:50,198 DEBUG org.apache.calcite.plan.RelOptPlanner - call#627: Apply rule [FilterToCalcRule] to [rel#353:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#352,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,198 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#367 via FilterToCalcRule
2021-04-15 17:47:50,199 DEBUG org.apache.calcite.plan.RelOptPlanner - call#627 generated 1 successors: [rel#367:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#352,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1',expr#3==($t0, $t2),proj#0..1={exprs},$condition=$t3)]
2021-04-15 17:47:50,199 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:50,199 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectFilterTransposeRule] rels [#355,#353]
2021-04-15 17:47:50,199 DEBUG org.apache.calcite.plan.RelOptPlanner - call#631: Apply rule [ProjectFilterTransposeRule] to [rel#355:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#354,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#353:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#352,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,199 DEBUG org.apache.calcite.plan.RelOptPlanner - call#631 generated 0 successors.
2021-04-15 17:47:50,200 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:50,200 DEBUG org.apache.calcite.plan.RelOptPlanner - Skip match: rule [ProjectMergeRule] rels [#340,#355]
2021-04-15 17:47:50,200 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#355]
2021-04-15 17:47:50,200 DEBUG org.apache.calcite.plan.RelOptPlanner - call#653: Apply rule [ProjectToCalcRule] to [rel#355:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#354,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])]
2021-04-15 17:47:50,200 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#368 via ProjectToCalcRule
2021-04-15 17:47:50,201 DEBUG org.apache.calcite.plan.RelOptPlanner - call#653 generated 1 successors: [rel#368:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#354,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t3,1=$t1)]
2021-04-15 17:47:50,201 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:50,201 DEBUG org.apache.calcite.plan.RelOptPlanner - Skip match: rule [ProjectCalcMergeRule] rels [#340,#356]
2021-04-15 17:47:50,201 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#356,#348]
2021-04-15 17:47:50,201 DEBUG org.apache.calcite.plan.RelOptPlanner - call#665: Apply rule [FlinkCalcMergeRule] to [rel#356:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#337,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t4,1=$t1), rel#348:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)]
2021-04-15 17:47:50,202 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#369 via FlinkCalcMergeRule
2021-04-15 17:47:50,202 DEBUG org.apache.calcite.plan.RelOptPlanner - call#665 generated 1 successors: [rel#369:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_1',expr#6==($t0, $t5),0=$t4,1=$t1,$condition=$t6)]
2021-04-15 17:47:50,202 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:50,202 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#356]
2021-04-15 17:47:50,202 DEBUG org.apache.calcite.plan.RelOptPlanner - call#668: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#356:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#337,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t4,1=$t1)]
2021-04-15 17:47:50,202 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#370 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:47:50,203 DEBUG org.apache.calcite.plan.RelOptPlanner - call#668 generated 1 successors: [rel#370:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#362,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature)]
2021-04-15 17:47:50,203 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.45E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,203 DEBUG org.apache.calcite.plan.RelOptPlanner - Skip match: rule [ProjectCalcMergeRule] rels [#340,#360]
2021-04-15 17:47:50,203 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#360]
2021-04-15 17:47:50,203 DEBUG org.apache.calcite.plan.RelOptPlanner - call#753: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#360:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_1',expr#6==($t0, $t5),0=$t4,1=$t1,$condition=$t6)]
2021-04-15 17:47:50,204 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#371 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:47:50,205 DEBUG org.apache.calcite.plan.RelOptPlanner - call#753 generated 1 successors: [rel#371:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#347,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,205 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,205 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FilterCalcMergeRule] rels [#353,#363]
2021-04-15 17:47:50,205 DEBUG org.apache.calcite.plan.RelOptPlanner - call#769: Apply rule [FilterCalcMergeRule] to [rel#353:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#352,condition==($0, _UTF-16LE'sensor_1')), rel#363:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},proj#0..1={exprs})]
2021-04-15 17:47:50,206 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#372 via FilterCalcMergeRule
2021-04-15 17:47:50,206 DEBUG org.apache.calcite.plan.RelOptPlanner - call#769 generated 1 successors: [rel#372:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..1={exprs},$condition=$t4)]
2021-04-15 17:47:50,207 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,207 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#363]
2021-04-15 17:47:50,207 DEBUG org.apache.calcite.plan.RelOptPlanner - call#774: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#363:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},proj#0..1={exprs})]
2021-04-15 17:47:50,207 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#373 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:47:50,208 DEBUG org.apache.calcite.plan.RelOptPlanner - call#774 generated 1 successors: [rel#373:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#347,select=id, temperature)]
2021-04-15 17:47:50,208 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,208 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectFilterTransposeRule] rels [#366,#336]
2021-04-15 17:47:50,208 DEBUG org.apache.calcite.plan.RelOptPlanner - call#777: Apply rule [ProjectFilterTransposeRule] to [rel#366:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#337,inputs=0..1), rel#336:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,209 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#376 via ProjectFilterTransposeRule
2021-04-15 17:47:50,209 DEBUG org.apache.calcite.plan.RelOptPlanner - call#777 generated 1 successors: [rel#376:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=LogicalProject#375,condition==($0, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,209 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,209 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectMergeRule] rels [#355,#366]
2021-04-15 17:47:50,209 DEBUG org.apache.calcite.plan.RelOptPlanner - call#782: Apply rule [ProjectMergeRule] to [rel#355:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#354,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#366:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#337,inputs=0..1)]
2021-04-15 17:47:50,209 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#378 via ProjectMergeRule
2021-04-15 17:47:50,210 DEBUG org.apache.calcite.plan.RelOptPlanner - call#782 generated 1 successors: [rel#378:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#337,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])]
2021-04-15 17:47:50,210 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,210 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectCalcMergeRule] rels [#366,#348]
2021-04-15 17:47:50,210 DEBUG org.apache.calcite.plan.RelOptPlanner - call#798: Apply rule [ProjectCalcMergeRule] to [rel#366:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#337,inputs=0..1), rel#348:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)]
2021-04-15 17:47:50,210 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#379 via ProjectCalcMergeRule
2021-04-15 17:47:50,211 DEBUG org.apache.calcite.plan.RelOptPlanner - call#798 generated 1 successors: [rel#379:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..1={exprs},$condition=$t4)]
2021-04-15 17:47:50,211 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,211 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#366]
2021-04-15 17:47:50,211 DEBUG org.apache.calcite.plan.RelOptPlanner - call#800: Apply rule [ProjectToCalcRule] to [rel#366:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#337,inputs=0..1)]
2021-04-15 17:47:50,212 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#380 via ProjectToCalcRule
2021-04-15 17:47:50,214 DEBUG org.apache.calcite.plan.RelOptPlanner - call#800 generated 1 successors: [rel#380:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#337,expr#0..2={inputs},proj#0..1={exprs})]
2021-04-15 17:47:50,214 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,214 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectCalcMergeRule] rels [#355,#367]
2021-04-15 17:47:50,215 DEBUG org.apache.calcite.plan.RelOptPlanner - call#810: Apply rule [ProjectCalcMergeRule] to [rel#355:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#354,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#367:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#352,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1',expr#3==($t0, $t2),proj#0..1={exprs},$condition=$t3)]
2021-04-15 17:47:50,217 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#381 via ProjectCalcMergeRule
2021-04-15 17:47:50,218 DEBUG org.apache.calcite.plan.RelOptPlanner - call#810 generated 1 successors: [rel#381:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#352,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=_UTF-16LE'sensor_1',expr#5==($t0, $t4),0=$t3,1=$t1,$condition=$t5)]
2021-04-15 17:47:50,219 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,219 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#367,#363]
2021-04-15 17:47:50,219 DEBUG org.apache.calcite.plan.RelOptPlanner - call#812: Apply rule [FlinkCalcMergeRule] to [rel#367:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#352,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1',expr#3==($t0, $t2),proj#0..1={exprs},$condition=$t3), rel#363:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},proj#0..1={exprs})]
2021-04-15 17:47:50,226 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#382 via FlinkCalcMergeRule
2021-04-15 17:47:50,226 DEBUG org.apache.calcite.plan.RelOptPlanner - call#812 generated 1 successors: [rel#382:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..1={exprs},$condition=$t4)]
2021-04-15 17:47:50,227 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,227 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#367]
2021-04-15 17:47:50,227 DEBUG org.apache.calcite.plan.RelOptPlanner - call#815: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#367:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#352,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1',expr#3==($t0, $t2),proj#0..1={exprs},$condition=$t3)]
2021-04-15 17:47:50,227 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#383 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:47:50,229 DEBUG org.apache.calcite.plan.RelOptPlanner - call#815 generated 1 successors: [rel#383:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#374,select=id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,229 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,229 DEBUG org.apache.calcite.plan.RelOptPlanner - Skip match: rule [ProjectCalcMergeRule] rels [#340,#368]
2021-04-15 17:47:50,229 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#368,#367]
2021-04-15 17:47:50,229 DEBUG org.apache.calcite.plan.RelOptPlanner - call#826: Apply rule [FlinkCalcMergeRule] to [rel#368:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#354,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t3,1=$t1), rel#367:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#352,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1',expr#3==($t0, $t2),proj#0..1={exprs},$condition=$t3)]
2021-04-15 17:47:50,231 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#385 via FlinkCalcMergeRule
2021-04-15 17:47:50,231 DEBUG org.apache.calcite.plan.RelOptPlanner - call#826 generated 1 successors: [rel#385:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#352,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=_UTF-16LE'sensor_1',expr#5==($t0, $t4),0=$t3,1=$t1,$condition=$t5)]
2021-04-15 17:47:50,231 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,231 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#368]
2021-04-15 17:47:50,231 DEBUG org.apache.calcite.plan.RelOptPlanner - call#829: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#368:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#354,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t3,1=$t1)]
2021-04-15 17:47:50,231 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#386 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:47:50,232 DEBUG org.apache.calcite.plan.RelOptPlanner - call#829 generated 1 successors: [rel#386:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#384,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature)]
2021-04-15 17:47:50,232 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,232 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#370,#361]
2021-04-15 17:47:50,232 DEBUG org.apache.calcite.plan.RelOptPlanner - call#837: Apply rule [FlinkCalcMergeRule] to [rel#370:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#362,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature), rel#361:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#347,select=id, temperature, timestamp,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,233 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#387 via FlinkCalcMergeRule
2021-04-15 17:47:50,234 DEBUG org.apache.calcite.plan.RelOptPlanner - call#837 generated 1 successors: [rel#387:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#347,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,234 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,234 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectCalcMergeRule] rels [#355,#372]
2021-04-15 17:47:50,234 DEBUG org.apache.calcite.plan.RelOptPlanner - call#855: Apply rule [ProjectCalcMergeRule] to [rel#355:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#354,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#372:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..1={exprs},$condition=$t4)]
2021-04-15 17:47:50,236 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#388 via ProjectCalcMergeRule
2021-04-15 17:47:50,236 DEBUG org.apache.calcite.plan.RelOptPlanner - call#855 generated 1 successors: [rel#388:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_1',expr#6==($t0, $t5),0=$t4,1=$t1,$condition=$t6)]
2021-04-15 17:47:50,236 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,236 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#368,#372]
2021-04-15 17:47:50,237 DEBUG org.apache.calcite.plan.RelOptPlanner - call#858: Apply rule [FlinkCalcMergeRule] to [rel#368:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#354,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t3,1=$t1), rel#372:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..1={exprs},$condition=$t4)]
2021-04-15 17:47:50,238 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#389 via FlinkCalcMergeRule
2021-04-15 17:47:50,238 DEBUG org.apache.calcite.plan.RelOptPlanner - call#858 generated 1 successors: [rel#389:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_1',expr#6==($t0, $t5),0=$t4,1=$t1,$condition=$t6)]
2021-04-15 17:47:50,238 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,238 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#372]
2021-04-15 17:47:50,238 DEBUG org.apache.calcite.plan.RelOptPlanner - call#860: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#372:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..1={exprs},$condition=$t4)]
2021-04-15 17:47:50,238 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#390 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:47:50,239 DEBUG org.apache.calcite.plan.RelOptPlanner - call#860 generated 1 successors: [rel#390:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#347,select=id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,239 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,239 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectCalcMergeRule] rels [#355,#380]
2021-04-15 17:47:50,239 DEBUG org.apache.calcite.plan.RelOptPlanner - call#877: Apply rule [ProjectCalcMergeRule] to [rel#355:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#354,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#380:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#337,expr#0..2={inputs},proj#0..1={exprs})]
2021-04-15 17:47:50,240 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#391 via ProjectCalcMergeRule
2021-04-15 17:47:50,240 DEBUG org.apache.calcite.plan.RelOptPlanner - call#877 generated 1 successors: [rel#391:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#337,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t4,1=$t1)]
2021-04-15 17:47:50,241 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,241 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#380,#348]
2021-04-15 17:47:50,241 DEBUG org.apache.calcite.plan.RelOptPlanner - call#879: Apply rule [FlinkCalcMergeRule] to [rel#380:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#337,expr#0..2={inputs},proj#0..1={exprs}), rel#348:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)]
2021-04-15 17:47:50,242 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#392 via FlinkCalcMergeRule
2021-04-15 17:47:50,242 DEBUG org.apache.calcite.plan.RelOptPlanner - call#879 generated 1 successors: [rel#392:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..1={exprs},$condition=$t4)]
2021-04-15 17:47:50,242 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,242 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#368,#380]
2021-04-15 17:47:50,242 DEBUG org.apache.calcite.plan.RelOptPlanner - call#881: Apply rule [FlinkCalcMergeRule] to [rel#368:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#354,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t3,1=$t1), rel#380:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#337,expr#0..2={inputs},proj#0..1={exprs})]
2021-04-15 17:47:50,243 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#393 via FlinkCalcMergeRule
2021-04-15 17:47:50,243 DEBUG org.apache.calcite.plan.RelOptPlanner - call#881 generated 1 successors: [rel#393:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#337,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t4,1=$t1)]
2021-04-15 17:47:50,243 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,243 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#380]
2021-04-15 17:47:50,243 DEBUG org.apache.calcite.plan.RelOptPlanner - call#883: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#380:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#337,expr#0..2={inputs},proj#0..1={exprs})]
2021-04-15 17:47:50,243 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#394 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:47:50,245 DEBUG org.apache.calcite.plan.RelOptPlanner - call#883 generated 1 successors: [rel#394:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#362,select=id, temperature)]
2021-04-15 17:47:50,245 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,245 DEBUG org.apache.calcite.plan.RelOptPlanner - Skip match: rule [ProjectCalcMergeRule] rels [#340,#381]
2021-04-15 17:47:50,245 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#381,#363]
2021-04-15 17:47:50,245 DEBUG org.apache.calcite.plan.RelOptPlanner - call#894: Apply rule [FlinkCalcMergeRule] to [rel#381:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#352,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=_UTF-16LE'sensor_1',expr#5==($t0, $t4),0=$t3,1=$t1,$condition=$t5), rel#363:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},proj#0..1={exprs})]
2021-04-15 17:47:50,246 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#395 via FlinkCalcMergeRule
2021-04-15 17:47:50,246 DEBUG org.apache.calcite.plan.RelOptPlanner - call#894 generated 1 successors: [rel#395:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_1',expr#6==($t0, $t5),0=$t4,1=$t1,$condition=$t6)]
2021-04-15 17:47:50,246 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,246 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#381]
2021-04-15 17:47:50,246 DEBUG org.apache.calcite.plan.RelOptPlanner - call#897: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#381:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#352,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=_UTF-16LE'sensor_1',expr#5==($t0, $t4),0=$t3,1=$t1,$condition=$t5)]
2021-04-15 17:47:50,246 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#396 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:47:50,249 DEBUG org.apache.calcite.plan.RelOptPlanner - call#897 generated 1 successors: [rel#396:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#374,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,252 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,252 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#383,#373]
2021-04-15 17:47:50,252 DEBUG org.apache.calcite.plan.RelOptPlanner - call#905: Apply rule [FlinkCalcMergeRule] to [rel#383:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#374,select=id, temperature,where==(id, _UTF-16LE'sensor_1')), rel#373:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#347,select=id, temperature)]
2021-04-15 17:47:50,253 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#397 via FlinkCalcMergeRule
2021-04-15 17:47:50,253 DEBUG org.apache.calcite.plan.RelOptPlanner - call#905 generated 1 successors: [rel#397:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#347,select=id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,253 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,253 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#386,#383]
2021-04-15 17:47:50,253 DEBUG org.apache.calcite.plan.RelOptPlanner - call#914: Apply rule [FlinkCalcMergeRule] to [rel#386:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#384,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature), rel#383:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#374,select=id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,255 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#398 via FlinkCalcMergeRule
2021-04-15 17:47:50,256 DEBUG org.apache.calcite.plan.RelOptPlanner - call#914 generated 1 successors: [rel#398:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#374,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,256 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,256 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#386,#390]
2021-04-15 17:47:50,256 DEBUG org.apache.calcite.plan.RelOptPlanner - call#924: Apply rule [FlinkCalcMergeRule] to [rel#386:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#384,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature), rel#390:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#347,select=id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,257 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#399 via FlinkCalcMergeRule
2021-04-15 17:47:50,258 DEBUG org.apache.calcite.plan.RelOptPlanner - call#924 generated 1 successors: [rel#399:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#347,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,258 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,258 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#394,#361]
2021-04-15 17:47:50,259 DEBUG org.apache.calcite.plan.RelOptPlanner - call#932: Apply rule [FlinkCalcMergeRule] to [rel#394:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#362,select=id, temperature), rel#361:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#347,select=id, temperature, timestamp,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,260 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#400 via FlinkCalcMergeRule
2021-04-15 17:47:50,261 DEBUG org.apache.calcite.plan.RelOptPlanner - call#932 generated 1 successors: [rel#400:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#347,select=id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,261 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,261 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#386,#394]
2021-04-15 17:47:50,261 DEBUG org.apache.calcite.plan.RelOptPlanner - call#934: Apply rule [FlinkCalcMergeRule] to [rel#386:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#384,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature), rel#394:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#362,select=id, temperature)]
2021-04-15 17:47:50,262 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#401 via FlinkCalcMergeRule
2021-04-15 17:47:50,262 DEBUG org.apache.calcite.plan.RelOptPlanner - call#934 generated 1 successors: [rel#401:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#362,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature)]
2021-04-15 17:47:50,263 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,263 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#396,#373]
2021-04-15 17:47:50,264 DEBUG org.apache.calcite.plan.RelOptPlanner - call#942: Apply rule [FlinkCalcMergeRule] to [rel#396:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#374,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1')), rel#373:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#347,select=id, temperature)]
2021-04-15 17:47:50,265 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#402 via FlinkCalcMergeRule
2021-04-15 17:47:50,266 DEBUG org.apache.calcite.plan.RelOptPlanner - call#942 generated 1 successors: [rel#402:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#347,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,266 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,266 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for VolcanoPlanner
2021-04-15 17:47:50,268 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
FlinkCalcMergeRule                                                            28              56,802
FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)                                18             117,327
ProjectCalcMergeRule                                                          10              18,917
ProjectToCalcRule                                                              8              15,961
ProjectFilterTransposeRule                                                     6              13,166
FilterToCalcRule                                                               4              12,213
ProjectMergeRule                                                               3              12,085
FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)                           2             122,377
FlinkLogicalDataStreamTableScanConverter(in:NONE,out:LOGICAL)                   2             104,677
FilterCalcMergeRule                                                            2               3,270
FilterProjectTransposeRule                                                     2               1,994
StreamExecDataStreamScanRule(in:LOGICAL,out:STREAM_PHYSICAL)                   1              65,537
StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)                       1              60,828
StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)                             1              57,914
* Total                                                                       88             663,068

2021-04-15 17:47:50,279 DEBUG org.apache.calcite.plan.RelOptPlanner - Cheapest plan:
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature]): rowcount = 1.5E7, cumulative cost = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 404
  FlinkLogicalCalc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[=(id, _UTF-16LE'sensor_1')]): rowcount = 1.5E7, cumulative cost = {1.15E8 rows, 1.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 403
    FlinkLogicalDataStreamTableScan(table=[[Unregistered_DataStream_1]]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 346

2021-04-15 17:47:50,280 DEBUG org.apache.calcite.plan.RelOptPlanner - Provenance:
rel#404:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=FlinkLogicalCalc#403,name=DataStreamTableSink,fields=id, temperature)
  direct
    rel#359:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#358,name=DataStreamTableSink,fields=id, temperature)
      call#561 rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)]
        rel#342:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#339,name=DataStreamTableSink,fields=id, temperature)
          no parent
rel#403:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=FlinkLogicalDataStreamTableScan#346,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))
  direct
    rel#371:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#347,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))
      call#753 rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)]
        rel#360:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_1',expr#6==($t0, $t5),0=$t4,1=$t1,$condition=$t6)
          call#580 rule [ProjectCalcMergeRule]
            rel#338:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#337,exprs=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])
              no parent
            rel#348:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_1',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)
              call#503 rule [FilterToCalcRule]
                rel#336:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#335,condition==($0, _UTF-16LE'sensor_1'))
                  no parent
rel#346:FlinkLogicalDataStreamTableScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
  call#484 rule [FlinkLogicalDataStreamTableScanConverter(in:NONE,out:LOGICAL)]
    rel#1:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
      no parent

2021-04-15 17:47:50,281 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize logical cost 164 ms.
optimize result: 
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- FlinkLogicalCalc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[=(id, _UTF-16LE'sensor_1')])
   +- FlinkLogicalDataStreamTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:50,282 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:50,282 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:47:50,282 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#408:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#407,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:50,282 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#406:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#405,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))
2021-04-15 17:47:50,283 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#346:FlinkLogicalDataStreamTableScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
2021-04-15 17:47:50,284 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize logical_rewrite cost 2 ms.
optimize result: 
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- FlinkLogicalCalc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[=(id, _UTF-16LE'sensor_1')])
   +- FlinkLogicalDataStreamTableScan(table=[[Unregistered_DataStream_1]])

2021-04-15 17:47:50,287 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:50,287 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecDataStreamScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#346]
2021-04-15 17:47:50,287 DEBUG org.apache.calcite.plan.RelOptPlanner - call#954: Apply rule [StreamExecDataStreamScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#346:FlinkLogicalDataStreamTableScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])]
2021-04-15 17:47:50,287 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#417 via StreamExecDataStreamScanRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:47:50,288 DEBUG org.apache.calcite.plan.RelOptPlanner - call#954 generated 1 successors: [rel#417:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1],fields=id, temperature, timestamp)]
2021-04-15 17:47:50,288 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:50,288 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#411]
2021-04-15 17:47:50,288 DEBUG org.apache.calcite.plan.RelOptPlanner - call#965: Apply rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#411:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#410,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,288 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#419 via StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:47:50,289 DEBUG org.apache.calcite.plan.RelOptPlanner - call#965 generated 1 successors: [rel#419:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#418,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,289 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {inf}
2021-04-15 17:47:50,289 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#413]
2021-04-15 17:47:50,290 DEBUG org.apache.calcite.plan.RelOptPlanner - call#982: Apply rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#413:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#412,name=DataStreamTableSink,fields=id, temperature)]
2021-04-15 17:47:50,290 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#421 via StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:47:50,290 DEBUG org.apache.calcite.plan.RelOptPlanner - call#982 generated 1 successors: [rel#421:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#420,name=DataStreamTableSink,fields=id, temperature)]
2021-04-15 17:47:50,290 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@6c70b7c3; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:47:50,290 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for VolcanoPlanner
2021-04-15 17:47:50,291 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
FlinkCalcMergeRule                                                            28              56,802
FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)                                18             117,327
ProjectCalcMergeRule                                                          10              18,917
ProjectToCalcRule                                                              8              15,961
ProjectFilterTransposeRule                                                     6              13,166
FilterToCalcRule                                                               4              12,213
ProjectMergeRule                                                               3              12,085
FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)                           2             122,377
FlinkLogicalDataStreamTableScanConverter(in:NONE,out:LOGICAL)                   2             104,677
StreamExecDataStreamScanRule(in:LOGICAL,out:STREAM_PHYSICAL)                   2              66,026
StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)                       2              61,507
StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)                             2              58,802
FilterCalcMergeRule                                                            2               3,270
FilterProjectTransposeRule                                                     2               1,994
* Total                                                                       91             665,124

2021-04-15 17:47:50,292 DEBUG org.apache.calcite.plan.RelOptPlanner - Cheapest plan:
StreamExecLegacySink(name=[DataStreamTableSink], fields=[id, temperature]): rowcount = 1.5E7, cumulative cost = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 423
  StreamExecCalc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[=(id, _UTF-16LE'sensor_1')]): rowcount = 1.5E7, cumulative cost = {1.15E8 rows, 1.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 422
    StreamExecDataStreamScan(table=[[Unregistered_DataStream_1]], fields=[id, temperature, timestamp]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 417

2021-04-15 17:47:50,292 DEBUG org.apache.calcite.plan.RelOptPlanner - Provenance:
rel#423:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=StreamExecCalc#422,name=DataStreamTableSink,fields=id, temperature)
  direct
    rel#421:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#420,name=DataStreamTableSink,fields=id, temperature)
      call#982 rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#413:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#412,name=DataStreamTableSink,fields=id, temperature)
          no parent
rel#422:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=StreamExecDataStreamScan#417,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))
  direct
    rel#419:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#418,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))
      call#965 rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#411:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#410,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))
          no parent
rel#417:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1],fields=id, temperature, timestamp)
  call#954 rule [StreamExecDataStreamScanRule(in:LOGICAL,out:STREAM_PHYSICAL)]
    rel#346:FlinkLogicalDataStreamTableScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1])
      no parent

2021-04-15 17:47:50,293 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize physical cost 8 ms.
optimize result: 
LegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[=(id, _UTF-16LE'sensor_1')])
   +- DataStreamScan(table=[[Unregistered_DataStream_1]], fields=[id, temperature, timestamp])

2021-04-15 17:47:50,293 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:47:50,293 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:50,293 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:47:50,293 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#427:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#426,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:50,293 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#425:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#424,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))
2021-04-15 17:47:50,294 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#417:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[Unregistered_DataStream_1],fields=id, temperature, timestamp)
2021-04-15 17:47:50,294 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize watermark transpose cost 1 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[=(id, _UTF-16LE'sensor_1')])
   +- DataStreamScan(table=[[Unregistered_DataStream_1]], fields=[id, temperature, timestamp])

2021-04-15 17:47:50,295 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize Changelog mode inference cost 1 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[=(id, _UTF-16LE'sensor_1')])
   +- DataStreamScan(table=[[Unregistered_DataStream_1]], fields=[id, temperature, timestamp])

2021-04-15 17:47:50,295 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize Initialization for mini-batch interval inference cost 0 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[=(id, _UTF-16LE'sensor_1')])
   +- DataStreamScan(table=[[Unregistered_DataStream_1]], fields=[id, temperature, timestamp])

2021-04-15 17:47:50,296 DEBUG org.apache.calcite.plan.RelOptPlanner - call#990: Apply rule [MiniBatchIntervalInferRule] to [rel#439:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#438,name=DataStreamTableSink,fields=id, temperature)]
2021-04-15 17:47:50,296 DEBUG org.apache.calcite.plan.RelOptPlanner - call#991: Apply rule [MiniBatchIntervalInferRule] to [rel#437:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[I].[NONE](input=HepRelVertex#436,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))]
2021-04-15 17:47:50,296 DEBUG org.apache.calcite.plan.RelOptPlanner - call#992: Apply rule [MiniBatchIntervalInferRule] to [rel#432:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[Unregistered_DataStream_1],fields=id, temperature, timestamp)]
2021-04-15 17:47:50,296 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:50,296 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
MiniBatchIntervalInferRule                                                     3                 151
* Total                                                                        3                 151

2021-04-15 17:47:50,296 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#439:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#438,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:50,297 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#437:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[I].[NONE](input=HepRelVertex#436,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))
2021-04-15 17:47:50,297 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#432:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[Unregistered_DataStream_1],fields=id, temperature, timestamp)
2021-04-15 17:47:50,297 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize mini-batch interval rules cost 2 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[=(id, _UTF-16LE'sensor_1')])
   +- DataStreamScan(table=[[Unregistered_DataStream_1]], fields=[id, temperature, timestamp])

2021-04-15 17:47:50,297 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:47:50,298 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:47:50,298 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#444:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#443,name=DataStreamTableSink,fields=id, temperature)
2021-04-15 17:47:50,298 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#442:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[I].[NONE](input=HepRelVertex#441,select=CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature,where==(id, _UTF-16LE'sensor_1'))
2021-04-15 17:47:50,298 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#432:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[Unregistered_DataStream_1],fields=id, temperature, timestamp)
2021-04-15 17:47:50,298 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize physical rewrite cost 1 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[=(id, _UTF-16LE'sensor_1')])
   +- DataStreamScan(table=[[Unregistered_DataStream_1]], fields=[id, temperature, timestamp])

2021-04-15 17:47:50,299 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize physical_rewrite cost 5 ms.
optimize result: 
LegacySink(name=[DataStreamTableSink], fields=[id, temperature])
+- Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[=(id, _UTF-16LE'sensor_1')])
   +- DataStreamScan(table=[[Unregistered_DataStream_1]], fields=[id, temperature, timestamp])

2021-04-15 17:47:50,311 DEBUG o.a.flink.table.planner.codegen.OperatorCodeGenerator$ - Compiling OneInputStreamOperator Code:
SourceConversion
2021-04-15 17:47:50,319 DEBUG o.a.flink.table.planner.codegen.OperatorCodeGenerator$ - Compiling OneInputStreamOperator Code:
StreamExecCalc
2021-04-15 17:47:50,321 DEBUG o.a.flink.table.planner.codegen.OperatorCodeGenerator$ - Compiling OneInputStreamOperator Code:
SinkConversion
2021-04-15 17:47:50,321 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
2021-04-15 17:47:50,321 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:47:50,321 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:47:50,321 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:47:50,322 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:47:50,322 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:47:50,343 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=4, name='SinkConversionToRow', outputType=Row(id: String, temperature: Double), parallelism=1}
2021-04-15 17:47:50,347 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=3, name='Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')])', outputType=ROW<`id` STRING, `temperature` DOUBLE>(org.apache.flink.table.data.RowData, org.apache.flink.table.runtime.typeutils.RowDataSerializer), parallelism=1}
2021-04-15 17:47:50,352 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=2, name='SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp])', outputType=ROW<`id` STRING, `temperature` DOUBLE, `timestamp` BIGINT>(org.apache.flink.table.data.RowData, org.apache.flink.table.runtime.typeutils.RowDataSerializer), parallelism=1}
2021-04-15 17:47:50,371 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySourceTransformation{id=1, name='sensor', outputType=PojoType<org.myorg.quickstart.dto.SensorReading, fields = [id: String, temperature: Double, timestamp: Long]>, parallelism=1}
2021-04-15 17:47:50,377 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 1
2021-04-15 17:47:50,378 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 2
2021-04-15 17:47:50,380 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 3
2021-04-15 17:47:50,381 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 4
2021-04-15 17:47:50,384 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySinkTransformation{id=5, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=1}
2021-04-15 17:47:50,385 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 5
2021-04-15 17:47:50,385 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=8, name='SinkConversionToRow', outputType=Row(id: String, temperature: Double), parallelism=1}
2021-04-15 17:47:50,385 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=7, name='Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')])', outputType=ROW<`id` STRING, `temperature` DOUBLE>(org.apache.flink.table.data.RowData, org.apache.flink.table.runtime.typeutils.RowDataSerializer), parallelism=1}
2021-04-15 17:47:50,385 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=6, name='SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp])', outputType=ROW<`id` STRING, `temperature` DOUBLE, `timestamp` BIGINT>(org.apache.flink.table.data.RowData, org.apache.flink.table.runtime.typeutils.RowDataSerializer), parallelism=1}
2021-04-15 17:47:50,385 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 6
2021-04-15 17:47:50,385 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 7
2021-04-15 17:47:50,386 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 8
2021-04-15 17:47:50,387 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySinkTransformation{id=9, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=1}
2021-04-15 17:47:50,387 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 9
2021-04-15 17:47:50,438 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'e3dfc0d7e9ecd8a43f85f0b68ebf3b80' for node 'Source: sensor-1' {id: 1, parallelism: 1, user function: org.myorg.quickstart.util.SourceUtil}
2021-04-15 17:47:50,438 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '7f13e76acd6ff9be99a3757408784a49' for node 'SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp])-2' {id: 2, parallelism: 1, user function: }
2021-04-15 17:47:50,438 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '0e90f93dd6c2bfc9de34a6a7c1979ccc' for node 'SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp])-6' {id: 6, parallelism: 1, user function: }
2021-04-15 17:47:50,438 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '0a46f19409cdd0f308853217632dc302' for node 'Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')])-3' {id: 3, parallelism: 1, user function: }
2021-04-15 17:47:50,438 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'c549952c0399ba9ed8a9b86f0ca78fd1' for node 'Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')])-7' {id: 7, parallelism: 1, user function: }
2021-04-15 17:47:50,438 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '46ba9b22862c3bbe9373c6abee964b2a' for node 'SinkConversionToRow-4' {id: 4, parallelism: 1, user function: }
2021-04-15 17:47:50,438 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '04897f5b0acd46127ed26e2af21c2bd1' for node 'SinkConversionToRow-8' {id: 8, parallelism: 1, user function: }
2021-04-15 17:47:50,438 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '018b8514c80198e54a547e60a27c4270' for node 'Sink: Print to Std. Out-5' {id: 5, parallelism: 1, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
2021-04-15 17:47:50,438 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'f04a552cc28bbc68559ce759344f5d02' for node 'Sink: Print to Std. Out-9' {id: 9, parallelism: 1, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
2021-04-15 17:47:50,499 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 1
2021-04-15 17:47:50,545 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.
2021-04-15 17:47:50,545 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.
2021-04-15 17:47:50,545 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.
2021-04-15 17:47:50,546 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.min required for local execution is not set, setting it to its default value 64 mb.
2021-04-15 17:47:50,546 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.max required for local execution is not set, setting it to its default value 64 mb.
2021-04-15 17:47:50,546 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.
2021-04-15 17:47:50,561 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting Flink Mini Cluster
2021-04-15 17:47:50,561 DEBUG org.apache.flink.runtime.minicluster.MiniCluster - Using configuration MiniClusterConfiguration {singleRpcService=SHARED, numTaskManagers=1, commonBindAddress='null', config={taskmanager.memory.network.min=64 mb, taskmanager.cpu.cores=1.7976931348623157E308, taskmanager.memory.task.off-heap.size=9223372036854775807 bytes, execution.target=local, rest.bind-port=0, taskmanager.memory.network.max=64 mb, execution.attached=true, taskmanager.memory.managed.size=128 mb, parallelism.default=4, taskmanager.numberOfTaskSlots=1, taskmanager.memory.task.heap.size=9223372036854775807 bytes, rest.address=localhost}}
2021-04-15 17:47:50,564 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting Metrics Registry
2021-04-15 17:47:50,636 INFO org.apache.flink.runtime.metrics.MetricRegistryImpl - No metrics reporter configured, no metrics will be exposed/reported.
2021-04-15 17:47:50,636 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting RPC Service(s)
2021-04-15 17:47:50,646 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
2021-04-15 17:47:50,661 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Using akka configuration
 Config(SimpleConfigObject({"akka":{"actor":{"default-dispatcher":{"executor":"fork-join-executor","fork-join-executor":{"parallelism-factor":1,"parallelism-max":4,"parallelism-min":2},"throughput":15},"guardian-supervisor-strategy":"org.apache.flink.runtime.akka.EscalatingSupervisorStrategy","supervisor-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"type":"Dispatcher"},"warn-about-java-serializer-usage":"off"},"daemonic":"off","jvm-exit-on-fatal-error":"on","log-config-on-start":"off","log-dead-letters":"off","log-dead-letters-during-shutdown":"off","logger-startup-timeout":"30s","loggers":["akka.event.slf4j.Slf4jLogger"],"logging-filter":"akka.event.slf4j.Slf4jLoggingFilter","loglevel":"DEBUG","serialize-messages":"off","stdout-loglevel":"OFF"}}))
2021-04-15 17:47:51,183 INFO akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2021-04-15 17:47:51,195 DEBUG akka.event.EventStream - logger log1-Slf4jLogger started
2021-04-15 17:47:51,198 DEBUG akka.event.EventStream - Default Loggers started
2021-04-15 17:47:51,539 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink
2021-04-15 17:47:51,566 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
2021-04-15 17:47:51,572 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Using akka configuration
 Config(SimpleConfigObject({"akka":{"actor":{"default-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"thread-priority":1,"throughput":15,"type":"akka.dispatch.PriorityThreadsDispatcher"},"guardian-supervisor-strategy":"org.apache.flink.runtime.akka.EscalatingSupervisorStrategy","supervisor-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"type":"Dispatcher"},"warn-about-java-serializer-usage":"off"},"daemonic":"off","jvm-exit-on-fatal-error":"on","log-config-on-start":"off","log-dead-letters":"off","log-dead-letters-during-shutdown":"off","logger-startup-timeout":"30s","loggers":["akka.event.slf4j.Slf4jLogger"],"logging-filter":"akka.event.slf4j.Slf4jLoggingFilter","loglevel":"DEBUG","serialize-messages":"off","stdout-loglevel":"OFF"}}))
2021-04-15 17:47:51,622 INFO akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2021-04-15 17:47:51,680 DEBUG akka.event.EventStream - logger log1-Slf4jLogger started
2021-04-15 17:47:51,680 DEBUG akka.event.EventStream - Default Loggers started
2021-04-15 17:47:51,726 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink-metrics
2021-04-15 17:47:51,757 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting AkkaRpcActor with name MetricQueryService.
2021-04-15 17:47:51,771 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
2021-04-15 17:47:51,896 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting high-availability services
2021-04-15 17:47:52,695 INFO org.apache.flink.runtime.blob.BlobServer - Created BLOB server storage directory C:\Users\ccy\AppData\Local\Temp\blobStore-15ed00b1-41e6-48da-bda7-6d5fa5a1af3c
2021-04-15 17:47:52,701 DEBUG org.apache.flink.util.NetUtils - Trying to open socket on port 0
2021-04-15 17:47:52,705 INFO org.apache.flink.runtime.blob.BlobServer - Started BLOB server at 0.0.0.0:62156 - max concurrent requests: 50 - max backlog: 1000
2021-04-15 17:47:52,709 INFO org.apache.flink.runtime.blob.PermanentBlobCache - Created BLOB cache storage directory C:\Users\ccy\AppData\Local\Temp\blobStore-8e2f690c-25c6-4813-844e-c3c6116099c8
2021-04-15 17:47:52,711 INFO org.apache.flink.runtime.blob.TransientBlobCache - Created BLOB cache storage directory C:\Users\ccy\AppData\Local\Temp\blobStore-dd1c74a3-f3b2-4fa5-8d13-d58fe4a74ae2
2021-04-15 17:47:52,712 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting 1 TaskManger(s)
2021-04-15 17:47:52,716 INFO org.apache.flink.runtime.taskexecutor.TaskManagerRunner - Starting TaskManager with ResourceID: 5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a
2021-04-15 17:47:52,750 INFO o.apache.flink.runtime.taskexecutor.TaskManagerServices - Temporary file directory 'C:\Users\ccy\AppData\Local\Temp': total 137 GB, usable 24 GB (17.52% usable)
2021-04-15 17:47:52,754 INFO org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\ccy\AppData\Local\Temp\flink-io-9a3dfb57-8378-45cf-8c3c-af3da52558bc for spill files.
2021-04-15 17:47:52,762 INFO org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\ccy\AppData\Local\Temp\flink-netty-shuffle-f31a2b31-f2e9-4d53-9e4f-8a018e322f98 for spill files.
2021-04-15 17:47:52,815 INFO o.a.flink.runtime.io.network.buffer.NetworkBufferPool - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2021-04-15 17:47:52,824 INFO o.a.flink.runtime.io.network.NettyShuffleEnvironment - Starting the network environment and its components.
2021-04-15 17:47:52,824 DEBUG o.a.flink.runtime.io.network.NettyShuffleEnvironment - Starting network connection manager
2021-04-15 17:47:52,825 INFO org.apache.flink.runtime.taskexecutor.KvStateService - Starting the kvState service and its components.
2021-04-15 17:47:52,836 DEBUG o.a.flink.runtime.taskexecutor.TaskManagerConfiguration - Messages have a max timeout of 10000 ms
2021-04-15 17:47:52,848 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting AkkaRpcActor with name taskmanager_0.
2021-04-15 17:47:52,849 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2021-04-15 17:47:52,866 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Start job leader service.
2021-04-15 17:47:52,869 INFO org.apache.flink.runtime.filecache.FileCache - User file cache uses directory C:\Users\ccy\AppData\Local\Temp\flink-dist-cache-21c51a01-4022-4f39-a388-0f5b581b5652
2021-04-15 17:47:52,896 DEBUG o.a.f.r.e.c.DefaultDispatcherResourceManagerComponentFactory - Starting Dispatcher REST endpoint.
2021-04-15 17:47:52,896 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Starting rest endpoint.
2021-04-15 17:47:52,903 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Failed to load web based job submission extension.
org.apache.flink.util.FlinkException: The module flink-runtime-web could not be found in the class path. Please add this jar in order to enable web based job submission.
	at org.apache.flink.runtime.webmonitor.WebMonitorUtils.loadWebSubmissionExtension(WebMonitorUtils.java:199) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint.initializeWebSubmissionHandlers(DispatcherRestEndpoint.java:112) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.webmonitor.WebMonitorEndpoint.initializeHandlers(WebMonitorEndpoint.java:228) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint.initializeHandlers(DispatcherRestEndpoint.java:89) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:144) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:172) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:463) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:422) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:366) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.program.PerJobMiniClusterFactory.submitJob(PerJobMiniClusterFactory.java:75) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:85) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1905) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1796) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:69) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1782) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1765) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.myorg.quickstart.other.FTable.BaseUsage.main(BaseUsage.java:43) ~[classes/:na]
2021-04-15 17:47:53,156 DEBUG o.a.f.s.n.i.n.u.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
2021-04-15 17:47:53,157 DEBUG o.a.f.s.n.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2021-04-15 17:47:53,157 DEBUG o.a.f.s.n.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2021-04-15 17:47:53,254 WARN org.apache.flink.runtime.webmonitor.WebMonitorUtils - Log file environment variable 'log.file' is not set.
2021-04-15 17:47:53,254 WARN org.apache.flink.runtime.webmonitor.WebMonitorUtils - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'web.log.path'.
2021-04-15 17:47:53,289 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - Platform: Windows
2021-04-15 17:47:53,290 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
2021-04-15 17:47:53,290 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - Java version: 11
2021-04-15 17:47:53,291 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
2021-04-15 17:47:53,292 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
2021-04-15 17:47:53,292 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
2021-04-15 17:47:53,293 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: unavailable
java.lang.UnsupportedOperationException: Reflective setAccessible(true) disabled
	at org.apache.flink.shaded.netty4.io.netty.util.internal.ReflectionUtil.trySetAccessible(ReflectionUtil.java:31) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0$4.run(PlatformDependent0.java:233) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at java.base/java.security.AccessController.doPrivileged(Native Method) ~[na:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:227) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.isAndroid(PlatformDependent.java:289) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:92) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:223) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:210) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.cached(AsciiString.java:1401) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<clinit>(AsciiString.java:48) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<init>(HttpMethod.java:135) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<clinit>(HttpMethod.java:36) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.runtime.rest.HttpMethodWrapper.<clinit>(HttpMethodWrapper.java:27) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.messages.cluster.ShutdownHeaders.getHttpMethod(ShutdownHeaders.java:57) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.checkAllEndpointsAndHandlersAreUnique(RestServerEndpoint.java:572) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:155) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:172) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:463) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:422) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:366) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.program.PerJobMiniClusterFactory.submitJob(PerJobMiniClusterFactory.java:75) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:85) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1905) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1796) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:69) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1782) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1765) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.myorg.quickstart.other.FTable.BaseUsage.main(BaseUsage.java:43) ~[classes/:na]
2021-04-15 17:47:53,294 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
2021-04-15 17:47:53,296 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable
java.lang.IllegalAccessException: class org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0$6 cannot access class jdk.internal.misc.Unsafe (in module java.base) because module java.base does not export jdk.internal.misc to unnamed module @4e52d2f2
	at java.base/jdk.internal.reflect.Reflection.newIllegalAccessException(Reflection.java:361) ~[na:na]
	at java.base/java.lang.reflect.AccessibleObject.checkAccess(AccessibleObject.java:591) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:558) ~[na:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0$6.run(PlatformDependent0.java:347) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at java.base/java.security.AccessController.doPrivileged(Native Method) ~[na:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:338) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.isAndroid(PlatformDependent.java:289) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:92) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:223) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:210) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.cached(AsciiString.java:1401) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<clinit>(AsciiString.java:48) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<init>(HttpMethod.java:135) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<clinit>(HttpMethod.java:36) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.runtime.rest.HttpMethodWrapper.<clinit>(HttpMethodWrapper.java:27) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.messages.cluster.ShutdownHeaders.getHttpMethod(ShutdownHeaders.java:57) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.checkAllEndpointsAndHandlersAreUnique(RestServerEndpoint.java:572) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:155) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:172) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:463) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:422) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:366) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.program.PerJobMiniClusterFactory.submitJob(PerJobMiniClusterFactory.java:75) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:85) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1905) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1796) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:69) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1782) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1765) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.myorg.quickstart.other.FTable.BaseUsage.main(BaseUsage.java:43) ~[classes/:na]
2021-04-15 17:47:53,297 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): unavailable
2021-04-15 17:47:53,297 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
2021-04-15 17:47:53,297 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - maxDirectMemory: 2122317824 bytes (maybe)
2021-04-15 17:47:53,298 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\ccy\AppData\Local\Temp (java.io.tmpdir)
2021-04-15 17:47:53,298 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
2021-04-15 17:47:53,298 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: -1 bytes
2021-04-15 17:47:53,298 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
2021-04-15 17:47:53,300 DEBUG o.a.f.shaded.netty4.io.netty.util.internal.CleanerJava9 - java.nio.ByteBuffer.cleaner(): available
2021-04-15 17:47:53,300 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
2021-04-15 17:47:53,306 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@42d96745 under DELETE@/v1/cluster.
2021-04-15 17:47:53,308 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@42d96745 under DELETE@/cluster.
2021-04-15 17:47:53,309 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@74159dc9 under GET@/v1/config.
2021-04-15 17:47:53,309 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@74159dc9 under GET@/config.
2021-04-15 17:47:53,309 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetListHandler@53086bdc under GET@/v1/datasets.
2021-04-15 17:47:53,309 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetListHandler@53086bdc under GET@/datasets.
2021-04-15 17:47:53,309 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteStatusHandler@254210b1 under GET@/v1/datasets/delete/:triggerid.
2021-04-15 17:47:53,309 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteStatusHandler@254210b1 under GET@/datasets/delete/:triggerid.
2021-04-15 17:47:53,309 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteTriggerHandler@600a1270 under DELETE@/v1/datasets/:datasetid.
2021-04-15 17:47:53,309 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteTriggerHandler@600a1270 under DELETE@/datasets/:datasetid.
2021-04-15 17:47:53,309 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@3829306d under GET@/v1/jobmanager/config.
2021-04-15 17:47:53,309 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@3829306d under GET@/jobmanager/config.
2021-04-15 17:47:53,309 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@28effa3f under GET@/v1/jobmanager/log.
2021-04-15 17:47:53,309 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@28effa3f under GET@/jobmanager/log.
2021-04-15 17:47:53,309 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogListHandler@1d1da00b under GET@/v1/jobmanager/logs.
2021-04-15 17:47:53,309 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogListHandler@1d1da00b under GET@/jobmanager/logs.
2021-04-15 17:47:53,309 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerCustomLogHandler@2db4a84a under GET@/v1/jobmanager/logs/:filename.
2021-04-15 17:47:53,309 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerCustomLogHandler@2db4a84a under GET@/jobmanager/logs/:filename.
2021-04-15 17:47:53,309 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@5cef5fc9 under GET@/v1/jobmanager/metrics.
2021-04-15 17:47:53,310 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@5cef5fc9 under GET@/jobmanager/metrics.
2021-04-15 17:47:53,310 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@b867869 under GET@/v1/jobmanager/stdout.
2021-04-15 17:47:53,310 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@b867869 under GET@/jobmanager/stdout.
2021-04-15 17:47:53,310 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@7b6b8cea under GET@/v1/jobs.
2021-04-15 17:47:53,310 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@7b6b8cea under GET@/jobs.
2021-04-15 17:47:53,310 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@73158d35 under POST@/v1/jobs.
2021-04-15 17:47:53,310 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@73158d35 under POST@/jobs.
2021-04-15 17:47:53,315 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@55a29589 under GET@/v1/jobs/metrics.
2021-04-15 17:47:53,315 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@55a29589 under GET@/jobs/metrics.
2021-04-15 17:47:53,316 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@6d5fea64 under GET@/v1/jobs/overview.
2021-04-15 17:47:53,316 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@6d5fea64 under GET@/jobs/overview.
2021-04-15 17:47:53,316 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@4a7427f9 under GET@/v1/jobs/:jobid.
2021-04-15 17:47:53,316 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@4a7427f9 under GET@/jobs/:jobid.
2021-04-15 17:47:53,316 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@155767a7 under PATCH@/v1/jobs/:jobid.
2021-04-15 17:47:53,316 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@155767a7 under PATCH@/jobs/:jobid.
2021-04-15 17:47:53,316 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@5418a659 under GET@/v1/jobs/:jobid/accumulators.
2021-04-15 17:47:53,316 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@5418a659 under GET@/jobs/:jobid/accumulators.
2021-04-15 17:47:53,316 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@46067a74 under GET@/v1/jobs/:jobid/checkpoints.
2021-04-15 17:47:53,316 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@46067a74 under GET@/jobs/:jobid/checkpoints.
2021-04-15 17:47:53,316 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@2d26c6a2 under GET@/v1/jobs/:jobid/checkpoints/config.
2021-04-15 17:47:53,316 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@2d26c6a2 under GET@/jobs/:jobid/checkpoints/config.
2021-04-15 17:47:53,316 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@362e6fe under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid.
2021-04-15 17:47:53,316 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@362e6fe under GET@/jobs/:jobid/checkpoints/details/:checkpointid.
2021-04-15 17:47:53,316 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@1259b2a5 under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
2021-04-15 17:47:53,316 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@1259b2a5 under GET@/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
2021-04-15 17:47:53,317 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@6779af40 under GET@/v1/jobs/:jobid/config.
2021-04-15 17:47:53,317 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@6779af40 under GET@/jobs/:jobid/config.
2021-04-15 17:47:53,317 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.coordination.ClientCoordinationHandler@7cf166db under POST@/v1/jobs/:jobid/coordinators/:operatorid.
2021-04-15 17:47:53,317 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.coordination.ClientCoordinationHandler@7cf166db under POST@/jobs/:jobid/coordinators/:operatorid.
2021-04-15 17:47:53,317 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@68303aad under GET@/v1/jobs/:jobid/exceptions.
2021-04-15 17:47:53,317 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@68303aad under GET@/jobs/:jobid/exceptions.
2021-04-15 17:47:53,317 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@37a36194 under GET@/v1/jobs/:jobid/execution-result.
2021-04-15 17:47:53,317 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@37a36194 under GET@/jobs/:jobid/execution-result.
2021-04-15 17:47:53,317 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@1d0acb8f under GET@/v1/jobs/:jobid/metrics.
2021-04-15 17:47:53,317 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@1d0acb8f under GET@/jobs/:jobid/metrics.
2021-04-15 17:47:53,317 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@6abaa14b under GET@/v1/jobs/:jobid/plan.
2021-04-15 17:47:53,317 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@6abaa14b under GET@/jobs/:jobid/plan.
2021-04-15 17:47:53,317 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@3b60be3 under PATCH@/v1/jobs/:jobid/rescaling.
2021-04-15 17:47:53,317 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@3b60be3 under PATCH@/jobs/:jobid/rescaling.
2021-04-15 17:47:53,317 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@2f3565c0 under GET@/v1/jobs/:jobid/rescaling/:triggerid.
2021-04-15 17:47:53,317 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@2f3565c0 under GET@/jobs/:jobid/rescaling/:triggerid.
2021-04-15 17:47:53,317 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@64a8851a under POST@/v1/jobs/:jobid/savepoints.
2021-04-15 17:47:53,317 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@64a8851a under POST@/jobs/:jobid/savepoints.
2021-04-15 17:47:53,317 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@5b27d03d under GET@/v1/jobs/:jobid/savepoints/:triggerid.
2021-04-15 17:47:53,317 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@5b27d03d under GET@/jobs/:jobid/savepoints/:triggerid.
2021-04-15 17:47:53,318 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@687d31a9 under POST@/v1/jobs/:jobid/stop.
2021-04-15 17:47:53,318 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@687d31a9 under POST@/jobs/:jobid/stop.
2021-04-15 17:47:53,318 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@6ce24203 under GET@/v1/jobs/:jobid/vertices/:vertexid.
2021-04-15 17:47:53,318 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@6ce24203 under GET@/jobs/:jobid/vertices/:vertexid.
2021-04-15 17:47:53,318 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@4cc28ad0 under GET@/v1/jobs/:jobid/vertices/:vertexid/accumulators.
2021-04-15 17:47:53,318 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@4cc28ad0 under GET@/jobs/:jobid/vertices/:vertexid/accumulators.
2021-04-15 17:47:53,318 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@29811d4d under GET@/v1/jobs/:jobid/vertices/:vertexid/backpressure.
2021-04-15 17:47:53,318 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@29811d4d under GET@/jobs/:jobid/vertices/:vertexid/backpressure.
2021-04-15 17:47:53,318 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@28f081ad under GET@/v1/jobs/:jobid/vertices/:vertexid/metrics.
2021-04-15 17:47:53,318 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@28f081ad under GET@/jobs/:jobid/vertices/:vertexid/metrics.
2021-04-15 17:47:53,318 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@56fc2cea under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
2021-04-15 17:47:53,318 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@56fc2cea under GET@/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
2021-04-15 17:47:53,318 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@e30a8ef under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
2021-04-15 17:47:53,318 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@e30a8ef under GET@/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
2021-04-15 17:47:53,318 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@2ffaa711 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
2021-04-15 17:47:53,318 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@2ffaa711 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
2021-04-15 17:47:53,318 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@3abb6aa under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
2021-04-15 17:47:53,318 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@3abb6aa under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
2021-04-15 17:47:53,318 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@34074149 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
2021-04-15 17:47:53,318 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@34074149 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
2021-04-15 17:47:53,318 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@3f7bf0f6 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
2021-04-15 17:47:53,318 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@3f7bf0f6 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
2021-04-15 17:47:53,318 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@45430a27 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasktimes.
2021-04-15 17:47:53,318 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@45430a27 under GET@/jobs/:jobid/vertices/:vertexid/subtasktimes.
2021-04-15 17:47:53,319 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@1b83fac3 under GET@/v1/jobs/:jobid/vertices/:vertexid/taskmanagers.
2021-04-15 17:47:53,319 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@1b83fac3 under GET@/jobs/:jobid/vertices/:vertexid/taskmanagers.
2021-04-15 17:47:53,319 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@1500edf3 under GET@/v1/jobs/:jobid/vertices/:vertexid/watermarks.
2021-04-15 17:47:53,319 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@1500edf3 under GET@/jobs/:jobid/vertices/:vertexid/watermarks.
2021-04-15 17:47:53,319 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@759c53e5 under GET@/v1/jobs/:jobid/yarn-cancel.
2021-04-15 17:47:53,319 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@759c53e5 under GET@/jobs/:jobid/yarn-cancel.
2021-04-15 17:47:53,319 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@28d37d43 under GET@/v1/jobs/:jobid/yarn-stop.
2021-04-15 17:47:53,319 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@28d37d43 under GET@/jobs/:jobid/yarn-stop.
2021-04-15 17:47:53,319 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@2c02cf78 under GET@/v1/overview.
2021-04-15 17:47:53,319 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@2c02cf78 under GET@/overview.
2021-04-15 17:47:53,319 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@3e7fc07e under POST@/v1/savepoint-disposal.
2021-04-15 17:47:53,319 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@3e7fc07e under POST@/savepoint-disposal.
2021-04-15 17:47:53,319 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@29ebaf2f under GET@/v1/savepoint-disposal/:triggerid.
2021-04-15 17:47:53,319 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@29ebaf2f under GET@/savepoint-disposal/:triggerid.
2021-04-15 17:47:53,319 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@1a61f634 under GET@/v1/taskmanagers.
2021-04-15 17:47:53,319 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@1a61f634 under GET@/taskmanagers.
2021-04-15 17:47:53,319 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@20a2930f under GET@/v1/taskmanagers/metrics.
2021-04-15 17:47:53,319 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@20a2930f under GET@/taskmanagers/metrics.
2021-04-15 17:47:53,319 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@609edb55 under GET@/v1/taskmanagers/:taskmanagerid.
2021-04-15 17:47:53,319 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@609edb55 under GET@/taskmanagers/:taskmanagerid.
2021-04-15 17:47:53,319 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@147892be under GET@/v1/taskmanagers/:taskmanagerid/log.
2021-04-15 17:47:53,319 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@147892be under GET@/taskmanagers/:taskmanagerid/log.
2021-04-15 17:47:53,319 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogListHandler@13d1653 under GET@/v1/taskmanagers/:taskmanagerid/logs.
2021-04-15 17:47:53,320 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogListHandler@13d1653 under GET@/taskmanagers/:taskmanagerid/logs.
2021-04-15 17:47:53,320 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerCustomLogHandler@3533d790 under GET@/v1/taskmanagers/:taskmanagerid/logs/:filename.
2021-04-15 17:47:53,320 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerCustomLogHandler@3533d790 under GET@/taskmanagers/:taskmanagerid/logs/:filename.
2021-04-15 17:47:53,320 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@23e1f610 under GET@/v1/taskmanagers/:taskmanagerid/metrics.
2021-04-15 17:47:53,320 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@23e1f610 under GET@/taskmanagers/:taskmanagerid/metrics.
2021-04-15 17:47:53,320 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@73dc7db0 under GET@/v1/taskmanagers/:taskmanagerid/stdout.
2021-04-15 17:47:53,320 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@73dc7db0 under GET@/taskmanagers/:taskmanagerid/stdout.
2021-04-15 17:47:53,320 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerThreadDumpHandler@1a3a6216 under GET@/v1/taskmanagers/:taskmanagerid/thread-dump.
2021-04-15 17:47:53,320 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerThreadDumpHandler@1a3a6216 under GET@/taskmanagers/:taskmanagerid/thread-dump.
2021-04-15 17:47:53,327 DEBUG o.a.f.s.n.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 8
2021-04-15 17:47:53,361 DEBUG o.a.f.shaded.netty4.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
2021-04-15 17:47:53,361 DEBUG o.a.f.shaded.netty4.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
2021-04-15 17:47:53,371 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
2021-04-15 17:47:53,426 DEBUG o.a.f.shaded.netty4.io.netty.channel.DefaultChannelId - -Dio.netty.processId: 896 (auto-detected)
2021-04-15 17:47:53,430 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
2021-04-15 17:47:53,430 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
2021-04-15 17:47:54,170 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
2021-04-15 17:47:54,170 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
2021-04-15 17:47:54,906 DEBUG o.a.f.shaded.netty4.io.netty.channel.DefaultChannelId - -Dio.netty.machineId: 2c:6f:c9:ff:fe:1c:21:83 (auto-detected)
2021-04-15 17:47:54,919 DEBUG o.a.f.shaded.netty4.io.netty.util.ResourceLeakDetector - -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.level: simple
2021-04-15 17:47:54,919 DEBUG o.a.f.shaded.netty4.io.netty.util.ResourceLeakDetector - -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.targetRecords: 4
2021-04-15 17:47:54,943 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 8
2021-04-15 17:47:54,943 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 8
2021-04-15 17:47:54,944 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
2021-04-15 17:47:54,944 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 11
2021-04-15 17:47:54,944 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 16777216
2021-04-15 17:47:54,944 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.tinyCacheSize: 512
2021-04-15 17:47:54,944 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
2021-04-15 17:47:54,944 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
2021-04-15 17:47:54,944 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2021-04-15 17:47:54,944 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
2021-04-15 17:47:54,944 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2021-04-15 17:47:54,944 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: true
2021-04-15 17:47:54,944 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2021-04-15 17:47:54,951 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
2021-04-15 17:47:54,951 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 0
2021-04-15 17:47:54,951 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
2021-04-15 17:47:54,969 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Binding rest endpoint to null:0.
2021-04-15 17:47:54,969 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Rest endpoint listening at localhost:62175
2021-04-15 17:47:54,972 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender http://localhost:62175
2021-04-15 17:47:54,975 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - http://localhost:62175 was granted leadership with leaderSessionID=7a255107-86ee-4cf8-ac86-c4eaabfb5006
2021-04-15 17:47:54,975 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader http://localhost:62175 , session=7a255107-86ee-4cf8-ac86-c4eaabfb5006
2021-04-15 17:47:54,994 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting FencedAkkaRpcActor with name resourcemanager_1.
2021-04-15 17:47:54,995 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_1 .
2021-04-15 17:47:55,008 DEBUG o.a.f.r.e.c.DefaultDispatcherResourceManagerComponentFactory - Starting Dispatcher.
2021-04-15 17:47:55,012 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
2021-04-15 17:47:55,013 DEBUG o.a.f.r.e.c.DefaultDispatcherResourceManagerComponentFactory - Starting ResourceManager.
2021-04-15 17:47:55,013 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: StandaloneResourceManager
2021-04-15 17:47:55,014 DEBUG o.a.f.runtime.dispatcher.runner.DefaultDispatcherRunner - Create new DispatcherLeaderProcess with leader session id 5119a712-286f-4fc0-b8ad-08668df98117.
2021-04-15 17:47:55,017 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - ResourceManager akka://flink/user/rpc/resourcemanager_1 was granted leadership with fencing token a607e97a0a92a478011ff4d8364c448a
2021-04-15 17:47:55,020 INFO org.apache.flink.runtime.minicluster.MiniCluster - Flink Mini Cluster started successfully
2021-04-15 17:47:55,021 INFO o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Starting the SlotManager.
2021-04-15 17:47:55,021 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Start SessionDispatcherLeaderProcess.
2021-04-15 17:47:55,026 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:47:55,027 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Recover all persisted job graphs.
2021-04-15 17:47:55,027 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/resourcemanager_1 , session=011ff4d8-364c-448a-a607-e97a0a92a478
2021-04-15 17:47:55,027 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:47:55,027 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Successfully recovered 0 persisted job graphs.
2021-04-15 17:47:55,028 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(a607e97a0a92a478011ff4d8364c448a).
2021-04-15 17:47:55,029 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:47:55,034 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:47:55,034 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting FencedAkkaRpcActor with name dispatcher_2.
2021-04-15 17:47:55,035 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_2 .
2021-04-15 17:47:55,036 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:47:55,051 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/dispatcher_2 , session=5119a712-286f-4fc0-b8ad-08668df98117
2021-04-15 17:47:55,054 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/dispatcher_2. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
2021-04-15 17:47:55,054 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/dispatcher_2. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
2021-04-15 17:47:55,058 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Resolved ResourceManager address, beginning registration
2021-04-15 17:47:55,058 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Registration at ResourceManager attempt 1 (timeout=100ms)
2021-04-15 17:47:55,061 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
2021-04-15 17:47:55,069 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Registering TaskManager with ResourceID 5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a (akka://flink/user/rpc/taskmanager_0) at ResourceManager
2021-04-15 17:47:55,071 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Successful registration at resource manager akka://flink/user/rpc/resourcemanager_1 under registration id ac7079ac47190b446ae32d1fc137f041.
2021-04-15 17:47:55,071 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Received JobGraph submission 11c7936231289f72fb545cb0fe73e5d0 (Flink Streaming Job).
2021-04-15 17:47:55,072 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Submitting job 11c7936231289f72fb545cb0fe73e5d0 (Flink Streaming Job).
2021-04-15 17:47:55,074 DEBUG o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Registering TaskManager 5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a under ac7079ac47190b446ae32d1fc137f041 at the SlotManager.
2021-04-15 17:47:55,084 DEBUG org.apache.flink.client.ClientUtils - Wait until job initialization is finished
2021-04-15 17:47:55,090 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: JobManagerRunnerImpl
2021-04-15 17:47:55,096 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting FencedAkkaRpcActor with name jobmanager_3.
2021-04-15 17:47:55,096 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
2021-04-15 17:47:55,105 INFO org.apache.flink.runtime.jobmaster.JobMaster - Initializing job Flink Streaming Job (11c7936231289f72fb545cb0fe73e5d0).
2021-04-15 17:47:55,120 INFO org.apache.flink.runtime.jobmaster.JobMaster - Using restart back off time strategy NoRestartBackoffTimeStrategy for Flink Streaming Job (11c7936231289f72fb545cb0fe73e5d0).
2021-04-15 17:47:55,150 INFO org.apache.flink.runtime.jobmaster.JobMaster - Running initialization on master for job Flink Streaming Job (11c7936231289f72fb545cb0fe73e5d0).
2021-04-15 17:47:55,150 INFO org.apache.flink.runtime.jobmaster.JobMaster - Successfully ran initialization on master in 0 ms.
2021-04-15 17:47:55,150 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Adding 1 vertices from job graph Flink Streaming Job (11c7936231289f72fb545cb0fe73e5d0).
2021-04-15 17:47:55,150 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Attaching 1 topologically sorted vertices to existing job graph with 0 vertices and 0 intermediate results.
2021-04-15 17:47:55,158 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex e3dfc0d7e9ecd8a43f85f0b68ebf3b80 (Source: sensor -> (SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out, SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out)) to 0 predecessors.
2021-04-15 17:47:55,163 INFO o.a.f.r.scheduler.adapter.DefaultExecutionTopology - Built 1 pipelined regions in 0 ms
2021-04-15 17:47:55,164 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Successfully created execution graph from job graph Flink Streaming Job (11c7936231289f72fb545cb0fe73e5d0).
2021-04-15 17:47:55,176 INFO org.apache.flink.runtime.jobmaster.JobMaster - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:47:55,191 DEBUG o.apache.flink.runtime.checkpoint.CheckpointCoordinator - Status of the shared state registry of job 11c7936231289f72fb545cb0fe73e5d0 after restore: SharedStateRegistry{registeredStates={}}.
2021-04-15 17:47:55,191 INFO o.apache.flink.runtime.checkpoint.CheckpointCoordinator - No checkpoint found during restore.
2021-04-15 17:47:55,194 INFO org.apache.flink.runtime.jobmaster.JobMaster - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@13f3696f for Flink Streaming Job (11c7936231289f72fb545cb0fe73e5d0).
2021-04-15 17:47:55,208 INFO org.apache.flink.runtime.jobmaster.JobManagerRunnerImpl - JobManager runner for job Flink Streaming Job (11c7936231289f72fb545cb0fe73e5d0) was granted leadership with session id 5e7d2fee-355d-4268-8759-7ec1f766f6ca at akka://flink/user/rpc/jobmanager_3.
2021-04-15 17:47:55,212 INFO org.apache.flink.runtime.jobmaster.JobMaster - Starting execution of job Flink Streaming Job (11c7936231289f72fb545cb0fe73e5d0) under job master id 87597ec1f766f6ca5e7d2fee355d4268.
2021-04-15 17:47:55,215 INFO org.apache.flink.runtime.jobmaster.JobMaster - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2021-04-15 17:47:55,215 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Job Flink Streaming Job (11c7936231289f72fb545cb0fe73e5d0) switched from state CREATED to RUNNING.
2021-04-15 17:47:55,221 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: sensor -> (SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out, SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out) (1/1) (47ae772326b89f44a261661a25d9a725) switched from CREATED to SCHEDULED.
2021-04-15 17:47:55,235 DEBUG o.a.f.r.jobmaster.slotpool.PhysicalSlotProviderImpl - Received slot request [SlotRequestId{f8b6d8113fe5c4ca63271eea1235d67d}] with resource requirements: ResourceProfile{UNKNOWN}
2021-04-15 17:47:55,238 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f8b6d8113fe5c4ca63271eea1235d67d}]
2021-04-15 17:47:55,240 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{5bab990165ee1a029a49ecdadb1b46af}) for execution vertex (id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0) from the physical slot (SlotRequestId{f8b6d8113fe5c4ca63271eea1235d67d})
2021-04-15 17:47:55,251 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
2021-04-15 17:47:55,252 INFO org.apache.flink.runtime.jobmaster.JobMaster - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(a607e97a0a92a478011ff4d8364c448a)
2021-04-15 17:47:55,253 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:47:55,253 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/jobmanager_3 , session=5e7d2fee-355d-4268-8759-7ec1f766f6ca
2021-04-15 17:47:55,255 INFO org.apache.flink.runtime.jobmaster.JobMaster - Resolved ResourceManager address, beginning registration
2021-04-15 17:47:55,255 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Registration at ResourceManager attempt 1 (timeout=100ms)
2021-04-15 17:47:55,255 DEBUG o.a.flink.runtime.resourcemanager.JobLeaderIdService - Add job 11c7936231289f72fb545cb0fe73e5d0 to job leader id monitoring.
2021-04-15 17:47:55,256 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Registering job manager 87597ec1f766f6ca5e7d2fee355d4268@akka://flink/user/rpc/jobmanager_3 for job 11c7936231289f72fb545cb0fe73e5d0.
2021-04-15 17:47:55,257 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/jobmanager_3. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2021-04-15 17:47:55,264 DEBUG o.a.flink.runtime.resourcemanager.JobLeaderIdService - Found a new job leader 5e7d2fee-355d-4268-8759-7ec1f766f6ca@akka://flink/user/rpc/jobmanager_3.
2021-04-15 17:47:55,271 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Registered job manager 87597ec1f766f6ca5e7d2fee355d4268@akka://flink/user/rpc/jobmanager_3 for job 11c7936231289f72fb545cb0fe73e5d0.
2021-04-15 17:47:55,274 INFO org.apache.flink.runtime.jobmaster.JobMaster - JobManager successfully registered at ResourceManager, leader id: a607e97a0a92a478011ff4d8364c448a.
2021-04-15 17:47:55,276 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{f8b6d8113fe5c4ca63271eea1235d67d}] and profile ResourceProfile{UNKNOWN} with allocation id 13209eebdd131355d765ef0279924883 from resource manager.
2021-04-15 17:47:55,277 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 11c7936231289f72fb545cb0fe73e5d0 with allocation id 13209eebdd131355d765ef0279924883.
2021-04-15 17:47:55,281 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 13209eebdd131355d765ef0279924883 for job 11c7936231289f72fb545cb0fe73e5d0 from resource manager with leader id a607e97a0a92a478011ff4d8364c448a.
2021-04-15 17:47:55,287 DEBUG org.apache.flink.runtime.memory.MemoryManager - Initialized MemoryManager with total memory size 134217728 and page size 32768.
2021-04-15 17:47:55,288 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 13209eebdd131355d765ef0279924883.
2021-04-15 17:47:55,289 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Add job 11c7936231289f72fb545cb0fe73e5d0 for job leader monitoring.
2021-04-15 17:47:55,292 DEBUG o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - New leader information for job 11c7936231289f72fb545cb0fe73e5d0. Address: akka://flink/user/rpc/jobmanager_3, leader id: 87597ec1f766f6ca5e7d2fee355d4268.
2021-04-15 17:47:55,293 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Try to register at job manager akka://flink/user/rpc/jobmanager_3 with leader id 5e7d2fee-355d-4268-8759-7ec1f766f6ca.
2021-04-15 17:47:55,293 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/jobmanager_3. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2021-04-15 17:47:55,296 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Resolved JobManager address, beginning registration
2021-04-15 17:47:55,296 DEBUG o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Registration at JobManager attempt 1 (timeout=100ms)
2021-04-15 17:47:55,300 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
2021-04-15 17:47:55,302 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Register new TaskExecutor 5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a.
2021-04-15 17:47:55,303 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Successful registration at job manager akka://flink/user/rpc/jobmanager_3 for job 11c7936231289f72fb545cb0fe73e5d0.
2021-04-15 17:47:55,304 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Establish JobManager connection for job 11c7936231289f72fb545cb0fe73e5d0.
2021-04-15 17:47:55,307 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Offer reserved slots to the leader of job 11c7936231289f72fb545cb0fe73e5d0.
2021-04-15 17:47:55,309 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Fulfilling pending slot request [SlotRequestId{f8b6d8113fe5c4ca63271eea1235d67d}] with slot [13209eebdd131355d765ef0279924883]
2021-04-15 17:47:55,310 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{5bab990165ee1a029a49ecdadb1b46af}) for execution vertex (id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0) from the physical slot (SlotRequestId{f8b6d8113fe5c4ca63271eea1235d67d})
2021-04-15 17:47:55,314 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: sensor -> (SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out, SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out) (1/1) (47ae772326b89f44a261661a25d9a725) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:47:55,315 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: sensor -> (SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out, SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out) (1/1) (attempt #0) with attempt id 47ae772326b89f44a261661a25d9a725 to 5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a @ server1 (dataPort=-1) with allocation id 13209eebdd131355d765ef0279924883
2021-04-15 17:47:55,324 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 13209eebdd131355d765ef0279924883.
2021-04-15 17:47:55,331 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new allocation id 13209eebdd131355d765ef0279924883 for local state stores for job 11c7936231289f72fb545cb0fe73e5d0.
2021-04-15 17:47:55,333 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_13209eebdd131355d765ef0279924883], jobID=11c7936231289f72fb545cb0fe73e5d0, jobVertexID=e3dfc0d7e9ecd8a43f85f0b68ebf3b80, subtaskIndex=0}} for 11c7936231289f72fb545cb0fe73e5d0 - e3dfc0d7e9ecd8a43f85f0b68ebf3b80 - 0 under allocation id 13209eebdd131355d765ef0279924883.
2021-04-15 17:47:55,346 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: sensor -> (SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out, SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out) (1/1)#0 (47ae772326b89f44a261661a25d9a725), deploy into slot with allocation id 13209eebdd131355d765ef0279924883.
2021-04-15 17:47:55,347 INFO org.apache.flink.runtime.taskmanager.Task - Source: sensor -> (SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out, SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out) (1/1)#0 (47ae772326b89f44a261661a25d9a725) switched from CREATED to DEPLOYING.
2021-04-15 17:47:55,347 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Source: sensor -> (SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out, SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out) (1/1)#0 (47ae772326b89f44a261661a25d9a725) [DEPLOYING]
2021-04-15 17:47:55,349 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 13209eebdd131355d765ef0279924883.
2021-04-15 17:47:55,352 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: sensor -> (SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out, SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out) (1/1)#0 (47ae772326b89f44a261661a25d9a725) [DEPLOYING].
2021-04-15 17:47:55,353 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 47ae772326b89f44a261661a25d9a725 at library cache manager took 0 milliseconds
2021-04-15 17:47:55,356 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: sensor -> (SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out, SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out) (1/1)#0 (47ae772326b89f44a261661a25d9a725) [DEPLOYING].
2021-04-15 17:47:55,367 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:47:55,373 INFO org.apache.flink.runtime.taskmanager.Task - Source: sensor -> (SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out, SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out) (1/1)#0 (47ae772326b89f44a261661a25d9a725) switched from DEPLOYING to RUNNING.
2021-04-15 17:47:55,374 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Source: sensor -> (SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out, SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out) (1/1)#0.
2021-04-15 17:47:55,374 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: sensor -> (SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out, SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out) (1/1) (47ae772326b89f44a261661a25d9a725) switched from DEPLOYING to RUNNING.
2021-04-15 17:47:55,400 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: SinkConversion$13 

 Code:

      public class SinkConversion$13 extends org.apache.flink.table.runtime.operators.TableStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.data.util.DataFormatConverters.RowConverter converter$12;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SinkConversion$13(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output,
            org.apache.flink.streaming.runtime.tasks.ProcessingTimeService processingTimeService) throws Exception {
          this.references = references;
          converter$12 = (((org.apache.flink.table.data.util.DataFormatConverters.RowConverter) references[0]));
          this.setup(task, config, output);
          if (this instanceof org.apache.flink.streaming.api.operators.AbstractStreamOperator) {
            ((org.apache.flink.streaming.api.operators.AbstractStreamOperator) this)
              .setProcessingTimeService(processingTimeService);
          }
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) element.getValue();
          
          
          
          
          
          output.collect(outElement.replace((org.apache.flink.types.Row) converter$12.toExternal((org.apache.flink.table.data.RowData) in1)));
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
2021-04-15 17:47:55,426 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: StreamExecCalc$11 

 Code:

      public class StreamExecCalc$11 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.runtime.typeutils.StringDataSerializer typeSerializer$5;
        
        private final org.apache.flink.table.data.binary.BinaryStringData str$7 = org.apache.flink.table.data.binary.BinaryStringData.fromString("sensor_1");
                   
        org.apache.flink.table.data.BoxedWrapperRowData out = new org.apache.flink.table.data.BoxedWrapperRowData(2);
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public StreamExecCalc$11(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output,
            org.apache.flink.streaming.runtime.tasks.ProcessingTimeService processingTimeService) throws Exception {
          this.references = references;
          typeSerializer$5 = (((org.apache.flink.table.runtime.typeutils.StringDataSerializer) references[0]));
          this.setup(task, config, output);
          if (this instanceof org.apache.flink.streaming.api.operators.AbstractStreamOperator) {
            ((org.apache.flink.streaming.api.operators.AbstractStreamOperator) this)
              .setProcessingTimeService(processingTimeService);
          }
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) element.getValue();
          
          org.apache.flink.table.data.binary.BinaryStringData field$4;
          boolean isNull$4;
          org.apache.flink.table.data.binary.BinaryStringData field$6;
          boolean isNull$8;
          boolean result$9;
          double field$10;
          boolean isNull$10;
          
          
          
          isNull$4 = in1.isNullAt(0);
          field$4 = org.apache.flink.table.data.binary.BinaryStringData.EMPTY_UTF8;
          if (!isNull$4) {
            field$4 = ((org.apache.flink.table.data.binary.BinaryStringData) in1.getString(0));
          }
          field$6 = field$4;
          if (!isNull$4) {
            field$6 = (org.apache.flink.table.data.binary.BinaryStringData) (typeSerializer$5.copy(field$6));
          }
                  
          
          
          
          isNull$8 = isNull$4 || false;
          result$9 = false;
          if (!isNull$8) {
            
            result$9 = field$6.equals(((org.apache.flink.table.data.binary.BinaryStringData) str$7));
            
          }
          
          if (result$9) {
            isNull$10 = in1.isNullAt(1);
          field$10 = -1.0d;
          if (!isNull$10) {
            field$10 = in1.getDouble(1);
          }
            
          out.setRowKind(in1.getRowKind());
          
          
          
          
          if (false) {
            out.setNullAt(0);
          } else {
            out.setNonPrimitiveValue(0, ((org.apache.flink.table.data.binary.BinaryStringData) str$7));
          }
                    
          
          
          if (isNull$10) {
            out.setNullAt(1);
          } else {
            out.setDouble(1, field$10);
          }
                    
                  
          output.collect(outElement.replace(out));
          
          }
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
2021-04-15 17:47:55,487 WARN org.apache.flink.metrics.MetricGroup - The operator name Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:47:55,500 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: SourceConversion$3 

 Code:

      public class SourceConversion$3 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.data.util.DataFormatConverters.PojoConverter converter$2;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SourceConversion$3(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output,
            org.apache.flink.streaming.runtime.tasks.ProcessingTimeService processingTimeService) throws Exception {
          this.references = references;
          converter$2 = (((org.apache.flink.table.data.util.DataFormatConverters.PojoConverter) references[0]));
          this.setup(task, config, output);
          if (this instanceof org.apache.flink.streaming.api.operators.AbstractStreamOperator) {
            ((org.apache.flink.streaming.api.operators.AbstractStreamOperator) this)
              .setProcessingTimeService(processingTimeService);
          }
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) (org.apache.flink.table.data.RowData) converter$2.toInternal((org.myorg.quickstart.dto.SensorReading) element.getValue());
          
          
          
          output.collect(outElement.replace(in1));
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
2021-04-15 17:47:55,512 WARN org.apache.flink.metrics.MetricGroup - The operator name SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:47:55,519 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: SinkConversion$33 

 Code:

      public class SinkConversion$33 extends org.apache.flink.table.runtime.operators.TableStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.data.util.DataFormatConverters.RowConverter converter$32;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SinkConversion$33(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output,
            org.apache.flink.streaming.runtime.tasks.ProcessingTimeService processingTimeService) throws Exception {
          this.references = references;
          converter$32 = (((org.apache.flink.table.data.util.DataFormatConverters.RowConverter) references[0]));
          this.setup(task, config, output);
          if (this instanceof org.apache.flink.streaming.api.operators.AbstractStreamOperator) {
            ((org.apache.flink.streaming.api.operators.AbstractStreamOperator) this)
              .setProcessingTimeService(processingTimeService);
          }
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) element.getValue();
          
          
          
          
          
          output.collect(outElement.replace((org.apache.flink.types.Row) converter$32.toExternal((org.apache.flink.table.data.RowData) in1)));
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
2021-04-15 17:47:55,531 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: StreamExecCalc$31 

 Code:

      public class StreamExecCalc$31 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.runtime.typeutils.StringDataSerializer typeSerializer$25;
        
        private final org.apache.flink.table.data.binary.BinaryStringData str$27 = org.apache.flink.table.data.binary.BinaryStringData.fromString("sensor_1");
                   
        org.apache.flink.table.data.BoxedWrapperRowData out = new org.apache.flink.table.data.BoxedWrapperRowData(2);
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public StreamExecCalc$31(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output,
            org.apache.flink.streaming.runtime.tasks.ProcessingTimeService processingTimeService) throws Exception {
          this.references = references;
          typeSerializer$25 = (((org.apache.flink.table.runtime.typeutils.StringDataSerializer) references[0]));
          this.setup(task, config, output);
          if (this instanceof org.apache.flink.streaming.api.operators.AbstractStreamOperator) {
            ((org.apache.flink.streaming.api.operators.AbstractStreamOperator) this)
              .setProcessingTimeService(processingTimeService);
          }
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) element.getValue();
          
          org.apache.flink.table.data.binary.BinaryStringData field$24;
          boolean isNull$24;
          org.apache.flink.table.data.binary.BinaryStringData field$26;
          boolean isNull$28;
          boolean result$29;
          double field$30;
          boolean isNull$30;
          
          
          
          isNull$24 = in1.isNullAt(0);
          field$24 = org.apache.flink.table.data.binary.BinaryStringData.EMPTY_UTF8;
          if (!isNull$24) {
            field$24 = ((org.apache.flink.table.data.binary.BinaryStringData) in1.getString(0));
          }
          field$26 = field$24;
          if (!isNull$24) {
            field$26 = (org.apache.flink.table.data.binary.BinaryStringData) (typeSerializer$25.copy(field$26));
          }
                  
          
          
          
          isNull$28 = isNull$24 || false;
          result$29 = false;
          if (!isNull$28) {
            
            result$29 = field$26.equals(((org.apache.flink.table.data.binary.BinaryStringData) str$27));
            
          }
          
          if (result$29) {
            isNull$30 = in1.isNullAt(1);
          field$30 = -1.0d;
          if (!isNull$30) {
            field$30 = in1.getDouble(1);
          }
            
          out.setRowKind(in1.getRowKind());
          
          
          
          
          if (false) {
            out.setNullAt(0);
          } else {
            out.setNonPrimitiveValue(0, ((org.apache.flink.table.data.binary.BinaryStringData) str$27));
          }
                    
          
          
          if (isNull$30) {
            out.setNullAt(1);
          } else {
            out.setDouble(1, field$30);
          }
                    
                  
          output.collect(outElement.replace(out));
          
          }
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
2021-04-15 17:47:55,544 WARN org.apache.flink.metrics.MetricGroup - The operator name Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:47:55,547 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: SourceConversion$23 

 Code:

      public class SourceConversion$23 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.data.util.DataFormatConverters.PojoConverter converter$22;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SourceConversion$23(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output,
            org.apache.flink.streaming.runtime.tasks.ProcessingTimeService processingTimeService) throws Exception {
          this.references = references;
          converter$22 = (((org.apache.flink.table.data.util.DataFormatConverters.PojoConverter) references[0]));
          this.setup(task, config, output);
          if (this instanceof org.apache.flink.streaming.api.operators.AbstractStreamOperator) {
            ((org.apache.flink.streaming.api.operators.AbstractStreamOperator) this)
              .setProcessingTimeService(processingTimeService);
          }
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) (org.apache.flink.table.data.RowData) converter$22.toInternal((org.myorg.quickstart.dto.SensorReading) element.getValue());
          
          
          
          output.collect(outElement.replace(in1));
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
2021-04-15 17:47:55,555 WARN org.apache.flink.metrics.MetricGroup - The operator name SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:47:55,558 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Source: sensor -> (SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out, SourceConversion(table=[Unregistered_DataStream_1], fields=[id, temperature, timestamp]) -> Calc(select=[CAST(_UTF-16LE'sensor_1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temperature], where=[(id = _UTF-16LE'sensor_1')]) -> SinkConversionToRow -> Sink: Print to Std. Out) (1/1)#0
2021-04-15 17:47:55,578 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_018b8514c80198e54a547e60a27c4270_(1/1) with empty state.
2021-04-15 17:47:55,596 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for SinkConversion$13_46ba9b22862c3bbe9373c6abee964b2a_(1/1) with empty state.
2021-04-15 17:47:55,596 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamExecCalc$11_0a46f19409cdd0f308853217632dc302_(1/1) with empty state.
2021-04-15 17:47:55,597 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for SourceConversion$3_7f13e76acd6ff9be99a3757408784a49_(1/1) with empty state.
2021-04-15 17:47:55,597 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_f04a552cc28bbc68559ce759344f5d02_(1/1) with empty state.
2021-04-15 17:47:55,597 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for SinkConversion$33_04897f5b0acd46127ed26e2af21c2bd1_(1/1) with empty state.
2021-04-15 17:47:55,597 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamExecCalc$31_c549952c0399ba9ed8a9b86f0ca78fd1_(1/1) with empty state.
2021-04-15 17:47:55,597 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for SourceConversion$23_0e90f93dd6c2bfc9de34a6a7c1979ccc_(1/1) with empty state.
2021-04-15 17:47:55,597 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSource_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_(1/1) with empty state.
2021-04-15 17:48:05,041 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:48:05,042 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:48:05,042 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat request from bc126d219592bf3100a9bf3e01f593bd.
2021-04-15 17:48:05,042 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from bc126d219592bf3100a9bf3e01f593bd.
2021-04-15 17:48:05,042 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from b53025fff2a14464e89a28ac8fb244d1.
2021-04-15 17:48:05,044 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a.
2021-04-15 17:48:05,044 DEBUG o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Received slot report from instance ac7079ac47190b446ae32d1fc137f041: SlotReport{SlotStatus{slotID=5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a_0, allocationID=13209eebdd131355d765ef0279924883, jobID=11c7936231289f72fb545cb0fe73e5d0, resourceProfile=ResourceProfile{managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}}}.
2021-04-15 17:48:05,046 DEBUG o.a.f.r.i.n.p.ResourceManagerPartitionTrackerImpl - Processing cluster partition report from task executor 5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a: PartitionReport{entries=[]}.
2021-04-15 17:48:05,271 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
2021-04-15 17:48:05,272 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from b53025fff2a14464e89a28ac8fb244d1.
2021-04-15 17:48:05,289 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat from 5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a.
2021-04-15 17:48:15,063 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:48:15,064 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:48:15,064 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from bc126d219592bf3100a9bf3e01f593bd.
2021-04-15 17:48:15,064 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat request from bc126d219592bf3100a9bf3e01f593bd.
2021-04-15 17:48:15,065 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from b53025fff2a14464e89a28ac8fb244d1.
2021-04-15 17:48:15,065 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a.
2021-04-15 17:48:15,065 DEBUG o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Received slot report from instance ac7079ac47190b446ae32d1fc137f041: SlotReport{SlotStatus{slotID=5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a_0, allocationID=13209eebdd131355d765ef0279924883, jobID=11c7936231289f72fb545cb0fe73e5d0, resourceProfile=ResourceProfile{managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}}}.
2021-04-15 17:48:15,066 DEBUG o.a.f.r.i.n.p.ResourceManagerPartitionTrackerImpl - Processing cluster partition report from task executor 5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a: PartitionReport{entries=[]}.
2021-04-15 17:48:15,290 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
2021-04-15 17:48:15,291 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from b53025fff2a14464e89a28ac8fb244d1.
2021-04-15 17:48:15,291 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat from 5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a.
2021-04-15 17:48:25,086 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:48:25,086 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:48:25,086 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat request from bc126d219592bf3100a9bf3e01f593bd.
2021-04-15 17:48:25,087 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from bc126d219592bf3100a9bf3e01f593bd.
2021-04-15 17:48:25,087 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from b53025fff2a14464e89a28ac8fb244d1.
2021-04-15 17:48:25,087 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a.
2021-04-15 17:48:25,088 DEBUG o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Received slot report from instance ac7079ac47190b446ae32d1fc137f041: SlotReport{SlotStatus{slotID=5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a_0, allocationID=13209eebdd131355d765ef0279924883, jobID=11c7936231289f72fb545cb0fe73e5d0, resourceProfile=ResourceProfile{managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}}}.
2021-04-15 17:48:25,089 DEBUG o.a.f.r.i.n.p.ResourceManagerPartitionTrackerImpl - Processing cluster partition report from task executor 5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a: PartitionReport{entries=[]}.
2021-04-15 17:48:25,311 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
2021-04-15 17:48:25,311 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from b53025fff2a14464e89a28ac8fb244d1.
2021-04-15 17:48:25,311 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat from 5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a.
2021-04-15 17:48:35,101 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:48:35,101 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:48:35,101 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from bc126d219592bf3100a9bf3e01f593bd.
2021-04-15 17:48:35,102 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a.
2021-04-15 17:48:35,102 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat request from bc126d219592bf3100a9bf3e01f593bd.
2021-04-15 17:48:35,102 DEBUG o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Received slot report from instance ac7079ac47190b446ae32d1fc137f041: SlotReport{SlotStatus{slotID=5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a_0, allocationID=13209eebdd131355d765ef0279924883, jobID=11c7936231289f72fb545cb0fe73e5d0, resourceProfile=ResourceProfile{managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}}}.
2021-04-15 17:48:35,102 DEBUG o.a.f.r.i.n.p.ResourceManagerPartitionTrackerImpl - Processing cluster partition report from task executor 5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a: PartitionReport{entries=[]}.
2021-04-15 17:48:35,103 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from b53025fff2a14464e89a28ac8fb244d1.
2021-04-15 17:48:35,333 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
2021-04-15 17:48:35,334 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from b53025fff2a14464e89a28ac8fb244d1.
2021-04-15 17:48:35,334 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat from 5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a.
2021-04-15 17:48:45,124 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:48:45,124 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:48:45,124 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from bc126d219592bf3100a9bf3e01f593bd.
2021-04-15 17:48:45,124 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat request from bc126d219592bf3100a9bf3e01f593bd.
2021-04-15 17:48:45,125 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from b53025fff2a14464e89a28ac8fb244d1.
2021-04-15 17:48:45,125 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a.
2021-04-15 17:48:45,125 DEBUG o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Received slot report from instance ac7079ac47190b446ae32d1fc137f041: SlotReport{SlotStatus{slotID=5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a_0, allocationID=13209eebdd131355d765ef0279924883, jobID=11c7936231289f72fb545cb0fe73e5d0, resourceProfile=ResourceProfile{managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}}}.
2021-04-15 17:48:45,125 DEBUG o.a.f.r.i.n.p.ResourceManagerPartitionTrackerImpl - Processing cluster partition report from task executor 5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a: PartitionReport{entries=[]}.
2021-04-15 17:48:45,355 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
2021-04-15 17:48:45,355 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from b53025fff2a14464e89a28ac8fb244d1.
2021-04-15 17:48:45,356 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat from 5bcb7e54-e7be-4ad6-9500-6bf81b4d7b7a.
2021-04-15 17:52:21,045 INFO org.apache.flink.api.java.typeutils.TypeExtractor - class org.apache.flink.types.Row is missing a default constructor so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2021-04-15 17:52:22,276 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:52:22,290 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:22,292 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:22,292 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#3:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#2,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:52:22,299 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:22,495 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert table references before rewriting sub-queries to semi-join cost 55 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:22,496 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:22,496 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:22,497 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#6:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#5,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:52:22,497 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:22,498 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize rewrite sub-queries to semi-join cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:22,498 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:22,499 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:22,499 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#9:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#8,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:52:22,499 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:22,500 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize sub-queries remove cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:22,500 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:22,500 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:22,501 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#12:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#11,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:52:22,501 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:22,501 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert table references after sub-queries removed cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:22,502 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize subquery_rewrite cost 228 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:22,502 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:52:22,503 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:22,504 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:22,504 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#15:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#14,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:52:22,504 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:22,505 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert correlate to temporal table join cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:22,506 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:22,506 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:22,506 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#18:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#17,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:52:22,506 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:22,507 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert enumerable table scan cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:22,508 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize temporal_join_rewrite cost 5 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:22,508 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:52:22,508 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:22,509 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:22,509 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#21:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#20,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:52:22,509 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:22,510 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize pre-rewrite before decorrelation cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:22,526 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize  cost 16 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:22,527 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize decorrelate cost 19 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:22,533 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize time_indicator cost 5 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:22,534 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:22,534 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:22,534 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#25:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#24,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:52:22,534 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:22,535 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize default_rewrite cost 1 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:22,535 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:52:22,536 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:22,537 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:22,537 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#28:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#27,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:52:22,537 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:22,537 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize filter rules cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:22,538 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:22,538 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:22,538 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#31:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#30,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:52:22,538 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:22,539 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize push predicate into table scan cost 0 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:22,539 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:22,539 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:22,539 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#34:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#33,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:52:22,540 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:22,541 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize prune empty after predicate push down cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:22,542 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize predicate_pushdown cost 6 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:22,707 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:22,707 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)] rels [#0]
2021-04-15 17:52:22,707 DEBUG org.apache.calcite.plan.RelOptPlanner - call#11: Apply rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)] to [rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])]
2021-04-15 17:52:22,710 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#41 via FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:22,791 DEBUG org.apache.calcite.plan.RelOptPlanner - call#11 generated 1 successors: [rel#41:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:52:22,798 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:22,798 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)] rels [#37]
2021-04-15 17:52:22,798 DEBUG org.apache.calcite.plan.RelOptPlanner - call#20: Apply rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)] to [rel#37:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#36,name=DataStreamTableSink,fields=id, timestamp, temp)]
2021-04-15 17:52:22,799 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#43 via FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:22,834 DEBUG org.apache.calcite.plan.RelOptPlanner - call#20 generated 1 successors: [rel#43:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#42,name=DataStreamTableSink,fields=id, timestamp, temp)]
2021-04-15 17:52:22,834 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0E8 rows, 2.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:22,838 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for VolcanoPlanner
2021-04-15 17:52:22,839 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)                   1              83,735
FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)                           1              34,998
* Total                                                                        2             118,733

2021-04-15 17:52:22,871 DEBUG org.apache.calcite.plan.RelOptPlanner - Cheapest plan:
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp]): rowcount = 1.0E8, cumulative cost = {2.0E8 rows, 2.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 44
  FlinkLogicalLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 41

2021-04-15 17:52:22,874 DEBUG org.apache.calcite.plan.RelOptPlanner - Provenance:
rel#44:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=FlinkLogicalLegacyTableSourceScan#41,name=DataStreamTableSink,fields=id, timestamp, temp)
  direct
    rel#43:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#42,name=DataStreamTableSink,fields=id, timestamp, temp)
      call#20 rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)]
        rel#37:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#36,name=DataStreamTableSink,fields=id, timestamp, temp)
          no parent
rel#41:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
  call#11 rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)]
    rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
      no parent

2021-04-15 17:52:22,875 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize logical cost 332 ms.
optimize result: 
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- FlinkLogicalLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:52:22,876 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:22,876 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:22,876 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#46:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#45,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:52:22,876 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#41:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
2021-04-15 17:52:22,877 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize logical_rewrite cost 2 ms.
optimize result: 
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- FlinkLogicalLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:52:22,886 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:22,886 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#41]
2021-04-15 17:52:22,886 DEBUG org.apache.calcite.plan.RelOptPlanner - call#38: Apply rule [StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#41:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:52:22,890 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#53 via StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:52:22,943 DEBUG org.apache.calcite.plan.RelOptPlanner - call#38 generated 1 successors: [rel#53:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:52:22,943 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:22,943 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#49]
2021-04-15 17:52:22,943 DEBUG org.apache.calcite.plan.RelOptPlanner - call#55: Apply rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#49:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#48,name=DataStreamTableSink,fields=id, timestamp, temp)]
2021-04-15 17:52:22,947 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#55 via StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:52:22,976 DEBUG org.apache.calcite.plan.RelOptPlanner - call#55 generated 1 successors: [rel#55:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#54,name=DataStreamTableSink,fields=id, timestamp, temp)]
2021-04-15 17:52:22,976 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0E8 rows, 2.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:22,976 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for VolcanoPlanner
2021-04-15 17:52:22,977 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)                   1              83,735
StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)                   1              56,702
FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)                           1              34,998
StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)                       1              32,924
* Total                                                                        4             208,359

2021-04-15 17:52:23,001 DEBUG org.apache.calcite.plan.RelOptPlanner - Cheapest plan:
StreamExecLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp]): rowcount = 1.0E8, cumulative cost = {2.0E8 rows, 2.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 56
  StreamExecLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 53

2021-04-15 17:52:23,001 DEBUG org.apache.calcite.plan.RelOptPlanner - Provenance:
rel#56:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=StreamExecLegacyTableSourceScan#53,name=DataStreamTableSink,fields=id, timestamp, temp)
  direct
    rel#55:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#54,name=DataStreamTableSink,fields=id, timestamp, temp)
      call#55 rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#49:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#48,name=DataStreamTableSink,fields=id, timestamp, temp)
          no parent
rel#53:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
  call#38 rule [StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)]
    rel#41:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
      no parent

2021-04-15 17:52:23,002 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize physical cost 123 ms.
optimize result: 
LegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:52:23,002 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:52:23,002 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:23,003 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:23,003 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#58:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#57,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:52:23,003 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#53:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
2021-04-15 17:52:23,004 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize watermark transpose cost 1 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:52:23,031 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize Changelog mode inference cost 27 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:52:23,032 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize Initialization for mini-batch interval inference cost 0 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:52:23,033 DEBUG org.apache.calcite.plan.RelOptPlanner - call#62: Apply rule [MiniBatchIntervalInferRule] to [rel#66:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#65,name=DataStreamTableSink,fields=id, timestamp, temp)]
2021-04-15 17:52:23,035 DEBUG org.apache.calcite.plan.RelOptPlanner - call#63: Apply rule [MiniBatchIntervalInferRule] to [rel#62:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:52:23,035 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:23,035 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
MiniBatchIntervalInferRule                                                     2               1,456
* Total                                                                        2               1,456

2021-04-15 17:52:23,036 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#66:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#65,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:52:23,036 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#62:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
2021-04-15 17:52:23,036 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize mini-batch interval rules cost 4 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:52:23,038 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:23,039 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:23,039 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#69:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#68,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:52:23,039 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#62:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
2021-04-15 17:52:23,040 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize physical rewrite cost 3 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:52:23,040 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize physical_rewrite cost 38 ms.
optimize result: 
LegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:52:23,101 INFO org.apache.flink.api.java.typeutils.TypeExtractor - class org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit does not contain a setter for field modificationTime
2021-04-15 17:52:23,102 INFO org.apache.flink.api.java.typeutils.TypeExtractor - Class class org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2021-04-15 17:52:23,116 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:52:23,118 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:52:23,134 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:52:23,134 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:52:23,137 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:52:23,137 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.java.io.RowCsvInputFormat
2021-04-15 17:52:23,137 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:52:23,137 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [Lorg.apache.flink.api.common.typeinfo.TypeInformation;
2021-04-15 17:52:23,160 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [I
2021-04-15 17:52:23,164 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:52:23,183 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Long
2021-04-15 17:52:23,183 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.streaming.api.functions.source.FileProcessingMode
2021-04-15 17:52:23,184 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Long
2021-04-15 17:52:23,184 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:52:23,326 DEBUG o.a.flink.table.planner.codegen.OperatorCodeGenerator$ - Compiling OneInputStreamOperator Code:
SourceConversion
2021-04-15 17:52:23,372 DEBUG o.a.flink.table.planner.codegen.OperatorCodeGenerator$ - Compiling OneInputStreamOperator Code:
SinkConversion
2021-04-15 17:52:23,374 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
2021-04-15 17:52:23,374 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:52:23,374 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:52:23,374 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:52:23,375 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:52:23,375 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:52:23,683 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'equals' from 'core' module.
2021-04-15 17:52:23,727 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'count' from 'core' module.
2021-04-15 17:52:23,728 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'avg' from 'core' module.
2021-04-15 17:52:23,730 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'as' from 'core' module.
2021-04-15 17:52:23,731 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'as' from 'core' module.
2021-04-15 17:52:23,758 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'as' from 'core' module.
2021-04-15 17:52:23,759 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'as' from 'core' module.
2021-04-15 17:52:23,773 DEBUG org.apache.calcite.sql.parser - Reduced `id` = 'sensor_6'
2021-04-15 17:52:23,841 DEBUG org.apache.flink.table.module.ModuleManager - Cannot find FunctionDefinition 'id' from any loaded modules.
2021-04-15 17:52:23,850 DEBUG org.apache.flink.table.module.ModuleManager - Cannot find FunctionDefinition '=' from any loaded modules.
2021-04-15 17:52:23,855 DEBUG org.apache.flink.table.module.ModuleManager - Cannot find FunctionDefinition 'id' from any loaded modules.
2021-04-15 17:52:23,856 DEBUG org.apache.flink.table.module.ModuleManager - Cannot find FunctionDefinition 'temp' from any loaded modules.
2021-04-15 17:52:23,900 DEBUG org.apache.calcite.sql2rel - Plan after converting SqlNode to RelNode
LogicalProject(id=[$0], temp=[$2])
  LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
    LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:23,907 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'count' from 'core' module.
2021-04-15 17:52:23,908 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'avg' from 'core' module.
2021-04-15 17:52:23,918 DEBUG org.apache.flink.table.module.ModuleManager - Cannot find FunctionDefinition 'id' from any loaded modules.
2021-04-15 17:52:23,919 DEBUG org.apache.flink.table.module.ModuleManager - Cannot find FunctionDefinition 'id' from any loaded modules.
2021-04-15 17:52:23,950 DEBUG org.apache.flink.table.module.ModuleManager - Cannot find FunctionDefinition 'id' from any loaded modules.
2021-04-15 17:52:23,951 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'count' from 'core' module.
2021-04-15 17:52:23,956 DEBUG org.apache.flink.table.module.ModuleManager - Cannot find FunctionDefinition 'temp' from any loaded modules.
2021-04-15 17:52:23,957 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'avg' from 'core' module.
2021-04-15 17:52:23,997 DEBUG org.apache.calcite.sql2rel - Plan after converting SqlNode to RelNode
LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
  LogicalProject(id=[$0], temp=[$2])
    LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:23,998 INFO org.apache.flink.api.java.typeutils.TypeExtractor - class org.apache.flink.types.Row is missing a default constructor so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2021-04-15 17:52:24,020 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:52:24,021 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,021 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:24,021 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#88:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#87,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:52:24,021 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#86:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#85,condition==($0, _UTF-16LE'sensor_6'))
2021-04-15 17:52:24,022 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#84:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#83,inputs=0,exprs=[$2])
2021-04-15 17:52:24,022 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#79:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:24,023 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert table references before rewriting sub-queries to semi-join cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,023 DEBUG org.apache.calcite.plan.RelOptPlanner - call#64: Apply rule [SimplifyFilterConditionRule:simplifySubQuery] to [rel#93:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#92,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,035 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,035 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
SimplifyFilterConditionRule:simplifySubQuery                                   1              10,933
* Total                                                                        1              10,933

2021-04-15 17:52:24,035 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#95:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#94,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:52:24,035 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#93:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#92,condition==($0, _UTF-16LE'sensor_6'))
2021-04-15 17:52:24,035 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#91:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#90,inputs=0,exprs=[$2])
2021-04-15 17:52:24,036 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#79:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:24,036 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize rewrite sub-queries to semi-join cost 13 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,037 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,037 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:24,037 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#102:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#101,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:52:24,037 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#100:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#99,condition==($0, _UTF-16LE'sensor_6'))
2021-04-15 17:52:24,037 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#98:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#97,inputs=0,exprs=[$2])
2021-04-15 17:52:24,037 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#79:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:24,038 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize sub-queries remove cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,039 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,039 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:24,039 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#109:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#108,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:52:24,039 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#107:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#106,condition==($0, _UTF-16LE'sensor_6'))
2021-04-15 17:52:24,039 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#105:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#104,inputs=0,exprs=[$2])
2021-04-15 17:52:24,039 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#79:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:24,040 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert table references after sub-queries removed cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,041 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize subquery_rewrite cost 20 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,041 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:52:24,042 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,042 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:24,042 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#116:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#115,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:52:24,042 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#114:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#113,condition==($0, _UTF-16LE'sensor_6'))
2021-04-15 17:52:24,043 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#112:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#111,inputs=0,exprs=[$2])
2021-04-15 17:52:24,043 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#79:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:24,044 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert correlate to temporal table join cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,044 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,044 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:24,045 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#123:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#122,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:52:24,045 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#121:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#120,condition==($0, _UTF-16LE'sensor_6'))
2021-04-15 17:52:24,045 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#119:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#118,inputs=0,exprs=[$2])
2021-04-15 17:52:24,045 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#79:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:24,045 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert enumerable table scan cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,046 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize temporal_join_rewrite cost 5 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,046 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:52:24,047 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,047 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:24,047 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#130:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#129,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:52:24,047 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#128:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#127,condition==($0, _UTF-16LE'sensor_6'))
2021-04-15 17:52:24,047 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#126:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#125,inputs=0,exprs=[$2])
2021-04-15 17:52:24,047 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#79:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:24,048 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize pre-rewrite before decorrelation cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,049 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize  cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,050 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize decorrelate cost 3 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,054 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize time_indicator cost 3 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,054 DEBUG org.apache.calcite.plan.RelOptPlanner - call#65: Apply rule [SimplifyFilterConditionRule] to [rel#138:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#137,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,059 DEBUG org.apache.calcite.plan.RelOptPlanner - call#68: Apply rule [ReduceExpressionsRule(Filter)] to [rel#138:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#137,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,089 DEBUG org.apache.calcite.plan.RelOptPlanner - call#69: Apply rule [ReduceExpressionsRule(Project)] to [rel#136:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#135,inputs=0,exprs=[$2])]
2021-04-15 17:52:24,092 DEBUG org.apache.calcite.plan.RelOptPlanner - call#70: Apply rule [ConvertToNotInOrInRule] to [rel#138:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#137,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,098 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,098 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
ReduceExpressionsRule(Filter)                                                  1              30,256
ConvertToNotInOrInRule                                                         1               6,209
SimplifyFilterConditionRule                                                    1                 310
ReduceExpressionsRule(Project)                                                 1                 129
* Total                                                                        4              36,904

2021-04-15 17:52:24,099 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#140:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#139,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:52:24,099 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#138:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#137,condition==($0, _UTF-16LE'sensor_6'))
2021-04-15 17:52:24,099 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#136:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#135,inputs=0,exprs=[$2])
2021-04-15 17:52:24,099 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#79:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:24,100 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize default_rewrite cost 45 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,100 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:52:24,101 DEBUG org.apache.calcite.plan.RelOptPlanner - call#71: Apply rule [ReduceExpressionsRule(Project)] to [rel#143:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#142,inputs=0,exprs=[$2])]
2021-04-15 17:52:24,101 DEBUG org.apache.calcite.plan.RelOptPlanner - call#72: Apply rule [FilterProjectTransposeRule] to [rel#145:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#144,condition==($0, _UTF-16LE'sensor_6')), rel#143:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#142,inputs=0,exprs=[$2])]
2021-04-15 17:52:24,102 DEBUG org.apache.calcite.plan.RelOptPlanner - call#72: Rule FilterProjectTransposeRule arguments [rel#145:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#144,condition==($0, _UTF-16LE'sensor_6')), rel#143:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#142,inputs=0,exprs=[$2])] produced rel#150:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=LogicalFilter#149,inputs=0,exprs=[$2])
2021-04-15 17:52:24,105 DEBUG org.apache.calcite.plan.RelOptPlanner - call#73: Apply rule [SimplifyFilterConditionRule] to [rel#149:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#142,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,106 DEBUG org.apache.calcite.plan.RelOptPlanner - call#74: Apply rule [ReduceExpressionsRule(Filter)] to [rel#149:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#142,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,107 DEBUG org.apache.calcite.plan.RelOptPlanner - call#75: Apply rule [ReduceExpressionsRule(Project)] to [rel#152:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#151,inputs=0,exprs=[$2])]
2021-04-15 17:52:24,184 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: ExpressionReducer$5 

 Code:

      public class ExpressionReducer$5
          extends org.apache.flink.api.common.functions.RichMapFunction {

        
        private final org.apache.flink.table.data.binary.BinaryStringData str$4 = org.apache.flink.table.data.binary.BinaryStringData.fromString("sensor_6");
                   
        org.apache.flink.table.data.GenericRowData out = new org.apache.flink.table.data.GenericRowData(1);

        public ExpressionReducer$5(Object[] references) throws Exception {
          
        }

        

        @Override
        public void open(org.apache.flink.configuration.Configuration parameters) throws Exception {
          
        }

        @Override
        public Object map(Object _in1) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) _in1;
          
          
          
          
          
          
          
          
          if (false) {
            out.setField(0, null);
          } else {
            out.setField(0, ((org.apache.flink.table.data.binary.BinaryStringData) str$4));
          }
                    
                  
          return out;
          
        }

        @Override
        public void close() throws Exception {
          
        }
      }
    
2021-04-15 17:52:24,200 DEBUG org.apache.calcite.plan.RelOptPlanner - call#75: Rule ReduceExpressionsRule(Project) arguments [rel#152:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#151,inputs=0,exprs=[$2])] produced rel#154:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#151,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $2])
2021-04-15 17:52:24,202 DEBUG org.apache.calcite.plan.RelOptPlanner - call#76: Apply rule [SimplifyFilterConditionRule] to [rel#149:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#142,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,204 DEBUG org.apache.calcite.plan.RelOptPlanner - call#77: Apply rule [ReduceExpressionsRule(Filter)] to [rel#149:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#142,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,206 DEBUG org.apache.calcite.plan.RelOptPlanner - call#78: Apply rule [ReduceExpressionsRule(Project)] to [rel#154:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#151,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $2])]
2021-04-15 17:52:24,208 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,209 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
ReduceExpressionsRule(Project)                                                 3              93,599
ReduceExpressionsRule(Filter)                                                  2               1,576
SimplifyFilterConditionRule                                                    2                 667
FilterProjectTransposeRule                                                     1                 857
* Total                                                                        8              96,699

2021-04-15 17:52:24,209 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#147:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#155,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:52:24,209 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#154:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#151,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $2])
2021-04-15 17:52:24,209 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#149:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#142,condition==($0, _UTF-16LE'sensor_6'))
2021-04-15 17:52:24,209 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#79:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:24,210 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize filter rules cost 110 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalProject(id=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE"], temp=[$2])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,212 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,212 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:24,212 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#161:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#160,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:52:24,212 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#159:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#158,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $2])
2021-04-15 17:52:24,212 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#157:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#156,condition==($0, _UTF-16LE'sensor_6'))
2021-04-15 17:52:24,212 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#79:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:24,213 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize push predicate into table scan cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalProject(id=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE"], temp=[$2])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,214 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,214 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:24,214 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#168:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#167,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:52:24,214 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#166:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#165,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $2])
2021-04-15 17:52:24,215 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#164:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#163,condition==($0, _UTF-16LE'sensor_6'))
2021-04-15 17:52:24,215 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#79:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:24,216 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize prune empty after predicate push down cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalProject(id=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE"], temp=[$2])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,216 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize predicate_pushdown cost 116 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalProject(id=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE"], temp=[$2])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,235 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,236 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)] rels [#79]
2021-04-15 17:52:24,236 DEBUG org.apache.calcite.plan.RelOptPlanner - call#94: Apply rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)] to [rel#79:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])]
2021-04-15 17:52:24,236 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#179 via FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:24,270 DEBUG org.apache.calcite.plan.RelOptPlanner - call#94 generated 1 successors: [rel#179:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:52:24,270 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,270 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FilterToCalcRule] rels [#171]
2021-04-15 17:52:24,270 DEBUG org.apache.calcite.plan.RelOptPlanner - call#114: Apply rule [FilterToCalcRule] to [rel#171:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,276 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#181 via FilterToCalcRule
2021-04-15 17:52:24,277 DEBUG org.apache.calcite.plan.RelOptPlanner - call#114 generated 1 successors: [rel#181:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)]
2021-04-15 17:52:24,277 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,277 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectFilterTransposeRule] rels [#173,#171]
2021-04-15 17:52:24,278 DEBUG org.apache.calcite.plan.RelOptPlanner - call#118: Apply rule [ProjectFilterTransposeRule] to [rel#173:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#172,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $2]), rel#171:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,285 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#184 via ProjectFilterTransposeRule
2021-04-15 17:52:24,287 DEBUG org.apache.calcite.plan.RelOptPlanner - call#118 generated 1 successors: [rel#184:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=LogicalFilter#183,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])]
2021-04-15 17:52:24,287 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,287 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#173]
2021-04-15 17:52:24,288 DEBUG org.apache.calcite.plan.RelOptPlanner - call#139: Apply rule [ProjectToCalcRule] to [rel#173:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#172,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $2])]
2021-04-15 17:52:24,288 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#189 via ProjectToCalcRule
2021-04-15 17:52:24,291 DEBUG org.apache.calcite.plan.RelOptPlanner - call#139 generated 1 successors: [rel#189:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#172,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t4,1=$t2)]
2021-04-15 17:52:24,291 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,291 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)] rels [#175]
2021-04-15 17:52:24,291 DEBUG org.apache.calcite.plan.RelOptPlanner - call#147: Apply rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)] to [rel#175:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#174,name=DataStreamTableSink,fields=id, temp)]
2021-04-15 17:52:24,292 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#191 via FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:24,332 DEBUG org.apache.calcite.plan.RelOptPlanner - call#147 generated 1 successors: [rel#191:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#190,name=DataStreamTableSink,fields=id, temp)]
2021-04-15 17:52:24,332 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,332 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectCalcMergeRule] rels [#173,#181]
2021-04-15 17:52:24,332 DEBUG org.apache.calcite.plan.RelOptPlanner - call#166: Apply rule [ProjectCalcMergeRule] to [rel#173:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#172,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $2]), rel#181:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)]
2021-04-15 17:52:24,337 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#192 via ProjectCalcMergeRule
2021-04-15 17:52:24,338 DEBUG org.apache.calcite.plan.RelOptPlanner - call#166 generated 1 successors: [rel#192:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_6',expr#6==($t0, $t5),0=$t4,1=$t2,$condition=$t6)]
2021-04-15 17:52:24,338 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,338 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#181]
2021-04-15 17:52:24,338 DEBUG org.apache.calcite.plan.RelOptPlanner - call#170: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#181:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)]
2021-04-15 17:52:24,340 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#193 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:24,374 DEBUG org.apache.calcite.plan.RelOptPlanner - call#170 generated 1 successors: [rel#193:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#180,select=id, timestamp, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,374 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,374 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [PushProjectIntoLegacyTableSourceScanRule] rels [#182,#79]
2021-04-15 17:52:24,375 DEBUG org.apache.calcite.plan.RelOptPlanner - call#184: Apply rule [PushProjectIntoLegacyTableSourceScanRule] to [rel#182:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,inputs=0,exprs=[$2]), rel#79:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])]
2021-04-15 17:52:24,387 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#195 via PushProjectIntoLegacyTableSourceScanRule
2021-04-15 17:52:24,388 DEBUG org.apache.calcite.plan.RelOptPlanner - call#184 generated 1 successors: [rel#195:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]])]
2021-04-15 17:52:24,388 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,389 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#182]
2021-04-15 17:52:24,389 DEBUG org.apache.calcite.plan.RelOptPlanner - call#194: Apply rule [ProjectToCalcRule] to [rel#182:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,inputs=0,exprs=[$2])]
2021-04-15 17:52:24,389 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#197 via ProjectToCalcRule
2021-04-15 17:52:24,390 DEBUG org.apache.calcite.plan.RelOptPlanner - call#194 generated 1 successors: [rel#197:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,expr#0..2={inputs},0=$t0,1=$t2)]
2021-04-15 17:52:24,390 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,390 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FilterProjectTransposeRule] rels [#186,#182]
2021-04-15 17:52:24,390 DEBUG org.apache.calcite.plan.RelOptPlanner - call#199: Apply rule [FilterProjectTransposeRule] to [rel#186:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#185,condition==($0, _UTF-16LE'sensor_6')), rel#182:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,inputs=0,exprs=[$2])]
2021-04-15 17:52:24,390 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#199 via FilterProjectTransposeRule
2021-04-15 17:52:24,391 DEBUG org.apache.calcite.plan.RelOptPlanner - call#199 generated 1 successors: [rel#199:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=LogicalFilter#198,inputs=0,exprs=[$2])]
2021-04-15 17:52:24,391 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,391 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FilterToCalcRule] rels [#186]
2021-04-15 17:52:24,392 DEBUG org.apache.calcite.plan.RelOptPlanner - call#214: Apply rule [FilterToCalcRule] to [rel#186:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#185,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,393 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#201 via FilterToCalcRule
2021-04-15 17:52:24,394 DEBUG org.apache.calcite.plan.RelOptPlanner - call#214 generated 1 successors: [rel#201:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#185,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6',expr#3==($t0, $t2),proj#0..1={exprs},$condition=$t3)]
2021-04-15 17:52:24,394 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,394 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectFilterTransposeRule] rels [#188,#186]
2021-04-15 17:52:24,394 DEBUG org.apache.calcite.plan.RelOptPlanner - call#218: Apply rule [ProjectFilterTransposeRule] to [rel#188:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#187,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#186:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#185,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,394 DEBUG org.apache.calcite.plan.RelOptPlanner - call#218 generated 0 successors.
2021-04-15 17:52:24,394 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,394 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#188]
2021-04-15 17:52:24,394 DEBUG org.apache.calcite.plan.RelOptPlanner - call#239: Apply rule [ProjectToCalcRule] to [rel#188:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#187,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])]
2021-04-15 17:52:24,395 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#202 via ProjectToCalcRule
2021-04-15 17:52:24,395 DEBUG org.apache.calcite.plan.RelOptPlanner - call#239 generated 1 successors: [rel#202:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#187,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t3,1=$t1)]
2021-04-15 17:52:24,395 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,396 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#189,#181]
2021-04-15 17:52:24,396 DEBUG org.apache.calcite.plan.RelOptPlanner - call#250: Apply rule [FlinkCalcMergeRule] to [rel#189:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#172,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t4,1=$t2), rel#181:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)]
2021-04-15 17:52:24,397 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#203 via FlinkCalcMergeRule
2021-04-15 17:52:24,397 DEBUG org.apache.calcite.plan.RelOptPlanner - call#250 generated 1 successors: [rel#203:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_6',expr#6==($t0, $t5),0=$t4,1=$t2,$condition=$t6)]
2021-04-15 17:52:24,397 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,398 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#189]
2021-04-15 17:52:24,398 DEBUG org.apache.calcite.plan.RelOptPlanner - call#253: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#189:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#172,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t4,1=$t2)]
2021-04-15 17:52:24,398 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#204 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:24,418 DEBUG org.apache.calcite.plan.RelOptPlanner - call#253 generated 1 successors: [rel#204:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#194,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp)]
2021-04-15 17:52:24,418 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.45E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,418 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#192]
2021-04-15 17:52:24,419 DEBUG org.apache.calcite.plan.RelOptPlanner - call#270: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#192:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_6',expr#6==($t0, $t5),0=$t4,1=$t2,$condition=$t6)]
2021-04-15 17:52:24,419 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#205 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:24,420 DEBUG org.apache.calcite.plan.RelOptPlanner - call#270 generated 1 successors: [rel#205:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#180,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,420 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,420 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)] rels [#195]
2021-04-15 17:52:24,420 DEBUG org.apache.calcite.plan.RelOptPlanner - call#290: Apply rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)] to [rel#195:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]])]
2021-04-15 17:52:24,421 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#206 via FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:24,422 DEBUG org.apache.calcite.plan.RelOptPlanner - call#290 generated 1 successors: [rel#206:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:52:24,422 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,422 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FilterCalcMergeRule] rels [#186,#197]
2021-04-15 17:52:24,422 DEBUG org.apache.calcite.plan.RelOptPlanner - call#300: Apply rule [FilterCalcMergeRule] to [rel#186:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#185,condition==($0, _UTF-16LE'sensor_6')), rel#197:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,expr#0..2={inputs},0=$t0,1=$t2)]
2021-04-15 17:52:24,423 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#208 via FilterCalcMergeRule
2021-04-15 17:52:24,424 DEBUG org.apache.calcite.plan.RelOptPlanner - call#300 generated 1 successors: [rel#208:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),0=$t0,1=$t2,$condition=$t4)]
2021-04-15 17:52:24,424 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,425 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#197]
2021-04-15 17:52:24,425 DEBUG org.apache.calcite.plan.RelOptPlanner - call#305: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#197:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,expr#0..2={inputs},0=$t0,1=$t2)]
2021-04-15 17:52:24,425 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#209 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:24,426 DEBUG org.apache.calcite.plan.RelOptPlanner - call#305 generated 1 successors: [rel#209:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#180,select=id, temp)]
2021-04-15 17:52:24,426 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,426 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectFilterTransposeRule] rels [#200,#171]
2021-04-15 17:52:24,426 DEBUG org.apache.calcite.plan.RelOptPlanner - call#308: Apply rule [ProjectFilterTransposeRule] to [rel#200:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#172,inputs=0,exprs=[$2]), rel#171:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,427 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#211 via ProjectFilterTransposeRule
2021-04-15 17:52:24,427 DEBUG org.apache.calcite.plan.RelOptPlanner - call#308 generated 1 successors: [rel#211:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=LogicalProject#210,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,427 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,427 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectMergeRule] rels [#188,#200]
2021-04-15 17:52:24,427 DEBUG org.apache.calcite.plan.RelOptPlanner - call#313: Apply rule [ProjectMergeRule] to [rel#188:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#187,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#200:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#172,inputs=0,exprs=[$2])]
2021-04-15 17:52:24,429 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#213 via ProjectMergeRule
2021-04-15 17:52:24,429 DEBUG org.apache.calcite.plan.RelOptPlanner - call#313 generated 1 successors: [rel#213:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#172,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $2])]
2021-04-15 17:52:24,429 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,429 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectCalcMergeRule] rels [#200,#181]
2021-04-15 17:52:24,429 DEBUG org.apache.calcite.plan.RelOptPlanner - call#329: Apply rule [ProjectCalcMergeRule] to [rel#200:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#172,inputs=0,exprs=[$2]), rel#181:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)]
2021-04-15 17:52:24,430 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#214 via ProjectCalcMergeRule
2021-04-15 17:52:24,430 DEBUG org.apache.calcite.plan.RelOptPlanner - call#329 generated 1 successors: [rel#214:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),0=$t0,1=$t2,$condition=$t4)]
2021-04-15 17:52:24,430 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,431 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#200]
2021-04-15 17:52:24,431 DEBUG org.apache.calcite.plan.RelOptPlanner - call#331: Apply rule [ProjectToCalcRule] to [rel#200:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#172,inputs=0,exprs=[$2])]
2021-04-15 17:52:24,432 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#215 via ProjectToCalcRule
2021-04-15 17:52:24,432 DEBUG org.apache.calcite.plan.RelOptPlanner - call#331 generated 1 successors: [rel#215:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#172,expr#0..2={inputs},0=$t0,1=$t2)]
2021-04-15 17:52:24,433 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,433 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectCalcMergeRule] rels [#188,#201]
2021-04-15 17:52:24,433 DEBUG org.apache.calcite.plan.RelOptPlanner - call#341: Apply rule [ProjectCalcMergeRule] to [rel#188:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#187,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#201:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#185,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6',expr#3==($t0, $t2),proj#0..1={exprs},$condition=$t3)]
2021-04-15 17:52:24,434 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#216 via ProjectCalcMergeRule
2021-04-15 17:52:24,435 DEBUG org.apache.calcite.plan.RelOptPlanner - call#341 generated 1 successors: [rel#216:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#185,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=_UTF-16LE'sensor_6',expr#5==($t0, $t4),0=$t3,1=$t1,$condition=$t5)]
2021-04-15 17:52:24,435 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,435 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#201,#197]
2021-04-15 17:52:24,436 DEBUG org.apache.calcite.plan.RelOptPlanner - call#343: Apply rule [FlinkCalcMergeRule] to [rel#201:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#185,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6',expr#3==($t0, $t2),proj#0..1={exprs},$condition=$t3), rel#197:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,expr#0..2={inputs},0=$t0,1=$t2)]
2021-04-15 17:52:24,437 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#217 via FlinkCalcMergeRule
2021-04-15 17:52:24,438 DEBUG org.apache.calcite.plan.RelOptPlanner - call#343 generated 1 successors: [rel#217:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),0=$t0,1=$t2,$condition=$t4)]
2021-04-15 17:52:24,438 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,438 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#201]
2021-04-15 17:52:24,438 DEBUG org.apache.calcite.plan.RelOptPlanner - call#346: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#201:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#185,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6',expr#3==($t0, $t2),proj#0..1={exprs},$condition=$t3)]
2021-04-15 17:52:24,438 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#218 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:24,440 DEBUG org.apache.calcite.plan.RelOptPlanner - call#346 generated 1 successors: [rel#218:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#207,select=id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,441 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,441 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#202,#201]
2021-04-15 17:52:24,441 DEBUG org.apache.calcite.plan.RelOptPlanner - call#356: Apply rule [FlinkCalcMergeRule] to [rel#202:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#187,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t3,1=$t1), rel#201:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#185,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6',expr#3==($t0, $t2),proj#0..1={exprs},$condition=$t3)]
2021-04-15 17:52:24,442 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#220 via FlinkCalcMergeRule
2021-04-15 17:52:24,442 DEBUG org.apache.calcite.plan.RelOptPlanner - call#356 generated 1 successors: [rel#220:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#185,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=_UTF-16LE'sensor_6',expr#5==($t0, $t4),0=$t3,1=$t1,$condition=$t5)]
2021-04-15 17:52:24,442 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,443 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#202]
2021-04-15 17:52:24,443 DEBUG org.apache.calcite.plan.RelOptPlanner - call#359: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#202:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#187,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t3,1=$t1)]
2021-04-15 17:52:24,443 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#221 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:24,444 DEBUG org.apache.calcite.plan.RelOptPlanner - call#359 generated 1 successors: [rel#221:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#219,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp)]
2021-04-15 17:52:24,445 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.45E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,445 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#204,#193]
2021-04-15 17:52:24,445 DEBUG org.apache.calcite.plan.RelOptPlanner - call#367: Apply rule [FlinkCalcMergeRule] to [rel#204:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#194,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp), rel#193:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#180,select=id, timestamp, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,447 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#222 via FlinkCalcMergeRule
2021-04-15 17:52:24,447 DEBUG org.apache.calcite.plan.RelOptPlanner - call#367 generated 1 successors: [rel#222:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#180,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,448 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.45E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,448 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectCalcMergeRule] rels [#188,#208]
2021-04-15 17:52:24,448 DEBUG org.apache.calcite.plan.RelOptPlanner - call#390: Apply rule [ProjectCalcMergeRule] to [rel#188:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#187,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#208:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),0=$t0,1=$t2,$condition=$t4)]
2021-04-15 17:52:24,449 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#223 via ProjectCalcMergeRule
2021-04-15 17:52:24,450 DEBUG org.apache.calcite.plan.RelOptPlanner - call#390 generated 1 successors: [rel#223:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_6',expr#6==($t0, $t5),0=$t4,1=$t2,$condition=$t6)]
2021-04-15 17:52:24,450 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.45E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,450 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#202,#208]
2021-04-15 17:52:24,450 DEBUG org.apache.calcite.plan.RelOptPlanner - call#393: Apply rule [FlinkCalcMergeRule] to [rel#202:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#187,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t3,1=$t1), rel#208:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),0=$t0,1=$t2,$condition=$t4)]
2021-04-15 17:52:24,451 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#224 via FlinkCalcMergeRule
2021-04-15 17:52:24,451 DEBUG org.apache.calcite.plan.RelOptPlanner - call#393 generated 1 successors: [rel#224:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_6',expr#6==($t0, $t5),0=$t4,1=$t2,$condition=$t6)]
2021-04-15 17:52:24,451 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.45E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,451 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#208]
2021-04-15 17:52:24,451 DEBUG org.apache.calcite.plan.RelOptPlanner - call#395: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#208:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),0=$t0,1=$t2,$condition=$t4)]
2021-04-15 17:52:24,452 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#225 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:24,453 DEBUG org.apache.calcite.plan.RelOptPlanner - call#395 generated 1 successors: [rel#225:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#180,select=id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,453 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.45E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,454 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectCalcMergeRule] rels [#188,#215]
2021-04-15 17:52:24,454 DEBUG org.apache.calcite.plan.RelOptPlanner - call#412: Apply rule [ProjectCalcMergeRule] to [rel#188:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#187,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#215:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#172,expr#0..2={inputs},0=$t0,1=$t2)]
2021-04-15 17:52:24,455 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#226 via ProjectCalcMergeRule
2021-04-15 17:52:24,455 DEBUG org.apache.calcite.plan.RelOptPlanner - call#412 generated 1 successors: [rel#226:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#172,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t4,1=$t2)]
2021-04-15 17:52:24,455 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.45E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,455 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#215,#181]
2021-04-15 17:52:24,455 DEBUG org.apache.calcite.plan.RelOptPlanner - call#414: Apply rule [FlinkCalcMergeRule] to [rel#215:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#172,expr#0..2={inputs},0=$t0,1=$t2), rel#181:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)]
2021-04-15 17:52:24,456 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#227 via FlinkCalcMergeRule
2021-04-15 17:52:24,456 DEBUG org.apache.calcite.plan.RelOptPlanner - call#414 generated 1 successors: [rel#227:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),0=$t0,1=$t2,$condition=$t4)]
2021-04-15 17:52:24,456 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.45E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,457 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#202,#215]
2021-04-15 17:52:24,457 DEBUG org.apache.calcite.plan.RelOptPlanner - call#416: Apply rule [FlinkCalcMergeRule] to [rel#202:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#187,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t3,1=$t1), rel#215:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#172,expr#0..2={inputs},0=$t0,1=$t2)]
2021-04-15 17:52:24,457 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#228 via FlinkCalcMergeRule
2021-04-15 17:52:24,457 DEBUG org.apache.calcite.plan.RelOptPlanner - call#416 generated 1 successors: [rel#228:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#172,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t4,1=$t2)]
2021-04-15 17:52:24,457 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.45E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,458 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#215]
2021-04-15 17:52:24,459 DEBUG org.apache.calcite.plan.RelOptPlanner - call#418: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#215:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#172,expr#0..2={inputs},0=$t0,1=$t2)]
2021-04-15 17:52:24,459 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#229 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:24,460 DEBUG org.apache.calcite.plan.RelOptPlanner - call#418 generated 1 successors: [rel#229:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#194,select=id, temp)]
2021-04-15 17:52:24,460 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.45E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,460 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#216,#197]
2021-04-15 17:52:24,460 DEBUG org.apache.calcite.plan.RelOptPlanner - call#428: Apply rule [FlinkCalcMergeRule] to [rel#216:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#185,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=_UTF-16LE'sensor_6',expr#5==($t0, $t4),0=$t3,1=$t1,$condition=$t5), rel#197:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,expr#0..2={inputs},0=$t0,1=$t2)]
2021-04-15 17:52:24,461 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#230 via FlinkCalcMergeRule
2021-04-15 17:52:24,461 DEBUG org.apache.calcite.plan.RelOptPlanner - call#428 generated 1 successors: [rel#230:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_6',expr#6==($t0, $t5),0=$t4,1=$t2,$condition=$t6)]
2021-04-15 17:52:24,462 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.45E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,462 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#216]
2021-04-15 17:52:24,462 DEBUG org.apache.calcite.plan.RelOptPlanner - call#431: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#216:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#185,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=_UTF-16LE'sensor_6',expr#5==($t0, $t4),0=$t3,1=$t1,$condition=$t5)]
2021-04-15 17:52:24,462 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#231 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:24,463 DEBUG org.apache.calcite.plan.RelOptPlanner - call#431 generated 1 successors: [rel#231:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#207,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,463 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,463 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#218,#209]
2021-04-15 17:52:24,464 DEBUG org.apache.calcite.plan.RelOptPlanner - call#439: Apply rule [FlinkCalcMergeRule] to [rel#218:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#207,select=id, temp,where==(id, _UTF-16LE'sensor_6')), rel#209:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#180,select=id, temp)]
2021-04-15 17:52:24,465 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#232 via FlinkCalcMergeRule
2021-04-15 17:52:24,466 DEBUG org.apache.calcite.plan.RelOptPlanner - call#439 generated 1 successors: [rel#232:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#180,select=id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,466 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,467 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#221,#218]
2021-04-15 17:52:24,467 DEBUG org.apache.calcite.plan.RelOptPlanner - call#448: Apply rule [FlinkCalcMergeRule] to [rel#221:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#219,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp), rel#218:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#207,select=id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,468 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#233 via FlinkCalcMergeRule
2021-04-15 17:52:24,469 DEBUG org.apache.calcite.plan.RelOptPlanner - call#448 generated 1 successors: [rel#233:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#207,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,469 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,469 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#221,#225]
2021-04-15 17:52:24,469 DEBUG org.apache.calcite.plan.RelOptPlanner - call#458: Apply rule [FlinkCalcMergeRule] to [rel#221:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#219,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp), rel#225:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#180,select=id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,471 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#234 via FlinkCalcMergeRule
2021-04-15 17:52:24,472 DEBUG org.apache.calcite.plan.RelOptPlanner - call#458 generated 1 successors: [rel#234:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#180,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,472 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,472 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#229,#193]
2021-04-15 17:52:24,473 DEBUG org.apache.calcite.plan.RelOptPlanner - call#466: Apply rule [FlinkCalcMergeRule] to [rel#229:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#194,select=id, temp), rel#193:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#180,select=id, timestamp, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,474 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#235 via FlinkCalcMergeRule
2021-04-15 17:52:24,474 DEBUG org.apache.calcite.plan.RelOptPlanner - call#466 generated 1 successors: [rel#235:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#180,select=id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,474 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,474 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#221,#229]
2021-04-15 17:52:24,474 DEBUG org.apache.calcite.plan.RelOptPlanner - call#468: Apply rule [FlinkCalcMergeRule] to [rel#221:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#219,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp), rel#229:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#194,select=id, temp)]
2021-04-15 17:52:24,476 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#236 via FlinkCalcMergeRule
2021-04-15 17:52:24,476 DEBUG org.apache.calcite.plan.RelOptPlanner - call#468 generated 1 successors: [rel#236:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#194,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp)]
2021-04-15 17:52:24,476 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,476 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#231,#209]
2021-04-15 17:52:24,477 DEBUG org.apache.calcite.plan.RelOptPlanner - call#476: Apply rule [FlinkCalcMergeRule] to [rel#231:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#207,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6')), rel#209:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#180,select=id, temp)]
2021-04-15 17:52:24,478 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#237 via FlinkCalcMergeRule
2021-04-15 17:52:24,478 DEBUG org.apache.calcite.plan.RelOptPlanner - call#476 generated 1 successors: [rel#237:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#180,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,478 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,479 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for VolcanoPlanner
2021-04-15 17:52:24,479 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
FlinkCalcMergeRule                                                            14              23,185
FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)                                 9              67,145
ProjectCalcMergeRule                                                           5              12,714
ProjectToCalcRule                                                              4               6,733
FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)                   3             119,278
ProjectFilterTransposeRule                                                     3              10,067
FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)                           2              75,464
FilterToCalcRule                                                               2               8,298
StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)                   1              56,702
StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)                       1              32,924
PushProjectIntoLegacyTableSourceScanRule                                       1              14,198
FilterCalcMergeRule                                                            1               2,170
ProjectMergeRule                                                               1               1,654
FilterProjectTransposeRule                                                     1               1,146
* Total                                                                       48             431,678

2021-04-15 17:52:24,501 DEBUG org.apache.calcite.plan.RelOptPlanner - Cheapest plan:
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp]): rowcount = 1.5E7, cumulative cost = {1.3E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}, id = 239
  FlinkLogicalCalc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[=(id, _UTF-16LE'sensor_6')]): rowcount = 1.5E7, cumulative cost = {1.15E8 rows, 1.0E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}, id = 238
    FlinkLogicalLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, timestamp, temp]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}, id = 206

2021-04-15 17:52:24,502 DEBUG org.apache.calcite.plan.RelOptPlanner - Provenance:
rel#239:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=FlinkLogicalCalc#238,name=DataStreamTableSink,fields=id, temp)
  direct
    rel#191:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#190,name=DataStreamTableSink,fields=id, temp)
      call#147 rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)]
        rel#175:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#174,name=DataStreamTableSink,fields=id, temp)
          no parent
rel#238:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=FlinkLogicalLegacyTableSourceScan#206,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))
  direct
    rel#231:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#207,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))
      call#431 rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)]
        rel#216:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#185,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=_UTF-16LE'sensor_6',expr#5==($t0, $t4),0=$t3,1=$t1,$condition=$t5)
          call#341 rule [ProjectCalcMergeRule]
            rel#188:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#187,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])
              call#118 rule [ProjectFilterTransposeRule]
                rel#173:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#172,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $2])
                  no parent
                rel#171:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,condition==($0, _UTF-16LE'sensor_6'))
                  no parent
            rel#201:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#185,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6',expr#3==($t0, $t2),proj#0..1={exprs},$condition=$t3)
              call#214 rule [FilterToCalcRule]
                rel#186:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#185,condition==($0, _UTF-16LE'sensor_6'))
                  call#118 rule [ProjectFilterTransposeRule]
                    rel#173 (see above)
                    rel#171 (see above)
rel#206:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, timestamp, temp)
  call#290 rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)]
    rel#195:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]])
      call#184 rule [PushProjectIntoLegacyTableSourceScanRule]
        rel#182:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,inputs=0,exprs=[$2])
          call#118 rule [ProjectFilterTransposeRule]
            rel#173 (see above)
            rel#171 (see above)
        rel#79:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
          no parent

2021-04-15 17:52:24,503 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize logical cost 287 ms.
optimize result: 
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- FlinkLogicalCalc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[=(id, _UTF-16LE'sensor_6')])
   +- FlinkLogicalLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:52:24,514 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,514 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:24,514 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#243:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#242,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:52:24,515 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#241:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#240,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))
2021-04-15 17:52:24,515 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#206:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, timestamp, temp)
2021-04-15 17:52:24,516 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize logical_rewrite cost 12 ms.
optimize result: 
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- FlinkLogicalCalc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[=(id, _UTF-16LE'sensor_6')])
   +- FlinkLogicalLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:52:24,522 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,522 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#206]
2021-04-15 17:52:24,522 DEBUG org.apache.calcite.plan.RelOptPlanner - call#488: Apply rule [StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#206:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:52:24,522 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#252 via StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:52:24,525 DEBUG org.apache.calcite.plan.RelOptPlanner - call#488 generated 1 successors: [rel#252:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)]
2021-04-15 17:52:24,525 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,525 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#246]
2021-04-15 17:52:24,526 DEBUG org.apache.calcite.plan.RelOptPlanner - call#499: Apply rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#246:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#245,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,527 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#254 via StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:52:24,554 DEBUG org.apache.calcite.plan.RelOptPlanner - call#499 generated 1 successors: [rel#254:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#253,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,554 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,554 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#248]
2021-04-15 17:52:24,554 DEBUG org.apache.calcite.plan.RelOptPlanner - call#516: Apply rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#248:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#247,name=DataStreamTableSink,fields=id, temp)]
2021-04-15 17:52:24,555 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#256 via StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:52:24,555 DEBUG org.apache.calcite.plan.RelOptPlanner - call#516 generated 1 successors: [rel#256:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#255,name=DataStreamTableSink,fields=id, temp)]
2021-04-15 17:52:24,555 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,555 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for VolcanoPlanner
2021-04-15 17:52:24,556 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
FlinkCalcMergeRule                                                            14              23,185
FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)                                 9              67,145
ProjectCalcMergeRule                                                           5              12,714
ProjectToCalcRule                                                              4               6,733
FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)                   3             119,278
ProjectFilterTransposeRule                                                     3              10,067
FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)                           2              75,464
StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)                   2              59,204
StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)                       2              33,807
FilterToCalcRule                                                               2               8,298
StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)                             1              28,176
PushProjectIntoLegacyTableSourceScanRule                                       1              14,198
FilterCalcMergeRule                                                            1               2,170
ProjectMergeRule                                                               1               1,654
FilterProjectTransposeRule                                                     1               1,146
* Total                                                                       51             463,239

2021-04-15 17:52:24,575 DEBUG org.apache.calcite.plan.RelOptPlanner - Cheapest plan:
StreamExecLegacySink(name=[DataStreamTableSink], fields=[id, temp]): rowcount = 1.5E7, cumulative cost = {1.3E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}, id = 258
  StreamExecCalc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[=(id, _UTF-16LE'sensor_6')]): rowcount = 1.5E7, cumulative cost = {1.15E8 rows, 1.0E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}, id = 257
    StreamExecLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}, id = 252

2021-04-15 17:52:24,576 DEBUG org.apache.calcite.plan.RelOptPlanner - Provenance:
rel#258:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=StreamExecCalc#257,name=DataStreamTableSink,fields=id, temp)
  direct
    rel#256:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#255,name=DataStreamTableSink,fields=id, temp)
      call#516 rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#248:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#247,name=DataStreamTableSink,fields=id, temp)
          no parent
rel#257:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=StreamExecLegacyTableSourceScan#252,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))
  direct
    rel#254:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#253,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))
      call#499 rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#246:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#245,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))
          no parent
rel#252:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)
  call#488 rule [StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)]
    rel#206:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, timestamp, temp)
      no parent

2021-04-15 17:52:24,577 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize physical cost 61 ms.
optimize result: 
LegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[=(id, _UTF-16LE'sensor_6')])
   +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:52:24,577 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:52:24,578 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,579 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:24,580 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#262:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#261,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:52:24,580 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#260:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#259,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))
2021-04-15 17:52:24,581 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#252:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)
2021-04-15 17:52:24,585 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize watermark transpose cost 5 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[=(id, _UTF-16LE'sensor_6')])
   +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:52:24,587 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize Changelog mode inference cost 1 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[=(id, _UTF-16LE'sensor_6')])
   +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:52:24,587 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize Initialization for mini-batch interval inference cost 0 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[=(id, _UTF-16LE'sensor_6')])
   +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:52:24,588 DEBUG org.apache.calcite.plan.RelOptPlanner - call#524: Apply rule [MiniBatchIntervalInferRule] to [rel#274:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#273,name=DataStreamTableSink,fields=id, temp)]
2021-04-15 17:52:24,588 DEBUG org.apache.calcite.plan.RelOptPlanner - call#525: Apply rule [MiniBatchIntervalInferRule] to [rel#272:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[I].[NONE](input=HepRelVertex#271,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:52:24,589 DEBUG org.apache.calcite.plan.RelOptPlanner - call#526: Apply rule [MiniBatchIntervalInferRule] to [rel#267:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)]
2021-04-15 17:52:24,589 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,589 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
MiniBatchIntervalInferRule                                                     3                 267
* Total                                                                        3                 267

2021-04-15 17:52:24,589 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#274:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#273,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:52:24,589 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#272:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[I].[NONE](input=HepRelVertex#271,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))
2021-04-15 17:52:24,590 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#267:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)
2021-04-15 17:52:24,591 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize mini-batch interval rules cost 3 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[=(id, _UTF-16LE'sensor_6')])
   +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:52:24,591 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,591 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:24,591 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#279:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#278,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:52:24,591 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#277:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[I].[NONE](input=HepRelVertex#276,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))
2021-04-15 17:52:24,591 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#267:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)
2021-04-15 17:52:24,592 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize physical rewrite cost 1 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[=(id, _UTF-16LE'sensor_6')])
   +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:52:24,593 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize physical_rewrite cost 15 ms.
optimize result: 
LegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[=(id, _UTF-16LE'sensor_6')])
   +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:52:24,599 INFO org.apache.flink.api.java.typeutils.TypeExtractor - class org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit does not contain a setter for field modificationTime
2021-04-15 17:52:24,599 INFO org.apache.flink.api.java.typeutils.TypeExtractor - Class class org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2021-04-15 17:52:24,599 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:52:24,599 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:52:24,599 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:52:24,599 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:52:24,599 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:52:24,599 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.java.io.RowCsvInputFormat
2021-04-15 17:52:24,599 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:52:24,599 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [Lorg.apache.flink.api.common.typeinfo.TypeInformation;
2021-04-15 17:52:24,600 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [I
2021-04-15 17:52:24,600 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:52:24,600 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Long
2021-04-15 17:52:24,600 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.streaming.api.functions.source.FileProcessingMode
2021-04-15 17:52:24,601 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Long
2021-04-15 17:52:24,601 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:52:24,606 DEBUG o.a.flink.table.planner.codegen.OperatorCodeGenerator$ - Compiling OneInputStreamOperator Code:
SourceConversion
2021-04-15 17:52:24,653 DEBUG o.a.flink.table.planner.codegen.OperatorCodeGenerator$ - Compiling OneInputStreamOperator Code:
StreamExecCalc
2021-04-15 17:52:24,656 DEBUG o.a.flink.table.planner.codegen.OperatorCodeGenerator$ - Compiling OneInputStreamOperator Code:
SinkConversion
2021-04-15 17:52:24,656 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
2021-04-15 17:52:24,656 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:52:24,656 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:52:24,656 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:52:24,656 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:52:24,657 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:52:24,658 INFO org.apache.flink.api.java.typeutils.TypeExtractor - class org.apache.flink.types.Row is missing a default constructor so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2021-04-15 17:52:24,689 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:52:24,690 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,690 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:24,690 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#290:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#289,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:52:24,690 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#288:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#287,inputs=0..2)
2021-04-15 17:52:24,690 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#286:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#285,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
2021-04-15 17:52:24,690 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#281:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:24,691 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert table references before rewriting sub-queries to semi-join cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,692 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,692 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:24,692 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#297:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#296,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:52:24,692 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#295:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#294,inputs=0..2)
2021-04-15 17:52:24,692 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#293:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#292,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
2021-04-15 17:52:24,692 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#281:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:24,693 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize rewrite sub-queries to semi-join cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,693 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,693 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:24,693 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#304:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#303,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:52:24,694 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#302:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#301,inputs=0..2)
2021-04-15 17:52:24,694 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#300:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#299,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
2021-04-15 17:52:24,694 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#281:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:24,694 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize sub-queries remove cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,695 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,695 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:24,695 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#311:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#310,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:52:24,695 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#309:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#308,inputs=0..2)
2021-04-15 17:52:24,695 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#307:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#306,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
2021-04-15 17:52:24,695 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#281:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:24,696 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert table references after sub-queries removed cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,696 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize subquery_rewrite cost 7 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,696 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:52:24,697 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,697 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:24,697 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#318:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#317,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:52:24,697 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#316:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#315,inputs=0..2)
2021-04-15 17:52:24,697 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#314:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#313,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
2021-04-15 17:52:24,697 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#281:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:24,698 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert correlate to temporal table join cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,698 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,699 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:24,699 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#325:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#324,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:52:24,699 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#323:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#322,inputs=0..2)
2021-04-15 17:52:24,699 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#321:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#320,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
2021-04-15 17:52:24,699 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#281:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:24,699 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert enumerable table scan cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,700 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize temporal_join_rewrite cost 3 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,700 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:52:24,700 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,700 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:24,701 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#332:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#331,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:52:24,701 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#330:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#329,inputs=0..2)
2021-04-15 17:52:24,701 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#328:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#327,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
2021-04-15 17:52:24,701 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#281:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:24,701 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize pre-rewrite before decorrelation cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,702 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize  cost 0 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,702 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize decorrelate cost 2 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,718 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize time_indicator cost 15 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,718 DEBUG org.apache.calcite.plan.RelOptPlanner - call#528: Apply rule [ReduceExpressionsRule(Project)] to [rel#340:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#339,inputs=0..2)]
2021-04-15 17:52:24,719 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,720 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
ReduceExpressionsRule(Project)                                                 1                 238
* Total                                                                        1                 238

2021-04-15 17:52:24,720 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#342:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#341,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:52:24,720 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#340:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#339,inputs=0..2)
2021-04-15 17:52:24,720 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#338:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#337,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
2021-04-15 17:52:24,721 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#281:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:24,721 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize default_rewrite cost 3 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,721 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:52:24,722 DEBUG org.apache.calcite.plan.RelOptPlanner - call#529: Apply rule [ReduceExpressionsRule(Project)] to [rel#347:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#346,inputs=0..2)]
2021-04-15 17:52:24,722 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,722 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
ReduceExpressionsRule(Project)                                                 1                 145
* Total                                                                        1                 145

2021-04-15 17:52:24,722 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#349:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#348,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:52:24,722 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#347:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#346,inputs=0..2)
2021-04-15 17:52:24,723 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#345:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#344,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
2021-04-15 17:52:24,723 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#281:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:24,724 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize filter rules cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,724 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,724 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:24,724 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#356:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#355,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:52:24,725 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#354:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#353,inputs=0..2)
2021-04-15 17:52:24,725 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#352:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#351,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
2021-04-15 17:52:24,725 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#281:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:24,725 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize push predicate into table scan cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,726 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,726 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:24,726 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#363:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#362,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:52:24,726 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#361:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#360,inputs=0..2)
2021-04-15 17:52:24,726 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#359:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#358,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
2021-04-15 17:52:24,726 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#281:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:24,727 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize prune empty after predicate push down cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,727 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize predicate_pushdown cost 6 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:24,734 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,734 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectRemoveRule] rels [#368]
2021-04-15 17:52:24,734 DEBUG org.apache.calcite.plan.RelOptPlanner - call#573: Apply rule [ProjectRemoveRule] to [rel#368:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#367,inputs=0..2)]
2021-04-15 17:52:24,734 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#367 via ProjectRemoveRule
2021-04-15 17:52:24,735 DEBUG org.apache.calcite.plan.RelOptPlanner - call#573 generated 1 successors: [rel#367:RelSubset#14.NONE.any.None: 0.[NONE].[NONE]]
2021-04-15 17:52:24,735 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,735 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)] rels [#281]
2021-04-15 17:52:24,735 DEBUG org.apache.calcite.plan.RelOptPlanner - call#541: Apply rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)] to [rel#281:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])]
2021-04-15 17:52:24,736 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#374 via FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:24,736 DEBUG org.apache.calcite.plan.RelOptPlanner - call#541 generated 1 successors: [rel#374:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:52:24,736 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,736 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [AggregateReduceFunctionsRule] rels [#366]
2021-04-15 17:52:24,737 DEBUG org.apache.calcite.plan.RelOptPlanner - call#560: Apply rule [AggregateReduceFunctionsRule] to [rel#366:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#365,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))]
2021-04-15 17:52:24,740 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#377 via AggregateReduceFunctionsRule
2021-04-15 17:52:24,741 DEBUG org.apache.calcite.plan.RelOptPlanner - call#560 generated 1 successors: [rel#377:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=LogicalAggregate#376,inputs=0..1,exprs=[/($2, $3)])]
2021-04-15 17:52:24,741 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,741 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] rels [#366]
2021-04-15 17:52:24,741 DEBUG org.apache.calcite.plan.RelOptPlanner - call#565: Apply rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] to [rel#366:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#365,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))]
2021-04-15 17:52:24,742 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#380 via FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:24,752 DEBUG org.apache.calcite.plan.RelOptPlanner - call#565 generated 1 successors: [rel#380:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#375,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))]
2021-04-15 17:52:24,752 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,753 DEBUG org.apache.calcite.plan.RelOptPlanner - Skip match: rule [ProjectToCalcRule] rels [#368]
2021-04-15 17:52:24,753 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)] rels [#370]
2021-04-15 17:52:24,753 DEBUG org.apache.calcite.plan.RelOptPlanner - call#598: Apply rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)] to [rel#370:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#367,name=DataStreamTableSink,fields=id, count, avgTemp)]
2021-04-15 17:52:24,753 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#382 via FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:24,817 DEBUG org.apache.calcite.plan.RelOptPlanner - call#598 generated 1 successors: [rel#382:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#381,name=DataStreamTableSink,fields=id, count, avgTemp)]
2021-04-15 17:52:24,818 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,819 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [AggregateReduceFunctionsRule] rels [#376]
2021-04-15 17:52:24,819 DEBUG org.apache.calcite.plan.RelOptPlanner - call#647: Apply rule [AggregateReduceFunctionsRule] to [rel#376:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#365,group={0},EXPR$0=COUNT($0),agg#1=SUM($2),agg#2=COUNT($2))]
2021-04-15 17:52:24,825 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#384 via AggregateReduceFunctionsRule
2021-04-15 17:52:24,826 DEBUG org.apache.calcite.plan.RelOptPlanner - call#647 generated 1 successors: [rel#384:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=LogicalAggregate#383,inputs=0..1,exprs=[CASE(=($3, 0), null:DOUBLE, $2), $3])]
2021-04-15 17:52:24,826 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,826 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] rels [#376]
2021-04-15 17:52:24,826 DEBUG org.apache.calcite.plan.RelOptPlanner - call#652: Apply rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] to [rel#376:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#365,group={0},EXPR$0=COUNT($0),agg#1=SUM($2),agg#2=COUNT($2))]
2021-04-15 17:52:24,826 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#387 via FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:24,827 DEBUG org.apache.calcite.plan.RelOptPlanner - call#652 generated 1 successors: [rel#387:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#375,group={0},EXPR$0=COUNT($0),agg#1=SUM($2),agg#2=COUNT($2))]
2021-04-15 17:52:24,827 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,827 DEBUG org.apache.calcite.plan.RelOptPlanner - Skip match: rule [ProjectMergeRule] rels [#368,#379]
2021-04-15 17:52:24,827 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#379]
2021-04-15 17:52:24,827 DEBUG org.apache.calcite.plan.RelOptPlanner - call#676: Apply rule [ProjectToCalcRule] to [rel#379:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#378,inputs=0..1,exprs=[/($2, $3)])]
2021-04-15 17:52:24,827 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#389 via ProjectToCalcRule
2021-04-15 17:52:24,829 DEBUG org.apache.calcite.plan.RelOptPlanner - call#676 generated 1 successors: [rel#389:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#378,expr#0..3={inputs},expr#4=/($t2, $t3),proj#0..1={exprs},2=$t4)]
2021-04-15 17:52:24,829 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,829 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] rels [#383]
2021-04-15 17:52:24,829 DEBUG org.apache.calcite.plan.RelOptPlanner - call#713: Apply rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] to [rel#383:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#365,group={0},EXPR$0=COUNT($0),agg#1=$SUM0($2),agg#2=COUNT($2))]
2021-04-15 17:52:24,829 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#390 via FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:24,830 DEBUG org.apache.calcite.plan.RelOptPlanner - call#713 generated 1 successors: [rel#390:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#375,group={0},EXPR$0=COUNT($0),agg#1=$SUM0($2),agg#2=COUNT($2))]
2021-04-15 17:52:24,830 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,830 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectMergeRule] rels [#379,#386]
2021-04-15 17:52:24,830 DEBUG org.apache.calcite.plan.RelOptPlanner - call#720: Apply rule [ProjectMergeRule] to [rel#379:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#378,inputs=0..1,exprs=[/($2, $3)]), rel#386:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#385,inputs=0..1,exprs=[CASE(=($3, 0), null:DOUBLE, $2), $3])]
2021-04-15 17:52:24,832 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#392 via ProjectMergeRule
2021-04-15 17:52:24,833 DEBUG org.apache.calcite.plan.RelOptPlanner - call#720 generated 1 successors: [rel#392:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#385,inputs=0..1,exprs=[/(CASE(=($3, 0), null:DOUBLE, $2), $3)])]
2021-04-15 17:52:24,833 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,833 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#386]
2021-04-15 17:52:24,833 DEBUG org.apache.calcite.plan.RelOptPlanner - call#737: Apply rule [ProjectToCalcRule] to [rel#386:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#385,inputs=0..1,exprs=[CASE(=($3, 0), null:DOUBLE, $2), $3])]
2021-04-15 17:52:24,834 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#393 via ProjectToCalcRule
2021-04-15 17:52:24,836 DEBUG org.apache.calcite.plan.RelOptPlanner - call#737 generated 1 successors: [rel#393:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#385,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),proj#0..1={exprs},2=$t7,3=$t3)]
2021-04-15 17:52:24,836 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,836 DEBUG org.apache.calcite.plan.RelOptPlanner - Skip match: rule [ProjectCalcMergeRule] rels [#368,#389]
2021-04-15 17:52:24,836 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#389]
2021-04-15 17:52:24,836 DEBUG org.apache.calcite.plan.RelOptPlanner - call#761: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#389:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#378,expr#0..3={inputs},expr#4=/($t2, $t3),proj#0..1={exprs},2=$t4)]
2021-04-15 17:52:24,836 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#394 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:24,854 DEBUG org.apache.calcite.plan.RelOptPlanner - call#761 generated 1 successors: [rel#394:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#388,select=id, EXPR$0, /($f2, $f3) AS EXPR$1)]
2021-04-15 17:52:24,854 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,854 DEBUG org.apache.calcite.plan.RelOptPlanner - Skip match: rule [ProjectMergeRule] rels [#368,#392]
2021-04-15 17:52:24,854 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#392]
2021-04-15 17:52:24,854 DEBUG org.apache.calcite.plan.RelOptPlanner - call#795: Apply rule [ProjectToCalcRule] to [rel#392:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#385,inputs=0..1,exprs=[/(CASE(=($3, 0), null:DOUBLE, $2), $3)])]
2021-04-15 17:52:24,855 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#395 via ProjectToCalcRule
2021-04-15 17:52:24,855 DEBUG org.apache.calcite.plan.RelOptPlanner - call#795 generated 1 successors: [rel#395:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#385,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),expr#8=/($t7, $t3),proj#0..1={exprs},2=$t8)]
2021-04-15 17:52:24,856 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,856 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectCalcMergeRule] rels [#379,#393]
2021-04-15 17:52:24,856 DEBUG org.apache.calcite.plan.RelOptPlanner - call#805: Apply rule [ProjectCalcMergeRule] to [rel#379:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#378,inputs=0..1,exprs=[/($2, $3)]), rel#393:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#385,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),proj#0..1={exprs},2=$t7,3=$t3)]
2021-04-15 17:52:24,857 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#396 via ProjectCalcMergeRule
2021-04-15 17:52:24,858 DEBUG org.apache.calcite.plan.RelOptPlanner - call#805 generated 1 successors: [rel#396:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#385,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),expr#8=/($t7, $t3),proj#0..1={exprs},2=$t8)]
2021-04-15 17:52:24,858 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,858 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#389,#393]
2021-04-15 17:52:24,858 DEBUG org.apache.calcite.plan.RelOptPlanner - call#808: Apply rule [FlinkCalcMergeRule] to [rel#389:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#378,expr#0..3={inputs},expr#4=/($t2, $t3),proj#0..1={exprs},2=$t4), rel#393:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#385,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),proj#0..1={exprs},2=$t7,3=$t3)]
2021-04-15 17:52:24,859 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#397 via FlinkCalcMergeRule
2021-04-15 17:52:24,859 DEBUG org.apache.calcite.plan.RelOptPlanner - call#808 generated 1 successors: [rel#397:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#385,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),expr#8=/($t7, $t3),proj#0..1={exprs},2=$t8)]
2021-04-15 17:52:24,859 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,859 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#393]
2021-04-15 17:52:24,860 DEBUG org.apache.calcite.plan.RelOptPlanner - call#810: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#393:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#385,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),proj#0..1={exprs},2=$t7,3=$t3)]
2021-04-15 17:52:24,860 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#398 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:24,861 DEBUG org.apache.calcite.plan.RelOptPlanner - call#810 generated 1 successors: [rel#398:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#391,select=id, EXPR$0, CASE(=($f3, 0), null:DOUBLE, $f2) AS $f2, $f3)]
2021-04-15 17:52:24,861 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,861 DEBUG org.apache.calcite.plan.RelOptPlanner - Skip match: rule [ProjectCalcMergeRule] rels [#368,#395]
2021-04-15 17:52:24,861 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#395]
2021-04-15 17:52:24,862 DEBUG org.apache.calcite.plan.RelOptPlanner - call#831: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#395:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#385,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),expr#8=/($t7, $t3),proj#0..1={exprs},2=$t8)]
2021-04-15 17:52:24,862 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#399 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:24,863 DEBUG org.apache.calcite.plan.RelOptPlanner - call#831 generated 1 successors: [rel#399:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#391,select=id, EXPR$0, /(CASE(=($f3, 0), null:DOUBLE, $f2), $f3) AS EXPR$1)]
2021-04-15 17:52:24,863 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,863 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#394,#398]
2021-04-15 17:52:24,863 DEBUG org.apache.calcite.plan.RelOptPlanner - call#840: Apply rule [FlinkCalcMergeRule] to [rel#394:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#388,select=id, EXPR$0, /($f2, $f3) AS EXPR$1), rel#398:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#391,select=id, EXPR$0, CASE(=($f3, 0), null:DOUBLE, $f2) AS $f2, $f3)]
2021-04-15 17:52:24,864 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#400 via FlinkCalcMergeRule
2021-04-15 17:52:24,865 DEBUG org.apache.calcite.plan.RelOptPlanner - call#840 generated 1 successors: [rel#400:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#391,select=id, EXPR$0, /(CASE(=($f3, 0), null:DOUBLE, $f2), $f3) AS EXPR$1)]
2021-04-15 17:52:24,865 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:24,866 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for VolcanoPlanner
2021-04-15 17:52:24,866 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
FlinkCalcMergeRule                                                            16              25,976
FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)                                12              88,000
ProjectToCalcRule                                                              7              12,117
ProjectCalcMergeRule                                                           6              14,799
FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)                   4             120,206
FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)                           3             140,857
FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)                      3              13,091
ProjectFilterTransposeRule                                                     3              10,067
StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)                   2              59,204
StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)                       2              33,807
AggregateReduceFunctionsRule                                                   2              11,165
FilterToCalcRule                                                               2               8,298
ProjectMergeRule                                                               2               3,942
StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)                             1              28,176
PushProjectIntoLegacyTableSourceScanRule                                       1              14,198
FilterCalcMergeRule                                                            1               2,170
ProjectRemoveRule                                                              1               1,161
FilterProjectTransposeRule                                                     1               1,146
* Total                                                                       69             588,380

2021-04-15 17:52:24,887 DEBUG org.apache.calcite.plan.RelOptPlanner - Cheapest plan:
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp]): rowcount = 9516258.19640405, cumulative cost = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}, id = 402
  FlinkLogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)]): rowcount = 9516258.19640405, cumulative cost = {2.0E8 rows, 4.1E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}, id = 401
    FlinkLogicalLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 374

2021-04-15 17:52:24,888 DEBUG org.apache.calcite.plan.RelOptPlanner - Provenance:
rel#402:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=FlinkLogicalAggregate#401,name=DataStreamTableSink,fields=id, count, avgTemp)
  direct
    rel#382:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#381,name=DataStreamTableSink,fields=id, count, avgTemp)
      call#598 rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)]
        rel#370:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#367,name=DataStreamTableSink,fields=id, count, avgTemp)
          no parent
rel#401:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=FlinkLogicalLegacyTableSourceScan#374,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
  direct
    rel#380:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#375,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
      call#565 rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)]
        rel#366:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#365,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
          no parent
rel#374:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
  call#541 rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)]
    rel#281:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
      no parent

2021-04-15 17:52:24,888 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize logical cost 161 ms.
optimize result: 
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- FlinkLogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
   +- FlinkLogicalLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:52:24,890 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:24,890 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:24,890 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#406:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#405,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:52:24,890 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#404:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#403,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
2021-04-15 17:52:24,890 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#374:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
2021-04-15 17:52:24,891 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize logical_rewrite cost 2 ms.
optimize result: 
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- FlinkLogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
   +- FlinkLogicalLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:52:24,898 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,898 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#374]
2021-04-15 17:52:24,898 DEBUG org.apache.calcite.plan.RelOptPlanner - call#852: Apply rule [StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#374:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:52:24,898 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#415 via StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:52:24,899 DEBUG org.apache.calcite.plan.RelOptPlanner - call#852 generated 1 successors: [rel#415:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:52:24,899 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:24,899 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#409]
2021-04-15 17:52:24,899 DEBUG org.apache.calcite.plan.RelOptPlanner - call#863: Apply rule [StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#409:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#408,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))]
2021-04-15 17:52:24,968 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#419 via StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:52:24,999 DEBUG org.apache.calcite.plan.RelOptPlanner - call#863 generated 1 successors: [rel#419:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#417,groupBy=id,select=id, COUNT_RETRACT(id) AS EXPR$0, AVG_RETRACT(temp) AS EXPR$1)]
2021-04-15 17:52:25,000 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:25,000 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#411]
2021-04-15 17:52:25,000 DEBUG org.apache.calcite.plan.RelOptPlanner - call#879: Apply rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#411:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#410,name=DataStreamTableSink,fields=id, count, avgTemp)]
2021-04-15 17:52:25,000 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#421 via StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:52:25,000 DEBUG org.apache.calcite.plan.RelOptPlanner - call#879 generated 1 successors: [rel#421:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#420,name=DataStreamTableSink,fields=id, count, avgTemp)]
2021-04-15 17:52:25,000 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:25,000 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkExpandConversionRule] rels [#418,#415]
2021-04-15 17:52:25,001 DEBUG org.apache.calcite.plan.RelOptPlanner - call#886: Apply rule [FlinkExpandConversionRule] to [rel#418:AbstractConverter.STREAM_PHYSICAL.hash[0]true.None: 0.[NONE].[NONE](input=RelSubset#416,convention=STREAM_PHYSICAL,FlinkRelDistributionTraitDef=hash[0]true,MiniBatchIntervalTraitDef=None: 0,ModifyKindSetTraitDef=[NONE],UpdateKindTraitDef=[NONE]), rel#415:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:52:25,002 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#422 via FlinkExpandConversionRule
2021-04-15 17:52:25,022 DEBUG org.apache.calcite.plan.RelOptPlanner - call#886 generated 1 successors: [rel#422:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[NONE].[NONE](input=StreamExecLegacyTableSourceScan#415,distribution=hash[id])]
2021-04-15 17:52:25,022 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {4.0E8 rows, 1.71E10 cpu, 2.8E9 io, 2.8E9 network, 0.0 memory}
2021-04-15 17:52:25,022 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for VolcanoPlanner
2021-04-15 17:52:25,023 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
FlinkCalcMergeRule                                                            16              25,976
FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)                                12              88,000
ProjectToCalcRule                                                              7              12,117
ProjectCalcMergeRule                                                           6              14,799
FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)                   4             120,206
FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)                           3             140,857
StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)                   3              60,033
StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)                       3              34,447
FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)                      3              13,091
ProjectFilterTransposeRule                                                     3              10,067
AggregateReduceFunctionsRule                                                   2              11,165
FilterToCalcRule                                                               2               8,298
ProjectMergeRule                                                               2               3,942
StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)                   1             100,602
StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)                             1              28,176
FlinkExpandConversionRule                                                      1              21,350
PushProjectIntoLegacyTableSourceScanRule                                       1              14,198
FilterCalcMergeRule                                                            1               2,170
ProjectRemoveRule                                                              1               1,161
FilterProjectTransposeRule                                                     1               1,146
* Total                                                                       73             711,801

2021-04-15 17:52:25,057 DEBUG org.apache.calcite.plan.RelOptPlanner - Cheapest plan:
StreamExecLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp]): rowcount = 1.0E8, cumulative cost = {4.0E8 rows, 1.71E10 cpu, 2.8E9 io, 2.8E9 network, 0.0 memory}, id = 426
  StreamExecGroupAggregate(groupBy=[id], select=[id, COUNT_RETRACT(id) AS EXPR$0, AVG_RETRACT(temp) AS EXPR$1]): rowcount = 1.0E8, cumulative cost = {3.0E8 rows, 1.7E10 cpu, 2.8E9 io, 2.8E9 network, 0.0 memory}, id = 425
    StreamExecExchange(distribution=[hash[id]]): rowcount = 1.0E8, cumulative cost = {2.0E8 rows, 1.69E10 cpu, 2.8E9 io, 2.8E9 network, 0.0 memory}, id = 424
      StreamExecLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 415

2021-04-15 17:52:25,059 DEBUG org.apache.calcite.plan.RelOptPlanner - Provenance:
rel#426:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=StreamExecGroupAggregate#425,name=DataStreamTableSink,fields=id, count, avgTemp)
  direct
    rel#421:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#420,name=DataStreamTableSink,fields=id, count, avgTemp)
      call#879 rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#411:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#410,name=DataStreamTableSink,fields=id, count, avgTemp)
          no parent
rel#425:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=StreamExecExchange#424,groupBy=id,select=id, COUNT_RETRACT(id) AS EXPR$0, AVG_RETRACT(temp) AS EXPR$1)
  direct
    rel#419:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#417,groupBy=id,select=id, COUNT_RETRACT(id) AS EXPR$0, AVG_RETRACT(temp) AS EXPR$1)
      call#863 rule [StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#409:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#408,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
          no parent
rel#424:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[NONE].[NONE](input=StreamExecLegacyTableSourceScan#415,distribution=hash[id])
  direct
    rel#423:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[NONE].[NONE](input=RelSubset#416,distribution=hash[id])
      call#886 rule [FlinkExpandConversionRule]
        rel#418:AbstractConverter.STREAM_PHYSICAL.hash[0]true.None: 0.[NONE].[NONE](input=RelSubset#416,convention=STREAM_PHYSICAL,FlinkRelDistributionTraitDef=hash[0]true,MiniBatchIntervalTraitDef=None: 0,ModifyKindSetTraitDef=[NONE],UpdateKindTraitDef=[NONE])
          call#863 rule [StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)]
            rel#409 (see above)
        rel#415:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
          call#852 rule [StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)]
            rel#374:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
              no parent
rel#415 (see above)

2021-04-15 17:52:25,060 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize physical cost 168 ms.
optimize result: 
LegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT_RETRACT(id) AS EXPR$0, AVG_RETRACT(temp) AS EXPR$1])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:52:25,060 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:52:25,062 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:25,062 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:25,062 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#432:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#431,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:52:25,062 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#430:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#429,groupBy=id,select=id, COUNT_RETRACT(id) AS EXPR$0, AVG_RETRACT(temp) AS EXPR$1)
2021-04-15 17:52:25,063 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#428:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[NONE].[NONE](input=HepRelVertex#427,distribution=hash[id])
2021-04-15 17:52:25,063 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#415:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
2021-04-15 17:52:25,064 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize watermark transpose cost 3 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT_RETRACT(id) AS EXPR$0, AVG_RETRACT(temp) AS EXPR$1])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:52:25,068 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize Changelog mode inference cost 3 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:52:25,069 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize Initialization for mini-batch interval inference cost 0 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:52:25,070 DEBUG org.apache.calcite.plan.RelOptPlanner - call#891: Apply rule [MiniBatchIntervalInferRule] to [rel#448:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#447,name=DataStreamTableSink,fields=id, count, avgTemp)]
2021-04-15 17:52:25,071 DEBUG org.apache.calcite.plan.RelOptPlanner - call#892: Apply rule [MiniBatchIntervalInferRule] to [rel#446:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[I,U].[BEFORE_AND_AFTER](input=HepRelVertex#445,groupBy=id,select=id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1)]
2021-04-15 17:52:25,071 DEBUG org.apache.calcite.plan.RelOptPlanner - call#893: Apply rule [MiniBatchIntervalInferRule] to [rel#444:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[I].[NONE](input=HepRelVertex#443,distribution=hash[id])]
2021-04-15 17:52:25,072 DEBUG org.apache.calcite.plan.RelOptPlanner - call#894: Apply rule [MiniBatchIntervalInferRule] to [rel#438:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:52:25,072 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:25,072 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
MiniBatchIntervalInferRule                                                     4                 176
* Total                                                                        4                 176

2021-04-15 17:52:25,072 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#448:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#447,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:52:25,072 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#446:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[I,U].[BEFORE_AND_AFTER](input=HepRelVertex#445,groupBy=id,select=id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1)
2021-04-15 17:52:25,073 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#444:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[I].[NONE](input=HepRelVertex#443,distribution=hash[id])
2021-04-15 17:52:25,073 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#438:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
2021-04-15 17:52:25,074 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize mini-batch interval rules cost 4 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:52:25,076 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:25,077 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:25,077 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#455:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#454,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:52:25,077 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#453:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[I,U].[BEFORE_AND_AFTER](input=HepRelVertex#452,groupBy=id,select=id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1)
2021-04-15 17:52:25,077 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#451:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[I].[NONE](input=HepRelVertex#450,distribution=hash[id])
2021-04-15 17:52:25,077 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#438:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
2021-04-15 17:52:25,078 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize physical rewrite cost 3 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:52:25,088 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize physical_rewrite cost 18 ms.
optimize result: 
LegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:52:25,092 INFO org.apache.flink.api.java.typeutils.TypeExtractor - class org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit does not contain a setter for field modificationTime
2021-04-15 17:52:25,092 INFO org.apache.flink.api.java.typeutils.TypeExtractor - Class class org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2021-04-15 17:52:25,093 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:52:25,093 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:52:25,093 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:52:25,093 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:52:25,093 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:52:25,093 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.java.io.RowCsvInputFormat
2021-04-15 17:52:25,093 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:52:25,093 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [Lorg.apache.flink.api.common.typeinfo.TypeInformation;
2021-04-15 17:52:25,094 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [I
2021-04-15 17:52:25,094 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:52:25,094 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Long
2021-04-15 17:52:25,098 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.streaming.api.functions.source.FileProcessingMode
2021-04-15 17:52:25,098 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Long
2021-04-15 17:52:25,098 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:52:25,104 DEBUG o.a.flink.table.planner.codegen.OperatorCodeGenerator$ - Compiling OneInputStreamOperator Code:
SourceConversion
2021-04-15 17:52:25,167 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'isnull' from 'core' module.
2021-04-15 17:52:25,168 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'plus' from 'core' module.
2021-04-15 17:52:25,174 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'ifthenelse' from 'core' module.
2021-04-15 17:52:25,185 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'isnull' from 'core' module.
2021-04-15 17:52:25,186 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'plus' from 'core' module.
2021-04-15 17:52:25,187 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'ifthenelse' from 'core' module.
2021-04-15 17:52:25,188 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'isnull' from 'core' module.
2021-04-15 17:52:25,189 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'plus' from 'core' module.
2021-04-15 17:52:25,190 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'ifthenelse' from 'core' module.
2021-04-15 17:52:25,194 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'equals' from 'core' module.
2021-04-15 17:52:25,195 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'divide' from 'core' module.
2021-04-15 17:52:25,196 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'cast' from 'core' module.
2021-04-15 17:52:25,197 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'ifthenelse' from 'core' module.
2021-04-15 17:52:25,215 DEBUG o.a.flink.table.planner.codegen.OperatorCodeGenerator$ - Compiling OneInputStreamOperator Code:
SinkConversion
2021-04-15 17:52:25,215 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
2021-04-15 17:52:25,215 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:52:25,215 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:52:25,215 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:52:25,215 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:52:25,215 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:52:25,216 INFO org.apache.flink.api.java.typeutils.TypeExtractor - class org.apache.flink.types.Row is missing a default constructor so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2021-04-15 17:52:25,218 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:52:25,219 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:25,219 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:25,219 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#463:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#462,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:52:25,219 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#461:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#460,group={0},cnt=COUNT($0),avgTemp=AVG($1))
2021-04-15 17:52:25,219 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#459:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#458,inputs=0,exprs=[$2])
2021-04-15 17:52:25,219 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#76:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:25,220 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert table references before rewriting sub-queries to semi-join cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:25,221 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:25,221 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:25,221 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#470:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#469,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:52:25,221 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#468:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#467,group={0},cnt=COUNT($0),avgTemp=AVG($1))
2021-04-15 17:52:25,221 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#466:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#465,inputs=0,exprs=[$2])
2021-04-15 17:52:25,222 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#76:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:25,222 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize rewrite sub-queries to semi-join cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:25,223 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:25,223 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:25,223 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#477:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#476,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:52:25,223 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#475:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#474,group={0},cnt=COUNT($0),avgTemp=AVG($1))
2021-04-15 17:52:25,223 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#473:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#472,inputs=0,exprs=[$2])
2021-04-15 17:52:25,223 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#76:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:25,223 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize sub-queries remove cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:25,224 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:25,224 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:25,224 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#484:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#483,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:52:25,224 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#482:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#481,group={0},cnt=COUNT($0),avgTemp=AVG($1))
2021-04-15 17:52:25,224 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#480:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#479,inputs=0,exprs=[$2])
2021-04-15 17:52:25,224 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#76:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:25,225 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert table references after sub-queries removed cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:25,225 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize subquery_rewrite cost 7 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:25,225 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:52:25,226 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:25,226 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:25,226 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#491:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#490,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:52:25,226 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#489:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#488,group={0},cnt=COUNT($0),avgTemp=AVG($1))
2021-04-15 17:52:25,226 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#487:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#486,inputs=0,exprs=[$2])
2021-04-15 17:52:25,226 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#76:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:25,227 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert correlate to temporal table join cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:25,227 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:25,227 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:25,227 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#498:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#497,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:52:25,227 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#496:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#495,group={0},cnt=COUNT($0),avgTemp=AVG($1))
2021-04-15 17:52:25,227 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#494:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#493,inputs=0,exprs=[$2])
2021-04-15 17:52:25,227 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#76:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:25,228 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert enumerable table scan cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:25,229 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize temporal_join_rewrite cost 4 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:25,229 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:52:25,229 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:25,230 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:25,230 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#505:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#504,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:52:25,230 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#503:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#502,group={0},cnt=COUNT($0),avgTemp=AVG($1))
2021-04-15 17:52:25,230 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#501:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#500,inputs=0,exprs=[$2])
2021-04-15 17:52:25,230 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#76:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:25,230 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize pre-rewrite before decorrelation cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:25,231 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize  cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:25,231 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize decorrelate cost 2 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:25,232 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize time_indicator cost 1 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:25,233 DEBUG org.apache.calcite.plan.RelOptPlanner - call#897: Apply rule [ReduceExpressionsRule(Project)] to [rel#511:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#510,inputs=0,exprs=[$2])]
2021-04-15 17:52:25,233 DEBUG org.apache.calcite.plan.RelOptPlanner - call#898: Apply rule [AggregateProjectPullUpConstantsRule] to [rel#513:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#512,group={0},cnt=COUNT($0),avgTemp=AVG($1)), rel#511:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#510,inputs=0,exprs=[$2])]
2021-04-15 17:52:25,235 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:25,236 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
ReduceExpressionsRule(Project)                                                 1                  62
AggregateProjectPullUpConstantsRule                                            1                  17
* Total                                                                        2                  79

2021-04-15 17:52:25,236 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#515:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#514,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:52:25,236 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#513:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#512,group={0},cnt=COUNT($0),avgTemp=AVG($1))
2021-04-15 17:52:25,236 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#511:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#510,inputs=0,exprs=[$2])
2021-04-15 17:52:25,236 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#76:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:25,237 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize default_rewrite cost 4 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:25,237 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:52:25,238 DEBUG org.apache.calcite.plan.RelOptPlanner - call#900: Apply rule [ReduceExpressionsRule(Project)] to [rel#518:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#517,inputs=0,exprs=[$2])]
2021-04-15 17:52:25,238 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:25,238 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
ReduceExpressionsRule(Project)                                                 1                  52
* Total                                                                        1                  52

2021-04-15 17:52:25,238 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#522:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#521,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:52:25,238 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#520:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#519,group={0},cnt=COUNT($0),avgTemp=AVG($1))
2021-04-15 17:52:25,238 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#518:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#517,inputs=0,exprs=[$2])
2021-04-15 17:52:25,238 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#76:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:25,239 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize filter rules cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:25,239 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:25,239 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:25,239 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#529:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#528,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:52:25,239 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#527:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#526,group={0},cnt=COUNT($0),avgTemp=AVG($1))
2021-04-15 17:52:25,239 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#525:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#524,inputs=0,exprs=[$2])
2021-04-15 17:52:25,240 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#76:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:25,240 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize push predicate into table scan cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:25,240 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:25,241 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:25,241 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#536:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#535,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:52:25,241 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#534:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#533,group={0},cnt=COUNT($0),avgTemp=AVG($1))
2021-04-15 17:52:25,242 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#532:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#531,inputs=0,exprs=[$2])
2021-04-15 17:52:25,242 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#76:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:52:25,242 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize prune empty after predicate push down cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:25,243 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize predicate_pushdown cost 5 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:52:25,245 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:25,245 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)] rels [#76]
2021-04-15 17:52:25,245 DEBUG org.apache.calcite.plan.RelOptPlanner - call#912: Apply rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)] to [rel#76:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])]
2021-04-15 17:52:25,246 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#547 via FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:25,246 DEBUG org.apache.calcite.plan.RelOptPlanner - call#912 generated 1 successors: [rel#547:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:52:25,246 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:25,247 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [PushProjectIntoLegacyTableSourceScanRule] rels [#539,#76]
2021-04-15 17:52:25,247 DEBUG org.apache.calcite.plan.RelOptPlanner - call#928: Apply rule [PushProjectIntoLegacyTableSourceScanRule] to [rel#539:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#538,inputs=0,exprs=[$2]), rel#76:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])]
2021-04-15 17:52:25,247 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#549 via PushProjectIntoLegacyTableSourceScanRule
2021-04-15 17:52:25,247 DEBUG org.apache.calcite.plan.RelOptPlanner - call#928 generated 1 successors: [rel#549:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]])]
2021-04-15 17:52:25,248 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:25,248 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#539]
2021-04-15 17:52:25,248 DEBUG org.apache.calcite.plan.RelOptPlanner - call#938: Apply rule [ProjectToCalcRule] to [rel#539:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#538,inputs=0,exprs=[$2])]
2021-04-15 17:52:25,248 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#551 via ProjectToCalcRule
2021-04-15 17:52:25,248 DEBUG org.apache.calcite.plan.RelOptPlanner - call#938 generated 1 successors: [rel#551:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#538,expr#0..2={inputs},0=$t0,1=$t2)]
2021-04-15 17:52:25,248 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:25,248 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [AggregateProjectPullUpConstantsRule] rels [#541,#539]
2021-04-15 17:52:25,248 DEBUG org.apache.calcite.plan.RelOptPlanner - call#942: Apply rule [AggregateProjectPullUpConstantsRule] to [rel#541:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#540,group={0},cnt=COUNT($0),avgTemp=AVG($1)), rel#539:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#538,inputs=0,exprs=[$2])]
2021-04-15 17:52:25,248 DEBUG org.apache.calcite.plan.RelOptPlanner - call#942 generated 0 successors.
2021-04-15 17:52:25,249 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:25,249 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [AggregateProjectMergeRule] rels [#541,#539]
2021-04-15 17:52:25,249 DEBUG org.apache.calcite.plan.RelOptPlanner - call#947: Apply rule [AggregateProjectMergeRule] to [rel#541:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#540,group={0},cnt=COUNT($0),avgTemp=AVG($1)), rel#539:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#538,inputs=0,exprs=[$2])]
2021-04-15 17:52:25,251 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#552 via AggregateProjectMergeRule
2021-04-15 17:52:25,251 DEBUG org.apache.calcite.plan.RelOptPlanner - call#947 generated 1 successors: [rel#552:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#538,group={0},cnt=COUNT($0),avgTemp=AVG($2))]
2021-04-15 17:52:25,251 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:25,251 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [AggregateReduceFunctionsRule] rels [#541]
2021-04-15 17:52:25,252 DEBUG org.apache.calcite.plan.RelOptPlanner - call#958: Apply rule [AggregateReduceFunctionsRule] to [rel#541:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#540,group={0},cnt=COUNT($0),avgTemp=AVG($1))]
2021-04-15 17:52:25,252 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#554 via AggregateReduceFunctionsRule
2021-04-15 17:52:25,254 DEBUG org.apache.calcite.plan.RelOptPlanner - call#958 generated 1 successors: [rel#554:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=LogicalAggregate#553,inputs=0..1,exprs=[/($2, $3)])]
2021-04-15 17:52:25,254 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:25,254 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] rels [#541]
2021-04-15 17:52:25,254 DEBUG org.apache.calcite.plan.RelOptPlanner - call#963: Apply rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] to [rel#541:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#540,group={0},cnt=COUNT($0),avgTemp=AVG($1))]
2021-04-15 17:52:25,254 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#558 via FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:25,255 DEBUG org.apache.calcite.plan.RelOptPlanner - call#963 generated 1 successors: [rel#558:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#557,group={0},cnt=COUNT($0),avgTemp=AVG($1))]
2021-04-15 17:52:25,255 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:25,255 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)] rels [#543]
2021-04-15 17:52:25,255 DEBUG org.apache.calcite.plan.RelOptPlanner - call#970: Apply rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)] to [rel#543:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#542,name=DataStreamTableSink,fields=id, cnt, avgTemp)]
2021-04-15 17:52:25,256 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#560 via FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:25,258 DEBUG org.apache.calcite.plan.RelOptPlanner - call#970 generated 1 successors: [rel#560:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#559,name=DataStreamTableSink,fields=id, cnt, avgTemp)]
2021-04-15 17:52:25,258 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:25,258 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)] rels [#549]
2021-04-15 17:52:25,258 DEBUG org.apache.calcite.plan.RelOptPlanner - call#992: Apply rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)] to [rel#549:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]])]
2021-04-15 17:52:25,258 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#562 via FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:25,259 DEBUG org.apache.calcite.plan.RelOptPlanner - call#992 generated 1 successors: [rel#562:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:52:25,259 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,260 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#551]
2021-04-15 17:52:25,260 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1006: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#551:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#538,expr#0..2={inputs},0=$t0,1=$t2)]
2021-04-15 17:52:25,260 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#563 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:25,260 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1006 generated 1 successors: [rel#563:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#548,select=id, temp)]
2021-04-15 17:52:25,260 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,260 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [AggregateReduceFunctionsRule] rels [#552]
2021-04-15 17:52:25,261 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1023: Apply rule [AggregateReduceFunctionsRule] to [rel#552:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#538,group={0},cnt=COUNT($0),avgTemp=AVG($2))]
2021-04-15 17:52:25,261 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#565 via AggregateReduceFunctionsRule
2021-04-15 17:52:25,262 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1023 generated 1 successors: [rel#565:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=LogicalAggregate#564,inputs=0..1,exprs=[/($2, $3)])]
2021-04-15 17:52:25,262 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,262 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] rels [#552]
2021-04-15 17:52:25,262 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1028: Apply rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] to [rel#552:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#538,group={0},cnt=COUNT($0),avgTemp=AVG($2))]
2021-04-15 17:52:25,263 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#568 via FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:25,263 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1028 generated 1 successors: [rel#568:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#548,group={0},cnt=COUNT($0),avgTemp=AVG($2))]
2021-04-15 17:52:25,263 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,263 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [AggregateProjectPullUpConstantsRule] rels [#553,#539]
2021-04-15 17:52:25,263 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1031: Apply rule [AggregateProjectPullUpConstantsRule] to [rel#553:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#540,group={0},cnt=COUNT($0),agg#1=SUM($1),agg#2=COUNT($1)), rel#539:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#538,inputs=0,exprs=[$2])]
2021-04-15 17:52:25,263 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1031 generated 0 successors.
2021-04-15 17:52:25,263 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,264 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [AggregateProjectMergeRule] rels [#553,#539]
2021-04-15 17:52:25,264 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1036: Apply rule [AggregateProjectMergeRule] to [rel#553:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#540,group={0},cnt=COUNT($0),agg#1=SUM($1),agg#2=COUNT($1)), rel#539:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#538,inputs=0,exprs=[$2])]
2021-04-15 17:52:25,264 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#569 via AggregateProjectMergeRule
2021-04-15 17:52:25,265 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1036 generated 1 successors: [rel#569:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#538,group={0},cnt=COUNT($0),agg#1=SUM($2),agg#2=COUNT($2))]
2021-04-15 17:52:25,265 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,265 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [AggregateReduceFunctionsRule] rels [#553]
2021-04-15 17:52:25,265 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1047: Apply rule [AggregateReduceFunctionsRule] to [rel#553:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#540,group={0},cnt=COUNT($0),agg#1=SUM($1),agg#2=COUNT($1))]
2021-04-15 17:52:25,267 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#571 via AggregateReduceFunctionsRule
2021-04-15 17:52:25,268 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1047 generated 1 successors: [rel#571:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=LogicalAggregate#570,inputs=0..1,exprs=[CASE(=($3, 0), null:DOUBLE, $2), $3])]
2021-04-15 17:52:25,268 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,268 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] rels [#553]
2021-04-15 17:52:25,268 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1052: Apply rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] to [rel#553:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#540,group={0},cnt=COUNT($0),agg#1=SUM($1),agg#2=COUNT($1))]
2021-04-15 17:52:25,268 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#574 via FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:25,269 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1052 generated 1 successors: [rel#574:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#557,group={0},cnt=COUNT($0),agg#1=SUM($1),agg#2=COUNT($1))]
2021-04-15 17:52:25,269 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,269 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#556]
2021-04-15 17:52:25,269 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1075: Apply rule [ProjectToCalcRule] to [rel#556:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#555,inputs=0..1,exprs=[/($2, $3)])]
2021-04-15 17:52:25,269 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#576 via ProjectToCalcRule
2021-04-15 17:52:25,270 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1075 generated 1 successors: [rel#576:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#555,expr#0..3={inputs},expr#4=/($t2, $t3),proj#0..1={exprs},2=$t4)]
2021-04-15 17:52:25,270 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,271 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [AggregateReduceFunctionsRule] rels [#564]
2021-04-15 17:52:25,271 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1121: Apply rule [AggregateReduceFunctionsRule] to [rel#564:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#538,group={0},cnt=COUNT($0),agg#1=SUM($2),agg#2=COUNT($2))]
2021-04-15 17:52:25,272 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#578 via AggregateReduceFunctionsRule
2021-04-15 17:52:25,273 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1121 generated 1 successors: [rel#578:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=LogicalAggregate#577,inputs=0..1,exprs=[CASE(=($3, 0), null:DOUBLE, $2), $3])]
2021-04-15 17:52:25,273 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,273 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] rels [#564]
2021-04-15 17:52:25,273 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1126: Apply rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] to [rel#564:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#538,group={0},cnt=COUNT($0),agg#1=SUM($2),agg#2=COUNT($2))]
2021-04-15 17:52:25,273 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#581 via FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:25,274 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1126 generated 1 successors: [rel#581:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#548,group={0},cnt=COUNT($0),agg#1=SUM($2),agg#2=COUNT($2))]
2021-04-15 17:52:25,274 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,274 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#567]
2021-04-15 17:52:25,274 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1149: Apply rule [ProjectToCalcRule] to [rel#567:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#555,inputs=0..1,exprs=[/($2, $3)])]
2021-04-15 17:52:25,274 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#582 via ProjectToCalcRule
2021-04-15 17:52:25,275 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1149 generated 1 successors: [rel#582:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#555,expr#0..3={inputs},expr#4=/($t2, $t3),proj#0..1={exprs},2=$t4)]
2021-04-15 17:52:25,275 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,275 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [AggregateProjectPullUpConstantsRule] rels [#570,#539]
2021-04-15 17:52:25,275 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1209: Apply rule [AggregateProjectPullUpConstantsRule] to [rel#570:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#540,group={0},cnt=COUNT($0),agg#1=$SUM0($1),agg#2=COUNT($1)), rel#539:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#538,inputs=0,exprs=[$2])]
2021-04-15 17:52:25,275 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1209 generated 0 successors.
2021-04-15 17:52:25,275 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,275 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [AggregateProjectMergeRule] rels [#570,#539]
2021-04-15 17:52:25,275 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1214: Apply rule [AggregateProjectMergeRule] to [rel#570:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#540,group={0},cnt=COUNT($0),agg#1=$SUM0($1),agg#2=COUNT($1)), rel#539:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#538,inputs=0,exprs=[$2])]
2021-04-15 17:52:25,275 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#583 via AggregateProjectMergeRule
2021-04-15 17:52:25,276 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1214 generated 1 successors: [rel#583:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#538,group={0},cnt=COUNT($0),agg#1=$SUM0($2),agg#2=COUNT($2))]
2021-04-15 17:52:25,277 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,277 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] rels [#570]
2021-04-15 17:52:25,277 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1229: Apply rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] to [rel#570:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#540,group={0},cnt=COUNT($0),agg#1=$SUM0($1),agg#2=COUNT($1))]
2021-04-15 17:52:25,277 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#584 via FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:25,277 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1229 generated 1 successors: [rel#584:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#557,group={0},cnt=COUNT($0),agg#1=$SUM0($1),agg#2=COUNT($1))]
2021-04-15 17:52:25,277 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,278 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectMergeRule] rels [#556,#573]
2021-04-15 17:52:25,278 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1236: Apply rule [ProjectMergeRule] to [rel#556:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#555,inputs=0..1,exprs=[/($2, $3)]), rel#573:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#572,inputs=0..1,exprs=[CASE(=($3, 0), null:DOUBLE, $2), $3])]
2021-04-15 17:52:25,278 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#586 via ProjectMergeRule
2021-04-15 17:52:25,278 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1236 generated 1 successors: [rel#586:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#572,inputs=0..1,exprs=[/(CASE(=($3, 0), null:DOUBLE, $2), $3)])]
2021-04-15 17:52:25,279 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,279 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#573]
2021-04-15 17:52:25,279 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1253: Apply rule [ProjectToCalcRule] to [rel#573:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#572,inputs=0..1,exprs=[CASE(=($3, 0), null:DOUBLE, $2), $3])]
2021-04-15 17:52:25,279 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#587 via ProjectToCalcRule
2021-04-15 17:52:25,280 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1253 generated 1 successors: [rel#587:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#572,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),proj#0..1={exprs},2=$t7,3=$t3)]
2021-04-15 17:52:25,280 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,280 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#576]
2021-04-15 17:52:25,280 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1276: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#576:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#555,expr#0..3={inputs},expr#4=/($t2, $t3),proj#0..1={exprs},2=$t4)]
2021-04-15 17:52:25,280 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#588 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:25,281 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1276 generated 1 successors: [rel#588:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#575,select=id, cnt, /($f2, $f3) AS avgTemp)]
2021-04-15 17:52:25,281 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,281 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] rels [#577]
2021-04-15 17:52:25,281 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1297: Apply rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] to [rel#577:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#538,group={0},cnt=COUNT($0),agg#1=$SUM0($2),agg#2=COUNT($2))]
2021-04-15 17:52:25,281 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#589 via FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:25,282 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1297 generated 1 successors: [rel#589:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#548,group={0},cnt=COUNT($0),agg#1=$SUM0($2),agg#2=COUNT($2))]
2021-04-15 17:52:25,282 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,282 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectMergeRule] rels [#556,#580]
2021-04-15 17:52:25,282 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1304: Apply rule [ProjectMergeRule] to [rel#556:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#555,inputs=0..1,exprs=[/($2, $3)]), rel#580:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#572,inputs=0..1,exprs=[CASE(=($3, 0), null:DOUBLE, $2), $3])]
2021-04-15 17:52:25,283 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#590 via ProjectMergeRule
2021-04-15 17:52:25,283 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1304 generated 1 successors: [rel#590:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#572,inputs=0..1,exprs=[/(CASE(=($3, 0), null:DOUBLE, $2), $3)])]
2021-04-15 17:52:25,283 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,284 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#580]
2021-04-15 17:52:25,284 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1321: Apply rule [ProjectToCalcRule] to [rel#580:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#572,inputs=0..1,exprs=[CASE(=($3, 0), null:DOUBLE, $2), $3])]
2021-04-15 17:52:25,284 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#591 via ProjectToCalcRule
2021-04-15 17:52:25,284 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1321 generated 1 successors: [rel#591:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#572,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),proj#0..1={exprs},2=$t7,3=$t3)]
2021-04-15 17:52:25,284 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,284 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#586]
2021-04-15 17:52:25,285 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1409: Apply rule [ProjectToCalcRule] to [rel#586:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#572,inputs=0..1,exprs=[/(CASE(=($3, 0), null:DOUBLE, $2), $3)])]
2021-04-15 17:52:25,285 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#592 via ProjectToCalcRule
2021-04-15 17:52:25,286 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1409 generated 1 successors: [rel#592:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#572,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),expr#8=/($t7, $t3),proj#0..1={exprs},2=$t8)]
2021-04-15 17:52:25,286 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,286 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectCalcMergeRule] rels [#556,#587]
2021-04-15 17:52:25,286 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1419: Apply rule [ProjectCalcMergeRule] to [rel#556:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#555,inputs=0..1,exprs=[/($2, $3)]), rel#587:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#572,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),proj#0..1={exprs},2=$t7,3=$t3)]
2021-04-15 17:52:25,287 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#593 via ProjectCalcMergeRule
2021-04-15 17:52:25,288 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1419 generated 1 successors: [rel#593:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#572,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),expr#8=/($t7, $t3),proj#0..1={exprs},2=$t8)]
2021-04-15 17:52:25,288 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,288 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#576,#587]
2021-04-15 17:52:25,288 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1422: Apply rule [FlinkCalcMergeRule] to [rel#576:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#555,expr#0..3={inputs},expr#4=/($t2, $t3),proj#0..1={exprs},2=$t4), rel#587:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#572,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),proj#0..1={exprs},2=$t7,3=$t3)]
2021-04-15 17:52:25,289 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#594 via FlinkCalcMergeRule
2021-04-15 17:52:25,289 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1422 generated 1 successors: [rel#594:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#572,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),expr#8=/($t7, $t3),proj#0..1={exprs},2=$t8)]
2021-04-15 17:52:25,289 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,289 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#587]
2021-04-15 17:52:25,289 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1424: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#587:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#572,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),proj#0..1={exprs},2=$t7,3=$t3)]
2021-04-15 17:52:25,289 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#595 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:25,290 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1424 generated 1 successors: [rel#595:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#585,select=id, cnt, CASE(=($f3, 0), null:DOUBLE, $f2) AS $f2, $f3)]
2021-04-15 17:52:25,290 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,290 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#592]
2021-04-15 17:52:25,290 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1454: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#592:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#572,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),expr#8=/($t7, $t3),proj#0..1={exprs},2=$t8)]
2021-04-15 17:52:25,290 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#596 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:52:25,291 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1454 generated 1 successors: [rel#596:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#585,select=id, cnt, /(CASE(=($f3, 0), null:DOUBLE, $f2), $f3) AS avgTemp)]
2021-04-15 17:52:25,291 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,291 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#588,#595]
2021-04-15 17:52:25,291 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1463: Apply rule [FlinkCalcMergeRule] to [rel#588:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#575,select=id, cnt, /($f2, $f3) AS avgTemp), rel#595:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#585,select=id, cnt, CASE(=($f3, 0), null:DOUBLE, $f2) AS $f2, $f3)]
2021-04-15 17:52:25,292 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#597 via FlinkCalcMergeRule
2021-04-15 17:52:25,292 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1463 generated 1 successors: [rel#597:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#585,select=id, cnt, /(CASE(=($f3, 0), null:DOUBLE, $f2), $f3) AS avgTemp)]
2021-04-15 17:52:25,293 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:52:25,293 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for VolcanoPlanner
2021-04-15 17:52:25,293 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
FlinkCalcMergeRule                                                            18              28,013
FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)                                16              91,799
ProjectToCalcRule                                                             13              17,126
FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)                      9              18,023
ProjectCalcMergeRule                                                           7              16,126
FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)                   6             122,214
AggregateReduceFunctionsRule                                                   6              20,167
FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)                           4             143,028
ProjectMergeRule                                                               4               6,055
StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)                   3              60,033
StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)                       3              34,447
ProjectFilterTransposeRule                                                     3              10,067
AggregateProjectMergeRule                                                      3               5,353
AggregateProjectPullUpConstantsRule                                            3                 137
PushProjectIntoLegacyTableSourceScanRule                                       2              15,163
FilterToCalcRule                                                               2               8,298
StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)                   1             100,602
StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)                             1              28,176
FlinkExpandConversionRule                                                      1              21,350
FilterCalcMergeRule                                                            1               2,170
ProjectRemoveRule                                                              1               1,161
FilterProjectTransposeRule                                                     1               1,146
* Total                                                                      108             750,654

2021-04-15 17:52:25,295 DEBUG org.apache.calcite.plan.RelOptPlanner - Cheapest plan:
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp]): rowcount = 9516258.19640405, cumulative cost = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}, id = 599
  FlinkLogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)]): rowcount = 9516258.19640405, cumulative cost = {2.0E8 rows, 4.1E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}, id = 598
    FlinkLogicalLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, timestamp, temp]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}, id = 562

2021-04-15 17:52:25,297 DEBUG org.apache.calcite.plan.RelOptPlanner - Provenance:
rel#599:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=FlinkLogicalAggregate#598,name=DataStreamTableSink,fields=id, cnt, avgTemp)
  direct
    rel#560:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#559,name=DataStreamTableSink,fields=id, cnt, avgTemp)
      call#970 rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)]
        rel#543:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#542,name=DataStreamTableSink,fields=id, cnt, avgTemp)
          no parent
rel#598:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=FlinkLogicalLegacyTableSourceScan#562,group={0},cnt=COUNT($0),avgTemp=AVG($1))
  direct
    rel#558:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#557,group={0},cnt=COUNT($0),avgTemp=AVG($1))
      call#963 rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)]
        rel#541:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#540,group={0},cnt=COUNT($0),avgTemp=AVG($1))
          no parent
rel#562:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, timestamp, temp)
  call#992 rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)]
    rel#549:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]])
      call#928 rule [PushProjectIntoLegacyTableSourceScanRule]
        rel#539:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#538,inputs=0,exprs=[$2])
          no parent
        rel#76:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
          no parent

2021-04-15 17:52:25,297 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize logical cost 54 ms.
optimize result: 
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- FlinkLogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- FlinkLogicalLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:52:25,298 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:25,298 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:25,298 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#603:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#602,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:52:25,298 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#601:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#600,group={0},cnt=COUNT($0),avgTemp=AVG($1))
2021-04-15 17:52:25,299 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#562:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, timestamp, temp)
2021-04-15 17:52:25,300 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize logical_rewrite cost 2 ms.
optimize result: 
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- FlinkLogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- FlinkLogicalLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:52:25,308 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:25,308 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#562]
2021-04-15 17:52:25,309 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1475: Apply rule [StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#562:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:52:25,309 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#612 via StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:52:25,309 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1475 generated 1 successors: [rel#612:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)]
2021-04-15 17:52:25,309 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:25,309 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#606]
2021-04-15 17:52:25,310 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1486: Apply rule [StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#606:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#605,group={0},cnt=COUNT($0),avgTemp=AVG($1))]
2021-04-15 17:52:25,311 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#616 via StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:52:25,311 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1486 generated 1 successors: [rel#616:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#614,groupBy=id,select=id, COUNT_RETRACT(id) AS cnt, AVG_RETRACT(temp) AS avgTemp)]
2021-04-15 17:52:25,312 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:25,312 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#608]
2021-04-15 17:52:25,312 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1502: Apply rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#608:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#607,name=DataStreamTableSink,fields=id, cnt, avgTemp)]
2021-04-15 17:52:25,312 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#618 via StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:52:25,312 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1502 generated 1 successors: [rel#618:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#617,name=DataStreamTableSink,fields=id, cnt, avgTemp)]
2021-04-15 17:52:25,313 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:52:25,313 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkExpandConversionRule] rels [#615,#612]
2021-04-15 17:52:25,313 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1509: Apply rule [FlinkExpandConversionRule] to [rel#615:AbstractConverter.STREAM_PHYSICAL.hash[0]true.None: 0.[NONE].[NONE](input=RelSubset#613,convention=STREAM_PHYSICAL,FlinkRelDistributionTraitDef=hash[0]true,MiniBatchIntervalTraitDef=None: 0,ModifyKindSetTraitDef=[NONE],UpdateKindTraitDef=[NONE]), rel#612:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)]
2021-04-15 17:52:25,313 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#619 via FlinkExpandConversionRule
2021-04-15 17:52:25,313 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1509 generated 1 successors: [rel#619:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[NONE].[NONE](input=StreamExecLegacyTableSourceScan#612,distribution=hash[id])]
2021-04-15 17:52:25,314 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {4.0E8 rows, 1.71E10 cpu, 2.0E9 io, 2.0E9 network, 0.0 memory}
2021-04-15 17:52:25,314 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for VolcanoPlanner
2021-04-15 17:52:25,315 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
FlinkCalcMergeRule                                                            18              28,013
FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)                                16              91,799
ProjectToCalcRule                                                             13              17,126
FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)                      9              18,023
ProjectCalcMergeRule                                                           7              16,126
FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)                   6             122,214
AggregateReduceFunctionsRule                                                   6              20,167
FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)                           4             143,028
StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)                   4              60,658
StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)                       4              35,180
ProjectMergeRule                                                               4               6,055
ProjectFilterTransposeRule                                                     3              10,067
AggregateProjectMergeRule                                                      3               5,353
AggregateProjectPullUpConstantsRule                                            3                 137
StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)                   2             102,779
FlinkExpandConversionRule                                                      2              22,627
PushProjectIntoLegacyTableSourceScanRule                                       2              15,163
FilterToCalcRule                                                               2               8,298
StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)                             1              28,176
FilterCalcMergeRule                                                            1               2,170
ProjectRemoveRule                                                              1               1,161
FilterProjectTransposeRule                                                     1               1,146
* Total                                                                      112             755,466

2021-04-15 17:52:25,317 DEBUG org.apache.calcite.plan.RelOptPlanner - Cheapest plan:
StreamExecLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp]): rowcount = 1.0E8, cumulative cost = {4.0E8 rows, 1.71E10 cpu, 2.0E9 io, 2.0E9 network, 0.0 memory}, id = 623
  StreamExecGroupAggregate(groupBy=[id], select=[id, COUNT_RETRACT(id) AS cnt, AVG_RETRACT(temp) AS avgTemp]): rowcount = 1.0E8, cumulative cost = {3.0E8 rows, 1.7E10 cpu, 2.0E9 io, 2.0E9 network, 0.0 memory}, id = 622
    StreamExecExchange(distribution=[hash[id]]): rowcount = 1.0E8, cumulative cost = {2.0E8 rows, 1.69E10 cpu, 2.0E9 io, 2.0E9 network, 0.0 memory}, id = 621
      StreamExecLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}, id = 612

2021-04-15 17:52:25,319 DEBUG org.apache.calcite.plan.RelOptPlanner - Provenance:
rel#623:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=StreamExecGroupAggregate#622,name=DataStreamTableSink,fields=id, cnt, avgTemp)
  direct
    rel#618:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#617,name=DataStreamTableSink,fields=id, cnt, avgTemp)
      call#1502 rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#608:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#607,name=DataStreamTableSink,fields=id, cnt, avgTemp)
          no parent
rel#622:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=StreamExecExchange#621,groupBy=id,select=id, COUNT_RETRACT(id) AS cnt, AVG_RETRACT(temp) AS avgTemp)
  direct
    rel#616:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#614,groupBy=id,select=id, COUNT_RETRACT(id) AS cnt, AVG_RETRACT(temp) AS avgTemp)
      call#1486 rule [StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#606:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#605,group={0},cnt=COUNT($0),avgTemp=AVG($1))
          no parent
rel#621:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[NONE].[NONE](input=StreamExecLegacyTableSourceScan#612,distribution=hash[id])
  direct
    rel#620:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[NONE].[NONE](input=RelSubset#613,distribution=hash[id])
      call#1509 rule [FlinkExpandConversionRule]
        rel#615:AbstractConverter.STREAM_PHYSICAL.hash[0]true.None: 0.[NONE].[NONE](input=RelSubset#613,convention=STREAM_PHYSICAL,FlinkRelDistributionTraitDef=hash[0]true,MiniBatchIntervalTraitDef=None: 0,ModifyKindSetTraitDef=[NONE],UpdateKindTraitDef=[NONE])
          call#1486 rule [StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)]
            rel#606 (see above)
        rel#612:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)
          call#1475 rule [StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)]
            rel#562:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, timestamp, temp)
              no parent
rel#612 (see above)

2021-04-15 17:52:25,319 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize physical cost 18 ms.
optimize result: 
LegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT_RETRACT(id) AS cnt, AVG_RETRACT(temp) AS avgTemp])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:52:25,319 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:52:25,321 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:25,321 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:25,321 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#629:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#628,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:52:25,321 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#627:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#626,groupBy=id,select=id, COUNT_RETRACT(id) AS cnt, AVG_RETRACT(temp) AS avgTemp)
2021-04-15 17:52:25,322 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#625:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[NONE].[NONE](input=HepRelVertex#624,distribution=hash[id])
2021-04-15 17:52:25,322 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#612:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)
2021-04-15 17:52:25,324 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize watermark transpose cost 3 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT_RETRACT(id) AS cnt, AVG_RETRACT(temp) AS avgTemp])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:52:25,328 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize Changelog mode inference cost 3 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:52:25,329 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize Initialization for mini-batch interval inference cost 0 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:52:25,332 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1514: Apply rule [MiniBatchIntervalInferRule] to [rel#645:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#644,name=DataStreamTableSink,fields=id, cnt, avgTemp)]
2021-04-15 17:52:25,333 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1515: Apply rule [MiniBatchIntervalInferRule] to [rel#643:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[I,U].[BEFORE_AND_AFTER](input=HepRelVertex#642,groupBy=id,select=id, COUNT(id) AS cnt, AVG(temp) AS avgTemp)]
2021-04-15 17:52:25,333 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1516: Apply rule [MiniBatchIntervalInferRule] to [rel#641:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[I].[NONE](input=HepRelVertex#640,distribution=hash[id])]
2021-04-15 17:52:25,333 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1517: Apply rule [MiniBatchIntervalInferRule] to [rel#635:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)]
2021-04-15 17:52:25,333 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:25,333 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
MiniBatchIntervalInferRule                                                     4                 186
* Total                                                                        4                 186

2021-04-15 17:52:25,333 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#645:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#644,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:52:25,334 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#643:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[I,U].[BEFORE_AND_AFTER](input=HepRelVertex#642,groupBy=id,select=id, COUNT(id) AS cnt, AVG(temp) AS avgTemp)
2021-04-15 17:52:25,334 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#641:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[I].[NONE](input=HepRelVertex#640,distribution=hash[id])
2021-04-15 17:52:25,334 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#635:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)
2021-04-15 17:52:25,335 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize mini-batch interval rules cost 5 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:52:25,336 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:52:25,336 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:52:25,336 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#652:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#651,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:52:25,336 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#650:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[I,U].[BEFORE_AND_AFTER](input=HepRelVertex#649,groupBy=id,select=id, COUNT(id) AS cnt, AVG(temp) AS avgTemp)
2021-04-15 17:52:25,337 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#648:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[I].[NONE](input=HepRelVertex#647,distribution=hash[id])
2021-04-15 17:52:25,337 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#635:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)
2021-04-15 17:52:25,337 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize physical rewrite cost 2 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:52:25,338 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize physical_rewrite cost 19 ms.
optimize result: 
LegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:52:25,352 INFO org.apache.flink.api.java.typeutils.TypeExtractor - class org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit does not contain a setter for field modificationTime
2021-04-15 17:52:25,352 INFO org.apache.flink.api.java.typeutils.TypeExtractor - Class class org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2021-04-15 17:52:25,353 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:52:25,353 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:52:25,353 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:52:25,353 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:52:25,353 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:52:25,353 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.java.io.RowCsvInputFormat
2021-04-15 17:52:25,353 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:52:25,353 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [Lorg.apache.flink.api.common.typeinfo.TypeInformation;
2021-04-15 17:52:25,353 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [I
2021-04-15 17:52:25,353 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:52:25,353 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Long
2021-04-15 17:52:25,354 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.streaming.api.functions.source.FileProcessingMode
2021-04-15 17:52:25,354 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Long
2021-04-15 17:52:25,354 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:52:25,358 DEBUG o.a.flink.table.planner.codegen.OperatorCodeGenerator$ - Compiling OneInputStreamOperator Code:
SourceConversion
2021-04-15 17:52:25,363 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'isnull' from 'core' module.
2021-04-15 17:52:25,364 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'plus' from 'core' module.
2021-04-15 17:52:25,365 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'ifthenelse' from 'core' module.
2021-04-15 17:52:25,368 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'isnull' from 'core' module.
2021-04-15 17:52:25,369 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'plus' from 'core' module.
2021-04-15 17:52:25,369 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'ifthenelse' from 'core' module.
2021-04-15 17:52:25,370 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'isnull' from 'core' module.
2021-04-15 17:52:25,371 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'plus' from 'core' module.
2021-04-15 17:52:25,372 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'ifthenelse' from 'core' module.
2021-04-15 17:52:25,374 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'equals' from 'core' module.
2021-04-15 17:52:25,375 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'divide' from 'core' module.
2021-04-15 17:52:25,377 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'cast' from 'core' module.
2021-04-15 17:52:25,378 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'ifthenelse' from 'core' module.
2021-04-15 17:52:25,383 DEBUG o.a.flink.table.planner.codegen.OperatorCodeGenerator$ - Compiling OneInputStreamOperator Code:
SinkConversion
2021-04-15 17:52:25,384 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
2021-04-15 17:52:25,384 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:52:25,384 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:52:25,384 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:52:25,384 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:52:25,384 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:52:25,415 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=4, name='SinkConversionToRow', outputType=Row(id: String, timestamp: Long, temp: Double), parallelism=1}
2021-04-15 17:52:25,418 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=3, name='SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp])', outputType=ROW<`id` STRING, `timestamp` BIGINT, `temp` DOUBLE>(org.apache.flink.table.data.RowData, org.apache.flink.table.runtime.typeutils.RowDataSerializer), parallelism=1}
2021-04-15 17:52:25,418 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=2, name='CsvTableSource(read fields: id, timestamp, temp)', outputType=Row(id: String, timestamp: Long, temp: Double), parallelism=1}
2021-04-15 17:52:25,418 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySourceTransformation{id=1, name='Custom File source', outputType=GenericType<org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit>, parallelism=1}
2021-04-15 17:52:25,431 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 1
2021-04-15 17:52:25,433 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 2
2021-04-15 17:52:25,443 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 3
2021-04-15 17:52:25,443 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 4
2021-04-15 17:52:25,443 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySinkTransformation{id=5, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=1}
2021-04-15 17:52:25,443 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 5
2021-04-15 17:52:25,444 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=10, name='SinkConversionToRow', outputType=Row(id: String, temp: Double), parallelism=1}
2021-04-15 17:52:25,444 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=9, name='Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')])', outputType=ROW<`id` STRING, `temp` DOUBLE>(org.apache.flink.table.data.RowData, org.apache.flink.table.runtime.typeutils.RowDataSerializer), parallelism=1}
2021-04-15 17:52:25,446 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=8, name='SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp])', outputType=ROW<`id` STRING, `temp` DOUBLE>(org.apache.flink.table.data.RowData, org.apache.flink.table.runtime.typeutils.RowDataSerializer), parallelism=1}
2021-04-15 17:52:25,446 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=7, name='CsvTableSource(read fields: id, temp)', outputType=Row(id: String, temp: Double), parallelism=1}
2021-04-15 17:52:25,446 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySourceTransformation{id=6, name='Custom File source', outputType=GenericType<org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit>, parallelism=1}
2021-04-15 17:52:25,447 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 6
2021-04-15 17:52:25,447 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 7
2021-04-15 17:52:25,447 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 8
2021-04-15 17:52:25,447 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 9
2021-04-15 17:52:25,447 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 10
2021-04-15 17:52:25,448 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySinkTransformation{id=11, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=1}
2021-04-15 17:52:25,448 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 11
2021-04-15 17:52:25,448 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=17, name='SinkConversionToTuple2', outputType=Java Tuple2<Boolean, Row(id: String, EXPR$0: Long, EXPR$1: Double)>, parallelism=-1}
2021-04-15 17:52:25,448 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=16, name='GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1])', outputType=ROW<`id` STRING, `EXPR$0` BIGINT NOT NULL, `EXPR$1` DOUBLE>(org.apache.flink.table.data.RowData, org.apache.flink.table.runtime.typeutils.RowDataSerializer), parallelism=-1}
2021-04-15 17:52:25,448 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming PartitionTransformation{id=15, name='Partition', outputType=ROW<`id` STRING, `timestamp` BIGINT, `temp` DOUBLE>(org.apache.flink.table.data.RowData, org.apache.flink.table.runtime.typeutils.RowDataSerializer), parallelism=-1}
2021-04-15 17:52:25,448 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=14, name='SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp])', outputType=ROW<`id` STRING, `timestamp` BIGINT, `temp` DOUBLE>(org.apache.flink.table.data.RowData, org.apache.flink.table.runtime.typeutils.RowDataSerializer), parallelism=1}
2021-04-15 17:52:25,448 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=13, name='CsvTableSource(read fields: id, timestamp, temp)', outputType=Row(id: String, timestamp: Long, temp: Double), parallelism=1}
2021-04-15 17:52:25,448 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySourceTransformation{id=12, name='Custom File source', outputType=GenericType<org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit>, parallelism=1}
2021-04-15 17:52:25,449 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 12
2021-04-15 17:52:25,449 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 13
2021-04-15 17:52:25,449 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 14
2021-04-15 17:52:25,450 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 16
2021-04-15 17:52:25,453 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 17
2021-04-15 17:52:25,453 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySinkTransformation{id=18, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=1}
2021-04-15 17:52:25,453 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 18
2021-04-15 17:52:25,454 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=24, name='SinkConversionToTuple2', outputType=Java Tuple2<Boolean, Row(id: String, cnt: Long, avgTemp: Double)>, parallelism=-1}
2021-04-15 17:52:25,454 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=23, name='GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp])', outputType=ROW<`id` STRING, `cnt` BIGINT NOT NULL, `avgTemp` DOUBLE>(org.apache.flink.table.data.RowData, org.apache.flink.table.runtime.typeutils.RowDataSerializer), parallelism=-1}
2021-04-15 17:52:25,454 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming PartitionTransformation{id=22, name='Partition', outputType=ROW<`id` STRING, `temp` DOUBLE>(org.apache.flink.table.data.RowData, org.apache.flink.table.runtime.typeutils.RowDataSerializer), parallelism=-1}
2021-04-15 17:52:25,454 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=21, name='SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp])', outputType=ROW<`id` STRING, `temp` DOUBLE>(org.apache.flink.table.data.RowData, org.apache.flink.table.runtime.typeutils.RowDataSerializer), parallelism=1}
2021-04-15 17:52:25,454 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=20, name='CsvTableSource(read fields: id, temp)', outputType=Row(id: String, temp: Double), parallelism=1}
2021-04-15 17:52:25,454 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySourceTransformation{id=19, name='Custom File source', outputType=GenericType<org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit>, parallelism=1}
2021-04-15 17:52:25,454 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 19
2021-04-15 17:52:25,455 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 20
2021-04-15 17:52:25,455 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 21
2021-04-15 17:52:25,455 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 23
2021-04-15 17:52:25,455 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 24
2021-04-15 17:52:25,455 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySinkTransformation{id=25, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=1}
2021-04-15 17:52:25,455 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 25
2021-04-15 17:52:25,492 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'bc764cd8ddf7a0cff126f51c16239658' for node 'Source: Custom File source-1' {id: 1, parallelism: 1, user function: org.apache.flink.streaming.api.functions.source.ContinuousFileMonitoringFunction}
2021-04-15 17:52:25,492 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'feca28aff5a3958840bee985ee7de4d3' for node 'Source: Custom File source-6' {id: 6, parallelism: 1, user function: org.apache.flink.streaming.api.functions.source.ContinuousFileMonitoringFunction}
2021-04-15 17:52:25,492 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '605b35e407e90cda15ad084365733fdd' for node 'Source: Custom File source-12' {id: 12, parallelism: 1, user function: org.apache.flink.streaming.api.functions.source.ContinuousFileMonitoringFunction}
2021-04-15 17:52:25,492 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '3ba1d27b7fde4848a86e865c6c402dfa' for node 'Source: Custom File source-19' {id: 19, parallelism: 1, user function: org.apache.flink.streaming.api.functions.source.ContinuousFileMonitoringFunction}
2021-04-15 17:52:25,493 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '77af20c908aca598f7bbebd4db138545' for node 'CsvTableSource(read fields: id, timestamp, temp)-2' {id: 2, parallelism: 1, user function: }
2021-04-15 17:52:25,493 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'b23642197a427ec5db481d3963c66cfb' for node 'CsvTableSource(read fields: id, temp)-7' {id: 7, parallelism: 1, user function: }
2021-04-15 17:52:25,493 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'a19bdf930ebdf056b3d6de069bc89bdd' for node 'CsvTableSource(read fields: id, timestamp, temp)-13' {id: 13, parallelism: 1, user function: }
2021-04-15 17:52:25,493 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'aecbb8a11dc0c28dc6c178e875ebcc43' for node 'CsvTableSource(read fields: id, temp)-20' {id: 20, parallelism: 1, user function: }
2021-04-15 17:52:25,493 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'e1caecf4e938c7437797fd5ffa107998' for node 'SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp])-3' {id: 3, parallelism: 1, user function: }
2021-04-15 17:52:25,493 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'f747214a7be91c9c2b6cc5b7a3c8c7eb' for node 'SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp])-8' {id: 8, parallelism: 1, user function: }
2021-04-15 17:52:25,493 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '7b8b09df1455080a34c77ad3d0c43cb7' for node 'SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp])-14' {id: 14, parallelism: 1, user function: }
2021-04-15 17:52:25,493 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'fd97fe1bcea3a8dd8f11b0abe0bb8fa7' for node 'SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp])-21' {id: 21, parallelism: 1, user function: }
2021-04-15 17:52:25,493 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'a74f42661a9b9f548012fab549771fb0' for node 'SinkConversionToRow-4' {id: 4, parallelism: 1, user function: }
2021-04-15 17:52:25,493 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'eac1a1ce1701c72ed31579ebbd62865a' for node 'Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')])-9' {id: 9, parallelism: 1, user function: }
2021-04-15 17:52:25,493 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '6177eb422127981c4dbb05ea3af8a2d4' for node 'GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1])-16' {id: 16, parallelism: 1, user function: org.apache.flink.table.runtime.operators.aggregate.GroupAggFunction}
2021-04-15 17:52:25,493 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '5528b14a6b129894d24927c518acc32a' for node 'GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp])-23' {id: 23, parallelism: 1, user function: org.apache.flink.table.runtime.operators.aggregate.GroupAggFunction}
2021-04-15 17:52:25,493 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '1ff151f0e73312424d48b44002b858b2' for node 'Sink: Print to Std. Out-5' {id: 5, parallelism: 1, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
2021-04-15 17:52:25,493 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '7be2b145deed960935698c82ec6584ff' for node 'SinkConversionToRow-10' {id: 10, parallelism: 1, user function: }
2021-04-15 17:52:25,493 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '82ccb120c1db7ba31f32cb138318e905' for node 'SinkConversionToTuple2-17' {id: 17, parallelism: 1, user function: }
2021-04-15 17:52:25,493 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'a0dd144f36ef19961046e87bafc35e9e' for node 'SinkConversionToTuple2-24' {id: 24, parallelism: 1, user function: }
2021-04-15 17:52:25,493 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'acef8fa5317ebae622515a3dd3a22b5b' for node 'Sink: Print to Std. Out-11' {id: 11, parallelism: 1, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
2021-04-15 17:52:25,493 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '5eabb43907f8f80df1ce4361a6f197f2' for node 'Sink: Print to Std. Out-18' {id: 18, parallelism: 1, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
2021-04-15 17:52:25,494 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '3ed91adabe57771c56cb72d2e8ef0077' for node 'Sink: Print to Std. Out-25' {id: 25, parallelism: 1, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
2021-04-15 17:52:25,539 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 2
2021-04-15 17:52:25,554 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 1
2021-04-15 17:52:25,563 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - CONNECTED: ForwardPartitioner - 1 -> 2
2021-04-15 17:52:25,566 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 7
2021-04-15 17:52:25,568 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 6
2021-04-15 17:52:25,569 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - CONNECTED: ForwardPartitioner - 6 -> 7
2021-04-15 17:52:25,575 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 16
2021-04-15 17:52:25,593 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 13
2021-04-15 17:52:25,596 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - CONNECTED: KeyGroupStreamPartitioner - 13 -> 16
2021-04-15 17:52:25,598 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 12
2021-04-15 17:52:25,599 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - CONNECTED: ForwardPartitioner - 12 -> 13
2021-04-15 17:52:25,602 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 23
2021-04-15 17:52:25,604 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 20
2021-04-15 17:52:25,605 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - CONNECTED: KeyGroupStreamPartitioner - 20 -> 23
2021-04-15 17:52:25,606 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 19
2021-04-15 17:52:25,606 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - CONNECTED: ForwardPartitioner - 19 -> 20
2021-04-15 17:52:25,650 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.
2021-04-15 17:52:25,651 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.
2021-04-15 17:52:25,651 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.
2021-04-15 17:52:25,651 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.min required for local execution is not set, setting it to its default value 64 mb.
2021-04-15 17:52:25,651 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.max required for local execution is not set, setting it to its default value 64 mb.
2021-04-15 17:52:25,652 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.
2021-04-15 17:52:25,667 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting Flink Mini Cluster
2021-04-15 17:52:25,667 DEBUG org.apache.flink.runtime.minicluster.MiniCluster - Using configuration MiniClusterConfiguration {singleRpcService=SHARED, numTaskManagers=1, commonBindAddress='null', config={taskmanager.memory.network.min=64 mb, taskmanager.cpu.cores=1.7976931348623157E308, taskmanager.memory.task.off-heap.size=9223372036854775807 bytes, execution.target=local, rest.bind-port=0, taskmanager.memory.network.max=64 mb, execution.attached=true, taskmanager.memory.managed.size=128 mb, parallelism.default=4, taskmanager.numberOfTaskSlots=1, taskmanager.memory.task.heap.size=9223372036854775807 bytes, rest.address=localhost}}
2021-04-15 17:52:25,669 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting Metrics Registry
2021-04-15 17:52:25,733 INFO org.apache.flink.runtime.metrics.MetricRegistryImpl - No metrics reporter configured, no metrics will be exposed/reported.
2021-04-15 17:52:25,733 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting RPC Service(s)
2021-04-15 17:52:25,742 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
2021-04-15 17:52:25,748 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Using akka configuration
 Config(SimpleConfigObject({"akka":{"actor":{"default-dispatcher":{"executor":"fork-join-executor","fork-join-executor":{"parallelism-factor":1,"parallelism-max":4,"parallelism-min":2},"throughput":15},"guardian-supervisor-strategy":"org.apache.flink.runtime.akka.EscalatingSupervisorStrategy","supervisor-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"type":"Dispatcher"},"warn-about-java-serializer-usage":"off"},"daemonic":"off","jvm-exit-on-fatal-error":"on","log-config-on-start":"off","log-dead-letters":"off","log-dead-letters-during-shutdown":"off","logger-startup-timeout":"30s","loggers":["akka.event.slf4j.Slf4jLogger"],"logging-filter":"akka.event.slf4j.Slf4jLoggingFilter","loglevel":"DEBUG","serialize-messages":"off","stdout-loglevel":"OFF"}}))
2021-04-15 17:52:26,205 INFO akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2021-04-15 17:52:26,215 DEBUG akka.event.EventStream - logger log1-Slf4jLogger started
2021-04-15 17:52:26,218 DEBUG akka.event.EventStream - Default Loggers started
2021-04-15 17:52:26,444 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink
2021-04-15 17:52:26,465 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
2021-04-15 17:52:26,468 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Using akka configuration
 Config(SimpleConfigObject({"akka":{"actor":{"default-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"thread-priority":1,"throughput":15,"type":"akka.dispatch.PriorityThreadsDispatcher"},"guardian-supervisor-strategy":"org.apache.flink.runtime.akka.EscalatingSupervisorStrategy","supervisor-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"type":"Dispatcher"},"warn-about-java-serializer-usage":"off"},"daemonic":"off","jvm-exit-on-fatal-error":"on","log-config-on-start":"off","log-dead-letters":"off","log-dead-letters-during-shutdown":"off","logger-startup-timeout":"30s","loggers":["akka.event.slf4j.Slf4jLogger"],"logging-filter":"akka.event.slf4j.Slf4jLoggingFilter","loglevel":"DEBUG","serialize-messages":"off","stdout-loglevel":"OFF"}}))
2021-04-15 17:52:26,501 INFO akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2021-04-15 17:52:26,504 DEBUG akka.event.EventStream - logger log1-Slf4jLogger started
2021-04-15 17:52:26,504 DEBUG akka.event.EventStream - Default Loggers started
2021-04-15 17:52:26,573 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink-metrics
2021-04-15 17:52:26,590 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting AkkaRpcActor with name MetricQueryService.
2021-04-15 17:52:26,594 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
2021-04-15 17:52:26,743 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting high-availability services
2021-04-15 17:52:27,485 INFO org.apache.flink.runtime.blob.BlobServer - Created BLOB server storage directory C:\Users\ccy\AppData\Local\Temp\blobStore-525afe69-0012-440d-b4c6-280ec2c6642d
2021-04-15 17:52:27,492 DEBUG org.apache.flink.util.NetUtils - Trying to open socket on port 0
2021-04-15 17:52:27,495 INFO org.apache.flink.runtime.blob.BlobServer - Started BLOB server at 0.0.0.0:62243 - max concurrent requests: 50 - max backlog: 1000
2021-04-15 17:52:27,500 INFO org.apache.flink.runtime.blob.PermanentBlobCache - Created BLOB cache storage directory C:\Users\ccy\AppData\Local\Temp\blobStore-7402a5b4-5406-4611-a1c4-e6ac08578b02
2021-04-15 17:52:27,503 INFO org.apache.flink.runtime.blob.TransientBlobCache - Created BLOB cache storage directory C:\Users\ccy\AppData\Local\Temp\blobStore-0fc3e84d-81dc-46db-ab12-659c48ccf4e7
2021-04-15 17:52:27,503 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting 1 TaskManger(s)
2021-04-15 17:52:27,508 INFO org.apache.flink.runtime.taskexecutor.TaskManagerRunner - Starting TaskManager with ResourceID: 760eb808-2346-426e-9abc-5c23a18cddf1
2021-04-15 17:52:27,534 INFO o.apache.flink.runtime.taskexecutor.TaskManagerServices - Temporary file directory 'C:\Users\ccy\AppData\Local\Temp': total 137 GB, usable 24 GB (17.52% usable)
2021-04-15 17:52:27,537 INFO org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\ccy\AppData\Local\Temp\flink-io-fddc0daf-edc1-4fcf-b22a-e8463860460d for spill files.
2021-04-15 17:52:27,544 INFO org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\ccy\AppData\Local\Temp\flink-netty-shuffle-1bb5688d-705e-42c9-b52e-3f8e777eee3d for spill files.
2021-04-15 17:52:27,588 INFO o.a.flink.runtime.io.network.buffer.NetworkBufferPool - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2021-04-15 17:52:27,600 INFO o.a.flink.runtime.io.network.NettyShuffleEnvironment - Starting the network environment and its components.
2021-04-15 17:52:27,600 DEBUG o.a.flink.runtime.io.network.NettyShuffleEnvironment - Starting network connection manager
2021-04-15 17:52:27,601 INFO org.apache.flink.runtime.taskexecutor.KvStateService - Starting the kvState service and its components.
2021-04-15 17:52:27,618 DEBUG o.a.flink.runtime.taskexecutor.TaskManagerConfiguration - Messages have a max timeout of 10000 ms
2021-04-15 17:52:27,639 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting AkkaRpcActor with name taskmanager_0.
2021-04-15 17:52:27,639 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2021-04-15 17:52:27,653 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Start job leader service.
2021-04-15 17:52:27,655 INFO org.apache.flink.runtime.filecache.FileCache - User file cache uses directory C:\Users\ccy\AppData\Local\Temp\flink-dist-cache-4d5668b6-0b3c-4b63-b6f5-037ce33fe547
2021-04-15 17:52:27,679 DEBUG o.a.f.r.e.c.DefaultDispatcherResourceManagerComponentFactory - Starting Dispatcher REST endpoint.
2021-04-15 17:52:27,679 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Starting rest endpoint.
2021-04-15 17:52:27,684 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Failed to load web based job submission extension.
org.apache.flink.util.FlinkException: The module flink-runtime-web could not be found in the class path. Please add this jar in order to enable web based job submission.
	at org.apache.flink.runtime.webmonitor.WebMonitorUtils.loadWebSubmissionExtension(WebMonitorUtils.java:199) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint.initializeWebSubmissionHandlers(DispatcherRestEndpoint.java:112) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.webmonitor.WebMonitorEndpoint.initializeHandlers(WebMonitorEndpoint.java:228) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint.initializeHandlers(DispatcherRestEndpoint.java:89) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:144) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:172) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:463) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:422) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:366) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.program.PerJobMiniClusterFactory.submitJob(PerJobMiniClusterFactory.java:75) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:85) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1905) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1796) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:69) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1782) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1765) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.myorg.quickstart.other.FTable.Base1Usage.main(Base1Usage.java:88) ~[classes/:na]
2021-04-15 17:52:27,897 DEBUG o.a.f.s.n.i.n.u.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
2021-04-15 17:52:27,898 DEBUG o.a.f.s.n.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2021-04-15 17:52:27,898 DEBUG o.a.f.s.n.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2021-04-15 17:52:27,977 WARN org.apache.flink.runtime.webmonitor.WebMonitorUtils - Log file environment variable 'log.file' is not set.
2021-04-15 17:52:27,977 WARN org.apache.flink.runtime.webmonitor.WebMonitorUtils - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'web.log.path'.
2021-04-15 17:52:28,011 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - Platform: Windows
2021-04-15 17:52:28,013 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
2021-04-15 17:52:28,013 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - Java version: 11
2021-04-15 17:52:28,013 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
2021-04-15 17:52:28,014 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
2021-04-15 17:52:28,014 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
2021-04-15 17:52:28,015 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: unavailable
java.lang.UnsupportedOperationException: Reflective setAccessible(true) disabled
	at org.apache.flink.shaded.netty4.io.netty.util.internal.ReflectionUtil.trySetAccessible(ReflectionUtil.java:31) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0$4.run(PlatformDependent0.java:233) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at java.base/java.security.AccessController.doPrivileged(Native Method) ~[na:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:227) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.isAndroid(PlatformDependent.java:289) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:92) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:223) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:210) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.cached(AsciiString.java:1401) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<clinit>(AsciiString.java:48) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<init>(HttpMethod.java:135) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<clinit>(HttpMethod.java:36) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.runtime.rest.HttpMethodWrapper.<clinit>(HttpMethodWrapper.java:27) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.messages.cluster.ShutdownHeaders.getHttpMethod(ShutdownHeaders.java:57) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.checkAllEndpointsAndHandlersAreUnique(RestServerEndpoint.java:572) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:155) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:172) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:463) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:422) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:366) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.program.PerJobMiniClusterFactory.submitJob(PerJobMiniClusterFactory.java:75) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:85) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1905) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1796) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:69) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1782) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1765) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.myorg.quickstart.other.FTable.Base1Usage.main(Base1Usage.java:88) ~[classes/:na]
2021-04-15 17:52:28,016 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
2021-04-15 17:52:28,018 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable
java.lang.IllegalAccessException: class org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0$6 cannot access class jdk.internal.misc.Unsafe (in module java.base) because module java.base does not export jdk.internal.misc to unnamed module @9729a97
	at java.base/jdk.internal.reflect.Reflection.newIllegalAccessException(Reflection.java:361) ~[na:na]
	at java.base/java.lang.reflect.AccessibleObject.checkAccess(AccessibleObject.java:591) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:558) ~[na:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0$6.run(PlatformDependent0.java:347) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at java.base/java.security.AccessController.doPrivileged(Native Method) ~[na:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:338) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.isAndroid(PlatformDependent.java:289) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:92) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:223) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:210) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.cached(AsciiString.java:1401) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<clinit>(AsciiString.java:48) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<init>(HttpMethod.java:135) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<clinit>(HttpMethod.java:36) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.runtime.rest.HttpMethodWrapper.<clinit>(HttpMethodWrapper.java:27) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.messages.cluster.ShutdownHeaders.getHttpMethod(ShutdownHeaders.java:57) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.checkAllEndpointsAndHandlersAreUnique(RestServerEndpoint.java:572) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:155) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:172) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:463) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:422) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:366) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.program.PerJobMiniClusterFactory.submitJob(PerJobMiniClusterFactory.java:75) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:85) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1905) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1796) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:69) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1782) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1765) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.myorg.quickstart.other.FTable.Base1Usage.main(Base1Usage.java:88) ~[classes/:na]
2021-04-15 17:52:28,018 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): unavailable
2021-04-15 17:52:28,018 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
2021-04-15 17:52:28,019 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - maxDirectMemory: 2122317824 bytes (maybe)
2021-04-15 17:52:28,019 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\ccy\AppData\Local\Temp (java.io.tmpdir)
2021-04-15 17:52:28,019 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
2021-04-15 17:52:28,020 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: -1 bytes
2021-04-15 17:52:28,020 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
2021-04-15 17:52:28,021 DEBUG o.a.f.shaded.netty4.io.netty.util.internal.CleanerJava9 - java.nio.ByteBuffer.cleaner(): available
2021-04-15 17:52:28,021 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
2021-04-15 17:52:28,025 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@4ed94e6a under DELETE@/v1/cluster.
2021-04-15 17:52:28,026 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@4ed94e6a under DELETE@/cluster.
2021-04-15 17:52:28,027 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@70a26eca under GET@/v1/config.
2021-04-15 17:52:28,027 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@70a26eca under GET@/config.
2021-04-15 17:52:28,027 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetListHandler@4b60ff1c under GET@/v1/datasets.
2021-04-15 17:52:28,027 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetListHandler@4b60ff1c under GET@/datasets.
2021-04-15 17:52:28,027 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteStatusHandler@1c74251b under GET@/v1/datasets/delete/:triggerid.
2021-04-15 17:52:28,027 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteStatusHandler@1c74251b under GET@/datasets/delete/:triggerid.
2021-04-15 17:52:28,027 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteTriggerHandler@1aaa3406 under DELETE@/v1/datasets/:datasetid.
2021-04-15 17:52:28,027 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteTriggerHandler@1aaa3406 under DELETE@/datasets/:datasetid.
2021-04-15 17:52:28,027 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@791dcda7 under GET@/v1/jobmanager/config.
2021-04-15 17:52:28,027 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@791dcda7 under GET@/jobmanager/config.
2021-04-15 17:52:28,027 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@35c95587 under GET@/v1/jobmanager/log.
2021-04-15 17:52:28,027 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@35c95587 under GET@/jobmanager/log.
2021-04-15 17:52:28,028 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogListHandler@828e2d8 under GET@/v1/jobmanager/logs.
2021-04-15 17:52:28,028 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogListHandler@828e2d8 under GET@/jobmanager/logs.
2021-04-15 17:52:28,028 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerCustomLogHandler@43e9eddf under GET@/v1/jobmanager/logs/:filename.
2021-04-15 17:52:28,028 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerCustomLogHandler@43e9eddf under GET@/jobmanager/logs/:filename.
2021-04-15 17:52:28,028 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@548e70f0 under GET@/v1/jobmanager/metrics.
2021-04-15 17:52:28,028 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@548e70f0 under GET@/jobmanager/metrics.
2021-04-15 17:52:28,028 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@2b14628b under GET@/v1/jobmanager/stdout.
2021-04-15 17:52:28,028 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@2b14628b under GET@/jobmanager/stdout.
2021-04-15 17:52:28,028 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@64657b13 under GET@/v1/jobs.
2021-04-15 17:52:28,028 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@64657b13 under GET@/jobs.
2021-04-15 17:52:28,028 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@686ee555 under POST@/v1/jobs.
2021-04-15 17:52:28,028 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@686ee555 under POST@/jobs.
2021-04-15 17:52:28,028 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@4fc00158 under GET@/v1/jobs/metrics.
2021-04-15 17:52:28,028 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@4fc00158 under GET@/jobs/metrics.
2021-04-15 17:52:28,028 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@47483211 under GET@/v1/jobs/overview.
2021-04-15 17:52:28,028 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@47483211 under GET@/jobs/overview.
2021-04-15 17:52:28,028 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@8ba7408 under GET@/v1/jobs/:jobid.
2021-04-15 17:52:28,029 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@8ba7408 under GET@/jobs/:jobid.
2021-04-15 17:52:28,029 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@17616c07 under PATCH@/v1/jobs/:jobid.
2021-04-15 17:52:28,029 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@17616c07 under PATCH@/jobs/:jobid.
2021-04-15 17:52:28,029 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@58e46572 under GET@/v1/jobs/:jobid/accumulators.
2021-04-15 17:52:28,029 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@58e46572 under GET@/jobs/:jobid/accumulators.
2021-04-15 17:52:28,029 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@5eba0cc5 under GET@/v1/jobs/:jobid/checkpoints.
2021-04-15 17:52:28,029 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@5eba0cc5 under GET@/jobs/:jobid/checkpoints.
2021-04-15 17:52:28,029 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@5fb392e under GET@/v1/jobs/:jobid/checkpoints/config.
2021-04-15 17:52:28,029 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@5fb392e under GET@/jobs/:jobid/checkpoints/config.
2021-04-15 17:52:28,029 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@19e67cc2 under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid.
2021-04-15 17:52:28,029 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@19e67cc2 under GET@/jobs/:jobid/checkpoints/details/:checkpointid.
2021-04-15 17:52:28,029 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@62525579 under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
2021-04-15 17:52:28,029 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@62525579 under GET@/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
2021-04-15 17:52:28,029 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@6c80b1d2 under GET@/v1/jobs/:jobid/config.
2021-04-15 17:52:28,029 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@6c80b1d2 under GET@/jobs/:jobid/config.
2021-04-15 17:52:28,029 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.coordination.ClientCoordinationHandler@30eed725 under POST@/v1/jobs/:jobid/coordinators/:operatorid.
2021-04-15 17:52:28,029 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.coordination.ClientCoordinationHandler@30eed725 under POST@/jobs/:jobid/coordinators/:operatorid.
2021-04-15 17:52:28,029 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@1a44ad96 under GET@/v1/jobs/:jobid/exceptions.
2021-04-15 17:52:28,029 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@1a44ad96 under GET@/jobs/:jobid/exceptions.
2021-04-15 17:52:28,029 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@6acdca3a under GET@/v1/jobs/:jobid/execution-result.
2021-04-15 17:52:28,029 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@6acdca3a under GET@/jobs/:jobid/execution-result.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@32ae890 under GET@/v1/jobs/:jobid/metrics.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@32ae890 under GET@/jobs/:jobid/metrics.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@45bb502f under GET@/v1/jobs/:jobid/plan.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@45bb502f under GET@/jobs/:jobid/plan.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@7aac6d13 under PATCH@/v1/jobs/:jobid/rescaling.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@7aac6d13 under PATCH@/jobs/:jobid/rescaling.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@7e34e466 under GET@/v1/jobs/:jobid/rescaling/:triggerid.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@7e34e466 under GET@/jobs/:jobid/rescaling/:triggerid.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@2a8eed58 under POST@/v1/jobs/:jobid/savepoints.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@2a8eed58 under POST@/jobs/:jobid/savepoints.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@352bea0e under GET@/v1/jobs/:jobid/savepoints/:triggerid.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@352bea0e under GET@/jobs/:jobid/savepoints/:triggerid.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@2cf6dd4d under POST@/v1/jobs/:jobid/stop.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@2cf6dd4d under POST@/jobs/:jobid/stop.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@75381b61 under GET@/v1/jobs/:jobid/vertices/:vertexid.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@75381b61 under GET@/jobs/:jobid/vertices/:vertexid.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@2801ccb3 under GET@/v1/jobs/:jobid/vertices/:vertexid/accumulators.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@2801ccb3 under GET@/jobs/:jobid/vertices/:vertexid/accumulators.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@42102827 under GET@/v1/jobs/:jobid/vertices/:vertexid/backpressure.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@42102827 under GET@/jobs/:jobid/vertices/:vertexid/backpressure.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@5896899d under GET@/v1/jobs/:jobid/vertices/:vertexid/metrics.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@5896899d under GET@/jobs/:jobid/vertices/:vertexid/metrics.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@6d4062fd under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@6d4062fd under GET@/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
2021-04-15 17:52:28,030 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@4b024fb2 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@4b024fb2 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@89017e5 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@89017e5 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@6426ad0b under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@6426ad0b under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@a9f7cf8 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@a9f7cf8 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@5339cdc6 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@5339cdc6 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@5b9ed77b under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasktimes.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@5b9ed77b under GET@/jobs/:jobid/vertices/:vertexid/subtasktimes.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@a8177f6 under GET@/v1/jobs/:jobid/vertices/:vertexid/taskmanagers.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@a8177f6 under GET@/jobs/:jobid/vertices/:vertexid/taskmanagers.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@7b88a2e2 under GET@/v1/jobs/:jobid/vertices/:vertexid/watermarks.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@7b88a2e2 under GET@/jobs/:jobid/vertices/:vertexid/watermarks.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@664217a8 under GET@/v1/jobs/:jobid/yarn-cancel.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@664217a8 under GET@/jobs/:jobid/yarn-cancel.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@4b4a3114 under GET@/v1/jobs/:jobid/yarn-stop.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@4b4a3114 under GET@/jobs/:jobid/yarn-stop.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@4af5c14c under GET@/v1/overview.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@4af5c14c under GET@/overview.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@74d4f542 under POST@/v1/savepoint-disposal.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@74d4f542 under POST@/savepoint-disposal.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@25d5327 under GET@/v1/savepoint-disposal/:triggerid.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@25d5327 under GET@/savepoint-disposal/:triggerid.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@188500e9 under GET@/v1/taskmanagers.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@188500e9 under GET@/taskmanagers.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@7c1e5d14 under GET@/v1/taskmanagers/metrics.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@7c1e5d14 under GET@/taskmanagers/metrics.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@2fb3c930 under GET@/v1/taskmanagers/:taskmanagerid.
2021-04-15 17:52:28,031 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@2fb3c930 under GET@/taskmanagers/:taskmanagerid.
2021-04-15 17:52:28,032 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@479f738a under GET@/v1/taskmanagers/:taskmanagerid/log.
2021-04-15 17:52:28,032 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@479f738a under GET@/taskmanagers/:taskmanagerid/log.
2021-04-15 17:52:28,032 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogListHandler@772db1d8 under GET@/v1/taskmanagers/:taskmanagerid/logs.
2021-04-15 17:52:28,032 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogListHandler@772db1d8 under GET@/taskmanagers/:taskmanagerid/logs.
2021-04-15 17:52:28,032 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerCustomLogHandler@7955b4d4 under GET@/v1/taskmanagers/:taskmanagerid/logs/:filename.
2021-04-15 17:52:28,032 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerCustomLogHandler@7955b4d4 under GET@/taskmanagers/:taskmanagerid/logs/:filename.
2021-04-15 17:52:28,032 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@489e1887 under GET@/v1/taskmanagers/:taskmanagerid/metrics.
2021-04-15 17:52:28,032 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@489e1887 under GET@/taskmanagers/:taskmanagerid/metrics.
2021-04-15 17:52:28,032 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@7421213d under GET@/v1/taskmanagers/:taskmanagerid/stdout.
2021-04-15 17:52:28,032 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@7421213d under GET@/taskmanagers/:taskmanagerid/stdout.
2021-04-15 17:52:28,032 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerThreadDumpHandler@6e98fd10 under GET@/v1/taskmanagers/:taskmanagerid/thread-dump.
2021-04-15 17:52:28,032 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerThreadDumpHandler@6e98fd10 under GET@/taskmanagers/:taskmanagerid/thread-dump.
2021-04-15 17:52:28,037 DEBUG o.a.f.s.n.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 8
2021-04-15 17:52:28,064 DEBUG o.a.f.shaded.netty4.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
2021-04-15 17:52:28,064 DEBUG o.a.f.shaded.netty4.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
2021-04-15 17:52:28,070 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
2021-04-15 17:52:28,119 DEBUG o.a.f.shaded.netty4.io.netty.channel.DefaultChannelId - -Dio.netty.processId: 16080 (auto-detected)
2021-04-15 17:52:28,121 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
2021-04-15 17:52:28,121 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
2021-04-15 17:52:28,939 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
2021-04-15 17:52:28,939 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
2021-04-15 17:52:29,698 DEBUG o.a.f.shaded.netty4.io.netty.channel.DefaultChannelId - -Dio.netty.machineId: 2c:6f:c9:ff:fe:1c:21:83 (auto-detected)
2021-04-15 17:52:29,712 DEBUG o.a.f.shaded.netty4.io.netty.util.ResourceLeakDetector - -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.level: simple
2021-04-15 17:52:29,712 DEBUG o.a.f.shaded.netty4.io.netty.util.ResourceLeakDetector - -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.targetRecords: 4
2021-04-15 17:52:29,736 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 8
2021-04-15 17:52:29,736 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 8
2021-04-15 17:52:29,736 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
2021-04-15 17:52:29,736 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 11
2021-04-15 17:52:29,736 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 16777216
2021-04-15 17:52:29,736 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.tinyCacheSize: 512
2021-04-15 17:52:29,736 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
2021-04-15 17:52:29,736 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
2021-04-15 17:52:29,736 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2021-04-15 17:52:29,736 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
2021-04-15 17:52:29,736 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2021-04-15 17:52:29,736 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: true
2021-04-15 17:52:29,736 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2021-04-15 17:52:29,745 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
2021-04-15 17:52:29,745 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 0
2021-04-15 17:52:29,745 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
2021-04-15 17:52:29,760 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Binding rest endpoint to null:0.
2021-04-15 17:52:29,760 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Rest endpoint listening at localhost:62262
2021-04-15 17:52:29,764 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender http://localhost:62262
2021-04-15 17:52:29,767 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - http://localhost:62262 was granted leadership with leaderSessionID=796ade89-9064-4872-9a54-fb6bf5b99734
2021-04-15 17:52:29,768 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader http://localhost:62262 , session=796ade89-9064-4872-9a54-fb6bf5b99734
2021-04-15 17:52:29,782 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting FencedAkkaRpcActor with name resourcemanager_1.
2021-04-15 17:52:29,783 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_1 .
2021-04-15 17:52:29,798 DEBUG o.a.f.r.e.c.DefaultDispatcherResourceManagerComponentFactory - Starting Dispatcher.
2021-04-15 17:52:29,802 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
2021-04-15 17:52:29,803 DEBUG o.a.f.r.e.c.DefaultDispatcherResourceManagerComponentFactory - Starting ResourceManager.
2021-04-15 17:52:29,803 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: StandaloneResourceManager
2021-04-15 17:52:29,804 DEBUG o.a.f.runtime.dispatcher.runner.DefaultDispatcherRunner - Create new DispatcherLeaderProcess with leader session id 3098f697-05d4-40bf-b8c7-99098e4af697.
2021-04-15 17:52:29,807 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - ResourceManager akka://flink/user/rpc/resourcemanager_1 was granted leadership with fencing token 88a920a2a2f769881e0853b7798542a5
2021-04-15 17:52:29,809 INFO org.apache.flink.runtime.minicluster.MiniCluster - Flink Mini Cluster started successfully
2021-04-15 17:52:29,811 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Start SessionDispatcherLeaderProcess.
2021-04-15 17:52:29,812 INFO o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Starting the SlotManager.
2021-04-15 17:52:29,817 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:52:29,817 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:52:29,818 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/resourcemanager_1 , session=1e0853b7-7985-42a5-88a9-20a2a2f76988
2021-04-15 17:52:29,818 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Recover all persisted job graphs.
2021-04-15 17:52:29,818 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Successfully recovered 0 persisted job graphs.
2021-04-15 17:52:29,819 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:52:29,823 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(88a920a2a2f769881e0853b7798542a5).
2021-04-15 17:52:29,826 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:52:29,827 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting FencedAkkaRpcActor with name dispatcher_2.
2021-04-15 17:52:29,833 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_2 .
2021-04-15 17:52:29,834 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:52:29,847 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/dispatcher_2 , session=3098f697-05d4-40bf-b8c7-99098e4af697
2021-04-15 17:52:29,848 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Resolved ResourceManager address, beginning registration
2021-04-15 17:52:29,848 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Registration at ResourceManager attempt 1 (timeout=100ms)
2021-04-15 17:52:29,850 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/dispatcher_2. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
2021-04-15 17:52:29,852 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
2021-04-15 17:52:29,852 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/dispatcher_2. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
2021-04-15 17:52:29,869 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Registering TaskManager with ResourceID 760eb808-2346-426e-9abc-5c23a18cddf1 (akka://flink/user/rpc/taskmanager_0) at ResourceManager
2021-04-15 17:52:29,872 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Successful registration at resource manager akka://flink/user/rpc/resourcemanager_1 under registration id 8409146bccc11dfe1db202a54e5e0aac.
2021-04-15 17:52:29,875 DEBUG o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Registering TaskManager 760eb808-2346-426e-9abc-5c23a18cddf1 under 8409146bccc11dfe1db202a54e5e0aac at the SlotManager.
2021-04-15 17:52:29,879 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Received JobGraph submission 0af35e8eb90492be8852415387a2352b (Flink Streaming Job).
2021-04-15 17:52:29,879 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Submitting job 0af35e8eb90492be8852415387a2352b (Flink Streaming Job).
2021-04-15 17:52:29,903 DEBUG org.apache.flink.client.ClientUtils - Wait until job initialization is finished
2021-04-15 17:52:29,909 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: JobManagerRunnerImpl
2021-04-15 17:52:29,918 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting FencedAkkaRpcActor with name jobmanager_3.
2021-04-15 17:52:29,918 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
2021-04-15 17:52:29,927 INFO org.apache.flink.runtime.jobmaster.JobMaster - Initializing job Flink Streaming Job (0af35e8eb90492be8852415387a2352b).
2021-04-15 17:52:29,950 INFO org.apache.flink.runtime.jobmaster.JobMaster - Using restart back off time strategy NoRestartBackoffTimeStrategy for Flink Streaming Job (0af35e8eb90492be8852415387a2352b).
2021-04-15 17:52:30,002 INFO org.apache.flink.runtime.jobmaster.JobMaster - Running initialization on master for job Flink Streaming Job (0af35e8eb90492be8852415387a2352b).
2021-04-15 17:52:30,003 INFO org.apache.flink.runtime.jobmaster.JobMaster - Successfully ran initialization on master in 0 ms.
2021-04-15 17:52:30,003 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Adding 10 vertices from job graph Flink Streaming Job (0af35e8eb90492be8852415387a2352b).
2021-04-15 17:52:30,003 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Attaching 10 topologically sorted vertices to existing job graph with 0 vertices and 0 intermediate results.
2021-04-15 17:52:30,027 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex bc764cd8ddf7a0cff126f51c16239658 (Source: Custom File source) to 0 predecessors.
2021-04-15 17:52:30,028 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex feca28aff5a3958840bee985ee7de4d3 (Source: Custom File source) to 0 predecessors.
2021-04-15 17:52:30,028 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex 605b35e407e90cda15ad084365733fdd (Source: Custom File source) to 0 predecessors.
2021-04-15 17:52:30,028 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex 3ba1d27b7fde4848a86e865c6c402dfa (Source: Custom File source) to 0 predecessors.
2021-04-15 17:52:30,028 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex 77af20c908aca598f7bbebd4db138545 (CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out) to 1 predecessors.
2021-04-15 17:52:30,028 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting input 0 of vertex 77af20c908aca598f7bbebd4db138545 (CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out) to intermediate result referenced via predecessor bc764cd8ddf7a0cff126f51c16239658 (Source: Custom File source).
2021-04-15 17:52:30,034 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex b23642197a427ec5db481d3963c66cfb (CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out) to 1 predecessors.
2021-04-15 17:52:30,034 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting input 0 of vertex b23642197a427ec5db481d3963c66cfb (CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out) to intermediate result referenced via predecessor feca28aff5a3958840bee985ee7de4d3 (Source: Custom File source).
2021-04-15 17:52:30,034 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex a19bdf930ebdf056b3d6de069bc89bdd (CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp])) to 1 predecessors.
2021-04-15 17:52:30,034 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting input 0 of vertex a19bdf930ebdf056b3d6de069bc89bdd (CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp])) to intermediate result referenced via predecessor 605b35e407e90cda15ad084365733fdd (Source: Custom File source).
2021-04-15 17:52:30,034 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex 6177eb422127981c4dbb05ea3af8a2d4 (GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out) to 1 predecessors.
2021-04-15 17:52:30,034 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting input 0 of vertex 6177eb422127981c4dbb05ea3af8a2d4 (GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out) to intermediate result referenced via predecessor a19bdf930ebdf056b3d6de069bc89bdd (CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp])).
2021-04-15 17:52:30,034 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex aecbb8a11dc0c28dc6c178e875ebcc43 (CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp])) to 1 predecessors.
2021-04-15 17:52:30,035 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting input 0 of vertex aecbb8a11dc0c28dc6c178e875ebcc43 (CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp])) to intermediate result referenced via predecessor 3ba1d27b7fde4848a86e865c6c402dfa (Source: Custom File source).
2021-04-15 17:52:30,035 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex 5528b14a6b129894d24927c518acc32a (GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out) to 1 predecessors.
2021-04-15 17:52:30,035 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting input 0 of vertex 5528b14a6b129894d24927c518acc32a (GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out) to intermediate result referenced via predecessor aecbb8a11dc0c28dc6c178e875ebcc43 (CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp])).
2021-04-15 17:52:30,051 INFO o.a.f.r.scheduler.adapter.DefaultExecutionTopology - Built 4 pipelined regions in 3 ms
2021-04-15 17:52:30,054 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Successfully created execution graph from job graph Flink Streaming Job (0af35e8eb90492be8852415387a2352b).
2021-04-15 17:52:30,081 INFO org.apache.flink.runtime.jobmaster.JobMaster - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:52:30,106 DEBUG o.apache.flink.runtime.checkpoint.CheckpointCoordinator - Status of the shared state registry of job 0af35e8eb90492be8852415387a2352b after restore: SharedStateRegistry{registeredStates={}}.
2021-04-15 17:52:30,106 INFO o.apache.flink.runtime.checkpoint.CheckpointCoordinator - No checkpoint found during restore.
2021-04-15 17:52:30,109 INFO org.apache.flink.runtime.jobmaster.JobMaster - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@45ee2fef for Flink Streaming Job (0af35e8eb90492be8852415387a2352b).
2021-04-15 17:52:30,124 INFO org.apache.flink.runtime.jobmaster.JobManagerRunnerImpl - JobManager runner for job Flink Streaming Job (0af35e8eb90492be8852415387a2352b) was granted leadership with session id 9503eff6-016f-41ad-a0ed-35acc06c35d3 at akka://flink/user/rpc/jobmanager_3.
2021-04-15 17:52:30,127 INFO org.apache.flink.runtime.jobmaster.JobMaster - Starting execution of job Flink Streaming Job (0af35e8eb90492be8852415387a2352b) under job master id a0ed35acc06c35d39503eff6016f41ad.
2021-04-15 17:52:30,129 INFO org.apache.flink.runtime.jobmaster.JobMaster - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2021-04-15 17:52:30,129 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Job Flink Streaming Job (0af35e8eb90492be8852415387a2352b) switched from state CREATED to RUNNING.
2021-04-15 17:52:30,136 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (4e1576c5820dd61a8a94ed976818593b) switched from CREATED to SCHEDULED.
2021-04-15 17:52:30,137 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1) (87de37c9db81dfdee6f377f619e5fb63) switched from CREATED to SCHEDULED.
2021-04-15 17:52:30,147 DEBUG o.a.f.r.jobmaster.slotpool.PhysicalSlotProviderImpl - Received slot request [SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02}] with resource requirements: ResourceProfile{UNKNOWN}
2021-04-15 17:52:30,151 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02}]
2021-04-15 17:52:30,153 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{e05d21cadc4440314da3b2cf4eb0aa6f}) for execution vertex (id bc764cd8ddf7a0cff126f51c16239658_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:30,154 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{af61292ac98dc045329d2ae43a038b51}) for execution vertex (id 77af20c908aca598f7bbebd4db138545_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:30,162 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (cb17ee903affddd528d81a985c2f7958) switched from CREATED to SCHEDULED.
2021-04-15 17:52:30,162 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1) (6fbd8c62478c21cfd14aa27a55b4fe5c) switched from CREATED to SCHEDULED.
2021-04-15 17:52:30,163 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{36e401178c6056cd342944b20cf6e6a1}) for execution vertex (id feca28aff5a3958840bee985ee7de4d3_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:30,163 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{581bcd2a53d5e252e4e20ef0d37bd444}) for execution vertex (id b23642197a427ec5db481d3963c66cfb_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:30,164 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (acf9733938da85c0b5a1639427e16cc2) switched from CREATED to SCHEDULED.
2021-04-15 17:52:30,164 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1) (1445820206b44a96a015433b0bf94390) switched from CREATED to SCHEDULED.
2021-04-15 17:52:30,164 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1) (1a583e156346e4c163645eac9e1ca58c) switched from CREATED to SCHEDULED.
2021-04-15 17:52:30,165 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{4e69337e25cfa52b6a824b14a1e974a0}) for execution vertex (id 605b35e407e90cda15ad084365733fdd_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:30,165 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{c0e998b887d56b33bab832f4437c6f72}) for execution vertex (id a19bdf930ebdf056b3d6de069bc89bdd_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:30,165 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{5e22984cabd4d6bb10ac74ab794f0bdd}) for execution vertex (id 6177eb422127981c4dbb05ea3af8a2d4_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:30,166 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (cc1f1a33b0c4d5646db685dd63371efa) switched from CREATED to SCHEDULED.
2021-04-15 17:52:30,166 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1) (5c528b6dc0ff91c03924e38491364291) switched from CREATED to SCHEDULED.
2021-04-15 17:52:30,166 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1) (68c2e08bbf47ccdb95efe49cb8e5faab) switched from CREATED to SCHEDULED.
2021-04-15 17:52:30,166 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{1bb63cfb0c5408c219a288c1a93235c5}) for execution vertex (id 3ba1d27b7fde4848a86e865c6c402dfa_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:30,166 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{6503bd97ad2a1863f5c5c68df981045d}) for execution vertex (id aecbb8a11dc0c28dc6c178e875ebcc43_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:30,166 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{6790c21350030d8e5d88dad6968d95fe}) for execution vertex (id 5528b14a6b129894d24927c518acc32a_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:30,167 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/jobmanager_3 , session=9503eff6-016f-41ad-a0ed-35acc06c35d3
2021-04-15 17:52:30,167 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
2021-04-15 17:52:30,168 INFO org.apache.flink.runtime.jobmaster.JobMaster - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(88a920a2a2f769881e0853b7798542a5)
2021-04-15 17:52:30,170 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:52:30,171 INFO org.apache.flink.runtime.jobmaster.JobMaster - Resolved ResourceManager address, beginning registration
2021-04-15 17:52:30,171 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Registration at ResourceManager attempt 1 (timeout=100ms)
2021-04-15 17:52:30,172 DEBUG o.a.flink.runtime.resourcemanager.JobLeaderIdService - Add job 0af35e8eb90492be8852415387a2352b to job leader id monitoring.
2021-04-15 17:52:30,173 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Registering job manager a0ed35acc06c35d39503eff6016f41ad@akka://flink/user/rpc/jobmanager_3 for job 0af35e8eb90492be8852415387a2352b.
2021-04-15 17:52:30,173 DEBUG o.a.flink.runtime.resourcemanager.JobLeaderIdService - Found a new job leader 9503eff6-016f-41ad-a0ed-35acc06c35d3@akka://flink/user/rpc/jobmanager_3.
2021-04-15 17:52:30,174 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/jobmanager_3. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2021-04-15 17:52:30,180 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Registered job manager a0ed35acc06c35d39503eff6016f41ad@akka://flink/user/rpc/jobmanager_3 for job 0af35e8eb90492be8852415387a2352b.
2021-04-15 17:52:30,182 INFO org.apache.flink.runtime.jobmaster.JobMaster - JobManager successfully registered at ResourceManager, leader id: 88a920a2a2f769881e0853b7798542a5.
2021-04-15 17:52:30,184 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02}] and profile ResourceProfile{UNKNOWN} with allocation id ef5374b4ae1c52fa2a3384b908df553a from resource manager.
2021-04-15 17:52:30,185 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 0af35e8eb90492be8852415387a2352b with allocation id ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,188 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request ef5374b4ae1c52fa2a3384b908df553a for job 0af35e8eb90492be8852415387a2352b from resource manager with leader id 88a920a2a2f769881e0853b7798542a5.
2021-04-15 17:52:30,196 DEBUG org.apache.flink.runtime.memory.MemoryManager - Initialized MemoryManager with total memory size 134217728 and page size 32768.
2021-04-15 17:52:30,197 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,199 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Add job 0af35e8eb90492be8852415387a2352b for job leader monitoring.
2021-04-15 17:52:30,200 DEBUG o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - New leader information for job 0af35e8eb90492be8852415387a2352b. Address: akka://flink/user/rpc/jobmanager_3, leader id: a0ed35acc06c35d39503eff6016f41ad.
2021-04-15 17:52:30,201 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Try to register at job manager akka://flink/user/rpc/jobmanager_3 with leader id 9503eff6-016f-41ad-a0ed-35acc06c35d3.
2021-04-15 17:52:30,201 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/jobmanager_3. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2021-04-15 17:52:30,203 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Resolved JobManager address, beginning registration
2021-04-15 17:52:30,203 DEBUG o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Registration at JobManager attempt 1 (timeout=100ms)
2021-04-15 17:52:30,205 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
2021-04-15 17:52:30,209 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Register new TaskExecutor 760eb808-2346-426e-9abc-5c23a18cddf1.
2021-04-15 17:52:30,213 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Successful registration at job manager akka://flink/user/rpc/jobmanager_3 for job 0af35e8eb90492be8852415387a2352b.
2021-04-15 17:52:30,214 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Establish JobManager connection for job 0af35e8eb90492be8852415387a2352b.
2021-04-15 17:52:30,219 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Offer reserved slots to the leader of job 0af35e8eb90492be8852415387a2352b.
2021-04-15 17:52:30,225 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Fulfilling pending slot request [SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02}] with slot [ef5374b4ae1c52fa2a3384b908df553a]
2021-04-15 17:52:30,227 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{e05d21cadc4440314da3b2cf4eb0aa6f}) for execution vertex (id bc764cd8ddf7a0cff126f51c16239658_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:30,244 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{af61292ac98dc045329d2ae43a038b51}) for execution vertex (id 77af20c908aca598f7bbebd4db138545_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:30,245 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (4e1576c5820dd61a8a94ed976818593b) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:52:30,245 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom File source (1/1) (attempt #0) with attempt id 4e1576c5820dd61a8a94ed976818593b to 760eb808-2346-426e-9abc-5c23a18cddf1 @ server1 (dataPort=-1) with allocation id ef5374b4ae1c52fa2a3384b908df553a
2021-04-15 17:52:30,261 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1) (87de37c9db81dfdee6f377f619e5fb63) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:52:30,261 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1) (attempt #0) with attempt id 87de37c9db81dfdee6f377f619e5fb63 to 760eb808-2346-426e-9abc-5c23a18cddf1 @ server1 (dataPort=-1) with allocation id ef5374b4ae1c52fa2a3384b908df553a
2021-04-15 17:52:30,263 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,270 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{36e401178c6056cd342944b20cf6e6a1}) for execution vertex (id feca28aff5a3958840bee985ee7de4d3_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:30,270 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{581bcd2a53d5e252e4e20ef0d37bd444}) for execution vertex (id b23642197a427ec5db481d3963c66cfb_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:30,270 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (cb17ee903affddd528d81a985c2f7958) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:52:30,271 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom File source (1/1) (attempt #0) with attempt id cb17ee903affddd528d81a985c2f7958 to 760eb808-2346-426e-9abc-5c23a18cddf1 @ server1 (dataPort=-1) with allocation id ef5374b4ae1c52fa2a3384b908df553a
2021-04-15 17:52:30,276 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1) (6fbd8c62478c21cfd14aa27a55b4fe5c) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:52:30,276 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1) (attempt #0) with attempt id 6fbd8c62478c21cfd14aa27a55b4fe5c to 760eb808-2346-426e-9abc-5c23a18cddf1 @ server1 (dataPort=-1) with allocation id ef5374b4ae1c52fa2a3384b908df553a
2021-04-15 17:52:30,279 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{4e69337e25cfa52b6a824b14a1e974a0}) for execution vertex (id 605b35e407e90cda15ad084365733fdd_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:30,280 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{c0e998b887d56b33bab832f4437c6f72}) for execution vertex (id a19bdf930ebdf056b3d6de069bc89bdd_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:30,280 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{5e22984cabd4d6bb10ac74ab794f0bdd}) for execution vertex (id 6177eb422127981c4dbb05ea3af8a2d4_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:30,281 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (acf9733938da85c0b5a1639427e16cc2) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:52:30,281 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom File source (1/1) (attempt #0) with attempt id acf9733938da85c0b5a1639427e16cc2 to 760eb808-2346-426e-9abc-5c23a18cddf1 @ server1 (dataPort=-1) with allocation id ef5374b4ae1c52fa2a3384b908df553a
2021-04-15 17:52:30,282 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1) (1445820206b44a96a015433b0bf94390) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:52:30,282 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1) (attempt #0) with attempt id 1445820206b44a96a015433b0bf94390 to 760eb808-2346-426e-9abc-5c23a18cddf1 @ server1 (dataPort=-1) with allocation id ef5374b4ae1c52fa2a3384b908df553a
2021-04-15 17:52:30,283 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1) (1a583e156346e4c163645eac9e1ca58c) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:52:30,283 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1) (attempt #0) with attempt id 1a583e156346e4c163645eac9e1ca58c to 760eb808-2346-426e-9abc-5c23a18cddf1 @ server1 (dataPort=-1) with allocation id ef5374b4ae1c52fa2a3384b908df553a
2021-04-15 17:52:30,285 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{1bb63cfb0c5408c219a288c1a93235c5}) for execution vertex (id 3ba1d27b7fde4848a86e865c6c402dfa_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:30,285 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{6503bd97ad2a1863f5c5c68df981045d}) for execution vertex (id aecbb8a11dc0c28dc6c178e875ebcc43_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:30,285 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{6790c21350030d8e5d88dad6968d95fe}) for execution vertex (id 5528b14a6b129894d24927c518acc32a_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:30,285 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (cc1f1a33b0c4d5646db685dd63371efa) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:52:30,285 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom File source (1/1) (attempt #0) with attempt id cc1f1a33b0c4d5646db685dd63371efa to 760eb808-2346-426e-9abc-5c23a18cddf1 @ server1 (dataPort=-1) with allocation id ef5374b4ae1c52fa2a3384b908df553a
2021-04-15 17:52:30,286 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1) (5c528b6dc0ff91c03924e38491364291) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:52:30,286 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1) (attempt #0) with attempt id 5c528b6dc0ff91c03924e38491364291 to 760eb808-2346-426e-9abc-5c23a18cddf1 @ server1 (dataPort=-1) with allocation id ef5374b4ae1c52fa2a3384b908df553a
2021-04-15 17:52:30,286 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1) (68c2e08bbf47ccdb95efe49cb8e5faab) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:52:30,286 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1) (attempt #0) with attempt id 68c2e08bbf47ccdb95efe49cb8e5faab to 760eb808-2346-426e-9abc-5c23a18cddf1 @ server1 (dataPort=-1) with allocation id ef5374b4ae1c52fa2a3384b908df553a
2021-04-15 17:52:30,295 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new allocation id ef5374b4ae1c52fa2a3384b908df553a for local state stores for job 0af35e8eb90492be8852415387a2352b.
2021-04-15 17:52:30,301 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_ef5374b4ae1c52fa2a3384b908df553a], jobID=0af35e8eb90492be8852415387a2352b, jobVertexID=bc764cd8ddf7a0cff126f51c16239658, subtaskIndex=0}} for 0af35e8eb90492be8852415387a2352b - bc764cd8ddf7a0cff126f51c16239658 - 0 under allocation id ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,340 DEBUG o.a.f.r.io.network.partition.ResultPartitionFactory - Source: Custom File source (1/1)#0 (4e1576c5820dd61a8a94ed976818593b): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@1bde9b5b
2021-04-15 17:52:30,349 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom File source (1/1)#0 (4e1576c5820dd61a8a94ed976818593b), deploy into slot with allocation id ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,352 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,361 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_ef5374b4ae1c52fa2a3384b908df553a], jobID=0af35e8eb90492be8852415387a2352b, jobVertexID=77af20c908aca598f7bbebd4db138545, subtaskIndex=0}} for 0af35e8eb90492be8852415387a2352b - 77af20c908aca598f7bbebd4db138545 - 0 under allocation id ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,372 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (87de37c9db81dfdee6f377f619e5fb63): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:52:30,381 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (87de37c9db81dfdee6f377f619e5fb63), deploy into slot with allocation id ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,382 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,386 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_ef5374b4ae1c52fa2a3384b908df553a], jobID=0af35e8eb90492be8852415387a2352b, jobVertexID=feca28aff5a3958840bee985ee7de4d3, subtaskIndex=0}} for 0af35e8eb90492be8852415387a2352b - feca28aff5a3958840bee985ee7de4d3 - 0 under allocation id ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,386 DEBUG o.a.f.r.io.network.partition.ResultPartitionFactory - Source: Custom File source (1/1)#0 (cb17ee903affddd528d81a985c2f7958): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@1bde9b5b
2021-04-15 17:52:30,388 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom File source (1/1)#0 (cb17ee903affddd528d81a985c2f7958), deploy into slot with allocation id ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,390 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,390 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,401 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_ef5374b4ae1c52fa2a3384b908df553a], jobID=0af35e8eb90492be8852415387a2352b, jobVertexID=b23642197a427ec5db481d3963c66cfb, subtaskIndex=0}} for 0af35e8eb90492be8852415387a2352b - b23642197a427ec5db481d3963c66cfb - 0 under allocation id ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,404 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (6fbd8c62478c21cfd14aa27a55b4fe5c): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:52:30,405 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (6fbd8c62478c21cfd14aa27a55b4fe5c), deploy into slot with allocation id ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,406 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,413 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_ef5374b4ae1c52fa2a3384b908df553a], jobID=0af35e8eb90492be8852415387a2352b, jobVertexID=605b35e407e90cda15ad084365733fdd, subtaskIndex=0}} for 0af35e8eb90492be8852415387a2352b - 605b35e407e90cda15ad084365733fdd - 0 under allocation id ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,413 DEBUG o.a.f.r.io.network.partition.ResultPartitionFactory - Source: Custom File source (1/1)#0 (acf9733938da85c0b5a1639427e16cc2): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@1bde9b5b
2021-04-15 17:52:30,413 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom File source (1/1)#0 (acf9733938da85c0b5a1639427e16cc2), deploy into slot with allocation id ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,414 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,416 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_ef5374b4ae1c52fa2a3384b908df553a], jobID=0af35e8eb90492be8852415387a2352b, jobVertexID=a19bdf930ebdf056b3d6de069bc89bdd, subtaskIndex=0}} for 0af35e8eb90492be8852415387a2352b - a19bdf930ebdf056b3d6de069bc89bdd - 0 under allocation id ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,416 DEBUG o.a.f.r.io.network.partition.ResultPartitionFactory - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (1445820206b44a96a015433b0bf94390): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@1bde9b5b
2021-04-15 17:52:30,416 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (1445820206b44a96a015433b0bf94390): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:52:30,417 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (1445820206b44a96a015433b0bf94390), deploy into slot with allocation id ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,417 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,425 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_ef5374b4ae1c52fa2a3384b908df553a], jobID=0af35e8eb90492be8852415387a2352b, jobVertexID=6177eb422127981c4dbb05ea3af8a2d4, subtaskIndex=0}} for 0af35e8eb90492be8852415387a2352b - 6177eb422127981c4dbb05ea3af8a2d4 - 0 under allocation id ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,427 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (1a583e156346e4c163645eac9e1ca58c): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:52:30,427 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (1a583e156346e4c163645eac9e1ca58c), deploy into slot with allocation id ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,428 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,432 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_ef5374b4ae1c52fa2a3384b908df553a], jobID=0af35e8eb90492be8852415387a2352b, jobVertexID=3ba1d27b7fde4848a86e865c6c402dfa, subtaskIndex=0}} for 0af35e8eb90492be8852415387a2352b - 3ba1d27b7fde4848a86e865c6c402dfa - 0 under allocation id ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,432 DEBUG o.a.f.r.io.network.partition.ResultPartitionFactory - Source: Custom File source (1/1)#0 (cc1f1a33b0c4d5646db685dd63371efa): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@1bde9b5b
2021-04-15 17:52:30,437 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom File source (1/1)#0 (cc1f1a33b0c4d5646db685dd63371efa), deploy into slot with allocation id ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,440 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,442 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_ef5374b4ae1c52fa2a3384b908df553a], jobID=0af35e8eb90492be8852415387a2352b, jobVertexID=aecbb8a11dc0c28dc6c178e875ebcc43, subtaskIndex=0}} for 0af35e8eb90492be8852415387a2352b - aecbb8a11dc0c28dc6c178e875ebcc43 - 0 under allocation id ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,442 DEBUG o.a.f.r.io.network.partition.ResultPartitionFactory - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (5c528b6dc0ff91c03924e38491364291): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@1bde9b5b
2021-04-15 17:52:30,442 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (5c528b6dc0ff91c03924e38491364291): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:52:30,443 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (5c528b6dc0ff91c03924e38491364291), deploy into slot with allocation id ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,443 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,451 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_ef5374b4ae1c52fa2a3384b908df553a], jobID=0af35e8eb90492be8852415387a2352b, jobVertexID=5528b14a6b129894d24927c518acc32a, subtaskIndex=0}} for 0af35e8eb90492be8852415387a2352b - 5528b14a6b129894d24927c518acc32a - 0 under allocation id ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,452 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (68c2e08bbf47ccdb95efe49cb8e5faab): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:52:30,452 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (68c2e08bbf47ccdb95efe49cb8e5faab), deploy into slot with allocation id ef5374b4ae1c52fa2a3384b908df553a.
2021-04-15 17:52:30,477 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File source (1/1)#0 (4e1576c5820dd61a8a94ed976818593b) switched from CREATED to DEPLOYING.
2021-04-15 17:52:30,478 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Source: Custom File source (1/1)#0 (4e1576c5820dd61a8a94ed976818593b) [DEPLOYING]
2021-04-15 17:52:30,478 INFO org.apache.flink.runtime.taskmanager.Task - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (87de37c9db81dfdee6f377f619e5fb63) switched from CREATED to DEPLOYING.
2021-04-15 17:52:30,479 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (87de37c9db81dfdee6f377f619e5fb63) [DEPLOYING]
2021-04-15 17:52:30,479 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File source (1/1)#0 (cb17ee903affddd528d81a985c2f7958) switched from CREATED to DEPLOYING.
2021-04-15 17:52:30,479 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Source: Custom File source (1/1)#0 (cb17ee903affddd528d81a985c2f7958) [DEPLOYING]
2021-04-15 17:52:30,488 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (87de37c9db81dfdee6f377f619e5fb63) [DEPLOYING].
2021-04-15 17:52:30,490 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 87de37c9db81dfdee6f377f619e5fb63 at library cache manager took 2 milliseconds
2021-04-15 17:52:30,490 INFO org.apache.flink.runtime.taskmanager.Task - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (68c2e08bbf47ccdb95efe49cb8e5faab) switched from CREATED to DEPLOYING.
2021-04-15 17:52:30,490 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (68c2e08bbf47ccdb95efe49cb8e5faab) [DEPLOYING]
2021-04-15 17:52:30,490 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File source (1/1)#0 (cc1f1a33b0c4d5646db685dd63371efa) switched from CREATED to DEPLOYING.
2021-04-15 17:52:30,493 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Source: Custom File source (1/1)#0 (cc1f1a33b0c4d5646db685dd63371efa) [DEPLOYING]
2021-04-15 17:52:30,493 INFO org.apache.flink.runtime.taskmanager.Task - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (1a583e156346e4c163645eac9e1ca58c) switched from CREATED to DEPLOYING.
2021-04-15 17:52:30,493 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (1a583e156346e4c163645eac9e1ca58c) [DEPLOYING]
2021-04-15 17:52:30,494 INFO org.apache.flink.runtime.taskmanager.Task - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (1445820206b44a96a015433b0bf94390) switched from CREATED to DEPLOYING.
2021-04-15 17:52:30,494 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (1445820206b44a96a015433b0bf94390) [DEPLOYING]
2021-04-15 17:52:30,503 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File source (1/1)#0 (acf9733938da85c0b5a1639427e16cc2) switched from CREATED to DEPLOYING.
2021-04-15 17:52:30,503 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Source: Custom File source (1/1)#0 (acf9733938da85c0b5a1639427e16cc2) [DEPLOYING]
2021-04-15 17:52:30,512 INFO org.apache.flink.runtime.taskmanager.Task - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (6fbd8c62478c21cfd14aa27a55b4fe5c) switched from CREATED to DEPLOYING.
2021-04-15 17:52:30,512 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (6fbd8c62478c21cfd14aa27a55b4fe5c) [DEPLOYING]
2021-04-15 17:52:30,490 INFO org.apache.flink.runtime.taskmanager.Task - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (5c528b6dc0ff91c03924e38491364291) switched from CREATED to DEPLOYING.
2021-04-15 17:52:30,515 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (5c528b6dc0ff91c03924e38491364291) [DEPLOYING]
2021-04-15 17:52:30,525 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (5c528b6dc0ff91c03924e38491364291) [DEPLOYING].
2021-04-15 17:52:30,527 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (87de37c9db81dfdee6f377f619e5fb63) [DEPLOYING].
2021-04-15 17:52:30,527 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 5c528b6dc0ff91c03924e38491364291 at library cache manager took 1 milliseconds
2021-04-15 17:52:30,527 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (6fbd8c62478c21cfd14aa27a55b4fe5c) [DEPLOYING].
2021-04-15 17:52:30,527 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 6fbd8c62478c21cfd14aa27a55b4fe5c at library cache manager took 0 milliseconds
2021-04-15 17:52:30,528 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (6fbd8c62478c21cfd14aa27a55b4fe5c) [DEPLOYING].
2021-04-15 17:52:30,528 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (5c528b6dc0ff91c03924e38491364291) [DEPLOYING].
2021-04-15 17:52:30,532 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom File source (1/1)#0 (acf9733938da85c0b5a1639427e16cc2) [DEPLOYING].
2021-04-15 17:52:30,532 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task acf9733938da85c0b5a1639427e16cc2 at library cache manager took 0 milliseconds
2021-04-15 17:52:30,533 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom File source (1/1)#0 (acf9733938da85c0b5a1639427e16cc2) [DEPLOYING].
2021-04-15 17:52:30,533 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (1445820206b44a96a015433b0bf94390) [DEPLOYING].
2021-04-15 17:52:30,534 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 1445820206b44a96a015433b0bf94390 at library cache manager took 0 milliseconds
2021-04-15 17:52:30,535 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (1445820206b44a96a015433b0bf94390) [DEPLOYING].
2021-04-15 17:52:30,536 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom File source (1/1)#0 (cb17ee903affddd528d81a985c2f7958) [DEPLOYING].
2021-04-15 17:52:30,537 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task cb17ee903affddd528d81a985c2f7958 at library cache manager took 0 milliseconds
2021-04-15 17:52:30,537 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom File source (1/1)#0 (cb17ee903affddd528d81a985c2f7958) [DEPLOYING].
2021-04-15 17:52:30,538 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (1a583e156346e4c163645eac9e1ca58c) [DEPLOYING].
2021-04-15 17:52:30,538 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 1a583e156346e4c163645eac9e1ca58c at library cache manager took 0 milliseconds
2021-04-15 17:52:30,539 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (1a583e156346e4c163645eac9e1ca58c) [DEPLOYING].
2021-04-15 17:52:30,539 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom File source (1/1)#0 (4e1576c5820dd61a8a94ed976818593b) [DEPLOYING].
2021-04-15 17:52:30,541 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 4e1576c5820dd61a8a94ed976818593b at library cache manager took 2 milliseconds
2021-04-15 17:52:30,542 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom File source (1/1)#0 (4e1576c5820dd61a8a94ed976818593b) [DEPLOYING].
2021-04-15 17:52:30,543 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom File source (1/1)#0 (cc1f1a33b0c4d5646db685dd63371efa) [DEPLOYING].
2021-04-15 17:52:30,543 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task cc1f1a33b0c4d5646db685dd63371efa at library cache manager took 0 milliseconds
2021-04-15 17:52:30,543 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (68c2e08bbf47ccdb95efe49cb8e5faab) [DEPLOYING].
2021-04-15 17:52:30,545 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:52:30,545 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 68c2e08bbf47ccdb95efe49cb8e5faab at library cache manager took 0 milliseconds
2021-04-15 17:52:30,545 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom File source (1/1)#0 (cc1f1a33b0c4d5646db685dd63371efa) [DEPLOYING].
2021-04-15 17:52:30,546 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (68c2e08bbf47ccdb95efe49cb8e5faab) [DEPLOYING].
2021-04-15 17:52:30,546 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 2-10 buffers
2021-04-15 17:52:30,549 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Registered PipelinedResultPartition de5d1a9da390a2613fba1a2678353f30#0@4e1576c5820dd61a8a94ed976818593b [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:52:30,549 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - registering de5d1a9da390a2613fba1a2678353f30#0@4e1576c5820dd61a8a94ed976818593b
2021-04-15 17:52:30,552 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:52:30,556 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 2-10 buffers
2021-04-15 17:52:30,557 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Registered PipelinedResultPartition 6162f7b1a326a5f60ff644efe4b5860a#0@cb17ee903affddd528d81a985c2f7958 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:52:30,557 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 2-10 buffers
2021-04-15 17:52:30,558 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Registered PipelinedResultPartition 51607ff8d2b6611b9769c5234071e407#0@1445820206b44a96a015433b0bf94390 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:52:30,558 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:52:30,559 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 2-10 buffers
2021-04-15 17:52:30,560 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Registered PipelinedResultPartition 80a2030ea85de8019886d216c59629fc#0@acf9733938da85c0b5a1639427e16cc2 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:52:30,565 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Using partitioner FORWARD for output 0 of task Source: Custom File source
2021-04-15 17:52:30,568 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:52:30,568 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - registering 80a2030ea85de8019886d216c59629fc#0@acf9733938da85c0b5a1639427e16cc2
2021-04-15 17:52:30,568 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Using partitioner FORWARD for output 0 of task Source: Custom File source
2021-04-15 17:52:30,569 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 2-10 buffers
2021-04-15 17:52:30,569 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - registering 51607ff8d2b6611b9769c5234071e407#0@1445820206b44a96a015433b0bf94390
2021-04-15 17:52:30,569 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:52:30,569 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:52:30,569 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - registering 6162f7b1a326a5f60ff644efe4b5860a#0@cb17ee903affddd528d81a985c2f7958
2021-04-15 17:52:30,573 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Using partitioner HASH for output 0 of task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp])
2021-04-15 17:52:30,573 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:52:30,574 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Using partitioner FORWARD for output 0 of task Source: Custom File source
2021-04-15 17:52:30,574 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:52:30,577 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:52:30,577 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Registered PipelinedResultPartition 7f0f187fc0f5c9ab9257872acece76a0#0@5c528b6dc0ff91c03924e38491364291 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:52:30,577 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:52:30,577 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - registering 7f0f187fc0f5c9ab9257872acece76a0#0@5c528b6dc0ff91c03924e38491364291
2021-04-15 17:52:30,579 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Using partitioner HASH for output 0 of task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp])
2021-04-15 17:52:30,580 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:52:30,582 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:52:30,591 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:52:30,591 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:52:30,592 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:52:30,593 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 2-10 buffers
2021-04-15 17:52:30,594 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Registered PipelinedResultPartition de9c468ad4f929549d1ef23076f82f16#0@cc1f1a33b0c4d5646db685dd63371efa [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:52:30,594 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - registering de9c468ad4f929549d1ef23076f82f16#0@cc1f1a33b0c4d5646db685dd63371efa
2021-04-15 17:52:30,595 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Using partitioner FORWARD for output 0 of task Source: Custom File source
2021-04-15 17:52:30,595 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:52:30,597 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File source (1/1)#0 (cc1f1a33b0c4d5646db685dd63371efa) switched from DEPLOYING to RUNNING.
2021-04-15 17:52:30,597 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Source: Custom File source (1/1)#0.
2021-04-15 17:52:30,598 INFO org.apache.flink.runtime.taskmanager.Task - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (1445820206b44a96a015433b0bf94390) switched from DEPLOYING to RUNNING.
2021-04-15 17:52:30,598 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0.
2021-04-15 17:52:30,598 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File source (1/1)#0 (cb17ee903affddd528d81a985c2f7958) switched from DEPLOYING to RUNNING.
2021-04-15 17:52:30,599 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Source: Custom File source (1/1)#0.
2021-04-15 17:52:30,599 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File source (1/1)#0 (acf9733938da85c0b5a1639427e16cc2) switched from DEPLOYING to RUNNING.
2021-04-15 17:52:30,599 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Source: Custom File source (1/1)#0.
2021-04-15 17:52:30,600 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (cc1f1a33b0c4d5646db685dd63371efa) switched from DEPLOYING to RUNNING.
2021-04-15 17:52:30,601 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1) (1445820206b44a96a015433b0bf94390) switched from DEPLOYING to RUNNING.
2021-04-15 17:52:30,601 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (cb17ee903affddd528d81a985c2f7958) switched from DEPLOYING to RUNNING.
2021-04-15 17:52:30,601 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (acf9733938da85c0b5a1639427e16cc2) switched from DEPLOYING to RUNNING.
2021-04-15 17:52:30,604 INFO org.apache.flink.runtime.taskmanager.Task - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (1a583e156346e4c163645eac9e1ca58c) switched from DEPLOYING to RUNNING.
2021-04-15 17:52:30,604 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0.
2021-04-15 17:52:30,617 INFO org.apache.flink.runtime.taskmanager.Task - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (68c2e08bbf47ccdb95efe49cb8e5faab) switched from DEPLOYING to RUNNING.
2021-04-15 17:52:30,617 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0.
2021-04-15 17:52:30,619 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1) (1a583e156346e4c163645eac9e1ca58c) switched from DEPLOYING to RUNNING.
2021-04-15 17:52:30,621 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1) (68c2e08bbf47ccdb95efe49cb8e5faab) switched from DEPLOYING to RUNNING.
2021-04-15 17:52:30,622 INFO org.apache.flink.runtime.taskmanager.Task - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (5c528b6dc0ff91c03924e38491364291) switched from DEPLOYING to RUNNING.
2021-04-15 17:52:30,622 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0.
2021-04-15 17:52:30,622 INFO org.apache.flink.runtime.taskmanager.Task - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (87de37c9db81dfdee6f377f619e5fb63) switched from DEPLOYING to RUNNING.
2021-04-15 17:52:30,624 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0.
2021-04-15 17:52:30,622 INFO org.apache.flink.runtime.taskmanager.Task - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (6fbd8c62478c21cfd14aa27a55b4fe5c) switched from DEPLOYING to RUNNING.
2021-04-15 17:52:30,623 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File source (1/1)#0 (4e1576c5820dd61a8a94ed976818593b) switched from DEPLOYING to RUNNING.
2021-04-15 17:52:30,634 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Source: Custom File source (1/1)#0.
2021-04-15 17:52:30,647 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1) (5c528b6dc0ff91c03924e38491364291) switched from DEPLOYING to RUNNING.
2021-04-15 17:52:30,647 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1) (87de37c9db81dfdee6f377f619e5fb63) switched from DEPLOYING to RUNNING.
2021-04-15 17:52:30,647 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (4e1576c5820dd61a8a94ed976818593b) switched from DEPLOYING to RUNNING.
2021-04-15 17:52:30,648 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0.
2021-04-15 17:52:30,651 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1) (6fbd8c62478c21cfd14aa27a55b4fe5c) switched from DEPLOYING to RUNNING.
2021-04-15 17:52:30,652 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: SourceConversion$19 

 Code:

      public class SourceConversion$19 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.data.conversion.RowRowConverter converter$18;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SourceConversion$19(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output,
            org.apache.flink.streaming.runtime.tasks.ProcessingTimeService processingTimeService) throws Exception {
          this.references = references;
          converter$18 = (((org.apache.flink.table.data.conversion.RowRowConverter) references[0]));
          this.setup(task, config, output);
          if (this instanceof org.apache.flink.streaming.api.operators.AbstractStreamOperator) {
            ((org.apache.flink.streaming.api.operators.AbstractStreamOperator) this)
              .setProcessingTimeService(processingTimeService);
          }
        }

        @Override
        public void open() throws Exception {
          super.open();
          
          converter$18.open(getRuntimeContext().getUserCodeClassLoader());
                     
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) (org.apache.flink.table.data.RowData) converter$18.toInternalOrNull((org.apache.flink.types.Row) element.getValue());
          
          
          
          output.collect(outElement.replace(in1));
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
2021-04-15 17:52:30,660 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: SourceConversion$54 

 Code:

      public class SourceConversion$54 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.data.conversion.RowRowConverter converter$53;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SourceConversion$54(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output,
            org.apache.flink.streaming.runtime.tasks.ProcessingTimeService processingTimeService) throws Exception {
          this.references = references;
          converter$53 = (((org.apache.flink.table.data.conversion.RowRowConverter) references[0]));
          this.setup(task, config, output);
          if (this instanceof org.apache.flink.streaming.api.operators.AbstractStreamOperator) {
            ((org.apache.flink.streaming.api.operators.AbstractStreamOperator) this)
              .setProcessingTimeService(processingTimeService);
          }
        }

        @Override
        public void open() throws Exception {
          super.open();
          
          converter$53.open(getRuntimeContext().getUserCodeClassLoader());
                     
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) (org.apache.flink.table.data.RowData) converter$53.toInternalOrNull((org.apache.flink.types.Row) element.getValue());
          
          
          
          output.collect(outElement.replace(in1));
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
2021-04-15 17:52:30,679 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Source: Custom File source (1/1)#0
2021-04-15 17:52:30,692 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Source: Custom File source (1/1)#0
2021-04-15 17:52:30,701 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: SinkConversion$17 

 Code:

      public class SinkConversion$17 extends org.apache.flink.table.runtime.operators.TableStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.data.util.DataFormatConverters.RowConverter converter$16;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SinkConversion$17(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output,
            org.apache.flink.streaming.runtime.tasks.ProcessingTimeService processingTimeService) throws Exception {
          this.references = references;
          converter$16 = (((org.apache.flink.table.data.util.DataFormatConverters.RowConverter) references[0]));
          this.setup(task, config, output);
          if (this instanceof org.apache.flink.streaming.api.operators.AbstractStreamOperator) {
            ((org.apache.flink.streaming.api.operators.AbstractStreamOperator) this)
              .setProcessingTimeService(processingTimeService);
          }
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) element.getValue();
          
          
          
          
          
          output.collect(outElement.replace((org.apache.flink.types.Row) converter$16.toExternal((org.apache.flink.table.data.RowData) in1)));
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
2021-04-15 17:52:30,709 WARN org.apache.flink.metrics.MetricGroup - The operator name SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:52:30,713 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: SinkConversion$52 

 Code:

      public class SinkConversion$52 extends org.apache.flink.table.runtime.operators.TableStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.data.util.DataFormatConverters.RowConverter converter$50;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SinkConversion$52(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output,
            org.apache.flink.streaming.runtime.tasks.ProcessingTimeService processingTimeService) throws Exception {
          this.references = references;
          converter$50 = (((org.apache.flink.table.data.util.DataFormatConverters.RowConverter) references[0]));
          this.setup(task, config, output);
          if (this instanceof org.apache.flink.streaming.api.operators.AbstractStreamOperator) {
            ((org.apache.flink.streaming.api.operators.AbstractStreamOperator) this)
              .setProcessingTimeService(processingTimeService);
          }
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) element.getValue();
          
          
          
          
          
          
          org.apache.flink.api.java.tuple.Tuple2 result$51 = new org.apache.flink.api.java.tuple.Tuple2();
          result$51.setField(org.apache.flink.table.data.util.RowDataUtil.isAccumulateMsg(in1), 0);
          result$51.setField((org.apache.flink.types.Row) converter$50.toExternal((org.apache.flink.table.data.RowData) in1), 1);
          output.collect(outElement.replace(result$51));
                   
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
2021-04-15 17:52:30,722 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: StreamExecCalc$15 

 Code:

      public class StreamExecCalc$15 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.runtime.typeutils.StringDataSerializer typeSerializer$9;
        
        private final org.apache.flink.table.data.binary.BinaryStringData str$11 = org.apache.flink.table.data.binary.BinaryStringData.fromString("sensor_6");
                   
        org.apache.flink.table.data.BoxedWrapperRowData out = new org.apache.flink.table.data.BoxedWrapperRowData(2);
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public StreamExecCalc$15(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output,
            org.apache.flink.streaming.runtime.tasks.ProcessingTimeService processingTimeService) throws Exception {
          this.references = references;
          typeSerializer$9 = (((org.apache.flink.table.runtime.typeutils.StringDataSerializer) references[0]));
          this.setup(task, config, output);
          if (this instanceof org.apache.flink.streaming.api.operators.AbstractStreamOperator) {
            ((org.apache.flink.streaming.api.operators.AbstractStreamOperator) this)
              .setProcessingTimeService(processingTimeService);
          }
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) element.getValue();
          
          org.apache.flink.table.data.binary.BinaryStringData field$8;
          boolean isNull$8;
          org.apache.flink.table.data.binary.BinaryStringData field$10;
          boolean isNull$12;
          boolean result$13;
          double field$14;
          boolean isNull$14;
          
          
          
          isNull$8 = in1.isNullAt(0);
          field$8 = org.apache.flink.table.data.binary.BinaryStringData.EMPTY_UTF8;
          if (!isNull$8) {
            field$8 = ((org.apache.flink.table.data.binary.BinaryStringData) in1.getString(0));
          }
          field$10 = field$8;
          if (!isNull$8) {
            field$10 = (org.apache.flink.table.data.binary.BinaryStringData) (typeSerializer$9.copy(field$10));
          }
                  
          
          
          
          isNull$12 = isNull$8 || false;
          result$13 = false;
          if (!isNull$12) {
            
            result$13 = field$10.equals(((org.apache.flink.table.data.binary.BinaryStringData) str$11));
            
          }
          
          if (result$13) {
            isNull$14 = in1.isNullAt(1);
          field$14 = -1.0d;
          if (!isNull$14) {
            field$14 = in1.getDouble(1);
          }
            
          out.setRowKind(in1.getRowKind());
          
          
          
          
          if (false) {
            out.setNullAt(0);
          } else {
            out.setNonPrimitiveValue(0, ((org.apache.flink.table.data.binary.BinaryStringData) str$11));
          }
                    
          
          
          if (isNull$14) {
            out.setNullAt(1);
          } else {
            out.setDouble(1, field$14);
          }
                    
                  
          output.collect(outElement.replace(out));
          
          }
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
2021-04-15 17:52:30,727 WARN org.apache.flink.metrics.MetricGroup - The operator name SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:52:30,747 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Source: Custom File source (1/1)#0
2021-04-15 17:52:30,748 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: SinkConversion$87 

 Code:

      public class SinkConversion$87 extends org.apache.flink.table.runtime.operators.TableStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.data.util.DataFormatConverters.RowConverter converter$85;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SinkConversion$87(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output,
            org.apache.flink.streaming.runtime.tasks.ProcessingTimeService processingTimeService) throws Exception {
          this.references = references;
          converter$85 = (((org.apache.flink.table.data.util.DataFormatConverters.RowConverter) references[0]));
          this.setup(task, config, output);
          if (this instanceof org.apache.flink.streaming.api.operators.AbstractStreamOperator) {
            ((org.apache.flink.streaming.api.operators.AbstractStreamOperator) this)
              .setProcessingTimeService(processingTimeService);
          }
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) element.getValue();
          
          
          
          
          
          
          org.apache.flink.api.java.tuple.Tuple2 result$86 = new org.apache.flink.api.java.tuple.Tuple2();
          result$86.setField(org.apache.flink.table.data.util.RowDataUtil.isAccumulateMsg(in1), 0);
          result$86.setField((org.apache.flink.types.Row) converter$85.toExternal((org.apache.flink.table.data.RowData) in1), 1);
          output.collect(outElement.replace(result$86));
                   
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
2021-04-15 17:52:30,763 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: SinkConversion$3 

 Code:

      public class SinkConversion$3 extends org.apache.flink.table.runtime.operators.TableStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.data.util.DataFormatConverters.RowConverter converter$2;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SinkConversion$3(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output,
            org.apache.flink.streaming.runtime.tasks.ProcessingTimeService processingTimeService) throws Exception {
          this.references = references;
          converter$2 = (((org.apache.flink.table.data.util.DataFormatConverters.RowConverter) references[0]));
          this.setup(task, config, output);
          if (this instanceof org.apache.flink.streaming.api.operators.AbstractStreamOperator) {
            ((org.apache.flink.streaming.api.operators.AbstractStreamOperator) this)
              .setProcessingTimeService(processingTimeService);
          }
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) element.getValue();
          
          
          
          
          
          output.collect(outElement.replace((org.apache.flink.types.Row) converter$2.toExternal((org.apache.flink.table.data.RowData) in1)));
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
2021-04-15 17:52:30,769 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Source: Custom File source (1/1)#0
2021-04-15 17:52:30,774 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: SourceConversion$1 

 Code:

      public class SourceConversion$1 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.data.conversion.RowRowConverter converter$0;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SourceConversion$1(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output,
            org.apache.flink.streaming.runtime.tasks.ProcessingTimeService processingTimeService) throws Exception {
          this.references = references;
          converter$0 = (((org.apache.flink.table.data.conversion.RowRowConverter) references[0]));
          this.setup(task, config, output);
          if (this instanceof org.apache.flink.streaming.api.operators.AbstractStreamOperator) {
            ((org.apache.flink.streaming.api.operators.AbstractStreamOperator) this)
              .setProcessingTimeService(processingTimeService);
          }
        }

        @Override
        public void open() throws Exception {
          super.open();
          
          converter$0.open(getRuntimeContext().getUserCodeClassLoader());
                     
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) (org.apache.flink.table.data.RowData) converter$0.toInternalOrNull((org.apache.flink.types.Row) element.getValue());
          
          
          
          output.collect(outElement.replace(in1));
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
2021-04-15 17:52:30,786 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSource_bc764cd8ddf7a0cff126f51c16239658_(1/1) with empty state.
2021-04-15 17:52:30,786 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSource_605b35e407e90cda15ad084365733fdd_(1/1) with empty state.
2021-04-15 17:52:30,786 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSource_feca28aff5a3958840bee985ee7de4d3_(1/1) with empty state.
2021-04-15 17:52:30,788 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSource_3ba1d27b7fde4848a86e865c6c402dfa_(1/1) with empty state.
2021-04-15 17:52:30,791 WARN org.apache.flink.metrics.MetricGroup - The operator name Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:52:30,798 WARN org.apache.flink.metrics.MetricGroup - The operator name SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:52:30,799 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: SourceConversion$7 

 Code:

      public class SourceConversion$7 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.data.conversion.RowRowConverter converter$6;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SourceConversion$7(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output,
            org.apache.flink.streaming.runtime.tasks.ProcessingTimeService processingTimeService) throws Exception {
          this.references = references;
          converter$6 = (((org.apache.flink.table.data.conversion.RowRowConverter) references[0]));
          this.setup(task, config, output);
          if (this instanceof org.apache.flink.streaming.api.operators.AbstractStreamOperator) {
            ((org.apache.flink.streaming.api.operators.AbstractStreamOperator) this)
              .setProcessingTimeService(processingTimeService);
          }
        }

        @Override
        public void open() throws Exception {
          super.open();
          
          converter$6.open(getRuntimeContext().getUserCodeClassLoader());
                     
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) (org.apache.flink.table.data.RowData) converter$6.toInternalOrNull((org.apache.flink.types.Row) element.getValue());
          
          
          
          output.collect(outElement.replace(in1));
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
2021-04-15 17:52:30,805 WARN org.apache.flink.metrics.MetricGroup - The operator name GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:52:30,815 WARN org.apache.flink.metrics.MetricGroup - The operator name GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:52:30,832 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0
2021-04-15 17:52:30,833 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_5eabb43907f8f80df1ce4361a6f197f2_(1/1) with empty state.
2021-04-15 17:52:30,833 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for SinkConversion$52_82ccb120c1db7ba31f32cb138318e905_(1/1) with empty state.
2021-04-15 17:52:30,836 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating keyed state backend for KeyedProcessOperator_6177eb422127981c4dbb05ea3af8a2d4_(1/1) with empty state.
2021-04-15 17:52:30,848 WARN org.apache.flink.metrics.MetricGroup - The operator name SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:52:30,850 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0
2021-04-15 17:52:30,851 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_acef8fa5317ebae622515a3dd3a22b5b_(1/1) with empty state.
2021-04-15 17:52:30,852 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for SinkConversion$17_7be2b145deed960935698c82ec6584ff_(1/1) with empty state.
2021-04-15 17:52:30,853 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamExecCalc$15_eac1a1ce1701c72ed31579ebbd62865a_(1/1) with empty state.
2021-04-15 17:52:30,853 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0
2021-04-15 17:52:30,854 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for SourceConversion$54_fd97fe1bcea3a8dd8f11b0abe0bb8fa7_(1/1) with empty state.
2021-04-15 17:52:30,864 INFO o.a.f.runtime.state.heap.HeapKeyedStateBackendBuilder - Finished to build heap keyed state-backend.
2021-04-15 17:52:30,875 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0
2021-04-15 17:52:30,886 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_1ff151f0e73312424d48b44002b858b2_(1/1) with empty state.
2021-04-15 17:52:30,887 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for SinkConversion$3_a74f42661a9b9f548012fab549771fb0_(1/1) with empty state.
2021-04-15 17:52:30,887 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for SourceConversion$1_e1caecf4e938c7437797fd5ffa107998_(1/1) with empty state.
2021-04-15 17:52:30,887 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for SourceConversion$7_f747214a7be91c9c2b6cc5b7a3c8c7eb_(1/1) with empty state.
2021-04-15 17:52:30,888 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for ContinuousFileReaderOperator_b23642197a427ec5db481d3963c66cfb_(1/1) with empty state.
2021-04-15 17:52:30,910 INFO o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - No state to restore for the ContinuousFileMonitoringFunction.
2021-04-15 17:52:30,911 DEBUG o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Opened ContinuousFileMonitoringFunction (taskIdx= 0) for path: src/main/resources/sensor.txt
2021-04-15 17:52:30,921 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0
2021-04-15 17:52:30,921 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_3ed91adabe57771c56cb72d2e8ef0077_(1/1) with empty state.
2021-04-15 17:52:30,922 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for SinkConversion$87_a0dd144f36ef19961046e87bafc35e9e_(1/1) with empty state.
2021-04-15 17:52:30,923 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating keyed state backend for KeyedProcessOperator_5528b14a6b129894d24927c518acc32a_(1/1) with empty state.
2021-04-15 17:52:30,924 INFO o.a.f.runtime.state.heap.HeapKeyedStateBackendBuilder - Finished to build heap keyed state-backend.
2021-04-15 17:52:30,933 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for ContinuousFileReaderOperator_77af20c908aca598f7bbebd4db138545_(1/1) with empty state.
2021-04-15 17:52:30,934 INFO o.a.f.s.a.functions.source.ContinuousFileReaderOperator - No state to restore for the ContinuousFileReaderOperator (taskIdx=0).
2021-04-15 17:52:30,945 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for ContinuousFileReaderOperator_aecbb8a11dc0c28dc6c178e875ebcc43_(1/1) with empty state.
2021-04-15 17:52:30,945 INFO o.a.f.s.a.functions.source.ContinuousFileReaderOperator - No state to restore for the ContinuousFileReaderOperator (taskIdx=0).
2021-04-15 17:52:30,946 INFO o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - No state to restore for the ContinuousFileMonitoringFunction.
2021-04-15 17:52:30,946 DEBUG o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Opened ContinuousFileMonitoringFunction (taskIdx= 0) for path: src/main/resources/sensor.txt
2021-04-15 17:52:30,946 INFO o.a.f.s.a.functions.source.ContinuousFileReaderOperator - No state to restore for the ContinuousFileReaderOperator (taskIdx=0).
2021-04-15 17:52:30,947 INFO o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - No state to restore for the ContinuousFileMonitoringFunction.
2021-04-15 17:52:30,947 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0
2021-04-15 17:52:30,947 DEBUG o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Opened ContinuousFileMonitoringFunction (taskIdx= 0) for path: src/main/resources/sensor.txt
2021-04-15 17:52:30,947 INFO o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - No state to restore for the ContinuousFileMonitoringFunction.
2021-04-15 17:52:30,947 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for SourceConversion$19_7b8b09df1455080a34c77ad3d0c43cb7_(1/1) with empty state.
2021-04-15 17:52:30,947 DEBUG o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Opened ContinuousFileMonitoringFunction (taskIdx= 0) for path: src/main/resources/sensor.txt
2021-04-15 17:52:30,948 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for ContinuousFileReaderOperator_a19bdf930ebdf056b3d6de069bc89bdd_(1/1) with empty state.
2021-04-15 17:52:30,948 INFO o.a.f.s.a.functions.source.ContinuousFileReaderOperator - No state to restore for the ContinuousFileReaderOperator (taskIdx=0).
2021-04-15 17:52:30,966 INFO org.apache.flink.core.fs.FileSystem - Hadoop is not in the classpath/dependencies. The extended set of supported File Systems via Hadoop is not available.
2021-04-15 17:52:30,973 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf - -Dorg.apache.flink.shaded.netty4.io.netty.buffer.checkAccessible: true
2021-04-15 17:52:30,974 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf - -Dorg.apache.flink.shaded.netty4.io.netty.buffer.checkBounds: true
2021-04-15 17:52:30,974 INFO o.apache.flink.runtime.state.heap.HeapKeyedStateBackend - Initializing heap keyed state backend with stream factory.
2021-04-15 17:52:30,974 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for KeyedProcessOperator_6177eb422127981c4dbb05ea3af8a2d4_(1/1) with empty state.
2021-04-15 17:52:30,975 DEBUG o.a.f.s.n.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.flink.shaded.netty4.io.netty.util.ResourceLeakDetector@789689d4
2021-04-15 17:52:30,975 INFO o.apache.flink.runtime.state.heap.HeapKeyedStateBackend - Initializing heap keyed state backend with stream factory.
2021-04-15 17:52:30,975 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for KeyedProcessOperator_5528b14a6b129894d24927c518acc32a_(1/1) with empty state.
2021-04-15 17:52:30,979 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: GroupAggsHandler$46 

 Code:

        public final class GroupAggsHandler$46 implements org.apache.flink.table.runtime.generated.AggsHandleFunction {

          long agg0_count;
          boolean agg0_countIsNull;
          double agg1_sum;
          boolean agg1_sumIsNull;
          long agg1_count;
          boolean agg1_countIsNull;
          org.apache.flink.table.data.GenericRowData acc$22 = new org.apache.flink.table.data.GenericRowData(3);
          org.apache.flink.table.data.GenericRowData acc$23 = new org.apache.flink.table.data.GenericRowData(3);
          private transient org.apache.flink.table.runtime.typeutils.StringDataSerializer typeSerializer$28;
          org.apache.flink.table.data.GenericRowData aggValue$45 = new org.apache.flink.table.data.GenericRowData(2);

          private org.apache.flink.table.runtime.dataview.StateDataViewStore store;

          public GroupAggsHandler$46(java.lang.Object[] references) throws Exception {
            typeSerializer$28 = (((org.apache.flink.table.runtime.typeutils.StringDataSerializer) references[0]));
          }

          private org.apache.flink.api.common.functions.RuntimeContext getRuntimeContext() {
            return store.getRuntimeContext();
          }

          @Override
          public void open(org.apache.flink.table.runtime.dataview.StateDataViewStore store) throws Exception {
            this.store = store;
            
          }

          @Override
          public void accumulate(org.apache.flink.table.data.RowData accInput) throws Exception {
            
            org.apache.flink.table.data.binary.BinaryStringData field$27;
            boolean isNull$27;
            org.apache.flink.table.data.binary.BinaryStringData field$29;
            boolean isNull$30;
            long result$31;
            double field$33;
            boolean isNull$33;
            boolean isNull$34;
            double result$35;
            boolean isNull$37;
            long result$38;
            isNull$33 = accInput.isNullAt(2);
            field$33 = -1.0d;
            if (!isNull$33) {
              field$33 = accInput.getDouble(2);
            }
            
            isNull$27 = accInput.isNullAt(0);
            field$27 = org.apache.flink.table.data.binary.BinaryStringData.EMPTY_UTF8;
            if (!isNull$27) {
              field$27 = ((org.apache.flink.table.data.binary.BinaryStringData) accInput.getString(0));
            }
            field$29 = field$27;
            if (!isNull$27) {
              field$29 = (org.apache.flink.table.data.binary.BinaryStringData) (typeSerializer$28.copy(field$29));
            }
            
            long result$32 = -1L;
            boolean isNull$32;
            if (isNull$27) {
              
              isNull$32 = agg0_countIsNull;
              if (!isNull$32) {
                result$32 = agg0_count;
              }
            }
            else {
              
            
            
            isNull$30 = agg0_countIsNull || false;
            result$31 = -1L;
            if (!isNull$30) {
              
              result$31 = (long) (agg0_count + ((long) 1L));
              
            }
            
              isNull$32 = isNull$30;
              if (!isNull$32) {
                result$32 = result$31;
              }
            }
            agg0_count = result$32;;
            agg0_countIsNull = isNull$32;
                   
            
            double result$36 = -1.0d;
            boolean isNull$36;
            if (isNull$33) {
              
              isNull$36 = agg1_sumIsNull;
              if (!isNull$36) {
                result$36 = agg1_sum;
              }
            }
            else {
              
            
            
            isNull$34 = agg1_sumIsNull || isNull$33;
            result$35 = -1.0d;
            if (!isNull$34) {
              
              result$35 = (double) (agg1_sum + field$33);
              
            }
            
              isNull$36 = isNull$34;
              if (!isNull$36) {
                result$36 = result$35;
              }
            }
            agg1_sum = result$36;;
            agg1_sumIsNull = isNull$36;
                   
            
            long result$39 = -1L;
            boolean isNull$39;
            if (isNull$33) {
              
              isNull$39 = agg1_countIsNull;
              if (!isNull$39) {
                result$39 = agg1_count;
              }
            }
            else {
              
            
            
            isNull$37 = agg1_countIsNull || false;
            result$38 = -1L;
            if (!isNull$37) {
              
              result$38 = (long) (agg1_count + ((long) 1L));
              
            }
            
              isNull$39 = isNull$37;
              if (!isNull$39) {
                result$39 = result$38;
              }
            }
            agg1_count = result$39;;
            agg1_countIsNull = isNull$39;
                   
            
          }

          @Override
          public void retract(org.apache.flink.table.data.RowData retractInput) throws Exception {
            
            throw new java.lang.RuntimeException("This function not require retract method, but the retract method is called.");
                 
          }

          @Override
          public void merge(org.apache.flink.table.data.RowData otherAcc) throws Exception {
            
            throw new java.lang.RuntimeException("This function not require merge method, but the merge method is called.");
                 
          }

          @Override
          public void setAccumulators(org.apache.flink.table.data.RowData acc) throws Exception {
            
            long field$24;
            boolean isNull$24;
            double field$25;
            boolean isNull$25;
            long field$26;
            boolean isNull$26;
            isNull$24 = acc.isNullAt(0);
            field$24 = -1L;
            if (!isNull$24) {
              field$24 = acc.getLong(0);
            }
            isNull$25 = acc.isNullAt(1);
            field$25 = -1.0d;
            if (!isNull$25) {
              field$25 = acc.getDouble(1);
            }
            isNull$26 = acc.isNullAt(2);
            field$26 = -1L;
            if (!isNull$26) {
              field$26 = acc.getLong(2);
            }
            
            agg0_count = field$24;;
            agg0_countIsNull = isNull$24;
                     
            
            agg1_sum = field$25;;
            agg1_sumIsNull = isNull$25;
                     
            
            agg1_count = field$26;;
            agg1_countIsNull = isNull$26;
                     
                
          }

          @Override
          public void resetAccumulators() throws Exception {
            
            
            
            
            agg0_count = ((long) 0L);
            agg0_countIsNull = false;
                     
            
            
            agg1_sum = ((double) 0.0d);
            agg1_sumIsNull = false;
                     
            
            
            agg1_count = ((long) 0L);
            agg1_countIsNull = false;
                     
                
          }

          @Override
          public org.apache.flink.table.data.RowData getAccumulators() throws Exception {
            
            
            
            acc$23 = new org.apache.flink.table.data.GenericRowData(3);
            
            
            if (agg0_countIsNull) {
              acc$23.setField(0, null);
            } else {
              acc$23.setField(0, agg0_count);
            }
                      
            
            
            if (agg1_sumIsNull) {
              acc$23.setField(1, null);
            } else {
              acc$23.setField(1, agg1_sum);
            }
                      
            
            
            if (agg1_countIsNull) {
              acc$23.setField(2, null);
            } else {
              acc$23.setField(2, agg1_count);
            }
                      
                    
            return acc$23;
                
          }

          @Override
          public org.apache.flink.table.data.RowData createAccumulators() throws Exception {
            
            
            
            acc$22 = new org.apache.flink.table.data.GenericRowData(3);
            
            
            if (false) {
              acc$22.setField(0, null);
            } else {
              acc$22.setField(0, ((long) 0L));
            }
                      
            
            
            if (false) {
              acc$22.setField(1, null);
            } else {
              acc$22.setField(1, ((double) 0.0d));
            }
                      
            
            
            if (false) {
              acc$22.setField(2, null);
            } else {
              acc$22.setField(2, ((long) 0L));
            }
                      
                    
            return acc$22;
                
          }

          @Override
          public org.apache.flink.table.data.RowData getValue() throws Exception {
            
            boolean isNull$40;
            boolean result$41;
            boolean isNull$42;
            double result$43;
            
            aggValue$45 = new org.apache.flink.table.data.GenericRowData(2);
            
            
            if (agg0_countIsNull) {
              aggValue$45.setField(0, null);
            } else {
              aggValue$45.setField(0, agg0_count);
            }
                      
            
            isNull$40 = agg1_countIsNull || false;
            result$41 = false;
            if (!isNull$40) {
              
              result$41 = agg1_count == ((long) 0L);
              
            }
            
            double result$44 = -1.0d;
            boolean isNull$44;
            if (result$41) {
              
              isNull$44 = true;
              if (!isNull$44) {
                result$44 = ((double) -1.0d);
              }
            }
            else {
              
            
            
            isNull$42 = agg1_sumIsNull || agg1_countIsNull;
            result$43 = -1.0d;
            if (!isNull$42) {
              
              result$43 = (double) (agg1_sum / (new java.lang.Long(agg1_count)).doubleValue());
              
            }
            
              isNull$44 = isNull$42;
              if (!isNull$44) {
                result$44 = result$43;
              }
            }
            if (isNull$44) {
              aggValue$45.setField(1, null);
            } else {
              aggValue$45.setField(1, result$44);
            }
                      
                    
            return aggValue$45;
                
          }

          @Override
          public void cleanup() throws Exception {
            
            
          }

          @Override
          public void close() throws Exception {
            
          }
        }
      
2021-04-15 17:52:30,980 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: GroupAggsHandler$81 

 Code:

        public final class GroupAggsHandler$81 implements org.apache.flink.table.runtime.generated.AggsHandleFunction {

          long agg0_count;
          boolean agg0_countIsNull;
          double agg1_sum;
          boolean agg1_sumIsNull;
          long agg1_count;
          boolean agg1_countIsNull;
          org.apache.flink.table.data.GenericRowData acc$57 = new org.apache.flink.table.data.GenericRowData(3);
          org.apache.flink.table.data.GenericRowData acc$58 = new org.apache.flink.table.data.GenericRowData(3);
          private transient org.apache.flink.table.runtime.typeutils.StringDataSerializer typeSerializer$63;
          org.apache.flink.table.data.GenericRowData aggValue$80 = new org.apache.flink.table.data.GenericRowData(2);

          private org.apache.flink.table.runtime.dataview.StateDataViewStore store;

          public GroupAggsHandler$81(java.lang.Object[] references) throws Exception {
            typeSerializer$63 = (((org.apache.flink.table.runtime.typeutils.StringDataSerializer) references[0]));
          }

          private org.apache.flink.api.common.functions.RuntimeContext getRuntimeContext() {
            return store.getRuntimeContext();
          }

          @Override
          public void open(org.apache.flink.table.runtime.dataview.StateDataViewStore store) throws Exception {
            this.store = store;
            
          }

          @Override
          public void accumulate(org.apache.flink.table.data.RowData accInput) throws Exception {
            
            org.apache.flink.table.data.binary.BinaryStringData field$62;
            boolean isNull$62;
            org.apache.flink.table.data.binary.BinaryStringData field$64;
            boolean isNull$65;
            long result$66;
            double field$68;
            boolean isNull$68;
            boolean isNull$69;
            double result$70;
            boolean isNull$72;
            long result$73;
            isNull$62 = accInput.isNullAt(0);
            field$62 = org.apache.flink.table.data.binary.BinaryStringData.EMPTY_UTF8;
            if (!isNull$62) {
              field$62 = ((org.apache.flink.table.data.binary.BinaryStringData) accInput.getString(0));
            }
            field$64 = field$62;
            if (!isNull$62) {
              field$64 = (org.apache.flink.table.data.binary.BinaryStringData) (typeSerializer$63.copy(field$64));
            }
                    
            isNull$68 = accInput.isNullAt(1);
            field$68 = -1.0d;
            if (!isNull$68) {
              field$68 = accInput.getDouble(1);
            }
            
            long result$67 = -1L;
            boolean isNull$67;
            if (isNull$62) {
              
              isNull$67 = agg0_countIsNull;
              if (!isNull$67) {
                result$67 = agg0_count;
              }
            }
            else {
              
            
            
            isNull$65 = agg0_countIsNull || false;
            result$66 = -1L;
            if (!isNull$65) {
              
              result$66 = (long) (agg0_count + ((long) 1L));
              
            }
            
              isNull$67 = isNull$65;
              if (!isNull$67) {
                result$67 = result$66;
              }
            }
            agg0_count = result$67;;
            agg0_countIsNull = isNull$67;
                   
            
            double result$71 = -1.0d;
            boolean isNull$71;
            if (isNull$68) {
              
              isNull$71 = agg1_sumIsNull;
              if (!isNull$71) {
                result$71 = agg1_sum;
              }
            }
            else {
              
            
            
            isNull$69 = agg1_sumIsNull || isNull$68;
            result$70 = -1.0d;
            if (!isNull$69) {
              
              result$70 = (double) (agg1_sum + field$68);
              
            }
            
              isNull$71 = isNull$69;
              if (!isNull$71) {
                result$71 = result$70;
              }
            }
            agg1_sum = result$71;;
            agg1_sumIsNull = isNull$71;
                   
            
            long result$74 = -1L;
            boolean isNull$74;
            if (isNull$68) {
              
              isNull$74 = agg1_countIsNull;
              if (!isNull$74) {
                result$74 = agg1_count;
              }
            }
            else {
              
            
            
            isNull$72 = agg1_countIsNull || false;
            result$73 = -1L;
            if (!isNull$72) {
              
              result$73 = (long) (agg1_count + ((long) 1L));
              
            }
            
              isNull$74 = isNull$72;
              if (!isNull$74) {
                result$74 = result$73;
              }
            }
            agg1_count = result$74;;
            agg1_countIsNull = isNull$74;
                   
            
          }

          @Override
          public void retract(org.apache.flink.table.data.RowData retractInput) throws Exception {
            
            throw new java.lang.RuntimeException("This function not require retract method, but the retract method is called.");
                 
          }

          @Override
          public void merge(org.apache.flink.table.data.RowData otherAcc) throws Exception {
            
            throw new java.lang.RuntimeException("This function not require merge method, but the merge method is called.");
                 
          }

          @Override
          public void setAccumulators(org.apache.flink.table.data.RowData acc) throws Exception {
            
            long field$59;
            boolean isNull$59;
            double field$60;
            boolean isNull$60;
            long field$61;
            boolean isNull$61;
            isNull$59 = acc.isNullAt(0);
            field$59 = -1L;
            if (!isNull$59) {
              field$59 = acc.getLong(0);
            }
            isNull$60 = acc.isNullAt(1);
            field$60 = -1.0d;
            if (!isNull$60) {
              field$60 = acc.getDouble(1);
            }
            isNull$61 = acc.isNullAt(2);
            field$61 = -1L;
            if (!isNull$61) {
              field$61 = acc.getLong(2);
            }
            
            agg0_count = field$59;;
            agg0_countIsNull = isNull$59;
                     
            
            agg1_sum = field$60;;
            agg1_sumIsNull = isNull$60;
                     
            
            agg1_count = field$61;;
            agg1_countIsNull = isNull$61;
                     
                
          }

          @Override
          public void resetAccumulators() throws Exception {
            
            
            
            
            agg0_count = ((long) 0L);
            agg0_countIsNull = false;
                     
            
            
            agg1_sum = ((double) 0.0d);
            agg1_sumIsNull = false;
                     
            
            
            agg1_count = ((long) 0L);
            agg1_countIsNull = false;
                     
                
          }

          @Override
          public org.apache.flink.table.data.RowData getAccumulators() throws Exception {
            
            
            
            acc$58 = new org.apache.flink.table.data.GenericRowData(3);
            
            
            if (agg0_countIsNull) {
              acc$58.setField(0, null);
            } else {
              acc$58.setField(0, agg0_count);
            }
                      
            
            
            if (agg1_sumIsNull) {
              acc$58.setField(1, null);
            } else {
              acc$58.setField(1, agg1_sum);
            }
                      
            
            
            if (agg1_countIsNull) {
              acc$58.setField(2, null);
            } else {
              acc$58.setField(2, agg1_count);
            }
                      
                    
            return acc$58;
                
          }

          @Override
          public org.apache.flink.table.data.RowData createAccumulators() throws Exception {
            
            
            
            acc$57 = new org.apache.flink.table.data.GenericRowData(3);
            
            
            if (false) {
              acc$57.setField(0, null);
            } else {
              acc$57.setField(0, ((long) 0L));
            }
                      
            
            
            if (false) {
              acc$57.setField(1, null);
            } else {
              acc$57.setField(1, ((double) 0.0d));
            }
                      
            
            
            if (false) {
              acc$57.setField(2, null);
            } else {
              acc$57.setField(2, ((long) 0L));
            }
                      
                    
            return acc$57;
                
          }

          @Override
          public org.apache.flink.table.data.RowData getValue() throws Exception {
            
            boolean isNull$75;
            boolean result$76;
            boolean isNull$77;
            double result$78;
            
            aggValue$80 = new org.apache.flink.table.data.GenericRowData(2);
            
            
            if (agg0_countIsNull) {
              aggValue$80.setField(0, null);
            } else {
              aggValue$80.setField(0, agg0_count);
            }
                      
            
            isNull$75 = agg1_countIsNull || false;
            result$76 = false;
            if (!isNull$75) {
              
              result$76 = agg1_count == ((long) 0L);
              
            }
            
            double result$79 = -1.0d;
            boolean isNull$79;
            if (result$76) {
              
              isNull$79 = true;
              if (!isNull$79) {
                result$79 = ((double) -1.0d);
              }
            }
            else {
              
            
            
            isNull$77 = agg1_sumIsNull || agg1_countIsNull;
            result$78 = -1.0d;
            if (!isNull$77) {
              
              result$78 = (double) (agg1_sum / (new java.lang.Long(agg1_count)).doubleValue());
              
            }
            
              isNull$79 = isNull$77;
              if (!isNull$79) {
                result$79 = result$78;
              }
            }
            if (isNull$79) {
              aggValue$80.setField(1, null);
            } else {
              aggValue$80.setField(1, result$79);
            }
                      
                    
            return aggValue$80;
                
          }

          @Override
          public void cleanup() throws Exception {
            
            
          }

          @Override
          public void close() throws Exception {
            
          }
        }
      
2021-04-15 17:52:31,009 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (1445820206b44a96a015433b0bf94390)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:52:31,010 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (5c528b6dc0ff91c03924e38491364291)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:52:31,012 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:52:31,015 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (87de37c9db81dfdee6f377f619e5fb63)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:52:31,016 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:52:31,017 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [de9c468ad4f929549d1ef23076f82f16#0@cc1f1a33b0c4d5646db685dd63371efa]: Requesting LOCAL subpartition 0 of partition de9c468ad4f929549d1ef23076f82f16#0@cc1f1a33b0c4d5646db685dd63371efa. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:52:31,017 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 0 of PipelinedResultPartition de9c468ad4f929549d1ef23076f82f16#0@cc1f1a33b0c4d5646db685dd63371efa [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:52:31,018 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (6fbd8c62478c21cfd14aa27a55b4fe5c)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:52:31,019 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:52:31,019 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:52:31,072 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File source (1/1)#0 (cc1f1a33b0c4d5646db685dd63371efa): Creating read view for subpartition 0 of partition de9c468ad4f929549d1ef23076f82f16#0@cc1f1a33b0c4d5646db685dd63371efa.
2021-04-15 17:52:31,073 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 0) of ResultPartition de9c468ad4f929549d1ef23076f82f16#0@cc1f1a33b0c4d5646db685dd63371efa
2021-04-15 17:52:31,074 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:52:31,074 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:52:31,075 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [80a2030ea85de8019886d216c59629fc#0@acf9733938da85c0b5a1639427e16cc2]: Requesting LOCAL subpartition 0 of partition 80a2030ea85de8019886d216c59629fc#0@acf9733938da85c0b5a1639427e16cc2. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:52:31,075 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 0 of PipelinedResultPartition 80a2030ea85de8019886d216c59629fc#0@acf9733938da85c0b5a1639427e16cc2 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:52:31,077 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [6162f7b1a326a5f60ff644efe4b5860a#0@cb17ee903affddd528d81a985c2f7958]: Requesting LOCAL subpartition 0 of partition 6162f7b1a326a5f60ff644efe4b5860a#0@cb17ee903affddd528d81a985c2f7958. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:52:31,077 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File source (1/1)#0 (acf9733938da85c0b5a1639427e16cc2): Creating read view for subpartition 0 of partition 80a2030ea85de8019886d216c59629fc#0@acf9733938da85c0b5a1639427e16cc2.
2021-04-15 17:52:31,077 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 0) of ResultPartition 80a2030ea85de8019886d216c59629fc#0@acf9733938da85c0b5a1639427e16cc2
2021-04-15 17:52:31,101 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: GroupAggValueEqualiser$82 

 Code:

        public final class GroupAggValueEqualiser$82 implements org.apache.flink.table.runtime.generated.RecordEqualiser {

          

          public GroupAggValueEqualiser$82(Object[] references) throws Exception {
            
          }

          @Override
          public boolean equals(org.apache.flink.table.data.RowData left, org.apache.flink.table.data.RowData right) {
            if (left instanceof org.apache.flink.table.data.binary.BinaryRowData && right instanceof org.apache.flink.table.data.binary.BinaryRowData) {
              return left.equals(right);
            } else {
              
              if (left.getRowKind() != right.getRowKind()) {
                return false;
              }
                     
              
              
              boolean leftIsNull$0 = left.isNullAt(0);
              boolean rightIsNull$0 = right.isNullAt(0);
              boolean cmp0;
              if (leftIsNull$0 && rightIsNull$0) {
                cmp0 = true;
              } else if (leftIsNull$0|| rightIsNull$0) {
                cmp0 = false;
              } else {
                long leftField$0 = left.getLong(0);
                long rightField$0 = right.getLong(0);
                
                cmp0 = leftField$0 == rightField$0;
              }
              if (!cmp0) {
                return false;
              }
                    
              
              boolean leftIsNull$1 = left.isNullAt(1);
              boolean rightIsNull$1 = right.isNullAt(1);
              boolean cmp1;
              if (leftIsNull$1 && rightIsNull$1) {
                cmp1 = true;
              } else if (leftIsNull$1|| rightIsNull$1) {
                cmp1 = false;
              } else {
                double leftField$1 = left.getDouble(1);
                double rightField$1 = right.getDouble(1);
                
                cmp1 = leftField$1 == rightField$1;
              }
              if (!cmp1) {
                return false;
              }
                    
              return true;
            }
          }
        }
      
2021-04-15 17:52:31,112 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 0 of PipelinedResultPartition 6162f7b1a326a5f60ff644efe4b5860a#0@cb17ee903affddd528d81a985c2f7958 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:52:31,117 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:52:31,117 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:52:31,117 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [de5d1a9da390a2613fba1a2678353f30#0@4e1576c5820dd61a8a94ed976818593b]: Requesting LOCAL subpartition 0 of partition de5d1a9da390a2613fba1a2678353f30#0@4e1576c5820dd61a8a94ed976818593b. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:52:31,117 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: GroupAggValueEqualiser$47 

 Code:

        public final class GroupAggValueEqualiser$47 implements org.apache.flink.table.runtime.generated.RecordEqualiser {

          

          public GroupAggValueEqualiser$47(Object[] references) throws Exception {
            
          }

          @Override
          public boolean equals(org.apache.flink.table.data.RowData left, org.apache.flink.table.data.RowData right) {
            if (left instanceof org.apache.flink.table.data.binary.BinaryRowData && right instanceof org.apache.flink.table.data.binary.BinaryRowData) {
              return left.equals(right);
            } else {
              
              if (left.getRowKind() != right.getRowKind()) {
                return false;
              }
                     
              
              
              boolean leftIsNull$0 = left.isNullAt(0);
              boolean rightIsNull$0 = right.isNullAt(0);
              boolean cmp0;
              if (leftIsNull$0 && rightIsNull$0) {
                cmp0 = true;
              } else if (leftIsNull$0|| rightIsNull$0) {
                cmp0 = false;
              } else {
                long leftField$0 = left.getLong(0);
                long rightField$0 = right.getLong(0);
                
                cmp0 = leftField$0 == rightField$0;
              }
              if (!cmp0) {
                return false;
              }
                    
              
              boolean leftIsNull$1 = left.isNullAt(1);
              boolean rightIsNull$1 = right.isNullAt(1);
              boolean cmp1;
              if (leftIsNull$1 && rightIsNull$1) {
                cmp1 = true;
              } else if (leftIsNull$1|| rightIsNull$1) {
                cmp1 = false;
              } else {
                double leftField$1 = left.getDouble(1);
                double rightField$1 = right.getDouble(1);
                
                cmp1 = leftField$1 == rightField$1;
              }
              if (!cmp1) {
                return false;
              }
                    
              return true;
            }
          }
        }
      
2021-04-15 17:52:31,117 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File source (1/1)#0 (cb17ee903affddd528d81a985c2f7958): Creating read view for subpartition 0 of partition 6162f7b1a326a5f60ff644efe4b5860a#0@cb17ee903affddd528d81a985c2f7958.
2021-04-15 17:52:31,130 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 0) of ResultPartition 6162f7b1a326a5f60ff644efe4b5860a#0@cb17ee903affddd528d81a985c2f7958
2021-04-15 17:52:31,131 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 0 of PipelinedResultPartition de5d1a9da390a2613fba1a2678353f30#0@4e1576c5820dd61a8a94ed976818593b [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:52:31,141 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File source (1/1)#0 (4e1576c5820dd61a8a94ed976818593b): Creating read view for subpartition 0 of partition de5d1a9da390a2613fba1a2678353f30#0@4e1576c5820dd61a8a94ed976818593b.
2021-04-15 17:52:31,141 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 0) of ResultPartition de5d1a9da390a2613fba1a2678353f30#0@4e1576c5820dd61a8a94ed976818593b
2021-04-15 17:52:31,180 DEBUG org.apache.flink.core.fs.FileSystem - Loading extension file systems via services
2021-04-15 17:52:31,182 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (68c2e08bbf47ccdb95efe49cb8e5faab)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:52:31,183 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (1a583e156346e4c163645eac9e1ca58c)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:52:31,183 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:52:31,183 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:52:31,185 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [7f0f187fc0f5c9ab9257872acece76a0#0@5c528b6dc0ff91c03924e38491364291]: Requesting LOCAL subpartition 0 of partition 7f0f187fc0f5c9ab9257872acece76a0#0@5c528b6dc0ff91c03924e38491364291. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:52:31,185 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 0 of PipelinedResultPartition 7f0f187fc0f5c9ab9257872acece76a0#0@5c528b6dc0ff91c03924e38491364291 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:52:31,186 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (5c528b6dc0ff91c03924e38491364291): Creating read view for subpartition 0 of partition 7f0f187fc0f5c9ab9257872acece76a0#0@5c528b6dc0ff91c03924e38491364291.
2021-04-15 17:52:31,186 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 0) of ResultPartition 7f0f187fc0f5c9ab9257872acece76a0#0@5c528b6dc0ff91c03924e38491364291
2021-04-15 17:52:31,190 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:52:31,190 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:52:31,190 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [51607ff8d2b6611b9769c5234071e407#0@1445820206b44a96a015433b0bf94390]: Requesting LOCAL subpartition 0 of partition 51607ff8d2b6611b9769c5234071e407#0@1445820206b44a96a015433b0bf94390. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:52:31,190 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 0 of PipelinedResultPartition 51607ff8d2b6611b9769c5234071e407#0@1445820206b44a96a015433b0bf94390 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:52:31,191 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (1445820206b44a96a015433b0bf94390): Creating read view for subpartition 0 of partition 51607ff8d2b6611b9769c5234071e407#0@1445820206b44a96a015433b0bf94390.
2021-04-15 17:52:31,191 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 0) of ResultPartition 51607ff8d2b6611b9769c5234071e407#0@1445820206b44a96a015433b0bf94390
2021-04-15 17:52:31,196 INFO o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Forwarding split: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 17:52:31,196 INFO o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Forwarding split: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 17:52:31,196 INFO o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Forwarding split: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 17:52:31,197 INFO o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Forwarding split: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 17:52:31,425 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task Source: Custom File source (1/1)#0
2021-04-15 17:52:31,425 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task Source: Custom File source (1/1)#0
2021-04-15 17:52:31,426 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task Source: Custom File source (1/1)#0
2021-04-15 17:52:31,427 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task Source: Custom File source (1/1)#0
2021-04-15 17:52:31,427 DEBUG o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Closed File Monitoring Source for path: src/main/resources/sensor.txt.
2021-04-15 17:52:31,427 DEBUG o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Closed File Monitoring Source for path: src/main/resources/sensor.txt.
2021-04-15 17:52:31,428 DEBUG o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Closed File Monitoring Source for path: src/main/resources/sensor.txt.
2021-04-15 17:52:31,428 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task Source: Custom File source (1/1)#0
2021-04-15 17:52:31,429 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task Source: Custom File source (1/1)#0
2021-04-15 17:52:31,430 DEBUG o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Closed File Monitoring Source for path: src/main/resources/sensor.txt.
2021-04-15 17:52:31,430 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task Source: Custom File source (1/1)#0
2021-04-15 17:52:31,431 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task Source: Custom File source (1/1)#0
2021-04-15 17:52:31,443 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File source (1/1)#0 (cb17ee903affddd528d81a985c2f7958): Finished PipelinedSubpartition#0 [number of buffers: 2 (133 bytes), number of buffers in backlog: 1, finished? true, read view? true].
2021-04-15 17:52:31,449 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File source (1/1)#0 (cb17ee903affddd528d81a985c2f7958) switched from RUNNING to FINISHED.
2021-04-15 17:52:31,449 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Source: Custom File source (1/1)#0 (cb17ee903affddd528d81a985c2f7958).
2021-04-15 17:52:31,450 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task Source: Custom File source (1/1)#0 network resources (state: FINISHED).
2021-04-15 17:52:31,450 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - unregistering 6162f7b1a326a5f60ff644efe4b5860a#0@cb17ee903affddd528d81a985c2f7958
2021-04-15 17:52:31,450 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File source (1/1)#0 (cc1f1a33b0c4d5646db685dd63371efa): Finished PipelinedSubpartition#0 [number of buffers: 2 (133 bytes), number of buffers in backlog: 1, finished? true, read view? true].
2021-04-15 17:52:31,450 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File source (1/1)#0 (cc1f1a33b0c4d5646db685dd63371efa) switched from RUNNING to FINISHED.
2021-04-15 17:52:31,450 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Source: Custom File source (1/1)#0 (cc1f1a33b0c4d5646db685dd63371efa).
2021-04-15 17:52:31,450 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task Source: Custom File source (1/1)#0 network resources (state: FINISHED).
2021-04-15 17:52:31,450 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - unregistering de9c468ad4f929549d1ef23076f82f16#0@cc1f1a33b0c4d5646db685dd63371efa
2021-04-15 17:52:31,455 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File source (1/1)#0 (4e1576c5820dd61a8a94ed976818593b): Finished PipelinedSubpartition#0 [number of buffers: 2 (133 bytes), number of buffers in backlog: 1, finished? true, read view? true].
2021-04-15 17:52:31,456 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File source (1/1)#0 (4e1576c5820dd61a8a94ed976818593b) switched from RUNNING to FINISHED.
2021-04-15 17:52:31,456 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Source: Custom File source (1/1)#0 (4e1576c5820dd61a8a94ed976818593b).
2021-04-15 17:52:31,456 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task Source: Custom File source (1/1)#0 network resources (state: FINISHED).
2021-04-15 17:52:31,456 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - unregistering de5d1a9da390a2613fba1a2678353f30#0@4e1576c5820dd61a8a94ed976818593b
2021-04-15 17:52:31,456 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File source (1/1)#0 (acf9733938da85c0b5a1639427e16cc2): Finished PipelinedSubpartition#0 [number of buffers: 2 (133 bytes), number of buffers in backlog: 1, finished? true, read view? true].
2021-04-15 17:52:31,456 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File source (1/1)#0 (acf9733938da85c0b5a1639427e16cc2) switched from RUNNING to FINISHED.
2021-04-15 17:52:31,456 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Source: Custom File source (1/1)#0 (acf9733938da85c0b5a1639427e16cc2).
2021-04-15 17:52:31,456 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task Source: Custom File source (1/1)#0 network resources (state: FINISHED).
2021-04-15 17:52:31,456 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - unregistering 80a2030ea85de8019886d216c59629fc#0@acf9733938da85c0b5a1639427e16cc2
2021-04-15 17:52:31,456 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Source: Custom File source (1/1)#0 (cb17ee903affddd528d81a985c2f7958) [FINISHED]
2021-04-15 17:52:31,457 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task Source: Custom File source (1/1)#0 cb17ee903affddd528d81a985c2f7958.
2021-04-15 17:52:31,459 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Source: Custom File source (1/1)#0 (acf9733938da85c0b5a1639427e16cc2) [FINISHED]
2021-04-15 17:52:31,460 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Source: Custom File source (1/1)#0 (4e1576c5820dd61a8a94ed976818593b) [FINISHED]
2021-04-15 17:52:31,461 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Source: Custom File source (1/1)#0 (cc1f1a33b0c4d5646db685dd63371efa) [FINISHED]
2021-04-15 17:52:31,474 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task Source: Custom File source (1/1)#0 acf9733938da85c0b5a1639427e16cc2.
2021-04-15 17:52:31,474 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task Source: Custom File source (1/1)#0 4e1576c5820dd61a8a94ed976818593b.
2021-04-15 17:52:31,474 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task Source: Custom File source (1/1)#0 cc1f1a33b0c4d5646db685dd63371efa.
2021-04-15 17:52:31,476 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (cb17ee903affddd528d81a985c2f7958) switched from RUNNING to FINISHED.
2021-04-15 17:52:31,476 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Source: Custom File source (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 17:52:31,477 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{36e401178c6056cd342944b20cf6e6a1}) for execution vertex (id feca28aff5a3958840bee985ee7de4d3_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:31,480 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (acf9733938da85c0b5a1639427e16cc2) switched from RUNNING to FINISHED.
2021-04-15 17:52:31,480 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Source: Custom File source (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 17:52:31,480 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{4e69337e25cfa52b6a824b14a1e974a0}) for execution vertex (id 605b35e407e90cda15ad084365733fdd_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:31,481 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (4e1576c5820dd61a8a94ed976818593b) switched from RUNNING to FINISHED.
2021-04-15 17:52:31,482 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Source: Custom File source (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 17:52:31,482 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{e05d21cadc4440314da3b2cf4eb0aa6f}) for execution vertex (id bc764cd8ddf7a0cff126f51c16239658_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:31,482 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (cc1f1a33b0c4d5646db685dd63371efa) switched from RUNNING to FINISHED.
2021-04-15 17:52:31,482 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Source: Custom File source (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 17:52:31,482 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{1bb63cfb0c5408c219a288c1a93235c5}) for execution vertex (id 3ba1d27b7fde4848a86e865c6c402dfa_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:31,504 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: IDLE -> OPENING
2021-04-15 17:52:31,504 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - load split: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 17:52:31,504 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: IDLE -> OPENING
2021-04-15 17:52:31,504 DEBUG org.apache.flink.api.common.io.FileInputFormat - Opening input split file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt [0,315]
2021-04-15 17:52:31,505 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: IDLE -> OPENING
2021-04-15 17:52:31,505 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: IDLE -> OPENING
2021-04-15 17:52:31,505 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - load split: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 17:52:31,505 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - load split: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 17:52:31,505 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - load split: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 17:52:31,505 DEBUG org.apache.flink.api.common.io.FileInputFormat - Opening input split file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt [0,315]
2021-04-15 17:52:31,505 DEBUG org.apache.flink.api.common.io.FileInputFormat - Opening input split file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt [0,315]
2021-04-15 17:52:31,505 DEBUG org.apache.flink.api.common.io.FileInputFormat - Opening input split file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt [0,315]
2021-04-15 17:52:31,510 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: OPENING -> READING
2021-04-15 17:52:31,510 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: OPENING -> READING
2021-04-15 17:52:31,510 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: OPENING -> READING
2021-04-15 17:52:31,510 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: KeyProjection$20 

 Code:

public class KeyProjection$20 implements org.apache.flink.table.runtime.generated.Projection<org.apache.flink.table.data.RowData, org.apache.flink.table.data.binary.BinaryRowData> {

  org.apache.flink.table.data.binary.BinaryRowData out = new org.apache.flink.table.data.binary.BinaryRowData(1);
org.apache.flink.table.data.writer.BinaryRowWriter outWriter = new org.apache.flink.table.data.writer.BinaryRowWriter(out);

  public KeyProjection$20(Object[] references) throws Exception {
    
  }

  @Override
  public org.apache.flink.table.data.binary.BinaryRowData apply(org.apache.flink.table.data.RowData in1) {
    org.apache.flink.table.data.binary.BinaryStringData field$21;
boolean isNull$21;
    



outWriter.reset();

isNull$21 = in1.isNullAt(0);
field$21 = org.apache.flink.table.data.binary.BinaryStringData.EMPTY_UTF8;
if (!isNull$21) {
  field$21 = ((org.apache.flink.table.data.binary.BinaryStringData) in1.getString(0));
}
if (isNull$21) {
  outWriter.setNullAt(0);
} else {
  outWriter.writeString(0, field$21);
}
             
outWriter.complete();
        
        
    return out;
  }
}
        
2021-04-15 17:52:31,510 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: KeyProjection$55 

 Code:

public class KeyProjection$55 implements org.apache.flink.table.runtime.generated.Projection<org.apache.flink.table.data.RowData, org.apache.flink.table.data.binary.BinaryRowData> {

  org.apache.flink.table.data.binary.BinaryRowData out = new org.apache.flink.table.data.binary.BinaryRowData(1);
org.apache.flink.table.data.writer.BinaryRowWriter outWriter = new org.apache.flink.table.data.writer.BinaryRowWriter(out);

  public KeyProjection$55(Object[] references) throws Exception {
    
  }

  @Override
  public org.apache.flink.table.data.binary.BinaryRowData apply(org.apache.flink.table.data.RowData in1) {
    org.apache.flink.table.data.binary.BinaryStringData field$56;
boolean isNull$56;
    



outWriter.reset();

isNull$56 = in1.isNullAt(0);
field$56 = org.apache.flink.table.data.binary.BinaryStringData.EMPTY_UTF8;
if (!isNull$56) {
  field$56 = ((org.apache.flink.table.data.binary.BinaryStringData) in1.getString(0));
}
if (isNull$56) {
  outWriter.setNullAt(0);
} else {
  outWriter.writeString(0, field$56);
}
             
outWriter.complete();
        
        
    return out;
  }
}
        
2021-04-15 17:52:31,511 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: OPENING -> READING
2021-04-15 17:52:31,515 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - PipelinedResultPartition 6162f7b1a326a5f60ff644efe4b5860a#0@cb17ee903affddd528d81a985c2f7958 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
2021-04-15 17:52:31,515 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Received consume notification from PipelinedResultPartition 6162f7b1a326a5f60ff644efe4b5860a#0@cb17ee903affddd528d81a985c2f7958 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 17:52:31,516 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Source: Custom File source (1/1)#0 (cb17ee903affddd528d81a985c2f7958): Releasing PipelinedResultPartition 6162f7b1a326a5f60ff644efe4b5860a#0@cb17ee903affddd528d81a985c2f7958 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 17:52:31,516 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File source (1/1)#0 (cb17ee903affddd528d81a985c2f7958): Released PipelinedSubpartition#0 [number of buffers: 2 (137 bytes), number of buffers in backlog: 0, finished? true, read view? false].
2021-04-15 17:52:31,517 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - PipelinedResultPartition de5d1a9da390a2613fba1a2678353f30#0@4e1576c5820dd61a8a94ed976818593b [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
2021-04-15 17:52:31,517 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Released partition 6162f7b1a326a5f60ff644efe4b5860a#0 produced by cb17ee903affddd528d81a985c2f7958.
2021-04-15 17:52:31,517 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Received consume notification from PipelinedResultPartition de5d1a9da390a2613fba1a2678353f30#0@4e1576c5820dd61a8a94ed976818593b [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 17:52:31,518 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0
2021-04-15 17:52:31,518 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Source: Custom File source (1/1)#0 (4e1576c5820dd61a8a94ed976818593b): Releasing PipelinedResultPartition de5d1a9da390a2613fba1a2678353f30#0@4e1576c5820dd61a8a94ed976818593b [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 17:52:31,518 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - closing
2021-04-15 17:52:31,518 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File source (1/1)#0 (4e1576c5820dd61a8a94ed976818593b): Released PipelinedSubpartition#0 [number of buffers: 2 (137 bytes), number of buffers in backlog: 0, finished? true, read view? false].
2021-04-15 17:52:31,519 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: READING -> CLOSING
2021-04-15 17:52:31,519 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Released partition de5d1a9da390a2613fba1a2678353f30#0 produced by 4e1576c5820dd61a8a94ed976818593b.
2021-04-15 17:52:31,521 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - split 1 processed: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 17:52:31,521 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: CLOSING -> CLOSED
2021-04-15 17:52:31,521 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0
2021-04-15 17:52:31,521 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - cleanup, state=CLOSED
2021-04-15 17:52:31,521 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - closing
2021-04-15 17:52:31,521 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: READING -> CLOSING
2021-04-15 17:52:31,523 WARN o.a.f.s.a.functions.source.ContinuousFileReaderOperator - not processing any records while closed
2021-04-15 17:52:31,523 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0
2021-04-15 17:52:31,524 INFO org.apache.flink.runtime.taskmanager.Task - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (6fbd8c62478c21cfd14aa27a55b4fe5c) switched from RUNNING to FINISHED.
2021-04-15 17:52:31,524 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (6fbd8c62478c21cfd14aa27a55b4fe5c).
2021-04-15 17:52:31,524 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 network resources (state: FINISHED).
2021-04-15 17:52:31,524 DEBUG o.a.f.r.io.network.partition.consumer.SingleInputGate - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (6fbd8c62478c21cfd14aa27a55b4fe5c): Releasing SingleInputGate{owningTaskName='CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (6fbd8c62478c21cfd14aa27a55b4fe5c)', gateIndex=0}.
2021-04-15 17:52:31,524 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (6fbd8c62478c21cfd14aa27a55b4fe5c) [FINISHED]
2021-04-15 17:52:31,528 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 6fbd8c62478c21cfd14aa27a55b4fe5c.
2021-04-15 17:52:31,529 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1) (6fbd8c62478c21cfd14aa27a55b4fe5c) switched from RUNNING to FINISHED.
2021-04-15 17:52:31,529 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 17:52:31,529 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{581bcd2a53d5e252e4e20ef0d37bd444}) for execution vertex (id b23642197a427ec5db481d3963c66cfb_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:31,534 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - split 1 processed: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 17:52:31,534 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: CLOSING -> CLOSED
2021-04-15 17:52:31,534 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - cleanup, state=CLOSED
2021-04-15 17:52:31,534 WARN o.a.f.s.a.functions.source.ContinuousFileReaderOperator - not processing any records while closed
2021-04-15 17:52:31,534 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0
2021-04-15 17:52:31,534 INFO org.apache.flink.runtime.taskmanager.Task - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (87de37c9db81dfdee6f377f619e5fb63) switched from RUNNING to FINISHED.
2021-04-15 17:52:31,534 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (87de37c9db81dfdee6f377f619e5fb63).
2021-04-15 17:52:31,534 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 network resources (state: FINISHED).
2021-04-15 17:52:31,534 DEBUG o.a.f.r.io.network.partition.consumer.SingleInputGate - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (87de37c9db81dfdee6f377f619e5fb63): Releasing SingleInputGate{owningTaskName='CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (87de37c9db81dfdee6f377f619e5fb63)', gateIndex=0}.
2021-04-15 17:52:31,535 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - PipelinedResultPartition de9c468ad4f929549d1ef23076f82f16#0@cc1f1a33b0c4d5646db685dd63371efa [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
2021-04-15 17:52:31,535 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Received consume notification from PipelinedResultPartition de9c468ad4f929549d1ef23076f82f16#0@cc1f1a33b0c4d5646db685dd63371efa [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 17:52:31,535 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Source: Custom File source (1/1)#0 (cc1f1a33b0c4d5646db685dd63371efa): Releasing PipelinedResultPartition de9c468ad4f929549d1ef23076f82f16#0@cc1f1a33b0c4d5646db685dd63371efa [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 17:52:31,535 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File source (1/1)#0 (cc1f1a33b0c4d5646db685dd63371efa): Released PipelinedSubpartition#0 [number of buffers: 2 (137 bytes), number of buffers in backlog: 0, finished? true, read view? false].
2021-04-15 17:52:31,536 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Released partition de9c468ad4f929549d1ef23076f82f16#0 produced by cc1f1a33b0c4d5646db685dd63371efa.
2021-04-15 17:52:31,536 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (87de37c9db81dfdee6f377f619e5fb63) [FINISHED]
2021-04-15 17:52:31,536 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0
2021-04-15 17:52:31,537 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - PipelinedResultPartition 80a2030ea85de8019886d216c59629fc#0@acf9733938da85c0b5a1639427e16cc2 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
2021-04-15 17:52:31,538 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - closing
2021-04-15 17:52:31,538 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Received consume notification from PipelinedResultPartition 80a2030ea85de8019886d216c59629fc#0@acf9733938da85c0b5a1639427e16cc2 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 17:52:31,538 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 87de37c9db81dfdee6f377f619e5fb63.
2021-04-15 17:52:31,538 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: READING -> CLOSING
2021-04-15 17:52:31,538 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Source: Custom File source (1/1)#0 (acf9733938da85c0b5a1639427e16cc2): Releasing PipelinedResultPartition 80a2030ea85de8019886d216c59629fc#0@acf9733938da85c0b5a1639427e16cc2 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 17:52:31,539 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1) (87de37c9db81dfdee6f377f619e5fb63) switched from RUNNING to FINISHED.
2021-04-15 17:52:31,540 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - split 1 processed: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 17:52:31,540 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File source (1/1)#0 (acf9733938da85c0b5a1639427e16cc2): Released PipelinedSubpartition#0 [number of buffers: 2 (137 bytes), number of buffers in backlog: 0, finished? true, read view? false].
2021-04-15 17:52:31,540 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 17:52:31,540 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: CLOSING -> CLOSED
2021-04-15 17:52:31,540 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Released partition 80a2030ea85de8019886d216c59629fc#0 produced by acf9733938da85c0b5a1639427e16cc2.
2021-04-15 17:52:31,540 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{af61292ac98dc045329d2ae43a038b51}) for execution vertex (id 77af20c908aca598f7bbebd4db138545_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:31,540 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - cleanup, state=CLOSED
2021-04-15 17:52:31,541 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0
2021-04-15 17:52:31,541 WARN o.a.f.s.a.functions.source.ContinuousFileReaderOperator - not processing any records while closed
2021-04-15 17:52:31,541 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - closing
2021-04-15 17:52:31,542 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0
2021-04-15 17:52:31,542 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: READING -> CLOSING
2021-04-15 17:52:31,542 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: KeyProjection$83 

 Code:

public class KeyProjection$83 implements org.apache.flink.table.runtime.generated.Projection<org.apache.flink.table.data.RowData, org.apache.flink.table.data.binary.BinaryRowData> {

  org.apache.flink.table.data.binary.BinaryRowData out = new org.apache.flink.table.data.binary.BinaryRowData(1);
org.apache.flink.table.data.writer.BinaryRowWriter outWriter = new org.apache.flink.table.data.writer.BinaryRowWriter(out);

  public KeyProjection$83(Object[] references) throws Exception {
    
  }

  @Override
  public org.apache.flink.table.data.binary.BinaryRowData apply(org.apache.flink.table.data.RowData in1) {
    org.apache.flink.table.data.binary.BinaryStringData field$84;
boolean isNull$84;
    



outWriter.reset();

isNull$84 = in1.isNullAt(0);
field$84 = org.apache.flink.table.data.binary.BinaryStringData.EMPTY_UTF8;
if (!isNull$84) {
  field$84 = ((org.apache.flink.table.data.binary.BinaryStringData) in1.getString(0));
}
if (isNull$84) {
  outWriter.setNullAt(0);
} else {
  outWriter.writeString(0, field$84);
}
             
outWriter.complete();
        
        
    return out;
  }
}
        
2021-04-15 17:52:31,544 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - split 1 processed: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 17:52:31,544 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: CLOSING -> CLOSED
2021-04-15 17:52:31,544 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - cleanup, state=CLOSED
2021-04-15 17:52:31,544 WARN o.a.f.s.a.functions.source.ContinuousFileReaderOperator - not processing any records while closed
2021-04-15 17:52:31,544 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0
2021-04-15 17:52:31,545 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: KeyProjection$48 

 Code:

public class KeyProjection$48 implements org.apache.flink.table.runtime.generated.Projection<org.apache.flink.table.data.RowData, org.apache.flink.table.data.binary.BinaryRowData> {

  org.apache.flink.table.data.binary.BinaryRowData out = new org.apache.flink.table.data.binary.BinaryRowData(1);
org.apache.flink.table.data.writer.BinaryRowWriter outWriter = new org.apache.flink.table.data.writer.BinaryRowWriter(out);

  public KeyProjection$48(Object[] references) throws Exception {
    
  }

  @Override
  public org.apache.flink.table.data.binary.BinaryRowData apply(org.apache.flink.table.data.RowData in1) {
    org.apache.flink.table.data.binary.BinaryStringData field$49;
boolean isNull$49;
    



outWriter.reset();

isNull$49 = in1.isNullAt(0);
field$49 = org.apache.flink.table.data.binary.BinaryStringData.EMPTY_UTF8;
if (!isNull$49) {
  field$49 = ((org.apache.flink.table.data.binary.BinaryStringData) in1.getString(0));
}
if (isNull$49) {
  outWriter.setNullAt(0);
} else {
  outWriter.writeString(0, field$49);
}
             
outWriter.complete();
        
        
    return out;
  }
}
        
2021-04-15 17:52:31,549 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (1445820206b44a96a015433b0bf94390): Finished PipelinedSubpartition#0 [number of buffers: 2 (617 bytes), number of buffers in backlog: 1, finished? true, read view? true].
2021-04-15 17:52:31,549 INFO org.apache.flink.runtime.taskmanager.Task - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (1445820206b44a96a015433b0bf94390) switched from RUNNING to FINISHED.
2021-04-15 17:52:31,549 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (1445820206b44a96a015433b0bf94390).
2021-04-15 17:52:31,549 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 network resources (state: FINISHED).
2021-04-15 17:52:31,549 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - unregistering 51607ff8d2b6611b9769c5234071e407#0@1445820206b44a96a015433b0bf94390
2021-04-15 17:52:31,549 DEBUG o.a.f.r.io.network.partition.consumer.SingleInputGate - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (1445820206b44a96a015433b0bf94390): Releasing SingleInputGate{owningTaskName='CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (1445820206b44a96a015433b0bf94390)', gateIndex=0}.
2021-04-15 17:52:31,549 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (1445820206b44a96a015433b0bf94390) [FINISHED]
2021-04-15 17:52:31,550 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (5c528b6dc0ff91c03924e38491364291): Finished PipelinedSubpartition#0 [number of buffers: 2 (521 bytes), number of buffers in backlog: 1, finished? true, read view? true].
2021-04-15 17:52:31,551 INFO org.apache.flink.runtime.taskmanager.Task - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (5c528b6dc0ff91c03924e38491364291) switched from RUNNING to FINISHED.
2021-04-15 17:52:31,551 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (5c528b6dc0ff91c03924e38491364291).
2021-04-15 17:52:31,551 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 network resources (state: FINISHED).
2021-04-15 17:52:31,551 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - unregistering 7f0f187fc0f5c9ab9257872acece76a0#0@5c528b6dc0ff91c03924e38491364291
2021-04-15 17:52:31,551 DEBUG o.a.f.r.io.network.partition.consumer.SingleInputGate - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (5c528b6dc0ff91c03924e38491364291): Releasing SingleInputGate{owningTaskName='CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (5c528b6dc0ff91c03924e38491364291)', gateIndex=0}.
2021-04-15 17:52:31,551 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (5c528b6dc0ff91c03924e38491364291) [FINISHED]
2021-04-15 17:52:31,552 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 1445820206b44a96a015433b0bf94390.
2021-04-15 17:52:31,552 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 5c528b6dc0ff91c03924e38491364291.
2021-04-15 17:52:31,553 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1) (1445820206b44a96a015433b0bf94390) switched from RUNNING to FINISHED.
2021-04-15 17:52:31,553 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 17:52:31,553 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{c0e998b887d56b33bab832f4437c6f72}) for execution vertex (id a19bdf930ebdf056b3d6de069bc89bdd_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:31,554 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1) (5c528b6dc0ff91c03924e38491364291) switched from RUNNING to FINISHED.
2021-04-15 17:52:31,554 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 17:52:31,554 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{6503bd97ad2a1863f5c5c68df981045d}) for execution vertex (id aecbb8a11dc0c28dc6c178e875ebcc43_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:31,565 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - PipelinedResultPartition 51607ff8d2b6611b9769c5234071e407#0@1445820206b44a96a015433b0bf94390 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
2021-04-15 17:52:31,566 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Received consume notification from PipelinedResultPartition 51607ff8d2b6611b9769c5234071e407#0@1445820206b44a96a015433b0bf94390 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 17:52:31,566 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (1445820206b44a96a015433b0bf94390): Releasing PipelinedResultPartition 51607ff8d2b6611b9769c5234071e407#0@1445820206b44a96a015433b0bf94390 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 17:52:31,566 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (1445820206b44a96a015433b0bf94390): Released PipelinedSubpartition#0 [number of buffers: 2 (621 bytes), number of buffers in backlog: 0, finished? true, read view? false].
2021-04-15 17:52:31,566 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Released partition 51607ff8d2b6611b9769c5234071e407#0 produced by 1445820206b44a96a015433b0bf94390.
2021-04-15 17:52:31,566 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0
2021-04-15 17:52:31,567 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - PipelinedResultPartition 7f0f187fc0f5c9ab9257872acece76a0#0@5c528b6dc0ff91c03924e38491364291 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
2021-04-15 17:52:31,567 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Received consume notification from PipelinedResultPartition 7f0f187fc0f5c9ab9257872acece76a0#0@5c528b6dc0ff91c03924e38491364291 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 17:52:31,567 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (5c528b6dc0ff91c03924e38491364291): Releasing PipelinedResultPartition 7f0f187fc0f5c9ab9257872acece76a0#0@5c528b6dc0ff91c03924e38491364291 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 17:52:31,567 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (5c528b6dc0ff91c03924e38491364291): Released PipelinedSubpartition#0 [number of buffers: 2 (525 bytes), number of buffers in backlog: 0, finished? true, read view? false].
2021-04-15 17:52:31,567 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Released partition 7f0f187fc0f5c9ab9257872acece76a0#0 produced by 5c528b6dc0ff91c03924e38491364291.
2021-04-15 17:52:31,567 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0
2021-04-15 17:52:31,567 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0
2021-04-15 17:52:31,567 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0
2021-04-15 17:52:31,568 INFO org.apache.flink.runtime.taskmanager.Task - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (68c2e08bbf47ccdb95efe49cb8e5faab) switched from RUNNING to FINISHED.
2021-04-15 17:52:31,568 INFO org.apache.flink.runtime.taskmanager.Task - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (1a583e156346e4c163645eac9e1ca58c) switched from RUNNING to FINISHED.
2021-04-15 17:52:31,568 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (68c2e08bbf47ccdb95efe49cb8e5faab).
2021-04-15 17:52:31,569 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 network resources (state: FINISHED).
2021-04-15 17:52:31,569 DEBUG o.a.f.r.io.network.partition.consumer.SingleInputGate - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (68c2e08bbf47ccdb95efe49cb8e5faab): Releasing SingleInputGate{owningTaskName='GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (68c2e08bbf47ccdb95efe49cb8e5faab)', gateIndex=0}.
2021-04-15 17:52:31,568 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (1a583e156346e4c163645eac9e1ca58c).
2021-04-15 17:52:31,569 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (68c2e08bbf47ccdb95efe49cb8e5faab) [FINISHED]
2021-04-15 17:52:31,569 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 network resources (state: FINISHED).
2021-04-15 17:52:31,569 DEBUG o.a.f.r.io.network.partition.consumer.SingleInputGate - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (1a583e156346e4c163645eac9e1ca58c): Releasing SingleInputGate{owningTaskName='GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (1a583e156346e4c163645eac9e1ca58c)', gateIndex=0}.
2021-04-15 17:52:31,569 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (1a583e156346e4c163645eac9e1ca58c) [FINISHED]
2021-04-15 17:52:31,570 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 68c2e08bbf47ccdb95efe49cb8e5faab.
2021-04-15 17:52:31,570 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 1a583e156346e4c163645eac9e1ca58c.
2021-04-15 17:52:31,571 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1) (68c2e08bbf47ccdb95efe49cb8e5faab) switched from RUNNING to FINISHED.
2021-04-15 17:52:31,571 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 17:52:31,571 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{6790c21350030d8e5d88dad6968d95fe}) for execution vertex (id 5528b14a6b129894d24927c518acc32a_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:31,572 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1) (1a583e156346e4c163645eac9e1ca58c) switched from RUNNING to FINISHED.
2021-04-15 17:52:31,572 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 17:52:31,572 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{5e22984cabd4d6bb10ac74ab794f0bdd}) for execution vertex (id 6177eb422127981c4dbb05ea3af8a2d4_0) from the physical slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:31,572 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Release shared slot externally (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:31,572 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Releasing slot [SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02}] because: Slot is being returned from SlotSharingExecutionSlotAllocator.
2021-04-15 17:52:31,572 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Release shared slot (SlotRequestId{8794061eb7aa69654f8a0d1a7b213b02})
2021-04-15 17:52:31,573 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Adding slot [ef5374b4ae1c52fa2a3384b908df553a] to available slots
2021-04-15 17:52:31,574 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Job Flink Streaming Job (0af35e8eb90492be8852415387a2352b) switched from state RUNNING to FINISHED.
2021-04-15 17:52:31,574 INFO o.apache.flink.runtime.checkpoint.CheckpointCoordinator - Stopping checkpoint coordinator for job 0af35e8eb90492be8852415387a2352b.
2021-04-15 17:52:31,579 INFO o.a.f.r.checkpoint.StandaloneCompletedCheckpointStore - Shutting down
2021-04-15 17:52:31,589 INFO org.apache.flink.runtime.minicluster.MiniCluster - Shutting down Flink Mini Cluster
2021-04-15 17:52:31,589 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Shutting down rest endpoint.
2021-04-15 17:52:31,591 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Job 0af35e8eb90492be8852415387a2352b reached globally terminal state FINISHED.
2021-04-15 17:52:31,592 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Stopping TaskExecutor akka://flink/user/rpc/taskmanager_0.
2021-04-15 17:52:31,593 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Close ResourceManager connection c951f54d42d4d857ceff27882850f482.
org.apache.flink.util.FlinkException: The TaskExecutor is shutting down.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:424) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:214) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:563) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:186) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 17:52:31,593 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Closing TaskExecutor connection 760eb808-2346-426e-9abc-5c23a18cddf1 because: The TaskExecutor is shutting down.
2021-04-15 17:52:31,593 DEBUG o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Unregister TaskManager 8409146bccc11dfe1db202a54e5e0aac from the SlotManager.
2021-04-15 17:52:31,593 DEBUG o.a.f.r.i.n.p.ResourceManagerPartitionTrackerImpl - Processing shutdown of task executor 760eb808-2346-426e-9abc-5c23a18cddf1.
2021-04-15 17:52:31,595 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Close JobManager connection for job 0af35e8eb90492be8852415387a2352b.
org.apache.flink.util.FlinkException: The TaskExecutor is shutting down.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:424) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:214) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:563) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:186) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 17:52:31,600 DEBUG o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Free slot TaskSlot(index:0, state:ALLOCATED, resource profile: ResourceProfile{managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}, allocationId: ef5374b4ae1c52fa2a3384b908df553a, jobId: 0af35e8eb90492be8852415387a2352b).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:169) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:441) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:214) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:563) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:186) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 17:52:31,609 INFO org.apache.flink.runtime.jobmaster.JobMaster - Stopping the JobMaster for job Flink Streaming Job(0af35e8eb90492be8852415387a2352b).
2021-04-15 17:52:31,617 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Disconnect TaskExecutor 760eb808-2346-426e-9abc-5c23a18cddf1 because: Stopping JobMaster for job Flink Streaming Job(0af35e8eb90492be8852415387a2352b).
2021-04-15 17:52:31,618 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Suspending SlotPool.
2021-04-15 17:52:31,619 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Close ResourceManager connection c951f54d42d4d857ceff27882850f482.
org.apache.flink.util.FlinkException: Stopping JobMaster for job Flink Streaming Job(0af35e8eb90492be8852415387a2352b).
	at org.apache.flink.runtime.jobmaster.JobMaster.onStop(JobMaster.java:416) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:214) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:563) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:186) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 17:52:31,619 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Stopping SlotPool.
2021-04-15 17:52:31,621 DEBUG org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor - The RpcEndpoint jobmanager_3 terminated successfully.
2021-04-15 17:52:31,623 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Disconnect job manager a0ed35acc06c35d39503eff6016f41ad@akka://flink/user/rpc/jobmanager_3 for job 0af35e8eb90492be8852415387a2352b from the resource manager.
2021-04-15 17:52:31,626 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Stop job leader service.
2021-04-15 17:52:31,626 INFO o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Shutting down TaskExecutorLocalStateStoresManager.
2021-04-15 17:52:31,638 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - AkkaRpcActor akka://flink/user/rpc/jobmanager_3 has terminated.
2021-04-15 17:52:31,639 DEBUG org.apache.flink.runtime.io.disk.iomanager.IOManager - Shutting down I/O manager.
2021-04-15 17:52:31,640 DEBUG o.a.flink.runtime.resourcemanager.JobLeaderIdService - Found a new job leader null@null.
2021-04-15 17:52:31,641 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Discard job leader lost leadership for outdated leader a0ed35acc06c35d39503eff6016f41ad for job 0af35e8eb90492be8852415387a2352b.
2021-04-15 17:52:31,645 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Removing cache directory C:\Users\ccy\AppData\Local\Temp\flink-web-ui
2021-04-15 17:52:31,646 INFO org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager removed spill file directory C:\Users\ccy\AppData\Local\Temp\flink-io-fddc0daf-edc1-4fcf-b22a-e8463860460d
2021-04-15 17:52:31,646 INFO o.a.flink.runtime.io.network.NettyShuffleEnvironment - Shutting down the network environment and its components.
2021-04-15 17:52:31,646 DEBUG o.a.flink.runtime.io.network.NettyShuffleEnvironment - Shutting down network connection manager
2021-04-15 17:52:31,646 DEBUG o.a.flink.runtime.io.network.NettyShuffleEnvironment - Shutting down intermediate result partition manager
2021-04-15 17:52:31,647 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Releasing 0 partitions because of shutdown.
2021-04-15 17:52:31,647 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Successful shutdown.
2021-04-15 17:52:31,647 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Shut down complete.
2021-04-15 17:52:31,648 INFO org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager removed spill file directory C:\Users\ccy\AppData\Local\Temp\flink-netty-shuffle-1bb5688d-705e-42c9-b52e-3f8e777eee3d
2021-04-15 17:52:31,648 INFO org.apache.flink.runtime.taskexecutor.KvStateService - Shutting down the kvState service and its components.
2021-04-15 17:52:31,648 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Stop job leader service.
2021-04-15 17:52:31,649 INFO org.apache.flink.runtime.filecache.FileCache - removed file cache directory C:\Users\ccy\AppData\Local\Temp\flink-dist-cache-4d5668b6-0b3c-4b63-b6f5-037ce33fe547
2021-04-15 17:52:31,650 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Stopped TaskExecutor akka://flink/user/rpc/taskmanager_0.
2021-04-15 17:52:31,650 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcActor - The RpcEndpoint taskmanager_0 terminated successfully.
2021-04-15 17:52:31,650 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - AkkaRpcActor akka://flink/user/rpc/taskmanager_0 has terminated.
2021-04-15 17:52:31,653 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..
2021-04-15 17:52:31,653 INFO o.a.f.r.e.component.DispatcherResourceManagerComponent - Closing components.
2021-04-15 17:52:31,654 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Stopping SessionDispatcherLeaderProcess.
2021-04-15 17:52:31,655 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Stopping dispatcher akka://flink/user/rpc/dispatcher_2.
2021-04-15 17:52:31,655 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Stopping all currently running jobs of dispatcher akka://flink/user/rpc/dispatcher_2.
2021-04-15 17:52:31,655 INFO o.a.f.r.r.h.l.b.BackPressureRequestCoordinator - Shutting down back pressure request coordinator.
2021-04-15 17:52:31,657 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Stopped dispatcher akka://flink/user/rpc/dispatcher_2.
2021-04-15 17:52:31,657 DEBUG org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor - The RpcEndpoint dispatcher_2 terminated successfully.
2021-04-15 17:52:31,658 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - AkkaRpcActor akka://flink/user/rpc/dispatcher_2 has terminated.
2021-04-15 17:52:31,662 INFO o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Closing the SlotManager.
2021-04-15 17:52:31,662 INFO o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Suspending the SlotManager.
2021-04-15 17:52:31,663 DEBUG org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor - The RpcEndpoint resourcemanager_1 terminated successfully.
2021-04-15 17:52:31,663 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - AkkaRpcActor akka://flink/user/rpc/resourcemanager_1 has terminated.
2021-04-15 17:52:31,665 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Stopping Akka RPC service.
2021-04-15 17:52:31,678 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcActor - The RpcEndpoint MetricQueryService terminated successfully.
2021-04-15 17:52:31,681 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - AkkaRpcActor akka://flink-metrics/user/rpc/MetricQueryService has terminated.
2021-04-15 17:52:31,693 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Stopping supervisor actor.
2021-04-15 17:52:31,742 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Stopping Akka RPC service.
2021-04-15 17:52:31,742 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Stopped Akka RPC service.
2021-04-15 17:52:31,743 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Stopping supervisor actor.
2021-04-15 17:52:31,744 DEBUG akka.event.EventStream - shutting down: StandardOutLogger
2021-04-15 17:52:31,754 INFO org.apache.flink.runtime.blob.PermanentBlobCache - Shutting down BLOB cache
2021-04-15 17:52:31,755 INFO org.apache.flink.runtime.blob.TransientBlobCache - Shutting down BLOB cache
2021-04-15 17:52:31,766 INFO org.apache.flink.runtime.blob.BlobServer - Stopped BLOB server at 0.0.0.0:62243
2021-04-15 17:52:31,766 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Stopped Akka RPC service.
2021-04-15 17:57:39,252 INFO org.apache.flink.api.java.typeutils.TypeExtractor - class org.apache.flink.types.Row is missing a default constructor so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2021-04-15 17:57:40,339 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:57:40,353 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:40,355 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:40,355 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#3:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#2,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:57:40,363 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:40,547 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert table references before rewriting sub-queries to semi-join cost 62 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:40,547 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:40,547 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:40,547 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#6:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#5,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:57:40,548 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:40,548 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize rewrite sub-queries to semi-join cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:40,549 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:40,550 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:40,550 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#9:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#8,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:57:40,550 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:40,550 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize sub-queries remove cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:40,551 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:40,551 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:40,551 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#12:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#11,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:57:40,551 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:40,552 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert table references after sub-queries removed cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:40,552 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize subquery_rewrite cost 215 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:40,552 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:57:40,553 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:40,553 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:40,553 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#15:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#14,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:57:40,553 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:40,554 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert correlate to temporal table join cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:40,555 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:40,555 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:40,555 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#18:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#17,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:57:40,555 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:40,555 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert enumerable table scan cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:40,556 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize temporal_join_rewrite cost 3 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:40,556 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:57:40,557 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:40,557 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:40,557 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#21:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#20,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:57:40,557 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:40,558 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize pre-rewrite before decorrelation cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:40,570 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize  cost 12 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:40,571 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize decorrelate cost 14 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:40,577 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize time_indicator cost 6 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:40,578 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:40,578 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:40,578 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#25:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#24,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:57:40,579 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:40,579 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize default_rewrite cost 2 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:40,579 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:57:40,580 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:40,580 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:40,580 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#28:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#27,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:57:40,581 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:40,581 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize filter rules cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:40,582 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:40,582 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:40,583 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#31:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#30,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:57:40,583 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:40,583 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize push predicate into table scan cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:40,584 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:40,584 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:40,584 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#34:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#33,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:57:40,585 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:40,585 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize prune empty after predicate push down cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:40,585 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize predicate_pushdown cost 6 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:40,731 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:40,731 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)] rels [#0]
2021-04-15 17:57:40,731 DEBUG org.apache.calcite.plan.RelOptPlanner - call#11: Apply rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)] to [rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])]
2021-04-15 17:57:40,733 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#41 via FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:40,825 DEBUG org.apache.calcite.plan.RelOptPlanner - call#11 generated 1 successors: [rel#41:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:57:40,831 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:40,831 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)] rels [#37]
2021-04-15 17:57:40,832 DEBUG org.apache.calcite.plan.RelOptPlanner - call#20: Apply rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)] to [rel#37:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#36,name=DataStreamTableSink,fields=id, timestamp, temp)]
2021-04-15 17:57:40,832 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#43 via FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:40,868 DEBUG org.apache.calcite.plan.RelOptPlanner - call#20 generated 1 successors: [rel#43:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#42,name=DataStreamTableSink,fields=id, timestamp, temp)]
2021-04-15 17:57:40,869 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0E8 rows, 2.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:40,872 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for VolcanoPlanner
2021-04-15 17:57:40,872 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)                   1              94,183
FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)                           1              36,708
* Total                                                                        2             130,891

2021-04-15 17:57:40,915 DEBUG org.apache.calcite.plan.RelOptPlanner - Cheapest plan:
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp]): rowcount = 1.0E8, cumulative cost = {2.0E8 rows, 2.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 44
  FlinkLogicalLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 41

2021-04-15 17:57:40,919 DEBUG org.apache.calcite.plan.RelOptPlanner - Provenance:
rel#44:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=FlinkLogicalLegacyTableSourceScan#41,name=DataStreamTableSink,fields=id, timestamp, temp)
  direct
    rel#43:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#42,name=DataStreamTableSink,fields=id, timestamp, temp)
      call#20 rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)]
        rel#37:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#36,name=DataStreamTableSink,fields=id, timestamp, temp)
          no parent
rel#41:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
  call#11 rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)]
    rel#0:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
      no parent

2021-04-15 17:57:40,920 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize logical cost 334 ms.
optimize result: 
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- FlinkLogicalLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:57:40,921 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:40,921 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:40,921 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#46:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#45,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:57:40,921 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#41:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
2021-04-15 17:57:40,922 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize logical_rewrite cost 2 ms.
optimize result: 
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- FlinkLogicalLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:57:40,936 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:40,937 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#41]
2021-04-15 17:57:40,937 DEBUG org.apache.calcite.plan.RelOptPlanner - call#38: Apply rule [StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#41:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:57:40,943 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#53 via StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:57:40,998 DEBUG org.apache.calcite.plan.RelOptPlanner - call#38 generated 1 successors: [rel#53:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:57:40,999 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:40,999 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#49]
2021-04-15 17:57:40,999 DEBUG org.apache.calcite.plan.RelOptPlanner - call#55: Apply rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#49:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#48,name=DataStreamTableSink,fields=id, timestamp, temp)]
2021-04-15 17:57:41,003 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#55 via StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:57:41,032 DEBUG org.apache.calcite.plan.RelOptPlanner - call#55 generated 1 successors: [rel#55:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#54,name=DataStreamTableSink,fields=id, timestamp, temp)]
2021-04-15 17:57:41,032 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0E8 rows, 2.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:41,032 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for VolcanoPlanner
2021-04-15 17:57:41,033 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)                   1              94,183
StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)                   1              61,646
FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)                           1              36,708
StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)                       1              32,717
* Total                                                                        4             225,254

2021-04-15 17:57:41,055 DEBUG org.apache.calcite.plan.RelOptPlanner - Cheapest plan:
StreamExecLegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp]): rowcount = 1.0E8, cumulative cost = {2.0E8 rows, 2.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 56
  StreamExecLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 53

2021-04-15 17:57:41,056 DEBUG org.apache.calcite.plan.RelOptPlanner - Provenance:
rel#56:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=StreamExecLegacyTableSourceScan#53,name=DataStreamTableSink,fields=id, timestamp, temp)
  direct
    rel#55:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#54,name=DataStreamTableSink,fields=id, timestamp, temp)
      call#55 rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#49:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#48,name=DataStreamTableSink,fields=id, timestamp, temp)
          no parent
rel#53:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
  call#38 rule [StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)]
    rel#41:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
      no parent

2021-04-15 17:57:41,056 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize physical cost 134 ms.
optimize result: 
LegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:57:41,056 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:57:41,057 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:41,057 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:41,058 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#58:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#57,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:57:41,058 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#53:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
2021-04-15 17:57:41,058 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize watermark transpose cost 2 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:57:41,079 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize Changelog mode inference cost 20 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:57:41,079 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize Initialization for mini-batch interval inference cost 0 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:57:41,080 DEBUG org.apache.calcite.plan.RelOptPlanner - call#62: Apply rule [MiniBatchIntervalInferRule] to [rel#66:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#65,name=DataStreamTableSink,fields=id, timestamp, temp)]
2021-04-15 17:57:41,083 DEBUG org.apache.calcite.plan.RelOptPlanner - call#63: Apply rule [MiniBatchIntervalInferRule] to [rel#62:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:57:41,083 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:41,084 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
MiniBatchIntervalInferRule                                                     2               2,089
* Total                                                                        2               2,089

2021-04-15 17:57:41,084 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#66:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#65,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:57:41,084 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#62:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
2021-04-15 17:57:41,085 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize mini-batch interval rules cost 4 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:57:41,085 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:41,086 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:41,086 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#69:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#68,name=DataStreamTableSink,fields=id, timestamp, temp)
2021-04-15 17:57:41,086 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#62:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
2021-04-15 17:57:41,087 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize physical rewrite cost 1 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:57:41,088 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize physical_rewrite cost 31 ms.
optimize result: 
LegacySink(name=[DataStreamTableSink], fields=[id, timestamp, temp])
+- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:57:41,151 INFO org.apache.flink.api.java.typeutils.TypeExtractor - class org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit does not contain a setter for field modificationTime
2021-04-15 17:57:41,151 INFO org.apache.flink.api.java.typeutils.TypeExtractor - Class class org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2021-04-15 17:57:41,157 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:57:41,159 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:57:41,175 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:57:41,175 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:57:41,177 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:57:41,177 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.java.io.RowCsvInputFormat
2021-04-15 17:57:41,177 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:57:41,178 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [Lorg.apache.flink.api.common.typeinfo.TypeInformation;
2021-04-15 17:57:41,200 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [I
2021-04-15 17:57:41,200 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:57:41,217 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Long
2021-04-15 17:57:41,218 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.streaming.api.functions.source.FileProcessingMode
2021-04-15 17:57:41,218 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Long
2021-04-15 17:57:41,218 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:57:41,360 DEBUG o.a.flink.table.planner.codegen.OperatorCodeGenerator$ - Compiling OneInputStreamOperator Code:
SourceConversion
2021-04-15 17:57:41,404 DEBUG o.a.flink.table.planner.codegen.OperatorCodeGenerator$ - Compiling OneInputStreamOperator Code:
SinkConversion
2021-04-15 17:57:41,406 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
2021-04-15 17:57:41,406 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:57:41,408 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:57:41,408 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:57:41,408 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:57:41,408 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:57:41,721 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'equals' from 'core' module.
2021-04-15 17:57:41,763 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'count' from 'core' module.
2021-04-15 17:57:41,765 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'avg' from 'core' module.
2021-04-15 17:57:41,768 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'as' from 'core' module.
2021-04-15 17:57:41,769 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'as' from 'core' module.
2021-04-15 17:57:41,781 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'as' from 'core' module.
2021-04-15 17:57:41,782 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'as' from 'core' module.
2021-04-15 17:57:41,821 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'count' from 'core' module.
2021-04-15 17:57:41,822 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'avg' from 'core' module.
2021-04-15 17:57:41,844 DEBUG org.apache.flink.table.module.ModuleManager - Cannot find FunctionDefinition 'id' from any loaded modules.
2021-04-15 17:57:41,850 DEBUG org.apache.flink.table.module.ModuleManager - Cannot find FunctionDefinition 'id' from any loaded modules.
2021-04-15 17:57:41,873 DEBUG org.apache.flink.table.module.ModuleManager - Cannot find FunctionDefinition 'id' from any loaded modules.
2021-04-15 17:57:41,875 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'count' from 'core' module.
2021-04-15 17:57:41,882 DEBUG org.apache.flink.table.module.ModuleManager - Cannot find FunctionDefinition 'temp' from any loaded modules.
2021-04-15 17:57:41,883 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'avg' from 'core' module.
2021-04-15 17:57:41,962 DEBUG org.apache.calcite.sql2rel - Plan after converting SqlNode to RelNode
LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
  LogicalProject(id=[$0], temp=[$2])
    LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:41,969 INFO org.apache.flink.api.java.typeutils.TypeExtractor - class org.apache.flink.types.Row is missing a default constructor so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2021-04-15 17:57:41,996 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:57:41,997 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:41,997 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:41,997 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#84:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#83,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:57:41,998 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#82:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#81,condition==($0, _UTF-16LE'sensor_6'))
2021-04-15 17:57:41,998 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#80:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#79,inputs=0,exprs=[$2])
2021-04-15 17:57:41,998 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#75:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:41,999 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert table references before rewriting sub-queries to semi-join cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:41,999 DEBUG org.apache.calcite.plan.RelOptPlanner - call#64: Apply rule [SimplifyFilterConditionRule:simplifySubQuery] to [rel#89:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#88,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,008 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,009 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
SimplifyFilterConditionRule:simplifySubQuery                                   1               8,828
* Total                                                                        1               8,828

2021-04-15 17:57:42,009 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#91:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#90,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:57:42,009 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#89:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#88,condition==($0, _UTF-16LE'sensor_6'))
2021-04-15 17:57:42,009 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#87:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#86,inputs=0,exprs=[$2])
2021-04-15 17:57:42,009 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#75:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:42,010 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize rewrite sub-queries to semi-join cost 10 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,011 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,011 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:42,011 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#98:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#97,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:57:42,012 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#96:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#95,condition==($0, _UTF-16LE'sensor_6'))
2021-04-15 17:57:42,012 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#94:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#93,inputs=0,exprs=[$2])
2021-04-15 17:57:42,012 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#75:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:42,013 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize sub-queries remove cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,014 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,014 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:42,014 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#105:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#104,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:57:42,014 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#103:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#102,condition==($0, _UTF-16LE'sensor_6'))
2021-04-15 17:57:42,014 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#101:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#100,inputs=0,exprs=[$2])
2021-04-15 17:57:42,014 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#75:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:42,015 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert table references after sub-queries removed cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,016 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize subquery_rewrite cost 19 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,016 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:57:42,016 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,017 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:42,018 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#112:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#111,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:57:42,018 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#110:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#109,condition==($0, _UTF-16LE'sensor_6'))
2021-04-15 17:57:42,018 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#108:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#107,inputs=0,exprs=[$2])
2021-04-15 17:57:42,018 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#75:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:42,019 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert correlate to temporal table join cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,019 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,019 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:42,019 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#119:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#118,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:57:42,020 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#117:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#116,condition==($0, _UTF-16LE'sensor_6'))
2021-04-15 17:57:42,020 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#115:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#114,inputs=0,exprs=[$2])
2021-04-15 17:57:42,020 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#75:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:42,020 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert enumerable table scan cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,021 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize temporal_join_rewrite cost 5 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,021 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:57:42,022 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,022 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:42,022 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#126:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#125,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:57:42,022 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#124:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#123,condition==($0, _UTF-16LE'sensor_6'))
2021-04-15 17:57:42,022 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#122:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#121,inputs=0,exprs=[$2])
2021-04-15 17:57:42,022 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#75:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:42,023 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize pre-rewrite before decorrelation cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,025 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize  cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,025 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize decorrelate cost 4 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,029 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize time_indicator cost 4 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,030 DEBUG org.apache.calcite.plan.RelOptPlanner - call#65: Apply rule [SimplifyFilterConditionRule] to [rel#134:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#133,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,032 DEBUG org.apache.calcite.plan.RelOptPlanner - call#68: Apply rule [ReduceExpressionsRule(Filter)] to [rel#134:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#133,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,052 DEBUG org.apache.calcite.plan.RelOptPlanner - call#69: Apply rule [ReduceExpressionsRule(Project)] to [rel#132:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#131,inputs=0,exprs=[$2])]
2021-04-15 17:57:42,054 DEBUG org.apache.calcite.plan.RelOptPlanner - call#70: Apply rule [ConvertToNotInOrInRule] to [rel#134:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#133,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,059 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,060 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
ReduceExpressionsRule(Filter)                                                  1              18,729
ConvertToNotInOrInRule                                                         1               5,587
SimplifyFilterConditionRule                                                    1                 345
ReduceExpressionsRule(Project)                                                 1                  88
* Total                                                                        4              24,749

2021-04-15 17:57:42,061 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#136:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#135,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:57:42,061 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#134:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#133,condition==($0, _UTF-16LE'sensor_6'))
2021-04-15 17:57:42,061 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#132:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#131,inputs=0,exprs=[$2])
2021-04-15 17:57:42,061 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#75:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:42,062 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize default_rewrite cost 32 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,062 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:57:42,062 DEBUG org.apache.calcite.plan.RelOptPlanner - call#71: Apply rule [ReduceExpressionsRule(Project)] to [rel#139:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#138,inputs=0,exprs=[$2])]
2021-04-15 17:57:42,063 DEBUG org.apache.calcite.plan.RelOptPlanner - call#72: Apply rule [FilterProjectTransposeRule] to [rel#141:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#140,condition==($0, _UTF-16LE'sensor_6')), rel#139:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#138,inputs=0,exprs=[$2])]
2021-04-15 17:57:42,064 DEBUG org.apache.calcite.plan.RelOptPlanner - call#72: Rule FilterProjectTransposeRule arguments [rel#141:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#140,condition==($0, _UTF-16LE'sensor_6')), rel#139:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#138,inputs=0,exprs=[$2])] produced rel#146:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=LogicalFilter#145,inputs=0,exprs=[$2])
2021-04-15 17:57:42,066 DEBUG org.apache.calcite.plan.RelOptPlanner - call#73: Apply rule [SimplifyFilterConditionRule] to [rel#145:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#138,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,067 DEBUG org.apache.calcite.plan.RelOptPlanner - call#74: Apply rule [ReduceExpressionsRule(Filter)] to [rel#145:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#138,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,068 DEBUG org.apache.calcite.plan.RelOptPlanner - call#75: Apply rule [ReduceExpressionsRule(Project)] to [rel#148:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#147,inputs=0,exprs=[$2])]
2021-04-15 17:57:42,139 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: ExpressionReducer$5 

 Code:

      public class ExpressionReducer$5
          extends org.apache.flink.api.common.functions.RichMapFunction {

        
        private final org.apache.flink.table.data.binary.BinaryStringData str$4 = org.apache.flink.table.data.binary.BinaryStringData.fromString("sensor_6");
                   
        org.apache.flink.table.data.GenericRowData out = new org.apache.flink.table.data.GenericRowData(1);

        public ExpressionReducer$5(Object[] references) throws Exception {
          
        }

        

        @Override
        public void open(org.apache.flink.configuration.Configuration parameters) throws Exception {
          
        }

        @Override
        public Object map(Object _in1) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) _in1;
          
          
          
          
          
          
          
          
          if (false) {
            out.setField(0, null);
          } else {
            out.setField(0, ((org.apache.flink.table.data.binary.BinaryStringData) str$4));
          }
                    
                  
          return out;
          
        }

        @Override
        public void close() throws Exception {
          
        }
      }
    
2021-04-15 17:57:42,154 DEBUG org.apache.calcite.plan.RelOptPlanner - call#75: Rule ReduceExpressionsRule(Project) arguments [rel#148:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#147,inputs=0,exprs=[$2])] produced rel#150:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#147,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $2])
2021-04-15 17:57:42,155 DEBUG org.apache.calcite.plan.RelOptPlanner - call#76: Apply rule [SimplifyFilterConditionRule] to [rel#145:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#138,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,155 DEBUG org.apache.calcite.plan.RelOptPlanner - call#77: Apply rule [ReduceExpressionsRule(Filter)] to [rel#145:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#138,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,156 DEBUG org.apache.calcite.plan.RelOptPlanner - call#78: Apply rule [ReduceExpressionsRule(Project)] to [rel#150:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#147,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $2])]
2021-04-15 17:57:42,156 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,157 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
ReduceExpressionsRule(Project)                                                 3              87,057
ReduceExpressionsRule(Filter)                                                  2                 780
SimplifyFilterConditionRule                                                    2                 691
FilterProjectTransposeRule                                                     1                 663
* Total                                                                        8              89,191

2021-04-15 17:57:42,157 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#143:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#151,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:57:42,157 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#150:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#147,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $2])
2021-04-15 17:57:42,157 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#145:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#138,condition==($0, _UTF-16LE'sensor_6'))
2021-04-15 17:57:42,157 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#75:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:42,158 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize filter rules cost 95 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalProject(id=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE"], temp=[$2])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,159 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,160 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:42,160 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#157:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#156,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:57:42,160 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#155:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#154,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $2])
2021-04-15 17:57:42,160 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#153:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#152,condition==($0, _UTF-16LE'sensor_6'))
2021-04-15 17:57:42,160 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#75:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:42,161 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize push predicate into table scan cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalProject(id=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE"], temp=[$2])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,161 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,162 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:42,162 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#164:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#163,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:57:42,162 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#162:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#161,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $2])
2021-04-15 17:57:42,162 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#160:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#159,condition==($0, _UTF-16LE'sensor_6'))
2021-04-15 17:57:42,162 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#75:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:42,163 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize prune empty after predicate push down cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalProject(id=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE"], temp=[$2])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,164 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize predicate_pushdown cost 101 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- LogicalProject(id=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE"], temp=[$2])
   +- LogicalFilter(condition=[=($0, _UTF-16LE'sensor_6')])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,180 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,181 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)] rels [#75]
2021-04-15 17:57:42,181 DEBUG org.apache.calcite.plan.RelOptPlanner - call#94: Apply rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)] to [rel#75:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])]
2021-04-15 17:57:42,182 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#175 via FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:42,223 DEBUG org.apache.calcite.plan.RelOptPlanner - call#94 generated 1 successors: [rel#175:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:57:42,223 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,223 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FilterToCalcRule] rels [#167]
2021-04-15 17:57:42,224 DEBUG org.apache.calcite.plan.RelOptPlanner - call#114: Apply rule [FilterToCalcRule] to [rel#167:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,231 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#177 via FilterToCalcRule
2021-04-15 17:57:42,233 DEBUG org.apache.calcite.plan.RelOptPlanner - call#114 generated 1 successors: [rel#177:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)]
2021-04-15 17:57:42,233 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,234 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectFilterTransposeRule] rels [#169,#167]
2021-04-15 17:57:42,234 DEBUG org.apache.calcite.plan.RelOptPlanner - call#118: Apply rule [ProjectFilterTransposeRule] to [rel#169:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#168,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $2]), rel#167:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,242 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#180 via ProjectFilterTransposeRule
2021-04-15 17:57:42,244 DEBUG org.apache.calcite.plan.RelOptPlanner - call#118 generated 1 successors: [rel#180:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=LogicalFilter#179,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])]
2021-04-15 17:57:42,244 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,244 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#169]
2021-04-15 17:57:42,244 DEBUG org.apache.calcite.plan.RelOptPlanner - call#139: Apply rule [ProjectToCalcRule] to [rel#169:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#168,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $2])]
2021-04-15 17:57:42,246 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#185 via ProjectToCalcRule
2021-04-15 17:57:42,249 DEBUG org.apache.calcite.plan.RelOptPlanner - call#139 generated 1 successors: [rel#185:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#168,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t4,1=$t2)]
2021-04-15 17:57:42,249 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,249 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)] rels [#171]
2021-04-15 17:57:42,249 DEBUG org.apache.calcite.plan.RelOptPlanner - call#147: Apply rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)] to [rel#171:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,name=DataStreamTableSink,fields=id, temp)]
2021-04-15 17:57:42,250 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#187 via FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:42,283 DEBUG org.apache.calcite.plan.RelOptPlanner - call#147 generated 1 successors: [rel#187:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#186,name=DataStreamTableSink,fields=id, temp)]
2021-04-15 17:57:42,284 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,284 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectCalcMergeRule] rels [#169,#177]
2021-04-15 17:57:42,284 DEBUG org.apache.calcite.plan.RelOptPlanner - call#166: Apply rule [ProjectCalcMergeRule] to [rel#169:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#168,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $2]), rel#177:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)]
2021-04-15 17:57:42,287 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#188 via ProjectCalcMergeRule
2021-04-15 17:57:42,287 DEBUG org.apache.calcite.plan.RelOptPlanner - call#166 generated 1 successors: [rel#188:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_6',expr#6==($t0, $t5),0=$t4,1=$t2,$condition=$t6)]
2021-04-15 17:57:42,288 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,288 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#177]
2021-04-15 17:57:42,288 DEBUG org.apache.calcite.plan.RelOptPlanner - call#170: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#177:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)]
2021-04-15 17:57:42,289 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#189 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:42,323 DEBUG org.apache.calcite.plan.RelOptPlanner - call#170 generated 1 successors: [rel#189:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#176,select=id, timestamp, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,324 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,324 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [PushProjectIntoLegacyTableSourceScanRule] rels [#178,#75]
2021-04-15 17:57:42,324 DEBUG org.apache.calcite.plan.RelOptPlanner - call#184: Apply rule [PushProjectIntoLegacyTableSourceScanRule] to [rel#178:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,inputs=0,exprs=[$2]), rel#75:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])]
2021-04-15 17:57:42,329 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#191 via PushProjectIntoLegacyTableSourceScanRule
2021-04-15 17:57:42,330 DEBUG org.apache.calcite.plan.RelOptPlanner - call#184 generated 1 successors: [rel#191:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]])]
2021-04-15 17:57:42,330 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,330 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#178]
2021-04-15 17:57:42,330 DEBUG org.apache.calcite.plan.RelOptPlanner - call#194: Apply rule [ProjectToCalcRule] to [rel#178:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,inputs=0,exprs=[$2])]
2021-04-15 17:57:42,331 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#193 via ProjectToCalcRule
2021-04-15 17:57:42,331 DEBUG org.apache.calcite.plan.RelOptPlanner - call#194 generated 1 successors: [rel#193:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..2={inputs},0=$t0,1=$t2)]
2021-04-15 17:57:42,331 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,331 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FilterProjectTransposeRule] rels [#182,#178]
2021-04-15 17:57:42,331 DEBUG org.apache.calcite.plan.RelOptPlanner - call#199: Apply rule [FilterProjectTransposeRule] to [rel#182:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#181,condition==($0, _UTF-16LE'sensor_6')), rel#178:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,inputs=0,exprs=[$2])]
2021-04-15 17:57:42,331 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#195 via FilterProjectTransposeRule
2021-04-15 17:57:42,332 DEBUG org.apache.calcite.plan.RelOptPlanner - call#199 generated 1 successors: [rel#195:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=LogicalFilter#194,inputs=0,exprs=[$2])]
2021-04-15 17:57:42,333 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,333 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FilterToCalcRule] rels [#182]
2021-04-15 17:57:42,333 DEBUG org.apache.calcite.plan.RelOptPlanner - call#214: Apply rule [FilterToCalcRule] to [rel#182:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#181,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,333 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#197 via FilterToCalcRule
2021-04-15 17:57:42,335 DEBUG org.apache.calcite.plan.RelOptPlanner - call#214 generated 1 successors: [rel#197:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#181,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6',expr#3==($t0, $t2),proj#0..1={exprs},$condition=$t3)]
2021-04-15 17:57:42,335 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,335 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectFilterTransposeRule] rels [#184,#182]
2021-04-15 17:57:42,335 DEBUG org.apache.calcite.plan.RelOptPlanner - call#218: Apply rule [ProjectFilterTransposeRule] to [rel#184:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#183,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#182:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#181,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,335 DEBUG org.apache.calcite.plan.RelOptPlanner - call#218 generated 0 successors.
2021-04-15 17:57:42,335 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,336 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#184]
2021-04-15 17:57:42,336 DEBUG org.apache.calcite.plan.RelOptPlanner - call#239: Apply rule [ProjectToCalcRule] to [rel#184:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#183,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])]
2021-04-15 17:57:42,336 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#198 via ProjectToCalcRule
2021-04-15 17:57:42,337 DEBUG org.apache.calcite.plan.RelOptPlanner - call#239 generated 1 successors: [rel#198:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#183,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t3,1=$t1)]
2021-04-15 17:57:42,338 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,338 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#185,#177]
2021-04-15 17:57:42,338 DEBUG org.apache.calcite.plan.RelOptPlanner - call#250: Apply rule [FlinkCalcMergeRule] to [rel#185:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#168,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t4,1=$t2), rel#177:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)]
2021-04-15 17:57:42,339 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#199 via FlinkCalcMergeRule
2021-04-15 17:57:42,339 DEBUG org.apache.calcite.plan.RelOptPlanner - call#250 generated 1 successors: [rel#199:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_6',expr#6==($t0, $t5),0=$t4,1=$t2,$condition=$t6)]
2021-04-15 17:57:42,340 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,340 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#185]
2021-04-15 17:57:42,340 DEBUG org.apache.calcite.plan.RelOptPlanner - call#253: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#185:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#168,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t4,1=$t2)]
2021-04-15 17:57:42,340 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#200 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:42,353 DEBUG org.apache.calcite.plan.RelOptPlanner - call#253 generated 1 successors: [rel#200:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#190,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp)]
2021-04-15 17:57:42,353 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.45E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,353 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#188]
2021-04-15 17:57:42,354 DEBUG org.apache.calcite.plan.RelOptPlanner - call#270: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#188:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_6',expr#6==($t0, $t5),0=$t4,1=$t2,$condition=$t6)]
2021-04-15 17:57:42,354 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#201 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:42,355 DEBUG org.apache.calcite.plan.RelOptPlanner - call#270 generated 1 successors: [rel#201:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#176,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,355 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,355 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)] rels [#191]
2021-04-15 17:57:42,356 DEBUG org.apache.calcite.plan.RelOptPlanner - call#290: Apply rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)] to [rel#191:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]])]
2021-04-15 17:57:42,356 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#202 via FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:42,357 DEBUG org.apache.calcite.plan.RelOptPlanner - call#290 generated 1 successors: [rel#202:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:57:42,357 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,357 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FilterCalcMergeRule] rels [#182,#193]
2021-04-15 17:57:42,357 DEBUG org.apache.calcite.plan.RelOptPlanner - call#300: Apply rule [FilterCalcMergeRule] to [rel#182:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#181,condition==($0, _UTF-16LE'sensor_6')), rel#193:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..2={inputs},0=$t0,1=$t2)]
2021-04-15 17:57:42,358 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#204 via FilterCalcMergeRule
2021-04-15 17:57:42,359 DEBUG org.apache.calcite.plan.RelOptPlanner - call#300 generated 1 successors: [rel#204:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),0=$t0,1=$t2,$condition=$t4)]
2021-04-15 17:57:42,359 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,359 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#193]
2021-04-15 17:57:42,359 DEBUG org.apache.calcite.plan.RelOptPlanner - call#305: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#193:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..2={inputs},0=$t0,1=$t2)]
2021-04-15 17:57:42,359 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#205 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:42,360 DEBUG org.apache.calcite.plan.RelOptPlanner - call#305 generated 1 successors: [rel#205:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#176,select=id, temp)]
2021-04-15 17:57:42,360 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,360 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectFilterTransposeRule] rels [#196,#167]
2021-04-15 17:57:42,360 DEBUG org.apache.calcite.plan.RelOptPlanner - call#308: Apply rule [ProjectFilterTransposeRule] to [rel#196:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#168,inputs=0,exprs=[$2]), rel#167:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,361 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#207 via ProjectFilterTransposeRule
2021-04-15 17:57:42,361 DEBUG org.apache.calcite.plan.RelOptPlanner - call#308 generated 1 successors: [rel#207:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=LogicalProject#206,condition==($0, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,361 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,361 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectMergeRule] rels [#184,#196]
2021-04-15 17:57:42,361 DEBUG org.apache.calcite.plan.RelOptPlanner - call#313: Apply rule [ProjectMergeRule] to [rel#184:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#183,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#196:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#168,inputs=0,exprs=[$2])]
2021-04-15 17:57:42,363 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#209 via ProjectMergeRule
2021-04-15 17:57:42,364 DEBUG org.apache.calcite.plan.RelOptPlanner - call#313 generated 1 successors: [rel#209:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#168,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $2])]
2021-04-15 17:57:42,364 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,364 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectCalcMergeRule] rels [#196,#177]
2021-04-15 17:57:42,364 DEBUG org.apache.calcite.plan.RelOptPlanner - call#329: Apply rule [ProjectCalcMergeRule] to [rel#196:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#168,inputs=0,exprs=[$2]), rel#177:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)]
2021-04-15 17:57:42,365 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#210 via ProjectCalcMergeRule
2021-04-15 17:57:42,365 DEBUG org.apache.calcite.plan.RelOptPlanner - call#329 generated 1 successors: [rel#210:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),0=$t0,1=$t2,$condition=$t4)]
2021-04-15 17:57:42,365 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,365 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#196]
2021-04-15 17:57:42,365 DEBUG org.apache.calcite.plan.RelOptPlanner - call#331: Apply rule [ProjectToCalcRule] to [rel#196:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#168,inputs=0,exprs=[$2])]
2021-04-15 17:57:42,366 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#211 via ProjectToCalcRule
2021-04-15 17:57:42,367 DEBUG org.apache.calcite.plan.RelOptPlanner - call#331 generated 1 successors: [rel#211:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#168,expr#0..2={inputs},0=$t0,1=$t2)]
2021-04-15 17:57:42,367 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,367 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectCalcMergeRule] rels [#184,#197]
2021-04-15 17:57:42,367 DEBUG org.apache.calcite.plan.RelOptPlanner - call#341: Apply rule [ProjectCalcMergeRule] to [rel#184:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#183,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#197:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#181,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6',expr#3==($t0, $t2),proj#0..1={exprs},$condition=$t3)]
2021-04-15 17:57:42,369 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#212 via ProjectCalcMergeRule
2021-04-15 17:57:42,370 DEBUG org.apache.calcite.plan.RelOptPlanner - call#341 generated 1 successors: [rel#212:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#181,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=_UTF-16LE'sensor_6',expr#5==($t0, $t4),0=$t3,1=$t1,$condition=$t5)]
2021-04-15 17:57:42,370 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,370 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#197,#193]
2021-04-15 17:57:42,370 DEBUG org.apache.calcite.plan.RelOptPlanner - call#343: Apply rule [FlinkCalcMergeRule] to [rel#197:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#181,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6',expr#3==($t0, $t2),proj#0..1={exprs},$condition=$t3), rel#193:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..2={inputs},0=$t0,1=$t2)]
2021-04-15 17:57:42,371 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#213 via FlinkCalcMergeRule
2021-04-15 17:57:42,371 DEBUG org.apache.calcite.plan.RelOptPlanner - call#343 generated 1 successors: [rel#213:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),0=$t0,1=$t2,$condition=$t4)]
2021-04-15 17:57:42,371 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,371 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#197]
2021-04-15 17:57:42,371 DEBUG org.apache.calcite.plan.RelOptPlanner - call#346: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#197:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#181,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6',expr#3==($t0, $t2),proj#0..1={exprs},$condition=$t3)]
2021-04-15 17:57:42,371 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#214 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:42,372 DEBUG org.apache.calcite.plan.RelOptPlanner - call#346 generated 1 successors: [rel#214:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#203,select=id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,373 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,373 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#198,#197]
2021-04-15 17:57:42,373 DEBUG org.apache.calcite.plan.RelOptPlanner - call#356: Apply rule [FlinkCalcMergeRule] to [rel#198:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#183,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t3,1=$t1), rel#197:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#181,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6',expr#3==($t0, $t2),proj#0..1={exprs},$condition=$t3)]
2021-04-15 17:57:42,374 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#216 via FlinkCalcMergeRule
2021-04-15 17:57:42,374 DEBUG org.apache.calcite.plan.RelOptPlanner - call#356 generated 1 successors: [rel#216:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#181,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=_UTF-16LE'sensor_6',expr#5==($t0, $t4),0=$t3,1=$t1,$condition=$t5)]
2021-04-15 17:57:42,374 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,374 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#198]
2021-04-15 17:57:42,375 DEBUG org.apache.calcite.plan.RelOptPlanner - call#359: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#198:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#183,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t3,1=$t1)]
2021-04-15 17:57:42,375 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#217 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:42,376 DEBUG org.apache.calcite.plan.RelOptPlanner - call#359 generated 1 successors: [rel#217:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#215,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp)]
2021-04-15 17:57:42,376 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.45E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,376 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#200,#189]
2021-04-15 17:57:42,376 DEBUG org.apache.calcite.plan.RelOptPlanner - call#367: Apply rule [FlinkCalcMergeRule] to [rel#200:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#190,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp), rel#189:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#176,select=id, timestamp, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,378 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#218 via FlinkCalcMergeRule
2021-04-15 17:57:42,378 DEBUG org.apache.calcite.plan.RelOptPlanner - call#367 generated 1 successors: [rel#218:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#176,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,379 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.45E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,379 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectCalcMergeRule] rels [#184,#204]
2021-04-15 17:57:42,379 DEBUG org.apache.calcite.plan.RelOptPlanner - call#390: Apply rule [ProjectCalcMergeRule] to [rel#184:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#183,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#204:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),0=$t0,1=$t2,$condition=$t4)]
2021-04-15 17:57:42,381 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#219 via ProjectCalcMergeRule
2021-04-15 17:57:42,381 DEBUG org.apache.calcite.plan.RelOptPlanner - call#390 generated 1 successors: [rel#219:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_6',expr#6==($t0, $t5),0=$t4,1=$t2,$condition=$t6)]
2021-04-15 17:57:42,381 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.45E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,381 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#198,#204]
2021-04-15 17:57:42,381 DEBUG org.apache.calcite.plan.RelOptPlanner - call#393: Apply rule [FlinkCalcMergeRule] to [rel#198:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#183,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t3,1=$t1), rel#204:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),0=$t0,1=$t2,$condition=$t4)]
2021-04-15 17:57:42,382 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#220 via FlinkCalcMergeRule
2021-04-15 17:57:42,383 DEBUG org.apache.calcite.plan.RelOptPlanner - call#393 generated 1 successors: [rel#220:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_6',expr#6==($t0, $t5),0=$t4,1=$t2,$condition=$t6)]
2021-04-15 17:57:42,383 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.45E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,383 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#204]
2021-04-15 17:57:42,383 DEBUG org.apache.calcite.plan.RelOptPlanner - call#395: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#204:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),0=$t0,1=$t2,$condition=$t4)]
2021-04-15 17:57:42,383 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#221 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:42,385 DEBUG org.apache.calcite.plan.RelOptPlanner - call#395 generated 1 successors: [rel#221:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#176,select=id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,385 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.45E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,385 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectCalcMergeRule] rels [#184,#211]
2021-04-15 17:57:42,385 DEBUG org.apache.calcite.plan.RelOptPlanner - call#412: Apply rule [ProjectCalcMergeRule] to [rel#184:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#183,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1]), rel#211:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#168,expr#0..2={inputs},0=$t0,1=$t2)]
2021-04-15 17:57:42,386 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#222 via ProjectCalcMergeRule
2021-04-15 17:57:42,387 DEBUG org.apache.calcite.plan.RelOptPlanner - call#412 generated 1 successors: [rel#222:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#168,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t4,1=$t2)]
2021-04-15 17:57:42,387 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.45E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,387 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#211,#177]
2021-04-15 17:57:42,387 DEBUG org.apache.calcite.plan.RelOptPlanner - call#414: Apply rule [FlinkCalcMergeRule] to [rel#211:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#168,expr#0..2={inputs},0=$t0,1=$t2), rel#177:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),proj#0..2={exprs},$condition=$t4)]
2021-04-15 17:57:42,388 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#223 via FlinkCalcMergeRule
2021-04-15 17:57:42,388 DEBUG org.apache.calcite.plan.RelOptPlanner - call#414 generated 1 successors: [rel#223:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6',expr#4==($t0, $t3),0=$t0,1=$t2,$condition=$t4)]
2021-04-15 17:57:42,388 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.45E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,389 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#198,#211]
2021-04-15 17:57:42,389 DEBUG org.apache.calcite.plan.RelOptPlanner - call#416: Apply rule [FlinkCalcMergeRule] to [rel#198:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#183,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t3,1=$t1), rel#211:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#168,expr#0..2={inputs},0=$t0,1=$t2)]
2021-04-15 17:57:42,390 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#224 via FlinkCalcMergeRule
2021-04-15 17:57:42,390 DEBUG org.apache.calcite.plan.RelOptPlanner - call#416 generated 1 successors: [rel#224:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#168,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",0=$t4,1=$t2)]
2021-04-15 17:57:42,390 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.45E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,391 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#211]
2021-04-15 17:57:42,391 DEBUG org.apache.calcite.plan.RelOptPlanner - call#418: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#211:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#168,expr#0..2={inputs},0=$t0,1=$t2)]
2021-04-15 17:57:42,391 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#225 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:42,394 DEBUG org.apache.calcite.plan.RelOptPlanner - call#418 generated 1 successors: [rel#225:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#190,select=id, temp)]
2021-04-15 17:57:42,394 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.45E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,394 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#212,#193]
2021-04-15 17:57:42,394 DEBUG org.apache.calcite.plan.RelOptPlanner - call#428: Apply rule [FlinkCalcMergeRule] to [rel#212:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#181,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=_UTF-16LE'sensor_6',expr#5==($t0, $t4),0=$t3,1=$t1,$condition=$t5), rel#193:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..2={inputs},0=$t0,1=$t2)]
2021-04-15 17:57:42,395 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#226 via FlinkCalcMergeRule
2021-04-15 17:57:42,395 DEBUG org.apache.calcite.plan.RelOptPlanner - call#428 generated 1 successors: [rel#226:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..2={inputs},expr#3=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=CAST($t3):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#5=_UTF-16LE'sensor_6',expr#6==($t0, $t5),0=$t4,1=$t2,$condition=$t6)]
2021-04-15 17:57:42,395 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.45E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,395 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#212]
2021-04-15 17:57:42,396 DEBUG org.apache.calcite.plan.RelOptPlanner - call#431: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#212:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#181,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=_UTF-16LE'sensor_6',expr#5==($t0, $t4),0=$t3,1=$t1,$condition=$t5)]
2021-04-15 17:57:42,396 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#227 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:42,397 DEBUG org.apache.calcite.plan.RelOptPlanner - call#431 generated 1 successors: [rel#227:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#203,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,397 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,397 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#214,#205]
2021-04-15 17:57:42,397 DEBUG org.apache.calcite.plan.RelOptPlanner - call#439: Apply rule [FlinkCalcMergeRule] to [rel#214:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#203,select=id, temp,where==(id, _UTF-16LE'sensor_6')), rel#205:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#176,select=id, temp)]
2021-04-15 17:57:42,398 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#228 via FlinkCalcMergeRule
2021-04-15 17:57:42,399 DEBUG org.apache.calcite.plan.RelOptPlanner - call#439 generated 1 successors: [rel#228:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#176,select=id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,399 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,400 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#217,#214]
2021-04-15 17:57:42,400 DEBUG org.apache.calcite.plan.RelOptPlanner - call#448: Apply rule [FlinkCalcMergeRule] to [rel#217:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#215,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp), rel#214:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#203,select=id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,401 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#229 via FlinkCalcMergeRule
2021-04-15 17:57:42,402 DEBUG org.apache.calcite.plan.RelOptPlanner - call#448 generated 1 successors: [rel#229:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#203,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,402 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,402 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#217,#221]
2021-04-15 17:57:42,402 DEBUG org.apache.calcite.plan.RelOptPlanner - call#458: Apply rule [FlinkCalcMergeRule] to [rel#217:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#215,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp), rel#221:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#176,select=id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,404 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#230 via FlinkCalcMergeRule
2021-04-15 17:57:42,404 DEBUG org.apache.calcite.plan.RelOptPlanner - call#458 generated 1 successors: [rel#230:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#176,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,405 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,405 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#225,#189]
2021-04-15 17:57:42,405 DEBUG org.apache.calcite.plan.RelOptPlanner - call#466: Apply rule [FlinkCalcMergeRule] to [rel#225:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#190,select=id, temp), rel#189:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#176,select=id, timestamp, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,406 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#231 via FlinkCalcMergeRule
2021-04-15 17:57:42,406 DEBUG org.apache.calcite.plan.RelOptPlanner - call#466 generated 1 successors: [rel#231:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#176,select=id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,407 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,407 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#217,#225]
2021-04-15 17:57:42,407 DEBUG org.apache.calcite.plan.RelOptPlanner - call#468: Apply rule [FlinkCalcMergeRule] to [rel#217:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#215,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp), rel#225:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#190,select=id, temp)]
2021-04-15 17:57:42,408 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#232 via FlinkCalcMergeRule
2021-04-15 17:57:42,408 DEBUG org.apache.calcite.plan.RelOptPlanner - call#468 generated 1 successors: [rel#232:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#190,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp)]
2021-04-15 17:57:42,408 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,408 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#227,#205]
2021-04-15 17:57:42,409 DEBUG org.apache.calcite.plan.RelOptPlanner - call#476: Apply rule [FlinkCalcMergeRule] to [rel#227:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#203,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6')), rel#205:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#176,select=id, temp)]
2021-04-15 17:57:42,410 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#233 via FlinkCalcMergeRule
2021-04-15 17:57:42,410 DEBUG org.apache.calcite.plan.RelOptPlanner - call#476 generated 1 successors: [rel#233:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#176,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,410 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,410 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for VolcanoPlanner
2021-04-15 17:57:42,412 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
FlinkCalcMergeRule                                                            14              22,606
FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)                                 9              60,009
ProjectCalcMergeRule                                                           5               9,911
ProjectToCalcRule                                                              4               8,173
FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)                   3             136,965
ProjectFilterTransposeRule                                                     3              11,586
FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)                           2              71,034
FilterToCalcRule                                                               2              11,218
StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)                   1              61,646
StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)                       1              32,717
PushProjectIntoLegacyTableSourceScanRule                                       1               6,172
ProjectMergeRule                                                               1               2,663
FilterCalcMergeRule                                                            1               1,741
FilterProjectTransposeRule                                                     1               1,275
* Total                                                                       48             437,716

2021-04-15 17:57:42,437 DEBUG org.apache.calcite.plan.RelOptPlanner - Cheapest plan:
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp]): rowcount = 1.5E7, cumulative cost = {1.3E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}, id = 235
  FlinkLogicalCalc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[=(id, _UTF-16LE'sensor_6')]): rowcount = 1.5E7, cumulative cost = {1.15E8 rows, 1.0E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}, id = 234
    FlinkLogicalLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, timestamp, temp]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}, id = 202

2021-04-15 17:57:42,438 DEBUG org.apache.calcite.plan.RelOptPlanner - Provenance:
rel#235:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=FlinkLogicalCalc#234,name=DataStreamTableSink,fields=id, temp)
  direct
    rel#187:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#186,name=DataStreamTableSink,fields=id, temp)
      call#147 rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)]
        rel#171:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#170,name=DataStreamTableSink,fields=id, temp)
          no parent
rel#234:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=FlinkLogicalLegacyTableSourceScan#202,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))
  direct
    rel#227:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#203,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))
      call#431 rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)]
        rel#212:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#181,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#3=CAST($t2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE",expr#4=_UTF-16LE'sensor_6',expr#5==($t0, $t4),0=$t3,1=$t1,$condition=$t5)
          call#341 rule [ProjectCalcMergeRule]
            rel#184:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#183,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $1])
              call#118 rule [ProjectFilterTransposeRule]
                rel#169:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#168,exprs=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"):VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $2])
                  no parent
                rel#167:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,condition==($0, _UTF-16LE'sensor_6'))
                  no parent
            rel#197:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#181,expr#0..1={inputs},expr#2=_UTF-16LE'sensor_6',expr#3==($t0, $t2),proj#0..1={exprs},$condition=$t3)
              call#214 rule [FilterToCalcRule]
                rel#182:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#181,condition==($0, _UTF-16LE'sensor_6'))
                  call#118 rule [ProjectFilterTransposeRule]
                    rel#169 (see above)
                    rel#167 (see above)
rel#202:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, timestamp, temp)
  call#290 rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)]
    rel#191:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]])
      call#184 rule [PushProjectIntoLegacyTableSourceScanRule]
        rel#178:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,inputs=0,exprs=[$2])
          call#118 rule [ProjectFilterTransposeRule]
            rel#169 (see above)
            rel#167 (see above)
        rel#75:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
          no parent

2021-04-15 17:57:42,441 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize logical cost 276 ms.
optimize result: 
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- FlinkLogicalCalc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[=(id, _UTF-16LE'sensor_6')])
   +- FlinkLogicalLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:57:42,449 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,449 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:42,449 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#239:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#238,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:57:42,450 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#237:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#236,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))
2021-04-15 17:57:42,450 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#202:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, timestamp, temp)
2021-04-15 17:57:42,451 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize logical_rewrite cost 9 ms.
optimize result: 
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- FlinkLogicalCalc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[=(id, _UTF-16LE'sensor_6')])
   +- FlinkLogicalLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:57:42,456 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,456 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#202]
2021-04-15 17:57:42,457 DEBUG org.apache.calcite.plan.RelOptPlanner - call#488: Apply rule [StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#202:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:57:42,457 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#248 via StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:57:42,458 DEBUG org.apache.calcite.plan.RelOptPlanner - call#488 generated 1 successors: [rel#248:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)]
2021-04-15 17:57:42,458 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,459 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#242]
2021-04-15 17:57:42,459 DEBUG org.apache.calcite.plan.RelOptPlanner - call#499: Apply rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#242:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#241,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,460 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#250 via StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:57:42,485 DEBUG org.apache.calcite.plan.RelOptPlanner - call#499 generated 1 successors: [rel#250:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#249,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,486 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,486 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#244]
2021-04-15 17:57:42,486 DEBUG org.apache.calcite.plan.RelOptPlanner - call#516: Apply rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#244:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#243,name=DataStreamTableSink,fields=id, temp)]
2021-04-15 17:57:42,486 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#252 via StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:57:42,487 DEBUG org.apache.calcite.plan.RelOptPlanner - call#516 generated 1 successors: [rel#252:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#251,name=DataStreamTableSink,fields=id, temp)]
2021-04-15 17:57:42,487 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {1.3E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,487 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for VolcanoPlanner
2021-04-15 17:57:42,488 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
FlinkCalcMergeRule                                                            14              22,606
FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)                                 9              60,009
ProjectCalcMergeRule                                                           5               9,911
ProjectToCalcRule                                                              4               8,173
FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)                   3             136,965
ProjectFilterTransposeRule                                                     3              11,586
FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)                           2              71,034
StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)                   2              63,300
StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)                       2              33,550
FilterToCalcRule                                                               2              11,218
StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)                             1              26,704
PushProjectIntoLegacyTableSourceScanRule                                       1               6,172
ProjectMergeRule                                                               1               2,663
FilterCalcMergeRule                                                            1               1,741
FilterProjectTransposeRule                                                     1               1,275
* Total                                                                       51             466,907

2021-04-15 17:57:42,508 DEBUG org.apache.calcite.plan.RelOptPlanner - Cheapest plan:
StreamExecLegacySink(name=[DataStreamTableSink], fields=[id, temp]): rowcount = 1.5E7, cumulative cost = {1.3E8 rows, 1.15E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}, id = 254
  StreamExecCalc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[=(id, _UTF-16LE'sensor_6')]): rowcount = 1.5E7, cumulative cost = {1.15E8 rows, 1.0E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}, id = 253
    StreamExecLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}, id = 248

2021-04-15 17:57:42,509 DEBUG org.apache.calcite.plan.RelOptPlanner - Provenance:
rel#254:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=StreamExecCalc#253,name=DataStreamTableSink,fields=id, temp)
  direct
    rel#252:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#251,name=DataStreamTableSink,fields=id, temp)
      call#516 rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#244:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#243,name=DataStreamTableSink,fields=id, temp)
          no parent
rel#253:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=StreamExecLegacyTableSourceScan#248,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))
  direct
    rel#250:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#249,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))
      call#499 rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#242:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#241,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))
          no parent
rel#248:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)
  call#488 rule [StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)]
    rel#202:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, timestamp, temp)
      no parent

2021-04-15 17:57:42,510 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize physical cost 58 ms.
optimize result: 
LegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[=(id, _UTF-16LE'sensor_6')])
   +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:57:42,510 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:57:42,511 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,511 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:42,511 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#258:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#257,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:57:42,511 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#256:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#255,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))
2021-04-15 17:57:42,511 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#248:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)
2021-04-15 17:57:42,512 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize watermark transpose cost 2 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[=(id, _UTF-16LE'sensor_6')])
   +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:57:42,514 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize Changelog mode inference cost 2 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[=(id, _UTF-16LE'sensor_6')])
   +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:57:42,515 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize Initialization for mini-batch interval inference cost 0 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[=(id, _UTF-16LE'sensor_6')])
   +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:57:42,515 DEBUG org.apache.calcite.plan.RelOptPlanner - call#524: Apply rule [MiniBatchIntervalInferRule] to [rel#270:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#269,name=DataStreamTableSink,fields=id, temp)]
2021-04-15 17:57:42,516 DEBUG org.apache.calcite.plan.RelOptPlanner - call#525: Apply rule [MiniBatchIntervalInferRule] to [rel#268:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[I].[NONE](input=HepRelVertex#267,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))]
2021-04-15 17:57:42,516 DEBUG org.apache.calcite.plan.RelOptPlanner - call#526: Apply rule [MiniBatchIntervalInferRule] to [rel#263:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)]
2021-04-15 17:57:42,516 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,517 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
MiniBatchIntervalInferRule                                                     3                 208
* Total                                                                        3                 208

2021-04-15 17:57:42,518 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#270:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#269,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:57:42,518 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#268:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[I].[NONE](input=HepRelVertex#267,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))
2021-04-15 17:57:42,518 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#263:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)
2021-04-15 17:57:42,518 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize mini-batch interval rules cost 3 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[=(id, _UTF-16LE'sensor_6')])
   +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:57:42,519 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,519 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:42,519 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#275:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#274,name=DataStreamTableSink,fields=id, temp)
2021-04-15 17:57:42,519 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#273:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[I].[NONE](input=HepRelVertex#272,select=CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp,where==(id, _UTF-16LE'sensor_6'))
2021-04-15 17:57:42,520 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#263:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)
2021-04-15 17:57:42,520 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize physical rewrite cost 1 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[=(id, _UTF-16LE'sensor_6')])
   +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:57:42,521 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize physical_rewrite cost 11 ms.
optimize result: 
LegacySink(name=[DataStreamTableSink], fields=[id, temp])
+- Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[=(id, _UTF-16LE'sensor_6')])
   +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:57:42,524 INFO org.apache.flink.api.java.typeutils.TypeExtractor - class org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit does not contain a setter for field modificationTime
2021-04-15 17:57:42,524 INFO org.apache.flink.api.java.typeutils.TypeExtractor - Class class org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2021-04-15 17:57:42,525 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:57:42,525 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:57:42,525 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:57:42,525 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:57:42,525 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:57:42,525 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.java.io.RowCsvInputFormat
2021-04-15 17:57:42,525 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:57:42,525 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [Lorg.apache.flink.api.common.typeinfo.TypeInformation;
2021-04-15 17:57:42,525 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [I
2021-04-15 17:57:42,525 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:57:42,526 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Long
2021-04-15 17:57:42,526 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.streaming.api.functions.source.FileProcessingMode
2021-04-15 17:57:42,526 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Long
2021-04-15 17:57:42,526 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:57:42,532 DEBUG o.a.flink.table.planner.codegen.OperatorCodeGenerator$ - Compiling OneInputStreamOperator Code:
SourceConversion
2021-04-15 17:57:42,566 DEBUG o.a.flink.table.planner.codegen.OperatorCodeGenerator$ - Compiling OneInputStreamOperator Code:
StreamExecCalc
2021-04-15 17:57:42,569 DEBUG o.a.flink.table.planner.codegen.OperatorCodeGenerator$ - Compiling OneInputStreamOperator Code:
SinkConversion
2021-04-15 17:57:42,569 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
2021-04-15 17:57:42,569 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:57:42,569 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:57:42,569 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:57:42,569 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:57:42,569 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:57:42,570 INFO org.apache.flink.api.java.typeutils.TypeExtractor - class org.apache.flink.types.Row is missing a default constructor so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2021-04-15 17:57:42,602 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:57:42,603 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,603 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:42,603 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#286:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#285,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:57:42,603 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#284:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#283,inputs=0..2)
2021-04-15 17:57:42,604 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#282:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#281,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
2021-04-15 17:57:42,604 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#277:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:42,604 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert table references before rewriting sub-queries to semi-join cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,605 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,605 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:42,605 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#293:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#292,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:57:42,605 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#291:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#290,inputs=0..2)
2021-04-15 17:57:42,605 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#289:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#288,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
2021-04-15 17:57:42,605 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#277:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:42,606 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize rewrite sub-queries to semi-join cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,607 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,607 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:42,607 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#300:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#299,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:57:42,607 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#298:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#297,inputs=0..2)
2021-04-15 17:57:42,607 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#296:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#295,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
2021-04-15 17:57:42,607 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#277:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:42,608 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize sub-queries remove cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,608 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,609 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:42,609 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#307:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#306,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:57:42,609 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#305:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#304,inputs=0..2)
2021-04-15 17:57:42,609 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#303:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#302,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
2021-04-15 17:57:42,609 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#277:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:42,610 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert table references after sub-queries removed cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,611 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize subquery_rewrite cost 8 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,611 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:57:42,611 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,612 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:42,612 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#314:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#313,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:57:42,612 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#312:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#311,inputs=0..2)
2021-04-15 17:57:42,612 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#310:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#309,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
2021-04-15 17:57:42,612 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#277:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:42,613 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert correlate to temporal table join cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,613 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,613 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:42,613 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#321:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#320,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:57:42,614 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#319:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#318,inputs=0..2)
2021-04-15 17:57:42,615 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#317:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#316,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
2021-04-15 17:57:42,615 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#277:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:42,615 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert enumerable table scan cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,616 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize temporal_join_rewrite cost 5 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,616 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:57:42,616 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,617 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:42,617 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#328:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#327,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:57:42,617 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#326:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#325,inputs=0..2)
2021-04-15 17:57:42,617 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#324:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#323,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
2021-04-15 17:57:42,617 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#277:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:42,618 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize pre-rewrite before decorrelation cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,618 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize  cost 0 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,619 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize decorrelate cost 2 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,628 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize time_indicator cost 8 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,629 DEBUG org.apache.calcite.plan.RelOptPlanner - call#528: Apply rule [ReduceExpressionsRule(Project)] to [rel#336:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#335,inputs=0..2)]
2021-04-15 17:57:42,629 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,630 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
ReduceExpressionsRule(Project)                                                 1                 233
* Total                                                                        1                 233

2021-04-15 17:57:42,630 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#338:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#337,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:57:42,630 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#336:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#335,inputs=0..2)
2021-04-15 17:57:42,630 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#334:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#333,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
2021-04-15 17:57:42,630 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#277:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:42,630 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize default_rewrite cost 2 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,630 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:57:42,631 DEBUG org.apache.calcite.plan.RelOptPlanner - call#529: Apply rule [ReduceExpressionsRule(Project)] to [rel#343:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#342,inputs=0..2)]
2021-04-15 17:57:42,631 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,632 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
ReduceExpressionsRule(Project)                                                 1                 165
* Total                                                                        1                 165

2021-04-15 17:57:42,632 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#345:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#344,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:57:42,632 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#343:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#342,inputs=0..2)
2021-04-15 17:57:42,632 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#341:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#340,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
2021-04-15 17:57:42,632 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#277:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:42,633 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize filter rules cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,633 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,634 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:42,634 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#352:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#351,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:57:42,634 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#350:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#349,inputs=0..2)
2021-04-15 17:57:42,634 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#348:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#347,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
2021-04-15 17:57:42,634 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#277:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:42,636 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize push predicate into table scan cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,637 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,637 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:42,637 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#359:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#358,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:57:42,638 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#357:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#356,inputs=0..2)
2021-04-15 17:57:42,638 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#355:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#354,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
2021-04-15 17:57:42,638 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#277:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:42,638 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize prune empty after predicate push down cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,639 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize predicate_pushdown cost 8 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- LogicalProject(id=[$0], count=[$1], avgTemp=[$2])
   +- LogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:42,647 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,648 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectRemoveRule] rels [#364]
2021-04-15 17:57:42,648 DEBUG org.apache.calcite.plan.RelOptPlanner - call#573: Apply rule [ProjectRemoveRule] to [rel#364:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#363,inputs=0..2)]
2021-04-15 17:57:42,648 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#363 via ProjectRemoveRule
2021-04-15 17:57:42,649 DEBUG org.apache.calcite.plan.RelOptPlanner - call#573 generated 1 successors: [rel#363:RelSubset#14.NONE.any.None: 0.[NONE].[NONE]]
2021-04-15 17:57:42,650 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,650 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)] rels [#277]
2021-04-15 17:57:42,650 DEBUG org.apache.calcite.plan.RelOptPlanner - call#541: Apply rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)] to [rel#277:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])]
2021-04-15 17:57:42,650 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#370 via FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:42,650 DEBUG org.apache.calcite.plan.RelOptPlanner - call#541 generated 1 successors: [rel#370:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:57:42,651 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,651 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [AggregateReduceFunctionsRule] rels [#362]
2021-04-15 17:57:42,651 DEBUG org.apache.calcite.plan.RelOptPlanner - call#560: Apply rule [AggregateReduceFunctionsRule] to [rel#362:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#361,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))]
2021-04-15 17:57:42,655 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#373 via AggregateReduceFunctionsRule
2021-04-15 17:57:42,656 DEBUG org.apache.calcite.plan.RelOptPlanner - call#560 generated 1 successors: [rel#373:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=LogicalAggregate#372,inputs=0..1,exprs=[/($2, $3)])]
2021-04-15 17:57:42,656 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,656 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] rels [#362]
2021-04-15 17:57:42,656 DEBUG org.apache.calcite.plan.RelOptPlanner - call#565: Apply rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] to [rel#362:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#361,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))]
2021-04-15 17:57:42,658 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#376 via FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:42,669 DEBUG org.apache.calcite.plan.RelOptPlanner - call#565 generated 1 successors: [rel#376:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#371,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))]
2021-04-15 17:57:42,670 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,670 DEBUG org.apache.calcite.plan.RelOptPlanner - Skip match: rule [ProjectToCalcRule] rels [#364]
2021-04-15 17:57:42,670 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)] rels [#366]
2021-04-15 17:57:42,670 DEBUG org.apache.calcite.plan.RelOptPlanner - call#598: Apply rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)] to [rel#366:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#363,name=DataStreamTableSink,fields=id, count, avgTemp)]
2021-04-15 17:57:42,670 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#378 via FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:42,719 DEBUG org.apache.calcite.plan.RelOptPlanner - call#598 generated 1 successors: [rel#378:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#377,name=DataStreamTableSink,fields=id, count, avgTemp)]
2021-04-15 17:57:42,719 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,720 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [AggregateReduceFunctionsRule] rels [#372]
2021-04-15 17:57:42,720 DEBUG org.apache.calcite.plan.RelOptPlanner - call#647: Apply rule [AggregateReduceFunctionsRule] to [rel#372:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#361,group={0},EXPR$0=COUNT($0),agg#1=SUM($2),agg#2=COUNT($2))]
2021-04-15 17:57:42,723 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#380 via AggregateReduceFunctionsRule
2021-04-15 17:57:42,724 DEBUG org.apache.calcite.plan.RelOptPlanner - call#647 generated 1 successors: [rel#380:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=LogicalAggregate#379,inputs=0..1,exprs=[CASE(=($3, 0), null:DOUBLE, $2), $3])]
2021-04-15 17:57:42,724 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,724 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] rels [#372]
2021-04-15 17:57:42,724 DEBUG org.apache.calcite.plan.RelOptPlanner - call#652: Apply rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] to [rel#372:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#361,group={0},EXPR$0=COUNT($0),agg#1=SUM($2),agg#2=COUNT($2))]
2021-04-15 17:57:42,724 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#383 via FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:42,725 DEBUG org.apache.calcite.plan.RelOptPlanner - call#652 generated 1 successors: [rel#383:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#371,group={0},EXPR$0=COUNT($0),agg#1=SUM($2),agg#2=COUNT($2))]
2021-04-15 17:57:42,725 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,725 DEBUG org.apache.calcite.plan.RelOptPlanner - Skip match: rule [ProjectMergeRule] rels [#364,#375]
2021-04-15 17:57:42,725 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#375]
2021-04-15 17:57:42,725 DEBUG org.apache.calcite.plan.RelOptPlanner - call#676: Apply rule [ProjectToCalcRule] to [rel#375:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#374,inputs=0..1,exprs=[/($2, $3)])]
2021-04-15 17:57:42,726 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#385 via ProjectToCalcRule
2021-04-15 17:57:42,727 DEBUG org.apache.calcite.plan.RelOptPlanner - call#676 generated 1 successors: [rel#385:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#374,expr#0..3={inputs},expr#4=/($t2, $t3),proj#0..1={exprs},2=$t4)]
2021-04-15 17:57:42,727 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,727 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] rels [#379]
2021-04-15 17:57:42,727 DEBUG org.apache.calcite.plan.RelOptPlanner - call#713: Apply rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] to [rel#379:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#361,group={0},EXPR$0=COUNT($0),agg#1=$SUM0($2),agg#2=COUNT($2))]
2021-04-15 17:57:42,727 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#386 via FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:42,728 DEBUG org.apache.calcite.plan.RelOptPlanner - call#713 generated 1 successors: [rel#386:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#371,group={0},EXPR$0=COUNT($0),agg#1=$SUM0($2),agg#2=COUNT($2))]
2021-04-15 17:57:42,728 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,728 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectMergeRule] rels [#375,#382]
2021-04-15 17:57:42,728 DEBUG org.apache.calcite.plan.RelOptPlanner - call#720: Apply rule [ProjectMergeRule] to [rel#375:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#374,inputs=0..1,exprs=[/($2, $3)]), rel#382:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#381,inputs=0..1,exprs=[CASE(=($3, 0), null:DOUBLE, $2), $3])]
2021-04-15 17:57:42,729 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#388 via ProjectMergeRule
2021-04-15 17:57:42,742 DEBUG org.apache.calcite.plan.RelOptPlanner - call#720 generated 1 successors: [rel#388:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#381,inputs=0..1,exprs=[/(CASE(=($3, 0), null:DOUBLE, $2), $3)])]
2021-04-15 17:57:42,743 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,743 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#382]
2021-04-15 17:57:42,743 DEBUG org.apache.calcite.plan.RelOptPlanner - call#737: Apply rule [ProjectToCalcRule] to [rel#382:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#381,inputs=0..1,exprs=[CASE(=($3, 0), null:DOUBLE, $2), $3])]
2021-04-15 17:57:42,743 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#389 via ProjectToCalcRule
2021-04-15 17:57:42,744 DEBUG org.apache.calcite.plan.RelOptPlanner - call#737 generated 1 successors: [rel#389:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#381,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),proj#0..1={exprs},2=$t7,3=$t3)]
2021-04-15 17:57:42,744 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,744 DEBUG org.apache.calcite.plan.RelOptPlanner - Skip match: rule [ProjectCalcMergeRule] rels [#364,#385]
2021-04-15 17:57:42,744 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#385]
2021-04-15 17:57:42,744 DEBUG org.apache.calcite.plan.RelOptPlanner - call#761: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#385:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#374,expr#0..3={inputs},expr#4=/($t2, $t3),proj#0..1={exprs},2=$t4)]
2021-04-15 17:57:42,745 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#390 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:42,759 DEBUG org.apache.calcite.plan.RelOptPlanner - call#761 generated 1 successors: [rel#390:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#384,select=id, EXPR$0, /($f2, $f3) AS EXPR$1)]
2021-04-15 17:57:42,759 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,759 DEBUG org.apache.calcite.plan.RelOptPlanner - Skip match: rule [ProjectMergeRule] rels [#364,#388]
2021-04-15 17:57:42,759 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#388]
2021-04-15 17:57:42,759 DEBUG org.apache.calcite.plan.RelOptPlanner - call#795: Apply rule [ProjectToCalcRule] to [rel#388:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#381,inputs=0..1,exprs=[/(CASE(=($3, 0), null:DOUBLE, $2), $3)])]
2021-04-15 17:57:42,760 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#391 via ProjectToCalcRule
2021-04-15 17:57:42,761 DEBUG org.apache.calcite.plan.RelOptPlanner - call#795 generated 1 successors: [rel#391:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#381,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),expr#8=/($t7, $t3),proj#0..1={exprs},2=$t8)]
2021-04-15 17:57:42,761 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,761 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectCalcMergeRule] rels [#375,#389]
2021-04-15 17:57:42,761 DEBUG org.apache.calcite.plan.RelOptPlanner - call#805: Apply rule [ProjectCalcMergeRule] to [rel#375:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#374,inputs=0..1,exprs=[/($2, $3)]), rel#389:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#381,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),proj#0..1={exprs},2=$t7,3=$t3)]
2021-04-15 17:57:42,764 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#392 via ProjectCalcMergeRule
2021-04-15 17:57:42,764 DEBUG org.apache.calcite.plan.RelOptPlanner - call#805 generated 1 successors: [rel#392:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#381,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),expr#8=/($t7, $t3),proj#0..1={exprs},2=$t8)]
2021-04-15 17:57:42,764 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,765 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#385,#389]
2021-04-15 17:57:42,765 DEBUG org.apache.calcite.plan.RelOptPlanner - call#808: Apply rule [FlinkCalcMergeRule] to [rel#385:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#374,expr#0..3={inputs},expr#4=/($t2, $t3),proj#0..1={exprs},2=$t4), rel#389:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#381,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),proj#0..1={exprs},2=$t7,3=$t3)]
2021-04-15 17:57:42,766 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#393 via FlinkCalcMergeRule
2021-04-15 17:57:42,767 DEBUG org.apache.calcite.plan.RelOptPlanner - call#808 generated 1 successors: [rel#393:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#381,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),expr#8=/($t7, $t3),proj#0..1={exprs},2=$t8)]
2021-04-15 17:57:42,767 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,767 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#389]
2021-04-15 17:57:42,767 DEBUG org.apache.calcite.plan.RelOptPlanner - call#810: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#389:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#381,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),proj#0..1={exprs},2=$t7,3=$t3)]
2021-04-15 17:57:42,767 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#394 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:42,769 DEBUG org.apache.calcite.plan.RelOptPlanner - call#810 generated 1 successors: [rel#394:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#387,select=id, EXPR$0, CASE(=($f3, 0), null:DOUBLE, $f2) AS $f2, $f3)]
2021-04-15 17:57:42,769 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,769 DEBUG org.apache.calcite.plan.RelOptPlanner - Skip match: rule [ProjectCalcMergeRule] rels [#364,#391]
2021-04-15 17:57:42,769 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#391]
2021-04-15 17:57:42,770 DEBUG org.apache.calcite.plan.RelOptPlanner - call#831: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#391:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#381,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),expr#8=/($t7, $t3),proj#0..1={exprs},2=$t8)]
2021-04-15 17:57:42,770 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#395 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:42,770 DEBUG org.apache.calcite.plan.RelOptPlanner - call#831 generated 1 successors: [rel#395:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#387,select=id, EXPR$0, /(CASE(=($f3, 0), null:DOUBLE, $f2), $f3) AS EXPR$1)]
2021-04-15 17:57:42,771 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,771 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#390,#394]
2021-04-15 17:57:42,771 DEBUG org.apache.calcite.plan.RelOptPlanner - call#840: Apply rule [FlinkCalcMergeRule] to [rel#390:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#384,select=id, EXPR$0, /($f2, $f3) AS EXPR$1), rel#394:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#387,select=id, EXPR$0, CASE(=($f3, 0), null:DOUBLE, $f2) AS $f2, $f3)]
2021-04-15 17:57:42,772 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#396 via FlinkCalcMergeRule
2021-04-15 17:57:42,772 DEBUG org.apache.calcite.plan.RelOptPlanner - call#840 generated 1 successors: [rel#396:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#387,select=id, EXPR$0, /(CASE(=($f3, 0), null:DOUBLE, $f2), $f3) AS EXPR$1)]
2021-04-15 17:57:42,773 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:42,773 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for VolcanoPlanner
2021-04-15 17:57:42,774 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
FlinkCalcMergeRule                                                            16              25,958
FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)                                12              78,377
ProjectToCalcRule                                                              7              12,607
ProjectCalcMergeRule                                                           6              12,658
FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)                   4             137,720
FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)                           3             120,361
FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)                      3              14,933
ProjectFilterTransposeRule                                                     3              11,586
StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)                   2              63,300
StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)                       2              33,550
ProjectMergeRule                                                               2              16,884
FilterToCalcRule                                                               2              11,218
AggregateReduceFunctionsRule                                                   2               9,421
StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)                             1              26,704
PushProjectIntoLegacyTableSourceScanRule                                       1               6,172
FilterCalcMergeRule                                                            1               1,741
ProjectRemoveRule                                                              1               1,462
FilterProjectTransposeRule                                                     1               1,275
* Total                                                                       69             585,927

2021-04-15 17:57:42,790 DEBUG org.apache.calcite.plan.RelOptPlanner - Cheapest plan:
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp]): rowcount = 9516258.19640405, cumulative cost = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}, id = 398
  FlinkLogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)]): rowcount = 9516258.19640405, cumulative cost = {2.0E8 rows, 4.1E8 cpu, 5.6E9 io, 0.0 network, 0.0 memory}, id = 397
    FlinkLogicalLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 370

2021-04-15 17:57:42,791 DEBUG org.apache.calcite.plan.RelOptPlanner - Provenance:
rel#398:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=FlinkLogicalAggregate#397,name=DataStreamTableSink,fields=id, count, avgTemp)
  direct
    rel#378:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#377,name=DataStreamTableSink,fields=id, count, avgTemp)
      call#598 rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)]
        rel#366:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#363,name=DataStreamTableSink,fields=id, count, avgTemp)
          no parent
rel#397:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=FlinkLogicalLegacyTableSourceScan#370,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
  direct
    rel#376:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#371,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
      call#565 rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)]
        rel#362:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#361,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
          no parent
rel#370:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
  call#541 rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)]
    rel#277:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
      no parent

2021-04-15 17:57:42,791 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize logical cost 152 ms.
optimize result: 
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- FlinkLogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
   +- FlinkLogicalLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:57:42,793 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,793 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:42,793 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#402:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#401,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:57:42,793 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#400:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#399,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
2021-04-15 17:57:42,793 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#370:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
2021-04-15 17:57:42,794 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize logical_rewrite cost 2 ms.
optimize result: 
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- FlinkLogicalAggregate(group=[{0}], EXPR$0=[COUNT($0)], EXPR$1=[AVG($2)])
   +- FlinkLogicalLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:57:42,800 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,800 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#370]
2021-04-15 17:57:42,801 DEBUG org.apache.calcite.plan.RelOptPlanner - call#852: Apply rule [StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#370:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:57:42,801 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#411 via StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:57:42,801 DEBUG org.apache.calcite.plan.RelOptPlanner - call#852 generated 1 successors: [rel#411:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:57:42,801 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,801 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#405]
2021-04-15 17:57:42,801 DEBUG org.apache.calcite.plan.RelOptPlanner - call#863: Apply rule [StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#405:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#404,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))]
2021-04-15 17:57:42,875 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#415 via StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:57:42,904 DEBUG org.apache.calcite.plan.RelOptPlanner - call#863 generated 1 successors: [rel#415:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#413,groupBy=id,select=id, COUNT_RETRACT(id) AS EXPR$0, AVG_RETRACT(temp) AS EXPR$1)]
2021-04-15 17:57:42,905 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,905 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#407]
2021-04-15 17:57:42,905 DEBUG org.apache.calcite.plan.RelOptPlanner - call#879: Apply rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#407:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#406,name=DataStreamTableSink,fields=id, count, avgTemp)]
2021-04-15 17:57:42,905 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#417 via StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:57:42,905 DEBUG org.apache.calcite.plan.RelOptPlanner - call#879 generated 1 successors: [rel#417:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#416,name=DataStreamTableSink,fields=id, count, avgTemp)]
2021-04-15 17:57:42,905 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:42,905 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkExpandConversionRule] rels [#414,#411]
2021-04-15 17:57:42,906 DEBUG org.apache.calcite.plan.RelOptPlanner - call#886: Apply rule [FlinkExpandConversionRule] to [rel#414:AbstractConverter.STREAM_PHYSICAL.hash[0]true.None: 0.[NONE].[NONE](input=RelSubset#412,convention=STREAM_PHYSICAL,FlinkRelDistributionTraitDef=hash[0]true,MiniBatchIntervalTraitDef=None: 0,ModifyKindSetTraitDef=[NONE],UpdateKindTraitDef=[NONE]), rel#411:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:57:42,907 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#418 via FlinkExpandConversionRule
2021-04-15 17:57:42,925 DEBUG org.apache.calcite.plan.RelOptPlanner - call#886 generated 1 successors: [rel#418:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[NONE].[NONE](input=StreamExecLegacyTableSourceScan#411,distribution=hash[id])]
2021-04-15 17:57:42,925 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {4.0E8 rows, 1.71E10 cpu, 2.8E9 io, 2.8E9 network, 0.0 memory}
2021-04-15 17:57:42,925 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for VolcanoPlanner
2021-04-15 17:57:42,926 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
FlinkCalcMergeRule                                                            16              25,958
FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)                                12              78,377
ProjectToCalcRule                                                              7              12,607
ProjectCalcMergeRule                                                           6              12,658
FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)                   4             137,720
FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)                           3             120,361
StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)                   3              64,023
StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)                       3              34,118
FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)                      3              14,933
ProjectFilterTransposeRule                                                     3              11,586
ProjectMergeRule                                                               2              16,884
FilterToCalcRule                                                               2              11,218
AggregateReduceFunctionsRule                                                   2               9,421
StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)                   1             103,110
StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)                             1              26,704
FlinkExpandConversionRule                                                      1              19,760
PushProjectIntoLegacyTableSourceScanRule                                       1               6,172
FilterCalcMergeRule                                                            1               1,741
ProjectRemoveRule                                                              1               1,462
FilterProjectTransposeRule                                                     1               1,275
* Total                                                                       73             710,088

2021-04-15 17:57:42,958 DEBUG org.apache.calcite.plan.RelOptPlanner - Cheapest plan:
StreamExecLegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp]): rowcount = 1.0E8, cumulative cost = {4.0E8 rows, 1.71E10 cpu, 2.8E9 io, 2.8E9 network, 0.0 memory}, id = 422
  StreamExecGroupAggregate(groupBy=[id], select=[id, COUNT_RETRACT(id) AS EXPR$0, AVG_RETRACT(temp) AS EXPR$1]): rowcount = 1.0E8, cumulative cost = {3.0E8 rows, 1.7E10 cpu, 2.8E9 io, 2.8E9 network, 0.0 memory}, id = 421
    StreamExecExchange(distribution=[hash[id]]): rowcount = 1.0E8, cumulative cost = {2.0E8 rows, 1.69E10 cpu, 2.8E9 io, 2.8E9 network, 0.0 memory}, id = 420
      StreamExecLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 411

2021-04-15 17:57:42,960 DEBUG org.apache.calcite.plan.RelOptPlanner - Provenance:
rel#422:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=StreamExecGroupAggregate#421,name=DataStreamTableSink,fields=id, count, avgTemp)
  direct
    rel#417:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#416,name=DataStreamTableSink,fields=id, count, avgTemp)
      call#879 rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#407:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#406,name=DataStreamTableSink,fields=id, count, avgTemp)
          no parent
rel#421:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=StreamExecExchange#420,groupBy=id,select=id, COUNT_RETRACT(id) AS EXPR$0, AVG_RETRACT(temp) AS EXPR$1)
  direct
    rel#415:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#413,groupBy=id,select=id, COUNT_RETRACT(id) AS EXPR$0, AVG_RETRACT(temp) AS EXPR$1)
      call#863 rule [StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#405:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#404,group={0},EXPR$0=COUNT($0),EXPR$1=AVG($2))
          no parent
rel#420:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[NONE].[NONE](input=StreamExecLegacyTableSourceScan#411,distribution=hash[id])
  direct
    rel#419:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[NONE].[NONE](input=RelSubset#412,distribution=hash[id])
      call#886 rule [FlinkExpandConversionRule]
        rel#414:AbstractConverter.STREAM_PHYSICAL.hash[0]true.None: 0.[NONE].[NONE](input=RelSubset#412,convention=STREAM_PHYSICAL,FlinkRelDistributionTraitDef=hash[0]true,MiniBatchIntervalTraitDef=None: 0,ModifyKindSetTraitDef=[NONE],UpdateKindTraitDef=[NONE])
          call#863 rule [StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)]
            rel#405 (see above)
        rel#411:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
          call#852 rule [StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)]
            rel#370:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
              no parent
rel#411 (see above)

2021-04-15 17:57:42,962 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize physical cost 166 ms.
optimize result: 
LegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT_RETRACT(id) AS EXPR$0, AVG_RETRACT(temp) AS EXPR$1])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:57:42,962 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:57:42,963 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,963 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:42,963 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#428:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#427,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:57:42,964 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#426:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#425,groupBy=id,select=id, COUNT_RETRACT(id) AS EXPR$0, AVG_RETRACT(temp) AS EXPR$1)
2021-04-15 17:57:42,964 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#424:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[NONE].[NONE](input=HepRelVertex#423,distribution=hash[id])
2021-04-15 17:57:42,964 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#411:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
2021-04-15 17:57:42,965 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize watermark transpose cost 2 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT_RETRACT(id) AS EXPR$0, AVG_RETRACT(temp) AS EXPR$1])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:57:42,968 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize Changelog mode inference cost 2 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:57:42,969 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize Initialization for mini-batch interval inference cost 0 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:57:42,972 DEBUG org.apache.calcite.plan.RelOptPlanner - call#891: Apply rule [MiniBatchIntervalInferRule] to [rel#444:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#443,name=DataStreamTableSink,fields=id, count, avgTemp)]
2021-04-15 17:57:42,973 DEBUG org.apache.calcite.plan.RelOptPlanner - call#892: Apply rule [MiniBatchIntervalInferRule] to [rel#442:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[I,U].[BEFORE_AND_AFTER](input=HepRelVertex#441,groupBy=id,select=id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1)]
2021-04-15 17:57:42,973 DEBUG org.apache.calcite.plan.RelOptPlanner - call#893: Apply rule [MiniBatchIntervalInferRule] to [rel#440:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[I].[NONE](input=HepRelVertex#439,distribution=hash[id])]
2021-04-15 17:57:42,973 DEBUG org.apache.calcite.plan.RelOptPlanner - call#894: Apply rule [MiniBatchIntervalInferRule] to [rel#434:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:57:42,973 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,973 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
MiniBatchIntervalInferRule                                                     4                 229
* Total                                                                        4                 229

2021-04-15 17:57:42,973 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#444:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#443,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:57:42,974 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#442:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[I,U].[BEFORE_AND_AFTER](input=HepRelVertex#441,groupBy=id,select=id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1)
2021-04-15 17:57:42,975 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#440:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[I].[NONE](input=HepRelVertex#439,distribution=hash[id])
2021-04-15 17:57:42,975 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#434:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
2021-04-15 17:57:42,976 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize mini-batch interval rules cost 6 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:57:42,978 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:42,978 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:42,978 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#451:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#450,name=DataStreamTableSink,fields=id, count, avgTemp)
2021-04-15 17:57:42,978 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#449:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[I,U].[BEFORE_AND_AFTER](input=HepRelVertex#448,groupBy=id,select=id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1)
2021-04-15 17:57:42,978 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#447:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[I].[NONE](input=HepRelVertex#446,distribution=hash[id])
2021-04-15 17:57:42,978 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#434:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)
2021-04-15 17:57:42,979 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize physical rewrite cost 2 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:57:42,980 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize physical_rewrite cost 17 ms.
optimize result: 
LegacySink(name=[DataStreamTableSink], fields=[id, count, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:57:42,985 INFO org.apache.flink.api.java.typeutils.TypeExtractor - class org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit does not contain a setter for field modificationTime
2021-04-15 17:57:42,985 INFO org.apache.flink.api.java.typeutils.TypeExtractor - Class class org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2021-04-15 17:57:42,985 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:57:42,985 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:57:42,985 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:57:42,985 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:57:42,985 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:57:42,985 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.java.io.RowCsvInputFormat
2021-04-15 17:57:42,985 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:57:42,986 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [Lorg.apache.flink.api.common.typeinfo.TypeInformation;
2021-04-15 17:57:42,986 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [I
2021-04-15 17:57:42,986 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:57:42,986 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Long
2021-04-15 17:57:42,986 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.streaming.api.functions.source.FileProcessingMode
2021-04-15 17:57:42,986 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Long
2021-04-15 17:57:42,986 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:57:42,994 DEBUG o.a.flink.table.planner.codegen.OperatorCodeGenerator$ - Compiling OneInputStreamOperator Code:
SourceConversion
2021-04-15 17:57:43,042 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'isnull' from 'core' module.
2021-04-15 17:57:43,043 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'plus' from 'core' module.
2021-04-15 17:57:43,047 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'ifthenelse' from 'core' module.
2021-04-15 17:57:43,057 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'isnull' from 'core' module.
2021-04-15 17:57:43,058 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'plus' from 'core' module.
2021-04-15 17:57:43,059 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'ifthenelse' from 'core' module.
2021-04-15 17:57:43,060 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'isnull' from 'core' module.
2021-04-15 17:57:43,060 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'plus' from 'core' module.
2021-04-15 17:57:43,061 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'ifthenelse' from 'core' module.
2021-04-15 17:57:43,066 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'equals' from 'core' module.
2021-04-15 17:57:43,068 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'divide' from 'core' module.
2021-04-15 17:57:43,068 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'cast' from 'core' module.
2021-04-15 17:57:43,069 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'ifthenelse' from 'core' module.
2021-04-15 17:57:43,087 DEBUG o.a.flink.table.planner.codegen.OperatorCodeGenerator$ - Compiling OneInputStreamOperator Code:
SinkConversion
2021-04-15 17:57:43,088 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
2021-04-15 17:57:43,088 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:57:43,088 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:57:43,088 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:57:43,088 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:57:43,088 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:57:43,089 INFO org.apache.flink.api.java.typeutils.TypeExtractor - class org.apache.flink.types.Row is missing a default constructor so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2021-04-15 17:57:43,091 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:57:43,091 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:43,092 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:43,092 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#459:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#458,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:57:43,092 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#457:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#456,group={0},cnt=COUNT($0),avgTemp=AVG($1))
2021-04-15 17:57:43,092 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#455:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#454,inputs=0,exprs=[$2])
2021-04-15 17:57:43,092 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#72:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:43,093 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert table references before rewriting sub-queries to semi-join cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:43,093 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:43,094 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:43,094 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#466:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#465,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:57:43,094 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#464:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#463,group={0},cnt=COUNT($0),avgTemp=AVG($1))
2021-04-15 17:57:43,094 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#462:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#461,inputs=0,exprs=[$2])
2021-04-15 17:57:43,094 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#72:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:43,095 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize rewrite sub-queries to semi-join cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:43,096 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:43,096 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:43,096 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#473:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#472,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:57:43,096 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#471:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#470,group={0},cnt=COUNT($0),avgTemp=AVG($1))
2021-04-15 17:57:43,096 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#469:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#468,inputs=0,exprs=[$2])
2021-04-15 17:57:43,096 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#72:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:43,099 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize sub-queries remove cost 4 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:43,100 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:43,100 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:43,100 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#480:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#479,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:57:43,100 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#478:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#477,group={0},cnt=COUNT($0),avgTemp=AVG($1))
2021-04-15 17:57:43,100 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#476:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#475,inputs=0,exprs=[$2])
2021-04-15 17:57:43,101 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#72:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:43,101 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert table references after sub-queries removed cost 2 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:43,102 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize subquery_rewrite cost 10 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:43,102 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:57:43,102 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:43,102 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:43,102 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#487:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#486,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:57:43,103 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#485:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#484,group={0},cnt=COUNT($0),avgTemp=AVG($1))
2021-04-15 17:57:43,103 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#483:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#482,inputs=0,exprs=[$2])
2021-04-15 17:57:43,103 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#72:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:43,103 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert correlate to temporal table join cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:43,104 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:43,104 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:43,104 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#494:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#493,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:57:43,104 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#492:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#491,group={0},cnt=COUNT($0),avgTemp=AVG($1))
2021-04-15 17:57:43,104 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#490:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#489,inputs=0,exprs=[$2])
2021-04-15 17:57:43,104 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#72:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:43,105 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize convert enumerable table scan cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:43,105 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize temporal_join_rewrite cost 3 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:43,105 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:57:43,105 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:43,106 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:43,106 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#501:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#500,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:57:43,106 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#499:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#498,group={0},cnt=COUNT($0),avgTemp=AVG($1))
2021-04-15 17:57:43,106 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#497:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#496,inputs=0,exprs=[$2])
2021-04-15 17:57:43,106 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#72:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:43,106 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize pre-rewrite before decorrelation cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:43,107 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize  cost 0 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:43,107 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize decorrelate cost 2 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:43,109 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize time_indicator cost 1 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:43,109 DEBUG org.apache.calcite.plan.RelOptPlanner - call#897: Apply rule [ReduceExpressionsRule(Project)] to [rel#507:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#506,inputs=0,exprs=[$2])]
2021-04-15 17:57:43,109 DEBUG org.apache.calcite.plan.RelOptPlanner - call#898: Apply rule [AggregateProjectPullUpConstantsRule] to [rel#509:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#508,group={0},cnt=COUNT($0),avgTemp=AVG($1)), rel#507:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#506,inputs=0,exprs=[$2])]
2021-04-15 17:57:43,111 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:43,111 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
ReduceExpressionsRule(Project)                                                 1                  52
AggregateProjectPullUpConstantsRule                                            1                  25
* Total                                                                        2                  77

2021-04-15 17:57:43,111 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#511:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#510,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:57:43,112 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#509:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#508,group={0},cnt=COUNT($0),avgTemp=AVG($1))
2021-04-15 17:57:43,112 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#507:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#506,inputs=0,exprs=[$2])
2021-04-15 17:57:43,112 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#72:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:43,112 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize default_rewrite cost 3 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:43,112 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:57:43,112 DEBUG org.apache.calcite.plan.RelOptPlanner - call#900: Apply rule [ReduceExpressionsRule(Project)] to [rel#514:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#513,inputs=0,exprs=[$2])]
2021-04-15 17:57:43,113 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:43,113 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
ReduceExpressionsRule(Project)                                                 1                  51
* Total                                                                        1                  51

2021-04-15 17:57:43,113 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#518:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#517,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:57:43,113 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#516:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#515,group={0},cnt=COUNT($0),avgTemp=AVG($1))
2021-04-15 17:57:43,113 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#514:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#513,inputs=0,exprs=[$2])
2021-04-15 17:57:43,113 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#72:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:43,113 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize filter rules cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:43,115 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:43,115 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:43,115 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#525:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#524,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:57:43,115 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#523:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#522,group={0},cnt=COUNT($0),avgTemp=AVG($1))
2021-04-15 17:57:43,115 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#521:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#520,inputs=0,exprs=[$2])
2021-04-15 17:57:43,115 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#72:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:43,116 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize push predicate into table scan cost 3 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:43,116 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:43,117 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:43,117 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#532:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#531,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:57:43,117 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#530:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#529,group={0},cnt=COUNT($0),avgTemp=AVG($1))
2021-04-15 17:57:43,117 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#528:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#527,inputs=0,exprs=[$2])
2021-04-15 17:57:43,117 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#72:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
2021-04-15 17:57:43,117 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize prune empty after predicate push down cost 1 ms.
optimize result:
 LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:43,118 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize predicate_pushdown cost 5 ms.
optimize result: 
LogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- LogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- LogicalProject(id=[$0], temp=[$2])
      +- LogicalTableScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]]])

2021-04-15 17:57:43,120 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:43,121 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)] rels [#72]
2021-04-15 17:57:43,121 DEBUG org.apache.calcite.plan.RelOptPlanner - call#912: Apply rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)] to [rel#72:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])]
2021-04-15 17:57:43,121 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#543 via FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:43,121 DEBUG org.apache.calcite.plan.RelOptPlanner - call#912 generated 1 successors: [rel#543:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:57:43,121 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:43,122 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [PushProjectIntoLegacyTableSourceScanRule] rels [#535,#72]
2021-04-15 17:57:43,122 DEBUG org.apache.calcite.plan.RelOptPlanner - call#928: Apply rule [PushProjectIntoLegacyTableSourceScanRule] to [rel#535:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#534,inputs=0,exprs=[$2]), rel#72:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])]
2021-04-15 17:57:43,122 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#545 via PushProjectIntoLegacyTableSourceScanRule
2021-04-15 17:57:43,122 DEBUG org.apache.calcite.plan.RelOptPlanner - call#928 generated 1 successors: [rel#545:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]])]
2021-04-15 17:57:43,123 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:43,123 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#535]
2021-04-15 17:57:43,123 DEBUG org.apache.calcite.plan.RelOptPlanner - call#938: Apply rule [ProjectToCalcRule] to [rel#535:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#534,inputs=0,exprs=[$2])]
2021-04-15 17:57:43,123 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#547 via ProjectToCalcRule
2021-04-15 17:57:43,123 DEBUG org.apache.calcite.plan.RelOptPlanner - call#938 generated 1 successors: [rel#547:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#534,expr#0..2={inputs},0=$t0,1=$t2)]
2021-04-15 17:57:43,123 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:43,123 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [AggregateProjectPullUpConstantsRule] rels [#537,#535]
2021-04-15 17:57:43,123 DEBUG org.apache.calcite.plan.RelOptPlanner - call#942: Apply rule [AggregateProjectPullUpConstantsRule] to [rel#537:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#536,group={0},cnt=COUNT($0),avgTemp=AVG($1)), rel#535:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#534,inputs=0,exprs=[$2])]
2021-04-15 17:57:43,123 DEBUG org.apache.calcite.plan.RelOptPlanner - call#942 generated 0 successors.
2021-04-15 17:57:43,123 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:43,124 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [AggregateProjectMergeRule] rels [#537,#535]
2021-04-15 17:57:43,124 DEBUG org.apache.calcite.plan.RelOptPlanner - call#947: Apply rule [AggregateProjectMergeRule] to [rel#537:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#536,group={0},cnt=COUNT($0),avgTemp=AVG($1)), rel#535:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#534,inputs=0,exprs=[$2])]
2021-04-15 17:57:43,126 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#548 via AggregateProjectMergeRule
2021-04-15 17:57:43,126 DEBUG org.apache.calcite.plan.RelOptPlanner - call#947 generated 1 successors: [rel#548:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#534,group={0},cnt=COUNT($0),avgTemp=AVG($2))]
2021-04-15 17:57:43,126 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:43,126 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [AggregateReduceFunctionsRule] rels [#537]
2021-04-15 17:57:43,127 DEBUG org.apache.calcite.plan.RelOptPlanner - call#958: Apply rule [AggregateReduceFunctionsRule] to [rel#537:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#536,group={0},cnt=COUNT($0),avgTemp=AVG($1))]
2021-04-15 17:57:43,127 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#550 via AggregateReduceFunctionsRule
2021-04-15 17:57:43,128 DEBUG org.apache.calcite.plan.RelOptPlanner - call#958 generated 1 successors: [rel#550:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=LogicalAggregate#549,inputs=0..1,exprs=[/($2, $3)])]
2021-04-15 17:57:43,128 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:43,128 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] rels [#537]
2021-04-15 17:57:43,128 DEBUG org.apache.calcite.plan.RelOptPlanner - call#963: Apply rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] to [rel#537:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#536,group={0},cnt=COUNT($0),avgTemp=AVG($1))]
2021-04-15 17:57:43,129 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#554 via FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:43,130 DEBUG org.apache.calcite.plan.RelOptPlanner - call#963 generated 1 successors: [rel#554:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#553,group={0},cnt=COUNT($0),avgTemp=AVG($1))]
2021-04-15 17:57:43,130 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:43,131 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)] rels [#539]
2021-04-15 17:57:43,131 DEBUG org.apache.calcite.plan.RelOptPlanner - call#970: Apply rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)] to [rel#539:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#538,name=DataStreamTableSink,fields=id, cnt, avgTemp)]
2021-04-15 17:57:43,131 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#556 via FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:43,132 DEBUG org.apache.calcite.plan.RelOptPlanner - call#970 generated 1 successors: [rel#556:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#555,name=DataStreamTableSink,fields=id, cnt, avgTemp)]
2021-04-15 17:57:43,132 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:43,132 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)] rels [#545]
2021-04-15 17:57:43,133 DEBUG org.apache.calcite.plan.RelOptPlanner - call#992: Apply rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)] to [rel#545:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]])]
2021-04-15 17:57:43,133 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#558 via FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:43,134 DEBUG org.apache.calcite.plan.RelOptPlanner - call#992 generated 1 successors: [rel#558:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:57:43,134 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,134 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#547]
2021-04-15 17:57:43,134 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1006: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#547:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#534,expr#0..2={inputs},0=$t0,1=$t2)]
2021-04-15 17:57:43,134 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#559 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:43,135 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1006 generated 1 successors: [rel#559:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#544,select=id, temp)]
2021-04-15 17:57:43,135 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,136 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [AggregateReduceFunctionsRule] rels [#548]
2021-04-15 17:57:43,136 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1023: Apply rule [AggregateReduceFunctionsRule] to [rel#548:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#534,group={0},cnt=COUNT($0),avgTemp=AVG($2))]
2021-04-15 17:57:43,136 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#561 via AggregateReduceFunctionsRule
2021-04-15 17:57:43,137 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1023 generated 1 successors: [rel#561:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=LogicalAggregate#560,inputs=0..1,exprs=[/($2, $3)])]
2021-04-15 17:57:43,137 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,138 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] rels [#548]
2021-04-15 17:57:43,138 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1028: Apply rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] to [rel#548:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#534,group={0},cnt=COUNT($0),avgTemp=AVG($2))]
2021-04-15 17:57:43,138 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#564 via FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:43,138 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1028 generated 1 successors: [rel#564:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#544,group={0},cnt=COUNT($0),avgTemp=AVG($2))]
2021-04-15 17:57:43,138 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,138 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [AggregateProjectPullUpConstantsRule] rels [#549,#535]
2021-04-15 17:57:43,138 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1031: Apply rule [AggregateProjectPullUpConstantsRule] to [rel#549:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#536,group={0},cnt=COUNT($0),agg#1=SUM($1),agg#2=COUNT($1)), rel#535:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#534,inputs=0,exprs=[$2])]
2021-04-15 17:57:43,138 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1031 generated 0 successors.
2021-04-15 17:57:43,138 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,138 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [AggregateProjectMergeRule] rels [#549,#535]
2021-04-15 17:57:43,139 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1036: Apply rule [AggregateProjectMergeRule] to [rel#549:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#536,group={0},cnt=COUNT($0),agg#1=SUM($1),agg#2=COUNT($1)), rel#535:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#534,inputs=0,exprs=[$2])]
2021-04-15 17:57:43,139 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#565 via AggregateProjectMergeRule
2021-04-15 17:57:43,140 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1036 generated 1 successors: [rel#565:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#534,group={0},cnt=COUNT($0),agg#1=SUM($2),agg#2=COUNT($2))]
2021-04-15 17:57:43,140 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,140 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [AggregateReduceFunctionsRule] rels [#549]
2021-04-15 17:57:43,140 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1047: Apply rule [AggregateReduceFunctionsRule] to [rel#549:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#536,group={0},cnt=COUNT($0),agg#1=SUM($1),agg#2=COUNT($1))]
2021-04-15 17:57:43,141 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#567 via AggregateReduceFunctionsRule
2021-04-15 17:57:43,142 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1047 generated 1 successors: [rel#567:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=LogicalAggregate#566,inputs=0..1,exprs=[CASE(=($3, 0), null:DOUBLE, $2), $3])]
2021-04-15 17:57:43,143 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,143 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] rels [#549]
2021-04-15 17:57:43,143 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1052: Apply rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] to [rel#549:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#536,group={0},cnt=COUNT($0),agg#1=SUM($1),agg#2=COUNT($1))]
2021-04-15 17:57:43,143 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#570 via FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:43,143 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1052 generated 1 successors: [rel#570:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#553,group={0},cnt=COUNT($0),agg#1=SUM($1),agg#2=COUNT($1))]
2021-04-15 17:57:43,143 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,144 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#552]
2021-04-15 17:57:43,144 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1075: Apply rule [ProjectToCalcRule] to [rel#552:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#551,inputs=0..1,exprs=[/($2, $3)])]
2021-04-15 17:57:43,144 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#572 via ProjectToCalcRule
2021-04-15 17:57:43,144 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1075 generated 1 successors: [rel#572:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#551,expr#0..3={inputs},expr#4=/($t2, $t3),proj#0..1={exprs},2=$t4)]
2021-04-15 17:57:43,144 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,145 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [AggregateReduceFunctionsRule] rels [#560]
2021-04-15 17:57:43,145 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1121: Apply rule [AggregateReduceFunctionsRule] to [rel#560:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#534,group={0},cnt=COUNT($0),agg#1=SUM($2),agg#2=COUNT($2))]
2021-04-15 17:57:43,146 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#574 via AggregateReduceFunctionsRule
2021-04-15 17:57:43,147 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1121 generated 1 successors: [rel#574:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=LogicalAggregate#573,inputs=0..1,exprs=[CASE(=($3, 0), null:DOUBLE, $2), $3])]
2021-04-15 17:57:43,147 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,147 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] rels [#560]
2021-04-15 17:57:43,147 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1126: Apply rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] to [rel#560:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#534,group={0},cnt=COUNT($0),agg#1=SUM($2),agg#2=COUNT($2))]
2021-04-15 17:57:43,148 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#577 via FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:43,148 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1126 generated 1 successors: [rel#577:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#544,group={0},cnt=COUNT($0),agg#1=SUM($2),agg#2=COUNT($2))]
2021-04-15 17:57:43,148 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,148 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#563]
2021-04-15 17:57:43,148 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1149: Apply rule [ProjectToCalcRule] to [rel#563:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#551,inputs=0..1,exprs=[/($2, $3)])]
2021-04-15 17:57:43,148 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#578 via ProjectToCalcRule
2021-04-15 17:57:43,149 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1149 generated 1 successors: [rel#578:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#551,expr#0..3={inputs},expr#4=/($t2, $t3),proj#0..1={exprs},2=$t4)]
2021-04-15 17:57:43,149 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,149 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [AggregateProjectPullUpConstantsRule] rels [#566,#535]
2021-04-15 17:57:43,149 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1209: Apply rule [AggregateProjectPullUpConstantsRule] to [rel#566:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#536,group={0},cnt=COUNT($0),agg#1=$SUM0($1),agg#2=COUNT($1)), rel#535:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#534,inputs=0,exprs=[$2])]
2021-04-15 17:57:43,149 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1209 generated 0 successors.
2021-04-15 17:57:43,149 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,149 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [AggregateProjectMergeRule] rels [#566,#535]
2021-04-15 17:57:43,149 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1214: Apply rule [AggregateProjectMergeRule] to [rel#566:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#536,group={0},cnt=COUNT($0),agg#1=$SUM0($1),agg#2=COUNT($1)), rel#535:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#534,inputs=0,exprs=[$2])]
2021-04-15 17:57:43,149 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#579 via AggregateProjectMergeRule
2021-04-15 17:57:43,150 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1214 generated 1 successors: [rel#579:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#534,group={0},cnt=COUNT($0),agg#1=$SUM0($2),agg#2=COUNT($2))]
2021-04-15 17:57:43,151 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,151 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] rels [#566]
2021-04-15 17:57:43,151 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1229: Apply rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] to [rel#566:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#536,group={0},cnt=COUNT($0),agg#1=$SUM0($1),agg#2=COUNT($1))]
2021-04-15 17:57:43,151 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#580 via FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:43,151 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1229 generated 1 successors: [rel#580:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#553,group={0},cnt=COUNT($0),agg#1=$SUM0($1),agg#2=COUNT($1))]
2021-04-15 17:57:43,151 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,152 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectMergeRule] rels [#552,#569]
2021-04-15 17:57:43,152 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1236: Apply rule [ProjectMergeRule] to [rel#552:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#551,inputs=0..1,exprs=[/($2, $3)]), rel#569:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#568,inputs=0..1,exprs=[CASE(=($3, 0), null:DOUBLE, $2), $3])]
2021-04-15 17:57:43,152 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#582 via ProjectMergeRule
2021-04-15 17:57:43,153 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1236 generated 1 successors: [rel#582:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#568,inputs=0..1,exprs=[/(CASE(=($3, 0), null:DOUBLE, $2), $3)])]
2021-04-15 17:57:43,153 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,153 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#569]
2021-04-15 17:57:43,153 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1253: Apply rule [ProjectToCalcRule] to [rel#569:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#568,inputs=0..1,exprs=[CASE(=($3, 0), null:DOUBLE, $2), $3])]
2021-04-15 17:57:43,153 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#583 via ProjectToCalcRule
2021-04-15 17:57:43,154 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1253 generated 1 successors: [rel#583:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#568,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),proj#0..1={exprs},2=$t7,3=$t3)]
2021-04-15 17:57:43,154 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,154 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#572]
2021-04-15 17:57:43,154 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1276: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#572:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#551,expr#0..3={inputs},expr#4=/($t2, $t3),proj#0..1={exprs},2=$t4)]
2021-04-15 17:57:43,155 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#584 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:43,155 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1276 generated 1 successors: [rel#584:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#571,select=id, cnt, /($f2, $f3) AS avgTemp)]
2021-04-15 17:57:43,155 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,156 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] rels [#573]
2021-04-15 17:57:43,156 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1297: Apply rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] to [rel#573:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#534,group={0},cnt=COUNT($0),agg#1=$SUM0($2),agg#2=COUNT($2))]
2021-04-15 17:57:43,156 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#585 via FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:43,156 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1297 generated 1 successors: [rel#585:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#544,group={0},cnt=COUNT($0),agg#1=$SUM0($2),agg#2=COUNT($2))]
2021-04-15 17:57:43,156 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,156 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectMergeRule] rels [#552,#576]
2021-04-15 17:57:43,156 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1304: Apply rule [ProjectMergeRule] to [rel#552:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#551,inputs=0..1,exprs=[/($2, $3)]), rel#576:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#568,inputs=0..1,exprs=[CASE(=($3, 0), null:DOUBLE, $2), $3])]
2021-04-15 17:57:43,157 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#586 via ProjectMergeRule
2021-04-15 17:57:43,157 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1304 generated 1 successors: [rel#586:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#568,inputs=0..1,exprs=[/(CASE(=($3, 0), null:DOUBLE, $2), $3)])]
2021-04-15 17:57:43,157 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,157 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#576]
2021-04-15 17:57:43,157 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1321: Apply rule [ProjectToCalcRule] to [rel#576:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#568,inputs=0..1,exprs=[CASE(=($3, 0), null:DOUBLE, $2), $3])]
2021-04-15 17:57:43,157 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#587 via ProjectToCalcRule
2021-04-15 17:57:43,158 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1321 generated 1 successors: [rel#587:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#568,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),proj#0..1={exprs},2=$t7,3=$t3)]
2021-04-15 17:57:43,158 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,158 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectToCalcRule] rels [#582]
2021-04-15 17:57:43,158 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1409: Apply rule [ProjectToCalcRule] to [rel#582:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#568,inputs=0..1,exprs=[/(CASE(=($3, 0), null:DOUBLE, $2), $3)])]
2021-04-15 17:57:43,158 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#588 via ProjectToCalcRule
2021-04-15 17:57:43,158 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1409 generated 1 successors: [rel#588:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#568,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),expr#8=/($t7, $t3),proj#0..1={exprs},2=$t8)]
2021-04-15 17:57:43,159 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,159 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [ProjectCalcMergeRule] rels [#552,#583]
2021-04-15 17:57:43,159 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1419: Apply rule [ProjectCalcMergeRule] to [rel#552:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#551,inputs=0..1,exprs=[/($2, $3)]), rel#583:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#568,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),proj#0..1={exprs},2=$t7,3=$t3)]
2021-04-15 17:57:43,160 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#589 via ProjectCalcMergeRule
2021-04-15 17:57:43,160 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1419 generated 1 successors: [rel#589:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#568,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),expr#8=/($t7, $t3),proj#0..1={exprs},2=$t8)]
2021-04-15 17:57:43,160 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,160 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#572,#583]
2021-04-15 17:57:43,160 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1422: Apply rule [FlinkCalcMergeRule] to [rel#572:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#551,expr#0..3={inputs},expr#4=/($t2, $t3),proj#0..1={exprs},2=$t4), rel#583:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#568,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),proj#0..1={exprs},2=$t7,3=$t3)]
2021-04-15 17:57:43,162 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#590 via FlinkCalcMergeRule
2021-04-15 17:57:43,163 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1422 generated 1 successors: [rel#590:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#568,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),expr#8=/($t7, $t3),proj#0..1={exprs},2=$t8)]
2021-04-15 17:57:43,163 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,163 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#583]
2021-04-15 17:57:43,163 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1424: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#583:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#568,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),proj#0..1={exprs},2=$t7,3=$t3)]
2021-04-15 17:57:43,163 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#591 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:43,164 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1424 generated 1 successors: [rel#591:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#581,select=id, cnt, CASE(=($f3, 0), null:DOUBLE, $f2) AS $f2, $f3)]
2021-04-15 17:57:43,164 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,165 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#588]
2021-04-15 17:57:43,165 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1454: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#588:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#568,expr#0..3={inputs},expr#4=0,expr#5==($t3, $t4),expr#6=null:DOUBLE,expr#7=CASE($t5, $t6, $t2),expr#8=/($t7, $t3),proj#0..1={exprs},2=$t8)]
2021-04-15 17:57:43,165 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#592 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-04-15 17:57:43,165 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1454 generated 1 successors: [rel#592:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#581,select=id, cnt, /(CASE(=($f3, 0), null:DOUBLE, $f2), $f3) AS avgTemp)]
2021-04-15 17:57:43,166 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,166 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkCalcMergeRule] rels [#584,#591]
2021-04-15 17:57:43,166 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1463: Apply rule [FlinkCalcMergeRule] to [rel#584:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#571,select=id, cnt, /($f2, $f3) AS avgTemp), rel#591:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#581,select=id, cnt, CASE(=($f3, 0), null:DOUBLE, $f2) AS $f2, $f3)]
2021-04-15 17:57:43,167 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#593 via FlinkCalcMergeRule
2021-04-15 17:57:43,167 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1463 generated 1 successors: [rel#593:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#581,select=id, cnt, /(CASE(=($f3, 0), null:DOUBLE, $f2), $f3) AS avgTemp)]
2021-04-15 17:57:43,167 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}
2021-04-15 17:57:43,168 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for VolcanoPlanner
2021-04-15 17:57:43,168 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
FlinkCalcMergeRule                                                            18              29,547
FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)                                16              83,080
ProjectToCalcRule                                                             13              16,915
FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)                      9              19,350
ProjectCalcMergeRule                                                           7              13,764
FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)                   6             139,537
AggregateReduceFunctionsRule                                                   6              17,531
FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)                           4             122,210
ProjectMergeRule                                                               4              18,472
StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)                   3              64,023
StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)                       3              34,118
ProjectFilterTransposeRule                                                     3              11,586
AggregateProjectMergeRule                                                      3               5,489
AggregateProjectPullUpConstantsRule                                            3                  64
FilterToCalcRule                                                               2              11,218
PushProjectIntoLegacyTableSourceScanRule                                       2               7,082
StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)                   1             103,110
StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)                             1              26,704
FlinkExpandConversionRule                                                      1              19,760
FilterCalcMergeRule                                                            1               1,741
ProjectRemoveRule                                                              1               1,462
FilterProjectTransposeRule                                                     1               1,275
* Total                                                                      108             748,038

2021-04-15 17:57:43,169 DEBUG org.apache.calcite.plan.RelOptPlanner - Cheapest plan:
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp]): rowcount = 9516258.19640405, cumulative cost = {2.0951625819640404E8 rows, 4.1951625819640404E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}, id = 595
  FlinkLogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)]): rowcount = 9516258.19640405, cumulative cost = {2.0E8 rows, 4.1E8 cpu, 4.0E9 io, 0.0 network, 0.0 memory}, id = 594
    FlinkLogicalLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, timestamp, temp]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}, id = 558

2021-04-15 17:57:43,169 DEBUG org.apache.calcite.plan.RelOptPlanner - Provenance:
rel#595:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=FlinkLogicalAggregate#594,name=DataStreamTableSink,fields=id, cnt, avgTemp)
  direct
    rel#556:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#555,name=DataStreamTableSink,fields=id, cnt, avgTemp)
      call#970 rule [FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)]
        rel#539:LogicalLegacySink.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#538,name=DataStreamTableSink,fields=id, cnt, avgTemp)
          no parent
rel#594:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=FlinkLogicalLegacyTableSourceScan#558,group={0},cnt=COUNT($0),avgTemp=AVG($1))
  direct
    rel#554:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#553,group={0},cnt=COUNT($0),avgTemp=AVG($1))
      call#963 rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)]
        rel#537:LogicalAggregate.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#536,group={0},cnt=COUNT($0),avgTemp=AVG($1))
          no parent
rel#558:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, timestamp, temp)
  call#992 rule [FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)]
    rel#545:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]])
      call#928 rule [PushProjectIntoLegacyTableSourceScanRule]
        rel#535:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#534,inputs=0,exprs=[$2])
          no parent
        rel#72:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]])
          no parent

2021-04-15 17:57:43,170 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize logical cost 51 ms.
optimize result: 
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- FlinkLogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- FlinkLogicalLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:57:43,171 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:43,171 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:43,171 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#599:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#598,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:57:43,171 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#597:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#596,group={0},cnt=COUNT($0),avgTemp=AVG($1))
2021-04-15 17:57:43,171 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#558:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, timestamp, temp)
2021-04-15 17:57:43,171 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize logical_rewrite cost 1 ms.
optimize result: 
FlinkLogicalLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- FlinkLogicalAggregate(group=[{0}], cnt=[COUNT($0)], avgTemp=[AVG($1)])
   +- FlinkLogicalLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, timestamp, temp])

2021-04-15 17:57:43,174 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:43,174 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#558]
2021-04-15 17:57:43,174 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1475: Apply rule [StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#558:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, timestamp, temp)]
2021-04-15 17:57:43,175 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#608 via StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:57:43,175 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1475 generated 1 successors: [rel#608:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)]
2021-04-15 17:57:43,175 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:43,175 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#602]
2021-04-15 17:57:43,175 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1486: Apply rule [StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#602:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#601,group={0},cnt=COUNT($0),avgTemp=AVG($1))]
2021-04-15 17:57:43,177 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#612 via StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:57:43,178 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1486 generated 1 successors: [rel#612:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#610,groupBy=id,select=id, COUNT_RETRACT(id) AS cnt, AVG_RETRACT(temp) AS avgTemp)]
2021-04-15 17:57:43,178 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:43,178 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#604]
2021-04-15 17:57:43,178 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1502: Apply rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#604:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#603,name=DataStreamTableSink,fields=id, cnt, avgTemp)]
2021-04-15 17:57:43,178 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#614 via StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-04-15 17:57:43,179 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1502 generated 1 successors: [rel#614:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#613,name=DataStreamTableSink,fields=id, cnt, avgTemp)]
2021-04-15 17:57:43,179 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {inf}
2021-04-15 17:57:43,179 DEBUG org.apache.calcite.plan.RelOptPlanner - Pop match: rule [FlinkExpandConversionRule] rels [#611,#608]
2021-04-15 17:57:43,179 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1509: Apply rule [FlinkExpandConversionRule] to [rel#611:AbstractConverter.STREAM_PHYSICAL.hash[0]true.None: 0.[NONE].[NONE](input=RelSubset#609,convention=STREAM_PHYSICAL,FlinkRelDistributionTraitDef=hash[0]true,MiniBatchIntervalTraitDef=None: 0,ModifyKindSetTraitDef=[NONE],UpdateKindTraitDef=[NONE]), rel#608:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)]
2021-04-15 17:57:43,179 DEBUG org.apache.calcite.plan.RelOptPlanner - Transform to: rel#615 via FlinkExpandConversionRule
2021-04-15 17:57:43,180 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1509 generated 1 successors: [rel#615:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[NONE].[NONE](input=StreamExecLegacyTableSourceScan#608,distribution=hash[id])]
2021-04-15 17:57:43,180 DEBUG org.apache.calcite.plan.RelOptPlanner - PLANNER = org.apache.calcite.plan.volcano.IterativeRuleDriver@589fb74d; COST = {4.0E8 rows, 1.71E10 cpu, 2.0E9 io, 2.0E9 network, 0.0 memory}
2021-04-15 17:57:43,180 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for VolcanoPlanner
2021-04-15 17:57:43,181 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
FlinkCalcMergeRule                                                            18              29,547
FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)                                16              83,080
ProjectToCalcRule                                                             13              16,915
FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)                      9              19,350
ProjectCalcMergeRule                                                           7              13,764
FlinkLogicalLegacyTableSourceScanConverter(in:NONE,out:LOGICAL)                   6             139,537
AggregateReduceFunctionsRule                                                   6              17,531
FlinkLogicalLegacySinkConverter(in:NONE,out:LOGICAL)                           4             122,210
StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)                   4              64,721
StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)                       4              34,770
ProjectMergeRule                                                               4              18,472
ProjectFilterTransposeRule                                                     3              11,586
AggregateProjectMergeRule                                                      3               5,489
AggregateProjectPullUpConstantsRule                                            3                  64
StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)                   2             105,534
FlinkExpandConversionRule                                                      2              20,563
FilterToCalcRule                                                               2              11,218
PushProjectIntoLegacyTableSourceScanRule                                       2               7,082
StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)                             1              26,704
FilterCalcMergeRule                                                            1               1,741
ProjectRemoveRule                                                              1               1,462
FilterProjectTransposeRule                                                     1               1,275
* Total                                                                      112             752,615

2021-04-15 17:57:43,183 DEBUG org.apache.calcite.plan.RelOptPlanner - Cheapest plan:
StreamExecLegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp]): rowcount = 1.0E8, cumulative cost = {4.0E8 rows, 1.71E10 cpu, 2.0E9 io, 2.0E9 network, 0.0 memory}, id = 619
  StreamExecGroupAggregate(groupBy=[id], select=[id, COUNT_RETRACT(id) AS cnt, AVG_RETRACT(temp) AS avgTemp]): rowcount = 1.0E8, cumulative cost = {3.0E8 rows, 1.7E10 cpu, 2.0E9 io, 2.0E9 network, 0.0 memory}, id = 618
    StreamExecExchange(distribution=[hash[id]]): rowcount = 1.0E8, cumulative cost = {2.0E8 rows, 1.69E10 cpu, 2.0E9 io, 2.0E9 network, 0.0 memory}, id = 617
      StreamExecLegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 2.0E9 io, 0.0 network, 0.0 memory}, id = 608

2021-04-15 17:57:43,184 DEBUG org.apache.calcite.plan.RelOptPlanner - Provenance:
rel#619:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=StreamExecGroupAggregate#618,name=DataStreamTableSink,fields=id, cnt, avgTemp)
  direct
    rel#614:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#613,name=DataStreamTableSink,fields=id, cnt, avgTemp)
      call#1502 rule [StreamExecLegacySinkRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#604:FlinkLogicalLegacySink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#603,name=DataStreamTableSink,fields=id, cnt, avgTemp)
          no parent
rel#618:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=StreamExecExchange#617,groupBy=id,select=id, COUNT_RETRACT(id) AS cnt, AVG_RETRACT(temp) AS avgTemp)
  direct
    rel#612:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#610,groupBy=id,select=id, COUNT_RETRACT(id) AS cnt, AVG_RETRACT(temp) AS avgTemp)
      call#1486 rule [StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#602:FlinkLogicalAggregate.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#601,group={0},cnt=COUNT($0),avgTemp=AVG($1))
          no parent
rel#617:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[NONE].[NONE](input=StreamExecLegacyTableSourceScan#608,distribution=hash[id])
  direct
    rel#616:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[NONE].[NONE](input=RelSubset#609,distribution=hash[id])
      call#1509 rule [FlinkExpandConversionRule]
        rel#611:AbstractConverter.STREAM_PHYSICAL.hash[0]true.None: 0.[NONE].[NONE](input=RelSubset#609,convention=STREAM_PHYSICAL,FlinkRelDistributionTraitDef=hash[0]true,MiniBatchIntervalTraitDef=None: 0,ModifyKindSetTraitDef=[NONE],UpdateKindTraitDef=[NONE])
          call#1486 rule [StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)]
            rel#602 (see above)
        rel#608:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)
          call#1475 rule [StreamExecLegacyTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)]
            rel#558:FlinkLogicalLegacyTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, timestamp, temp)
              no parent
rel#608 (see above)

2021-04-15 17:57:43,185 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize physical cost 12 ms.
optimize result: 
LegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT_RETRACT(id) AS cnt, AVG_RETRACT(temp) AS avgTemp])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:57:43,185 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - iteration: 1
2021-04-15 17:57:43,186 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:43,186 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:43,186 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#625:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#624,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:57:43,187 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#623:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#622,groupBy=id,select=id, COUNT_RETRACT(id) AS cnt, AVG_RETRACT(temp) AS avgTemp)
2021-04-15 17:57:43,187 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#621:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[NONE].[NONE](input=HepRelVertex#620,distribution=hash[id])
2021-04-15 17:57:43,187 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#608:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)
2021-04-15 17:57:43,189 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize watermark transpose cost 2 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT_RETRACT(id) AS cnt, AVG_RETRACT(temp) AS avgTemp])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:57:43,194 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize Changelog mode inference cost 4 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:57:43,198 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize Initialization for mini-batch interval inference cost 0 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:57:43,200 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1514: Apply rule [MiniBatchIntervalInferRule] to [rel#641:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#640,name=DataStreamTableSink,fields=id, cnt, avgTemp)]
2021-04-15 17:57:43,200 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1515: Apply rule [MiniBatchIntervalInferRule] to [rel#639:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[I,U].[BEFORE_AND_AFTER](input=HepRelVertex#638,groupBy=id,select=id, COUNT(id) AS cnt, AVG(temp) AS avgTemp)]
2021-04-15 17:57:43,200 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1516: Apply rule [MiniBatchIntervalInferRule] to [rel#637:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[I].[NONE](input=HepRelVertex#636,distribution=hash[id])]
2021-04-15 17:57:43,200 DEBUG org.apache.calcite.plan.RelOptPlanner - call#1517: Apply rule [MiniBatchIntervalInferRule] to [rel#631:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)]
2021-04-15 17:57:43,200 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:43,201 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
MiniBatchIntervalInferRule                                                     4                 170
* Total                                                                        4                 170

2021-04-15 17:57:43,201 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#641:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#640,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:57:43,201 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#639:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[I,U].[BEFORE_AND_AFTER](input=HepRelVertex#638,groupBy=id,select=id, COUNT(id) AS cnt, AVG(temp) AS avgTemp)
2021-04-15 17:57:43,201 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#637:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[I].[NONE](input=HepRelVertex#636,distribution=hash[id])
2021-04-15 17:57:43,201 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#631:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)
2021-04-15 17:57:43,202 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize mini-batch interval rules cost 3 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:57:43,203 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - Rule Attempts Info for HepPlanner
2021-04-15 17:57:43,203 DEBUG o.a.c.plan.AbstractRelOptPlanner.rule_execution_summary - 
Rules                                                                   Attempts           Time (us)
* Total                                                                        0                   0

2021-04-15 17:57:43,203 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#648:StreamExecLegacySink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#647,name=DataStreamTableSink,fields=id, cnt, avgTemp)
2021-04-15 17:57:43,203 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#646:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.[I,U].[BEFORE_AND_AFTER](input=HepRelVertex#645,groupBy=id,select=id, COUNT(id) AS cnt, AVG(temp) AS avgTemp)
2021-04-15 17:57:43,203 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#644:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.[I].[NONE](input=HepRelVertex#643,distribution=hash[id])
2021-04-15 17:57:43,203 DEBUG org.apache.calcite.plan.RelOptPlanner - For final plan, using rel#631:StreamExecLegacyTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]],fields=id, temp)
2021-04-15 17:57:43,204 DEBUG o.a.f.t.planner.plan.optimize.program.FlinkGroupProgram - optimize physical rewrite cost 1 ms.
optimize result:
 LegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:57:43,204 DEBUG o.a.f.t.p.plan.optimize.program.FlinkChainedProgram - optimize physical_rewrite cost 19 ms.
optimize result: 
LegacySink(name=[DataStreamTableSink], fields=[id, cnt, avgTemp])
+- GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp])
   +- Exchange(distribution=[hash[id]])
      +- LegacyTableSourceScan(table=[[default_catalog, default_database, inputTable, source: [CsvTableSource(read fields: id, temp)]]], fields=[id, temp])

2021-04-15 17:57:43,208 INFO org.apache.flink.api.java.typeutils.TypeExtractor - class org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit does not contain a setter for field modificationTime
2021-04-15 17:57:43,208 INFO org.apache.flink.api.java.typeutils.TypeExtractor - Class class org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2021-04-15 17:57:43,208 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:57:43,209 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:57:43,209 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:57:43,209 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:57:43,209 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:57:43,209 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.java.io.RowCsvInputFormat
2021-04-15 17:57:43,209 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:57:43,209 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [Lorg.apache.flink.api.common.typeinfo.TypeInformation;
2021-04-15 17:57:43,210 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [I
2021-04-15 17:57:43,210 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:57:43,210 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Long
2021-04-15 17:57:43,210 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.streaming.api.functions.source.FileProcessingMode
2021-04-15 17:57:43,210 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Long
2021-04-15 17:57:43,210 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:57:43,214 DEBUG o.a.flink.table.planner.codegen.OperatorCodeGenerator$ - Compiling OneInputStreamOperator Code:
SourceConversion
2021-04-15 17:57:43,221 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'isnull' from 'core' module.
2021-04-15 17:57:43,221 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'plus' from 'core' module.
2021-04-15 17:57:43,222 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'ifthenelse' from 'core' module.
2021-04-15 17:57:43,225 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'isnull' from 'core' module.
2021-04-15 17:57:43,225 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'plus' from 'core' module.
2021-04-15 17:57:43,226 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'ifthenelse' from 'core' module.
2021-04-15 17:57:43,227 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'isnull' from 'core' module.
2021-04-15 17:57:43,227 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'plus' from 'core' module.
2021-04-15 17:57:43,228 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'ifthenelse' from 'core' module.
2021-04-15 17:57:43,230 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'equals' from 'core' module.
2021-04-15 17:57:43,231 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'divide' from 'core' module.
2021-04-15 17:57:43,232 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'cast' from 'core' module.
2021-04-15 17:57:43,232 DEBUG org.apache.flink.table.module.ModuleManager - Got FunctionDefinition 'ifthenelse' from 'core' module.
2021-04-15 17:57:43,237 DEBUG o.a.flink.table.planner.codegen.OperatorCodeGenerator$ - Compiling OneInputStreamOperator Code:
SinkConversion
2021-04-15 17:57:43,237 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
2021-04-15 17:57:43,237 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Boolean
2021-04-15 17:57:43,237 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.String
2021-04-15 17:57:43,237 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the [B
2021-04-15 17:57:43,238 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Byte
2021-04-15 17:57:43,238 DEBUG org.apache.flink.api.java.ClosureCleaner - Dig to clean the java.lang.Integer
2021-04-15 17:57:43,260 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=4, name='SinkConversionToRow', outputType=Row(id: String, timestamp: Long, temp: Double), parallelism=1}
2021-04-15 17:57:43,276 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=3, name='SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp])', outputType=ROW<`id` STRING, `timestamp` BIGINT, `temp` DOUBLE>(org.apache.flink.table.data.RowData, org.apache.flink.table.runtime.typeutils.RowDataSerializer), parallelism=1}
2021-04-15 17:57:43,276 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=2, name='CsvTableSource(read fields: id, timestamp, temp)', outputType=Row(id: String, timestamp: Long, temp: Double), parallelism=1}
2021-04-15 17:57:43,276 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySourceTransformation{id=1, name='Custom File source', outputType=GenericType<org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit>, parallelism=1}
2021-04-15 17:57:43,287 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 1
2021-04-15 17:57:43,288 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 2
2021-04-15 17:57:43,289 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 3
2021-04-15 17:57:43,289 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 4
2021-04-15 17:57:43,289 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySinkTransformation{id=5, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=1}
2021-04-15 17:57:43,290 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 5
2021-04-15 17:57:43,290 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=10, name='SinkConversionToRow', outputType=Row(id: String, temp: Double), parallelism=1}
2021-04-15 17:57:43,290 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=9, name='Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')])', outputType=ROW<`id` STRING, `temp` DOUBLE>(org.apache.flink.table.data.RowData, org.apache.flink.table.runtime.typeutils.RowDataSerializer), parallelism=1}
2021-04-15 17:57:43,290 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=8, name='SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp])', outputType=ROW<`id` STRING, `temp` DOUBLE>(org.apache.flink.table.data.RowData, org.apache.flink.table.runtime.typeutils.RowDataSerializer), parallelism=1}
2021-04-15 17:57:43,290 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=7, name='CsvTableSource(read fields: id, temp)', outputType=Row(id: String, temp: Double), parallelism=1}
2021-04-15 17:57:43,290 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySourceTransformation{id=6, name='Custom File source', outputType=GenericType<org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit>, parallelism=1}
2021-04-15 17:57:43,290 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 6
2021-04-15 17:57:43,291 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 7
2021-04-15 17:57:43,291 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 8
2021-04-15 17:57:43,291 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 9
2021-04-15 17:57:43,291 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 10
2021-04-15 17:57:43,291 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySinkTransformation{id=11, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=1}
2021-04-15 17:57:43,291 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 11
2021-04-15 17:57:43,291 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=17, name='SinkConversionToTuple2', outputType=Java Tuple2<Boolean, Row(id: String, EXPR$0: Long, EXPR$1: Double)>, parallelism=-1}
2021-04-15 17:57:43,291 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=16, name='GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1])', outputType=ROW<`id` STRING, `EXPR$0` BIGINT NOT NULL, `EXPR$1` DOUBLE>(org.apache.flink.table.data.RowData, org.apache.flink.table.runtime.typeutils.RowDataSerializer), parallelism=-1}
2021-04-15 17:57:43,291 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming PartitionTransformation{id=15, name='Partition', outputType=ROW<`id` STRING, `timestamp` BIGINT, `temp` DOUBLE>(org.apache.flink.table.data.RowData, org.apache.flink.table.runtime.typeutils.RowDataSerializer), parallelism=-1}
2021-04-15 17:57:43,292 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=14, name='SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp])', outputType=ROW<`id` STRING, `timestamp` BIGINT, `temp` DOUBLE>(org.apache.flink.table.data.RowData, org.apache.flink.table.runtime.typeutils.RowDataSerializer), parallelism=1}
2021-04-15 17:57:43,292 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=13, name='CsvTableSource(read fields: id, timestamp, temp)', outputType=Row(id: String, timestamp: Long, temp: Double), parallelism=1}
2021-04-15 17:57:43,292 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySourceTransformation{id=12, name='Custom File source', outputType=GenericType<org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit>, parallelism=1}
2021-04-15 17:57:43,292 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 12
2021-04-15 17:57:43,292 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 13
2021-04-15 17:57:43,293 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 14
2021-04-15 17:57:43,293 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 16
2021-04-15 17:57:43,295 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 17
2021-04-15 17:57:43,296 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySinkTransformation{id=18, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=1}
2021-04-15 17:57:43,296 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 18
2021-04-15 17:57:43,296 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=24, name='SinkConversionToTuple2', outputType=Java Tuple2<Boolean, Row(id: String, cnt: Long, avgTemp: Double)>, parallelism=-1}
2021-04-15 17:57:43,296 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=23, name='GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp])', outputType=ROW<`id` STRING, `cnt` BIGINT NOT NULL, `avgTemp` DOUBLE>(org.apache.flink.table.data.RowData, org.apache.flink.table.runtime.typeutils.RowDataSerializer), parallelism=-1}
2021-04-15 17:57:43,296 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming PartitionTransformation{id=22, name='Partition', outputType=ROW<`id` STRING, `temp` DOUBLE>(org.apache.flink.table.data.RowData, org.apache.flink.table.runtime.typeutils.RowDataSerializer), parallelism=-1}
2021-04-15 17:57:43,297 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=21, name='SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp])', outputType=ROW<`id` STRING, `temp` DOUBLE>(org.apache.flink.table.data.RowData, org.apache.flink.table.runtime.typeutils.RowDataSerializer), parallelism=1}
2021-04-15 17:57:43,297 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming OneInputTransformation{id=20, name='CsvTableSource(read fields: id, temp)', outputType=Row(id: String, temp: Double), parallelism=1}
2021-04-15 17:57:43,297 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySourceTransformation{id=19, name='Custom File source', outputType=GenericType<org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit>, parallelism=1}
2021-04-15 17:57:43,305 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 19
2021-04-15 17:57:43,305 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 20
2021-04-15 17:57:43,306 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 21
2021-04-15 17:57:43,306 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 23
2021-04-15 17:57:43,306 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 24
2021-04-15 17:57:43,306 DEBUG o.apache.flink.streaming.api.graph.StreamGraphGenerator - Transforming LegacySinkTransformation{id=25, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=1}
2021-04-15 17:57:43,306 DEBUG org.apache.flink.streaming.api.graph.StreamGraph - Vertex: 25
2021-04-15 17:57:43,340 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'bc764cd8ddf7a0cff126f51c16239658' for node 'Source: Custom File source-1' {id: 1, parallelism: 1, user function: org.apache.flink.streaming.api.functions.source.ContinuousFileMonitoringFunction}
2021-04-15 17:57:43,340 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'feca28aff5a3958840bee985ee7de4d3' for node 'Source: Custom File source-6' {id: 6, parallelism: 1, user function: org.apache.flink.streaming.api.functions.source.ContinuousFileMonitoringFunction}
2021-04-15 17:57:43,340 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '605b35e407e90cda15ad084365733fdd' for node 'Source: Custom File source-12' {id: 12, parallelism: 1, user function: org.apache.flink.streaming.api.functions.source.ContinuousFileMonitoringFunction}
2021-04-15 17:57:43,340 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '3ba1d27b7fde4848a86e865c6c402dfa' for node 'Source: Custom File source-19' {id: 19, parallelism: 1, user function: org.apache.flink.streaming.api.functions.source.ContinuousFileMonitoringFunction}
2021-04-15 17:57:43,340 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '77af20c908aca598f7bbebd4db138545' for node 'CsvTableSource(read fields: id, timestamp, temp)-2' {id: 2, parallelism: 1, user function: }
2021-04-15 17:57:43,341 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'b23642197a427ec5db481d3963c66cfb' for node 'CsvTableSource(read fields: id, temp)-7' {id: 7, parallelism: 1, user function: }
2021-04-15 17:57:43,341 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'a19bdf930ebdf056b3d6de069bc89bdd' for node 'CsvTableSource(read fields: id, timestamp, temp)-13' {id: 13, parallelism: 1, user function: }
2021-04-15 17:57:43,341 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'aecbb8a11dc0c28dc6c178e875ebcc43' for node 'CsvTableSource(read fields: id, temp)-20' {id: 20, parallelism: 1, user function: }
2021-04-15 17:57:43,341 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'e1caecf4e938c7437797fd5ffa107998' for node 'SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp])-3' {id: 3, parallelism: 1, user function: }
2021-04-15 17:57:43,341 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'f747214a7be91c9c2b6cc5b7a3c8c7eb' for node 'SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp])-8' {id: 8, parallelism: 1, user function: }
2021-04-15 17:57:43,341 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '7b8b09df1455080a34c77ad3d0c43cb7' for node 'SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp])-14' {id: 14, parallelism: 1, user function: }
2021-04-15 17:57:43,341 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'fd97fe1bcea3a8dd8f11b0abe0bb8fa7' for node 'SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp])-21' {id: 21, parallelism: 1, user function: }
2021-04-15 17:57:43,341 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'a74f42661a9b9f548012fab549771fb0' for node 'SinkConversionToRow-4' {id: 4, parallelism: 1, user function: }
2021-04-15 17:57:43,341 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'eac1a1ce1701c72ed31579ebbd62865a' for node 'Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')])-9' {id: 9, parallelism: 1, user function: }
2021-04-15 17:57:43,341 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '6177eb422127981c4dbb05ea3af8a2d4' for node 'GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1])-16' {id: 16, parallelism: 1, user function: org.apache.flink.table.runtime.operators.aggregate.GroupAggFunction}
2021-04-15 17:57:43,341 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '5528b14a6b129894d24927c518acc32a' for node 'GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp])-23' {id: 23, parallelism: 1, user function: org.apache.flink.table.runtime.operators.aggregate.GroupAggFunction}
2021-04-15 17:57:43,341 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '1ff151f0e73312424d48b44002b858b2' for node 'Sink: Print to Std. Out-5' {id: 5, parallelism: 1, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
2021-04-15 17:57:43,341 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '7be2b145deed960935698c82ec6584ff' for node 'SinkConversionToRow-10' {id: 10, parallelism: 1, user function: }
2021-04-15 17:57:43,341 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '82ccb120c1db7ba31f32cb138318e905' for node 'SinkConversionToTuple2-17' {id: 17, parallelism: 1, user function: }
2021-04-15 17:57:43,341 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'a0dd144f36ef19961046e87bafc35e9e' for node 'SinkConversionToTuple2-24' {id: 24, parallelism: 1, user function: }
2021-04-15 17:57:43,341 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash 'acef8fa5317ebae622515a3dd3a22b5b' for node 'Sink: Print to Std. Out-11' {id: 11, parallelism: 1, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
2021-04-15 17:57:43,341 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '5eabb43907f8f80df1ce4361a6f197f2' for node 'Sink: Print to Std. Out-18' {id: 18, parallelism: 1, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
2021-04-15 17:57:43,341 DEBUG o.apache.flink.streaming.api.graph.StreamGraphHasherV2 - Generated hash '3ed91adabe57771c56cb72d2e8ef0077' for node 'Sink: Print to Std. Out-25' {id: 25, parallelism: 1, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
2021-04-15 17:57:43,385 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 2
2021-04-15 17:57:43,403 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 1
2021-04-15 17:57:43,410 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - CONNECTED: ForwardPartitioner - 1 -> 2
2021-04-15 17:57:43,415 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 7
2021-04-15 17:57:43,420 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 6
2021-04-15 17:57:43,421 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - CONNECTED: ForwardPartitioner - 6 -> 7
2021-04-15 17:57:43,429 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 16
2021-04-15 17:57:43,444 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 13
2021-04-15 17:57:43,445 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - CONNECTED: KeyGroupStreamPartitioner - 13 -> 16
2021-04-15 17:57:43,445 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 12
2021-04-15 17:57:43,446 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - CONNECTED: ForwardPartitioner - 12 -> 13
2021-04-15 17:57:43,447 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 23
2021-04-15 17:57:43,448 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 20
2021-04-15 17:57:43,449 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - CONNECTED: KeyGroupStreamPartitioner - 20 -> 23
2021-04-15 17:57:43,450 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - Parallelism set: 1 for 19
2021-04-15 17:57:43,450 DEBUG o.a.f.streaming.api.graph.StreamingJobGraphGenerator - CONNECTED: ForwardPartitioner - 19 -> 20
2021-04-15 17:57:43,485 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.
2021-04-15 17:57:43,485 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.
2021-04-15 17:57:43,485 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.
2021-04-15 17:57:43,486 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.min required for local execution is not set, setting it to its default value 64 mb.
2021-04-15 17:57:43,486 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.max required for local execution is not set, setting it to its default value 64 mb.
2021-04-15 17:57:43,486 INFO o.a.f.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.
2021-04-15 17:57:43,498 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting Flink Mini Cluster
2021-04-15 17:57:43,499 DEBUG org.apache.flink.runtime.minicluster.MiniCluster - Using configuration MiniClusterConfiguration {singleRpcService=SHARED, numTaskManagers=1, commonBindAddress='null', config={taskmanager.memory.network.min=64 mb, taskmanager.cpu.cores=1.7976931348623157E308, taskmanager.memory.task.off-heap.size=9223372036854775807 bytes, execution.target=local, rest.bind-port=0, taskmanager.memory.network.max=64 mb, execution.attached=true, taskmanager.memory.managed.size=128 mb, parallelism.default=4, taskmanager.numberOfTaskSlots=1, taskmanager.memory.task.heap.size=9223372036854775807 bytes, rest.address=localhost}}
2021-04-15 17:57:43,500 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting Metrics Registry
2021-04-15 17:57:43,549 INFO org.apache.flink.runtime.metrics.MetricRegistryImpl - No metrics reporter configured, no metrics will be exposed/reported.
2021-04-15 17:57:43,549 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting RPC Service(s)
2021-04-15 17:57:43,557 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
2021-04-15 17:57:43,561 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Using akka configuration
 Config(SimpleConfigObject({"akka":{"actor":{"default-dispatcher":{"executor":"fork-join-executor","fork-join-executor":{"parallelism-factor":1,"parallelism-max":4,"parallelism-min":2},"throughput":15},"guardian-supervisor-strategy":"org.apache.flink.runtime.akka.EscalatingSupervisorStrategy","supervisor-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"type":"Dispatcher"},"warn-about-java-serializer-usage":"off"},"daemonic":"off","jvm-exit-on-fatal-error":"on","log-config-on-start":"off","log-dead-letters":"off","log-dead-letters-during-shutdown":"off","logger-startup-timeout":"30s","loggers":["akka.event.slf4j.Slf4jLogger"],"logging-filter":"akka.event.slf4j.Slf4jLoggingFilter","loglevel":"DEBUG","serialize-messages":"off","stdout-loglevel":"OFF"}}))
2021-04-15 17:57:43,969 INFO akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2021-04-15 17:57:43,977 DEBUG akka.event.EventStream - logger log1-Slf4jLogger started
2021-04-15 17:57:43,979 DEBUG akka.event.EventStream - Default Loggers started
2021-04-15 17:57:44,204 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink
2021-04-15 17:57:44,227 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
2021-04-15 17:57:44,229 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Using akka configuration
 Config(SimpleConfigObject({"akka":{"actor":{"default-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"thread-priority":1,"throughput":15,"type":"akka.dispatch.PriorityThreadsDispatcher"},"guardian-supervisor-strategy":"org.apache.flink.runtime.akka.EscalatingSupervisorStrategy","supervisor-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"type":"Dispatcher"},"warn-about-java-serializer-usage":"off"},"daemonic":"off","jvm-exit-on-fatal-error":"on","log-config-on-start":"off","log-dead-letters":"off","log-dead-letters-during-shutdown":"off","logger-startup-timeout":"30s","loggers":["akka.event.slf4j.Slf4jLogger"],"logging-filter":"akka.event.slf4j.Slf4jLoggingFilter","loglevel":"DEBUG","serialize-messages":"off","stdout-loglevel":"OFF"}}))
2021-04-15 17:57:44,247 INFO akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2021-04-15 17:57:44,250 DEBUG akka.event.EventStream - logger log1-Slf4jLogger started
2021-04-15 17:57:44,250 DEBUG akka.event.EventStream - Default Loggers started
2021-04-15 17:57:44,309 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink-metrics
2021-04-15 17:57:44,324 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting AkkaRpcActor with name MetricQueryService.
2021-04-15 17:57:44,329 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
2021-04-15 17:57:44,473 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting high-availability services
2021-04-15 17:57:45,234 INFO org.apache.flink.runtime.blob.BlobServer - Created BLOB server storage directory C:\Users\ccy\AppData\Local\Temp\blobStore-4f4a66ff-0c65-473b-870a-bd6969d4b312
2021-04-15 17:57:45,242 DEBUG org.apache.flink.util.NetUtils - Trying to open socket on port 0
2021-04-15 17:57:45,244 INFO org.apache.flink.runtime.blob.BlobServer - Started BLOB server at 0.0.0.0:62344 - max concurrent requests: 50 - max backlog: 1000
2021-04-15 17:57:45,249 INFO org.apache.flink.runtime.blob.PermanentBlobCache - Created BLOB cache storage directory C:\Users\ccy\AppData\Local\Temp\blobStore-1c09d896-ec68-47cd-9c7f-4889402148b8
2021-04-15 17:57:45,251 INFO org.apache.flink.runtime.blob.TransientBlobCache - Created BLOB cache storage directory C:\Users\ccy\AppData\Local\Temp\blobStore-7c66167f-9a5a-4597-ae34-1f62d6dd3501
2021-04-15 17:57:45,251 INFO org.apache.flink.runtime.minicluster.MiniCluster - Starting 1 TaskManger(s)
2021-04-15 17:57:45,254 INFO org.apache.flink.runtime.taskexecutor.TaskManagerRunner - Starting TaskManager with ResourceID: 5825669a-8d86-4e2a-99d8-ca5e01d959fa
2021-04-15 17:57:45,281 INFO o.apache.flink.runtime.taskexecutor.TaskManagerServices - Temporary file directory 'C:\Users\ccy\AppData\Local\Temp': total 137 GB, usable 24 GB (17.52% usable)
2021-04-15 17:57:45,284 INFO org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\ccy\AppData\Local\Temp\flink-io-fcf4f52c-a1ee-4529-99e1-242d040ac8fe for spill files.
2021-04-15 17:57:45,292 INFO org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\ccy\AppData\Local\Temp\flink-netty-shuffle-d1eb3332-90b7-44e7-a6f5-3f604c6bf91d for spill files.
2021-04-15 17:57:45,334 INFO o.a.flink.runtime.io.network.buffer.NetworkBufferPool - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2021-04-15 17:57:45,344 INFO o.a.flink.runtime.io.network.NettyShuffleEnvironment - Starting the network environment and its components.
2021-04-15 17:57:45,344 DEBUG o.a.flink.runtime.io.network.NettyShuffleEnvironment - Starting network connection manager
2021-04-15 17:57:45,346 INFO org.apache.flink.runtime.taskexecutor.KvStateService - Starting the kvState service and its components.
2021-04-15 17:57:45,360 DEBUG o.a.flink.runtime.taskexecutor.TaskManagerConfiguration - Messages have a max timeout of 10000 ms
2021-04-15 17:57:45,373 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting AkkaRpcActor with name taskmanager_0.
2021-04-15 17:57:45,374 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2021-04-15 17:57:45,388 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Start job leader service.
2021-04-15 17:57:45,390 INFO org.apache.flink.runtime.filecache.FileCache - User file cache uses directory C:\Users\ccy\AppData\Local\Temp\flink-dist-cache-4bc36192-9a10-49ef-bf9c-979b1c6f2c2f
2021-04-15 17:57:45,419 DEBUG o.a.f.r.e.c.DefaultDispatcherResourceManagerComponentFactory - Starting Dispatcher REST endpoint.
2021-04-15 17:57:45,419 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Starting rest endpoint.
2021-04-15 17:57:45,426 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Failed to load web based job submission extension.
org.apache.flink.util.FlinkException: The module flink-runtime-web could not be found in the class path. Please add this jar in order to enable web based job submission.
	at org.apache.flink.runtime.webmonitor.WebMonitorUtils.loadWebSubmissionExtension(WebMonitorUtils.java:199) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint.initializeWebSubmissionHandlers(DispatcherRestEndpoint.java:112) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.webmonitor.WebMonitorEndpoint.initializeHandlers(WebMonitorEndpoint.java:228) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint.initializeHandlers(DispatcherRestEndpoint.java:89) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:144) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:172) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:463) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:422) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:366) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.program.PerJobMiniClusterFactory.submitJob(PerJobMiniClusterFactory.java:75) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:85) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1905) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1796) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:69) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1782) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1765) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.myorg.quickstart.other.FTable.Base1Usage.main(Base1Usage.java:88) ~[classes/:na]
2021-04-15 17:57:45,638 DEBUG o.a.f.s.n.i.n.u.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
2021-04-15 17:57:45,639 DEBUG o.a.f.s.n.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2021-04-15 17:57:45,639 DEBUG o.a.f.s.n.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2021-04-15 17:57:45,718 WARN org.apache.flink.runtime.webmonitor.WebMonitorUtils - Log file environment variable 'log.file' is not set.
2021-04-15 17:57:45,718 WARN org.apache.flink.runtime.webmonitor.WebMonitorUtils - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'web.log.path'.
2021-04-15 17:57:45,749 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - Platform: Windows
2021-04-15 17:57:45,751 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
2021-04-15 17:57:45,751 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - Java version: 11
2021-04-15 17:57:45,752 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
2021-04-15 17:57:45,752 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
2021-04-15 17:57:45,753 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
2021-04-15 17:57:45,754 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: unavailable
java.lang.UnsupportedOperationException: Reflective setAccessible(true) disabled
	at org.apache.flink.shaded.netty4.io.netty.util.internal.ReflectionUtil.trySetAccessible(ReflectionUtil.java:31) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0$4.run(PlatformDependent0.java:233) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at java.base/java.security.AccessController.doPrivileged(Native Method) ~[na:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:227) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.isAndroid(PlatformDependent.java:289) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:92) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:223) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:210) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.cached(AsciiString.java:1401) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<clinit>(AsciiString.java:48) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<init>(HttpMethod.java:135) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<clinit>(HttpMethod.java:36) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.runtime.rest.HttpMethodWrapper.<clinit>(HttpMethodWrapper.java:27) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.messages.cluster.ShutdownHeaders.getHttpMethod(ShutdownHeaders.java:57) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.checkAllEndpointsAndHandlersAreUnique(RestServerEndpoint.java:572) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:155) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:172) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:463) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:422) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:366) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.program.PerJobMiniClusterFactory.submitJob(PerJobMiniClusterFactory.java:75) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:85) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1905) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1796) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:69) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1782) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1765) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.myorg.quickstart.other.FTable.Base1Usage.main(Base1Usage.java:88) ~[classes/:na]
2021-04-15 17:57:45,755 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
2021-04-15 17:57:45,756 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable
java.lang.IllegalAccessException: class org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0$6 cannot access class jdk.internal.misc.Unsafe (in module java.base) because module java.base does not export jdk.internal.misc to unnamed module @9729a97
	at java.base/jdk.internal.reflect.Reflection.newIllegalAccessException(Reflection.java:361) ~[na:na]
	at java.base/java.lang.reflect.AccessibleObject.checkAccess(AccessibleObject.java:591) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:558) ~[na:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0$6.run(PlatformDependent0.java:347) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at java.base/java.security.AccessController.doPrivileged(Native Method) ~[na:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:338) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.isAndroid(PlatformDependent.java:289) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:92) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:223) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<init>(AsciiString.java:210) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.cached(AsciiString.java:1401) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.util.AsciiString.<clinit>(AsciiString.java:48) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<init>(HttpMethod.java:135) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod.<clinit>(HttpMethod.java:36) ~[flink-shaded-netty-4.1.49.Final-12.0.jar:na]
	at org.apache.flink.runtime.rest.HttpMethodWrapper.<clinit>(HttpMethodWrapper.java:27) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.messages.cluster.ShutdownHeaders.getHttpMethod(ShutdownHeaders.java:57) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.checkAllEndpointsAndHandlersAreUnique(RestServerEndpoint.java:572) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:155) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:172) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:463) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:422) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:366) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.program.PerJobMiniClusterFactory.submitJob(PerJobMiniClusterFactory.java:75) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:85) ~[flink-clients_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1905) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1796) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:69) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1782) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1765) ~[flink-streaming-java_2.11-1.12.2.jar:1.12.2]
	at org.myorg.quickstart.other.FTable.Base1Usage.main(Base1Usage.java:88) ~[classes/:na]
2021-04-15 17:57:45,757 DEBUG o.a.f.s.n.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): unavailable
2021-04-15 17:57:45,757 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
2021-04-15 17:57:45,757 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - maxDirectMemory: 2122317824 bytes (maybe)
2021-04-15 17:57:45,758 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\ccy\AppData\Local\Temp (java.io.tmpdir)
2021-04-15 17:57:45,758 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
2021-04-15 17:57:45,758 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: -1 bytes
2021-04-15 17:57:45,758 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
2021-04-15 17:57:45,759 DEBUG o.a.f.shaded.netty4.io.netty.util.internal.CleanerJava9 - java.nio.ByteBuffer.cleaner(): available
2021-04-15 17:57:45,759 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
2021-04-15 17:57:45,763 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@2df0a4c3 under DELETE@/v1/cluster.
2021-04-15 17:57:45,764 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@2df0a4c3 under DELETE@/cluster.
2021-04-15 17:57:45,764 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@723aa04 under GET@/v1/config.
2021-04-15 17:57:45,764 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@723aa04 under GET@/config.
2021-04-15 17:57:45,764 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetListHandler@12128849 under GET@/v1/datasets.
2021-04-15 17:57:45,764 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetListHandler@12128849 under GET@/datasets.
2021-04-15 17:57:45,764 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteStatusHandler@367e0b0e under GET@/v1/datasets/delete/:triggerid.
2021-04-15 17:57:45,764 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteStatusHandler@367e0b0e under GET@/datasets/delete/:triggerid.
2021-04-15 17:57:45,764 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteTriggerHandler@3049dcac under DELETE@/v1/datasets/:datasetid.
2021-04-15 17:57:45,764 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteTriggerHandler@3049dcac under DELETE@/datasets/:datasetid.
2021-04-15 17:57:45,764 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@2a20332b under GET@/v1/jobmanager/config.
2021-04-15 17:57:45,764 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@2a20332b under GET@/jobmanager/config.
2021-04-15 17:57:45,764 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@2cf6b6e6 under GET@/v1/jobmanager/log.
2021-04-15 17:57:45,764 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@2cf6b6e6 under GET@/jobmanager/log.
2021-04-15 17:57:45,764 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogListHandler@6a16ee0d under GET@/v1/jobmanager/logs.
2021-04-15 17:57:45,764 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogListHandler@6a16ee0d under GET@/jobmanager/logs.
2021-04-15 17:57:45,764 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerCustomLogHandler@1444e35f under GET@/v1/jobmanager/logs/:filename.
2021-04-15 17:57:45,764 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerCustomLogHandler@1444e35f under GET@/jobmanager/logs/:filename.
2021-04-15 17:57:45,765 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@3f563397 under GET@/v1/jobmanager/metrics.
2021-04-15 17:57:45,765 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@3f563397 under GET@/jobmanager/metrics.
2021-04-15 17:57:45,765 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@268ee31d under GET@/v1/jobmanager/stdout.
2021-04-15 17:57:45,765 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@268ee31d under GET@/jobmanager/stdout.
2021-04-15 17:57:45,765 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@7bb50747 under GET@/v1/jobs.
2021-04-15 17:57:45,765 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@7bb50747 under GET@/jobs.
2021-04-15 17:57:45,765 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@48d84d75 under POST@/v1/jobs.
2021-04-15 17:57:45,765 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@48d84d75 under POST@/jobs.
2021-04-15 17:57:45,765 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@461c0572 under GET@/v1/jobs/metrics.
2021-04-15 17:57:45,765 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@461c0572 under GET@/jobs/metrics.
2021-04-15 17:57:45,765 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@17db90a7 under GET@/v1/jobs/overview.
2021-04-15 17:57:45,765 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@17db90a7 under GET@/jobs/overview.
2021-04-15 17:57:45,765 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@44872224 under GET@/v1/jobs/:jobid.
2021-04-15 17:57:45,765 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@44872224 under GET@/jobs/:jobid.
2021-04-15 17:57:45,765 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@4ebe6c24 under PATCH@/v1/jobs/:jobid.
2021-04-15 17:57:45,765 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@4ebe6c24 under PATCH@/jobs/:jobid.
2021-04-15 17:57:45,765 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@682fc714 under GET@/v1/jobs/:jobid/accumulators.
2021-04-15 17:57:45,765 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@682fc714 under GET@/jobs/:jobid/accumulators.
2021-04-15 17:57:45,765 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@23ba2c1e under GET@/v1/jobs/:jobid/checkpoints.
2021-04-15 17:57:45,765 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@23ba2c1e under GET@/jobs/:jobid/checkpoints.
2021-04-15 17:57:45,765 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@5ed1bc4f under GET@/v1/jobs/:jobid/checkpoints/config.
2021-04-15 17:57:45,766 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@5ed1bc4f under GET@/jobs/:jobid/checkpoints/config.
2021-04-15 17:57:45,766 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@63b334fd under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid.
2021-04-15 17:57:45,766 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@63b334fd under GET@/jobs/:jobid/checkpoints/details/:checkpointid.
2021-04-15 17:57:45,766 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@753248f8 under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
2021-04-15 17:57:45,766 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@753248f8 under GET@/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
2021-04-15 17:57:45,766 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@71a509c under GET@/v1/jobs/:jobid/config.
2021-04-15 17:57:45,766 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@71a509c under GET@/jobs/:jobid/config.
2021-04-15 17:57:45,766 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.coordination.ClientCoordinationHandler@547aa7f4 under POST@/v1/jobs/:jobid/coordinators/:operatorid.
2021-04-15 17:57:45,766 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.coordination.ClientCoordinationHandler@547aa7f4 under POST@/jobs/:jobid/coordinators/:operatorid.
2021-04-15 17:57:45,766 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@2e94655a under GET@/v1/jobs/:jobid/exceptions.
2021-04-15 17:57:45,766 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@2e94655a under GET@/jobs/:jobid/exceptions.
2021-04-15 17:57:45,766 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@49868df8 under GET@/v1/jobs/:jobid/execution-result.
2021-04-15 17:57:45,766 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@49868df8 under GET@/jobs/:jobid/execution-result.
2021-04-15 17:57:45,766 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@1ccdbae4 under GET@/v1/jobs/:jobid/metrics.
2021-04-15 17:57:45,766 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@1ccdbae4 under GET@/jobs/:jobid/metrics.
2021-04-15 17:57:45,766 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@1d09fb8e under GET@/v1/jobs/:jobid/plan.
2021-04-15 17:57:45,766 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@1d09fb8e under GET@/jobs/:jobid/plan.
2021-04-15 17:57:45,766 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@10bae3c0 under PATCH@/v1/jobs/:jobid/rescaling.
2021-04-15 17:57:45,766 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@10bae3c0 under PATCH@/jobs/:jobid/rescaling.
2021-04-15 17:57:45,766 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@6dae5562 under GET@/v1/jobs/:jobid/rescaling/:triggerid.
2021-04-15 17:57:45,766 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@6dae5562 under GET@/jobs/:jobid/rescaling/:triggerid.
2021-04-15 17:57:45,766 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@1cc5d8a9 under POST@/v1/jobs/:jobid/savepoints.
2021-04-15 17:57:45,767 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@1cc5d8a9 under POST@/jobs/:jobid/savepoints.
2021-04-15 17:57:45,767 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@4ec28534 under GET@/v1/jobs/:jobid/savepoints/:triggerid.
2021-04-15 17:57:45,767 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@4ec28534 under GET@/jobs/:jobid/savepoints/:triggerid.
2021-04-15 17:57:45,767 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@921dbcf under POST@/v1/jobs/:jobid/stop.
2021-04-15 17:57:45,767 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@921dbcf under POST@/jobs/:jobid/stop.
2021-04-15 17:57:45,767 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@163b8acc under GET@/v1/jobs/:jobid/vertices/:vertexid.
2021-04-15 17:57:45,767 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@163b8acc under GET@/jobs/:jobid/vertices/:vertexid.
2021-04-15 17:57:45,767 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@24090832 under GET@/v1/jobs/:jobid/vertices/:vertexid/accumulators.
2021-04-15 17:57:45,767 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@24090832 under GET@/jobs/:jobid/vertices/:vertexid/accumulators.
2021-04-15 17:57:45,767 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@7e38d2a2 under GET@/v1/jobs/:jobid/vertices/:vertexid/backpressure.
2021-04-15 17:57:45,767 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@7e38d2a2 under GET@/jobs/:jobid/vertices/:vertexid/backpressure.
2021-04-15 17:57:45,767 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@79408109 under GET@/v1/jobs/:jobid/vertices/:vertexid/metrics.
2021-04-15 17:57:45,767 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@79408109 under GET@/jobs/:jobid/vertices/:vertexid/metrics.
2021-04-15 17:57:45,767 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@33671907 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
2021-04-15 17:57:45,767 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@33671907 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
2021-04-15 17:57:45,767 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@5fc3dfc1 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
2021-04-15 17:57:45,767 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@5fc3dfc1 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
2021-04-15 17:57:45,767 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@67d6bb59 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
2021-04-15 17:57:45,767 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@67d6bb59 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
2021-04-15 17:57:45,767 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@1a632663 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@1a632663 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@1147ab09 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@1147ab09 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@503b5337 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@503b5337 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@265361a under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasktimes.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@265361a under GET@/jobs/:jobid/vertices/:vertexid/subtasktimes.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@136480b under GET@/v1/jobs/:jobid/vertices/:vertexid/taskmanagers.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@136480b under GET@/jobs/:jobid/vertices/:vertexid/taskmanagers.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@2d85a4c7 under GET@/v1/jobs/:jobid/vertices/:vertexid/watermarks.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@2d85a4c7 under GET@/jobs/:jobid/vertices/:vertexid/watermarks.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@272de8ab under GET@/v1/jobs/:jobid/yarn-cancel.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@272de8ab under GET@/jobs/:jobid/yarn-cancel.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@c53dfb2 under GET@/v1/jobs/:jobid/yarn-stop.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@c53dfb2 under GET@/jobs/:jobid/yarn-stop.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@3f16a823 under GET@/v1/overview.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@3f16a823 under GET@/overview.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@3fb5809a under POST@/v1/savepoint-disposal.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@3fb5809a under POST@/savepoint-disposal.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@77954f77 under GET@/v1/savepoint-disposal/:triggerid.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@77954f77 under GET@/savepoint-disposal/:triggerid.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@6529b078 under GET@/v1/taskmanagers.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@6529b078 under GET@/taskmanagers.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@6f744b4e under GET@/v1/taskmanagers/metrics.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@6f744b4e under GET@/taskmanagers/metrics.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@7cd6b76a under GET@/v1/taskmanagers/:taskmanagerid.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@7cd6b76a under GET@/taskmanagers/:taskmanagerid.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@2165b170 under GET@/v1/taskmanagers/:taskmanagerid/log.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@2165b170 under GET@/taskmanagers/:taskmanagerid/log.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogListHandler@9677f54 under GET@/v1/taskmanagers/:taskmanagerid/logs.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogListHandler@9677f54 under GET@/taskmanagers/:taskmanagerid/logs.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerCustomLogHandler@44046b0d under GET@/v1/taskmanagers/:taskmanagerid/logs/:filename.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerCustomLogHandler@44046b0d under GET@/taskmanagers/:taskmanagerid/logs/:filename.
2021-04-15 17:57:45,768 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@d20e900 under GET@/v1/taskmanagers/:taskmanagerid/metrics.
2021-04-15 17:57:45,769 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@d20e900 under GET@/taskmanagers/:taskmanagerid/metrics.
2021-04-15 17:57:45,769 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@14237e5 under GET@/v1/taskmanagers/:taskmanagerid/stdout.
2021-04-15 17:57:45,769 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@14237e5 under GET@/taskmanagers/:taskmanagerid/stdout.
2021-04-15 17:57:45,769 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerThreadDumpHandler@33ed6546 under GET@/v1/taskmanagers/:taskmanagerid/thread-dump.
2021-04-15 17:57:45,769 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerThreadDumpHandler@33ed6546 under GET@/taskmanagers/:taskmanagerid/thread-dump.
2021-04-15 17:57:45,773 DEBUG o.a.f.s.n.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 8
2021-04-15 17:57:45,794 DEBUG o.a.f.shaded.netty4.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
2021-04-15 17:57:45,794 DEBUG o.a.f.shaded.netty4.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
2021-04-15 17:57:45,800 DEBUG o.a.f.s.netty4.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
2021-04-15 17:57:45,841 DEBUG o.a.f.shaded.netty4.io.netty.channel.DefaultChannelId - -Dio.netty.processId: 6868 (auto-detected)
2021-04-15 17:57:45,844 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
2021-04-15 17:57:45,844 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
2021-04-15 17:57:46,540 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
2021-04-15 17:57:46,540 DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
2021-04-15 17:57:47,255 DEBUG o.a.f.shaded.netty4.io.netty.channel.DefaultChannelId - -Dio.netty.machineId: 2c:6f:c9:ff:fe:1c:21:83 (auto-detected)
2021-04-15 17:57:47,266 DEBUG o.a.f.shaded.netty4.io.netty.util.ResourceLeakDetector - -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.level: simple
2021-04-15 17:57:47,266 DEBUG o.a.f.shaded.netty4.io.netty.util.ResourceLeakDetector - -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.targetRecords: 4
2021-04-15 17:57:47,291 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 8
2021-04-15 17:57:47,291 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 8
2021-04-15 17:57:47,291 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
2021-04-15 17:57:47,291 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 11
2021-04-15 17:57:47,291 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 16777216
2021-04-15 17:57:47,291 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.tinyCacheSize: 512
2021-04-15 17:57:47,291 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
2021-04-15 17:57:47,291 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
2021-04-15 17:57:47,292 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2021-04-15 17:57:47,292 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
2021-04-15 17:57:47,292 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2021-04-15 17:57:47,292 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: true
2021-04-15 17:57:47,292 DEBUG o.a.f.s.netty4.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2021-04-15 17:57:47,298 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
2021-04-15 17:57:47,299 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 0
2021-04-15 17:57:47,299 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
2021-04-15 17:57:47,315 DEBUG o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Binding rest endpoint to null:0.
2021-04-15 17:57:47,315 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Rest endpoint listening at localhost:62363
2021-04-15 17:57:47,318 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender http://localhost:62363
2021-04-15 17:57:47,321 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - http://localhost:62363 was granted leadership with leaderSessionID=17cee242-4e92-4911-a4e5-09e5ba1f09d1
2021-04-15 17:57:47,321 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader http://localhost:62363 , session=17cee242-4e92-4911-a4e5-09e5ba1f09d1
2021-04-15 17:57:47,334 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting FencedAkkaRpcActor with name resourcemanager_1.
2021-04-15 17:57:47,334 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_1 .
2021-04-15 17:57:47,345 DEBUG o.a.f.r.e.c.DefaultDispatcherResourceManagerComponentFactory - Starting Dispatcher.
2021-04-15 17:57:47,348 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
2021-04-15 17:57:47,348 DEBUG o.a.f.r.e.c.DefaultDispatcherResourceManagerComponentFactory - Starting ResourceManager.
2021-04-15 17:57:47,349 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: StandaloneResourceManager
2021-04-15 17:57:47,349 DEBUG o.a.f.runtime.dispatcher.runner.DefaultDispatcherRunner - Create new DispatcherLeaderProcess with leader session id 42c92951-b2ff-4146-b5d4-e1a033f51288.
2021-04-15 17:57:47,351 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - ResourceManager akka://flink/user/rpc/resourcemanager_1 was granted leadership with fencing token 99eb21b89c2406d40dfb84b2b1f84bcc
2021-04-15 17:57:47,353 INFO org.apache.flink.runtime.minicluster.MiniCluster - Flink Mini Cluster started successfully
2021-04-15 17:57:47,354 INFO o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Starting the SlotManager.
2021-04-15 17:57:47,355 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Start SessionDispatcherLeaderProcess.
2021-04-15 17:57:47,358 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:57:47,359 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
2021-04-15 17:57:47,360 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Recover all persisted job graphs.
2021-04-15 17:57:47,361 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/resourcemanager_1 , session=0dfb84b2-b1f8-4bcc-99eb-21b89c2406d4
2021-04-15 17:57:47,361 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Successfully recovered 0 persisted job graphs.
2021-04-15 17:57:47,363 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:57:47,364 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(99eb21b89c2406d40dfb84b2b1f84bcc).
2021-04-15 17:57:47,368 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:57:47,368 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting FencedAkkaRpcActor with name dispatcher_2.
2021-04-15 17:57:47,372 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_2 .
2021-04-15 17:57:47,375 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:57:47,384 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/dispatcher_2 , session=42c92951-b2ff-4146-b5d4-e1a033f51288
2021-04-15 17:57:47,385 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/dispatcher_2. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
2021-04-15 17:57:47,385 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/dispatcher_2. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
2021-04-15 17:57:47,390 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Resolved ResourceManager address, beginning registration
2021-04-15 17:57:47,390 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Registration at ResourceManager attempt 1 (timeout=100ms)
2021-04-15 17:57:47,394 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
2021-04-15 17:57:47,402 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Registering TaskManager with ResourceID 5825669a-8d86-4e2a-99d8-ca5e01d959fa (akka://flink/user/rpc/taskmanager_0) at ResourceManager
2021-04-15 17:57:47,403 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Received JobGraph submission 4202ea6720b3ddc8c9b3f82ef324fcdc (Flink Streaming Job).
2021-04-15 17:57:47,404 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Submitting job 4202ea6720b3ddc8c9b3f82ef324fcdc (Flink Streaming Job).
2021-04-15 17:57:47,404 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Successful registration at resource manager akka://flink/user/rpc/resourcemanager_1 under registration id 3ffd65fb658322224a5495ed94311761.
2021-04-15 17:57:47,406 DEBUG o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Registering TaskManager 5825669a-8d86-4e2a-99d8-ca5e01d959fa under 3ffd65fb658322224a5495ed94311761 at the SlotManager.
2021-04-15 17:57:47,415 DEBUG org.apache.flink.client.ClientUtils - Wait until job initialization is finished
2021-04-15 17:57:47,424 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: JobManagerRunnerImpl
2021-04-15 17:57:47,433 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Starting FencedAkkaRpcActor with name jobmanager_3.
2021-04-15 17:57:47,434 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
2021-04-15 17:57:47,442 INFO org.apache.flink.runtime.jobmaster.JobMaster - Initializing job Flink Streaming Job (4202ea6720b3ddc8c9b3f82ef324fcdc).
2021-04-15 17:57:47,456 INFO org.apache.flink.runtime.jobmaster.JobMaster - Using restart back off time strategy NoRestartBackoffTimeStrategy for Flink Streaming Job (4202ea6720b3ddc8c9b3f82ef324fcdc).
2021-04-15 17:57:47,486 INFO org.apache.flink.runtime.jobmaster.JobMaster - Running initialization on master for job Flink Streaming Job (4202ea6720b3ddc8c9b3f82ef324fcdc).
2021-04-15 17:57:47,486 INFO org.apache.flink.runtime.jobmaster.JobMaster - Successfully ran initialization on master in 0 ms.
2021-04-15 17:57:47,486 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Adding 10 vertices from job graph Flink Streaming Job (4202ea6720b3ddc8c9b3f82ef324fcdc).
2021-04-15 17:57:47,486 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Attaching 10 topologically sorted vertices to existing job graph with 0 vertices and 0 intermediate results.
2021-04-15 17:57:47,495 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex bc764cd8ddf7a0cff126f51c16239658 (Source: Custom File source) to 0 predecessors.
2021-04-15 17:57:47,495 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex feca28aff5a3958840bee985ee7de4d3 (Source: Custom File source) to 0 predecessors.
2021-04-15 17:57:47,496 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex 605b35e407e90cda15ad084365733fdd (Source: Custom File source) to 0 predecessors.
2021-04-15 17:57:47,496 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex 3ba1d27b7fde4848a86e865c6c402dfa (Source: Custom File source) to 0 predecessors.
2021-04-15 17:57:47,496 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex 77af20c908aca598f7bbebd4db138545 (CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out) to 1 predecessors.
2021-04-15 17:57:47,496 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting input 0 of vertex 77af20c908aca598f7bbebd4db138545 (CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out) to intermediate result referenced via predecessor bc764cd8ddf7a0cff126f51c16239658 (Source: Custom File source).
2021-04-15 17:57:47,496 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex b23642197a427ec5db481d3963c66cfb (CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out) to 1 predecessors.
2021-04-15 17:57:47,496 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting input 0 of vertex b23642197a427ec5db481d3963c66cfb (CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out) to intermediate result referenced via predecessor feca28aff5a3958840bee985ee7de4d3 (Source: Custom File source).
2021-04-15 17:57:47,496 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex a19bdf930ebdf056b3d6de069bc89bdd (CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp])) to 1 predecessors.
2021-04-15 17:57:47,496 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting input 0 of vertex a19bdf930ebdf056b3d6de069bc89bdd (CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp])) to intermediate result referenced via predecessor 605b35e407e90cda15ad084365733fdd (Source: Custom File source).
2021-04-15 17:57:47,496 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex 6177eb422127981c4dbb05ea3af8a2d4 (GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out) to 1 predecessors.
2021-04-15 17:57:47,496 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting input 0 of vertex 6177eb422127981c4dbb05ea3af8a2d4 (GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out) to intermediate result referenced via predecessor a19bdf930ebdf056b3d6de069bc89bdd (CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp])).
2021-04-15 17:57:47,497 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex aecbb8a11dc0c28dc6c178e875ebcc43 (CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp])) to 1 predecessors.
2021-04-15 17:57:47,497 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting input 0 of vertex aecbb8a11dc0c28dc6c178e875ebcc43 (CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp])) to intermediate result referenced via predecessor 3ba1d27b7fde4848a86e865c6c402dfa (Source: Custom File source).
2021-04-15 17:57:47,497 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting ExecutionJobVertex 5528b14a6b129894d24927c518acc32a (GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out) to 1 predecessors.
2021-04-15 17:57:47,497 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Connecting input 0 of vertex 5528b14a6b129894d24927c518acc32a (GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out) to intermediate result referenced via predecessor aecbb8a11dc0c28dc6c178e875ebcc43 (CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp])).
2021-04-15 17:57:47,502 INFO o.a.f.r.scheduler.adapter.DefaultExecutionTopology - Built 4 pipelined regions in 0 ms
2021-04-15 17:57:47,503 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Successfully created execution graph from job graph Flink Streaming Job (4202ea6720b3ddc8c9b3f82ef324fcdc).
2021-04-15 17:57:47,516 INFO org.apache.flink.runtime.jobmaster.JobMaster - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:57:47,531 DEBUG o.apache.flink.runtime.checkpoint.CheckpointCoordinator - Status of the shared state registry of job 4202ea6720b3ddc8c9b3f82ef324fcdc after restore: SharedStateRegistry{registeredStates={}}.
2021-04-15 17:57:47,531 INFO o.apache.flink.runtime.checkpoint.CheckpointCoordinator - No checkpoint found during restore.
2021-04-15 17:57:47,533 INFO org.apache.flink.runtime.jobmaster.JobMaster - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@6d77a6f8 for Flink Streaming Job (4202ea6720b3ddc8c9b3f82ef324fcdc).
2021-04-15 17:57:47,544 INFO org.apache.flink.runtime.jobmaster.JobManagerRunnerImpl - JobManager runner for job Flink Streaming Job (4202ea6720b3ddc8c9b3f82ef324fcdc) was granted leadership with session id f154de81-bc5b-4727-88d9-0394f4c80399 at akka://flink/user/rpc/jobmanager_3.
2021-04-15 17:57:47,548 INFO org.apache.flink.runtime.jobmaster.JobMaster - Starting execution of job Flink Streaming Job (4202ea6720b3ddc8c9b3f82ef324fcdc) under job master id 88d90394f4c80399f154de81bc5b4727.
2021-04-15 17:57:47,550 INFO org.apache.flink.runtime.jobmaster.JobMaster - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2021-04-15 17:57:47,550 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Job Flink Streaming Job (4202ea6720b3ddc8c9b3f82ef324fcdc) switched from state CREATED to RUNNING.
2021-04-15 17:57:47,555 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (56a8a7eaf61a1c9778ec2910a7e8b378) switched from CREATED to SCHEDULED.
2021-04-15 17:57:47,555 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1) (0bd850202103b66807f1ab92cd4c2d87) switched from CREATED to SCHEDULED.
2021-04-15 17:57:47,571 DEBUG o.a.f.r.jobmaster.slotpool.PhysicalSlotProviderImpl - Received slot request [SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8}] with resource requirements: ResourceProfile{UNKNOWN}
2021-04-15 17:57:47,575 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8}]
2021-04-15 17:57:47,578 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{d9934b227092dad05c6f5b66420bc4dd}) for execution vertex (id bc764cd8ddf7a0cff126f51c16239658_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:47,582 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{051965ca28d42de89a07a022a3dd2ca6}) for execution vertex (id 77af20c908aca598f7bbebd4db138545_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:47,588 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (92aa1adebb2d1dc1601d0f7f4a004df2) switched from CREATED to SCHEDULED.
2021-04-15 17:57:47,588 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1) (e5911ca3febd32cb141752fc539271cb) switched from CREATED to SCHEDULED.
2021-04-15 17:57:47,588 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{1a87552f8a7062503ca02711bd24dac4}) for execution vertex (id feca28aff5a3958840bee985ee7de4d3_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:47,589 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{befec021a1fc4559379be6dc0f63a1f2}) for execution vertex (id b23642197a427ec5db481d3963c66cfb_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:47,589 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (962280473929e656fa9a072f81a110fc) switched from CREATED to SCHEDULED.
2021-04-15 17:57:47,589 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1) (0c86dd8ae9385e8de4892823517d828a) switched from CREATED to SCHEDULED.
2021-04-15 17:57:47,589 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1) (543e948d2479323821cf9240a4cf531c) switched from CREATED to SCHEDULED.
2021-04-15 17:57:47,589 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{81e6ddc90fe8fd184c21a67ec0aa8720}) for execution vertex (id 605b35e407e90cda15ad084365733fdd_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:47,589 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{c372b731ac3a85a1363c047265d823cf}) for execution vertex (id a19bdf930ebdf056b3d6de069bc89bdd_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:47,589 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{748b7d08cf0c4d7584d04c0c2a99599f}) for execution vertex (id 6177eb422127981c4dbb05ea3af8a2d4_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:47,590 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (f38e7381ef80e4fcfb1a02e00ec66f00) switched from CREATED to SCHEDULED.
2021-04-15 17:57:47,590 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1) (83787021e7a56db67c8fd5ee21262bc8) switched from CREATED to SCHEDULED.
2021-04-15 17:57:47,590 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1) (4c48ef46868aeabfa4c1687d52cd0352) switched from CREATED to SCHEDULED.
2021-04-15 17:57:47,590 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{a4e3f5a6275ea538b362bd2665892b25}) for execution vertex (id 3ba1d27b7fde4848a86e865c6c402dfa_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:47,590 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{ecc6474d1a1ef6a742e529fe1034ce02}) for execution vertex (id aecbb8a11dc0c28dc6c178e875ebcc43_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:47,590 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Request a logical slot (SlotRequestId{317da2b0fc07f6c82b370f5da9864a30}) for execution vertex (id 5528b14a6b129894d24927c518acc32a_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:47,591 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
2021-04-15 17:57:47,593 INFO o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/jobmanager_3 , session=f154de81-bc5b-4727-88d9-0394f4c80399
2021-04-15 17:57:47,593 INFO org.apache.flink.runtime.jobmaster.JobMaster - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(99eb21b89c2406d40dfb84b2b1f84bcc)
2021-04-15 17:57:47,598 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2021-04-15 17:57:47,600 INFO org.apache.flink.runtime.jobmaster.JobMaster - Resolved ResourceManager address, beginning registration
2021-04-15 17:57:47,600 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Registration at ResourceManager attempt 1 (timeout=100ms)
2021-04-15 17:57:47,601 DEBUG o.a.flink.runtime.resourcemanager.JobLeaderIdService - Add job 4202ea6720b3ddc8c9b3f82ef324fcdc to job leader id monitoring.
2021-04-15 17:57:47,605 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Registering job manager 88d90394f4c80399f154de81bc5b4727@akka://flink/user/rpc/jobmanager_3 for job 4202ea6720b3ddc8c9b3f82ef324fcdc.
2021-04-15 17:57:47,605 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/jobmanager_3. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2021-04-15 17:57:47,606 DEBUG o.a.flink.runtime.resourcemanager.JobLeaderIdService - Found a new job leader f154de81-bc5b-4727-88d9-0394f4c80399@akka://flink/user/rpc/jobmanager_3.
2021-04-15 17:57:47,617 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Registered job manager 88d90394f4c80399f154de81bc5b4727@akka://flink/user/rpc/jobmanager_3 for job 4202ea6720b3ddc8c9b3f82ef324fcdc.
2021-04-15 17:57:47,619 INFO org.apache.flink.runtime.jobmaster.JobMaster - JobManager successfully registered at ResourceManager, leader id: 99eb21b89c2406d40dfb84b2b1f84bcc.
2021-04-15 17:57:47,621 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8}] and profile ResourceProfile{UNKNOWN} with allocation id 915191b9e9164762cfcc8afd3e693a9f from resource manager.
2021-04-15 17:57:47,621 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 4202ea6720b3ddc8c9b3f82ef324fcdc with allocation id 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,625 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 915191b9e9164762cfcc8afd3e693a9f for job 4202ea6720b3ddc8c9b3f82ef324fcdc from resource manager with leader id 99eb21b89c2406d40dfb84b2b1f84bcc.
2021-04-15 17:57:47,633 DEBUG org.apache.flink.runtime.memory.MemoryManager - Initialized MemoryManager with total memory size 134217728 and page size 32768.
2021-04-15 17:57:47,634 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,636 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Add job 4202ea6720b3ddc8c9b3f82ef324fcdc for job leader monitoring.
2021-04-15 17:57:47,637 DEBUG o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - New leader information for job 4202ea6720b3ddc8c9b3f82ef324fcdc. Address: akka://flink/user/rpc/jobmanager_3, leader id: 88d90394f4c80399f154de81bc5b4727.
2021-04-15 17:57:47,638 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Try to register at job manager akka://flink/user/rpc/jobmanager_3 with leader id f154de81-bc5b-4727-88d9-0394f4c80399.
2021-04-15 17:57:47,638 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/jobmanager_3. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2021-04-15 17:57:47,639 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Resolved JobManager address, beginning registration
2021-04-15 17:57:47,639 DEBUG o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Registration at JobManager attempt 1 (timeout=100ms)
2021-04-15 17:57:47,641 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
2021-04-15 17:57:47,645 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Register new TaskExecutor 5825669a-8d86-4e2a-99d8-ca5e01d959fa.
2021-04-15 17:57:47,648 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Successful registration at job manager akka://flink/user/rpc/jobmanager_3 for job 4202ea6720b3ddc8c9b3f82ef324fcdc.
2021-04-15 17:57:47,649 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Establish JobManager connection for job 4202ea6720b3ddc8c9b3f82ef324fcdc.
2021-04-15 17:57:47,653 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Offer reserved slots to the leader of job 4202ea6720b3ddc8c9b3f82ef324fcdc.
2021-04-15 17:57:47,656 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Fulfilling pending slot request [SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8}] with slot [915191b9e9164762cfcc8afd3e693a9f]
2021-04-15 17:57:47,656 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{d9934b227092dad05c6f5b66420bc4dd}) for execution vertex (id bc764cd8ddf7a0cff126f51c16239658_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:47,663 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{051965ca28d42de89a07a022a3dd2ca6}) for execution vertex (id 77af20c908aca598f7bbebd4db138545_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:47,664 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (56a8a7eaf61a1c9778ec2910a7e8b378) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:57:47,664 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom File source (1/1) (attempt #0) with attempt id 56a8a7eaf61a1c9778ec2910a7e8b378 to 5825669a-8d86-4e2a-99d8-ca5e01d959fa @ server1 (dataPort=-1) with allocation id 915191b9e9164762cfcc8afd3e693a9f
2021-04-15 17:57:47,673 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1) (0bd850202103b66807f1ab92cd4c2d87) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:57:47,673 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1) (attempt #0) with attempt id 0bd850202103b66807f1ab92cd4c2d87 to 5825669a-8d86-4e2a-99d8-ca5e01d959fa @ server1 (dataPort=-1) with allocation id 915191b9e9164762cfcc8afd3e693a9f
2021-04-15 17:57:47,674 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,679 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{1a87552f8a7062503ca02711bd24dac4}) for execution vertex (id feca28aff5a3958840bee985ee7de4d3_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:47,679 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{befec021a1fc4559379be6dc0f63a1f2}) for execution vertex (id b23642197a427ec5db481d3963c66cfb_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:47,680 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (92aa1adebb2d1dc1601d0f7f4a004df2) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:57:47,680 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom File source (1/1) (attempt #0) with attempt id 92aa1adebb2d1dc1601d0f7f4a004df2 to 5825669a-8d86-4e2a-99d8-ca5e01d959fa @ server1 (dataPort=-1) with allocation id 915191b9e9164762cfcc8afd3e693a9f
2021-04-15 17:57:47,680 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1) (e5911ca3febd32cb141752fc539271cb) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:57:47,680 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1) (attempt #0) with attempt id e5911ca3febd32cb141752fc539271cb to 5825669a-8d86-4e2a-99d8-ca5e01d959fa @ server1 (dataPort=-1) with allocation id 915191b9e9164762cfcc8afd3e693a9f
2021-04-15 17:57:47,681 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{81e6ddc90fe8fd184c21a67ec0aa8720}) for execution vertex (id 605b35e407e90cda15ad084365733fdd_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:47,682 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{c372b731ac3a85a1363c047265d823cf}) for execution vertex (id a19bdf930ebdf056b3d6de069bc89bdd_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:47,682 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{748b7d08cf0c4d7584d04c0c2a99599f}) for execution vertex (id 6177eb422127981c4dbb05ea3af8a2d4_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:47,682 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (962280473929e656fa9a072f81a110fc) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:57:47,683 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom File source (1/1) (attempt #0) with attempt id 962280473929e656fa9a072f81a110fc to 5825669a-8d86-4e2a-99d8-ca5e01d959fa @ server1 (dataPort=-1) with allocation id 915191b9e9164762cfcc8afd3e693a9f
2021-04-15 17:57:47,684 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1) (0c86dd8ae9385e8de4892823517d828a) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:57:47,684 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1) (attempt #0) with attempt id 0c86dd8ae9385e8de4892823517d828a to 5825669a-8d86-4e2a-99d8-ca5e01d959fa @ server1 (dataPort=-1) with allocation id 915191b9e9164762cfcc8afd3e693a9f
2021-04-15 17:57:47,685 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1) (543e948d2479323821cf9240a4cf531c) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:57:47,685 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1) (attempt #0) with attempt id 543e948d2479323821cf9240a4cf531c to 5825669a-8d86-4e2a-99d8-ca5e01d959fa @ server1 (dataPort=-1) with allocation id 915191b9e9164762cfcc8afd3e693a9f
2021-04-15 17:57:47,685 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{a4e3f5a6275ea538b362bd2665892b25}) for execution vertex (id 3ba1d27b7fde4848a86e865c6c402dfa_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:47,685 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{ecc6474d1a1ef6a742e529fe1034ce02}) for execution vertex (id aecbb8a11dc0c28dc6c178e875ebcc43_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:47,685 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Allocated logical slot (SlotRequestId{317da2b0fc07f6c82b370f5da9864a30}) for execution vertex (id 5528b14a6b129894d24927c518acc32a_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:47,685 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (f38e7381ef80e4fcfb1a02e00ec66f00) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:57:47,685 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom File source (1/1) (attempt #0) with attempt id f38e7381ef80e4fcfb1a02e00ec66f00 to 5825669a-8d86-4e2a-99d8-ca5e01d959fa @ server1 (dataPort=-1) with allocation id 915191b9e9164762cfcc8afd3e693a9f
2021-04-15 17:57:47,686 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1) (83787021e7a56db67c8fd5ee21262bc8) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:57:47,686 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1) (attempt #0) with attempt id 83787021e7a56db67c8fd5ee21262bc8 to 5825669a-8d86-4e2a-99d8-ca5e01d959fa @ server1 (dataPort=-1) with allocation id 915191b9e9164762cfcc8afd3e693a9f
2021-04-15 17:57:47,686 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1) (4c48ef46868aeabfa4c1687d52cd0352) switched from SCHEDULED to DEPLOYING.
2021-04-15 17:57:47,686 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1) (attempt #0) with attempt id 4c48ef46868aeabfa4c1687d52cd0352 to 5825669a-8d86-4e2a-99d8-ca5e01d959fa @ server1 (dataPort=-1) with allocation id 915191b9e9164762cfcc8afd3e693a9f
2021-04-15 17:57:47,690 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new allocation id 915191b9e9164762cfcc8afd3e693a9f for local state stores for job 4202ea6720b3ddc8c9b3f82ef324fcdc.
2021-04-15 17:57:47,694 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_915191b9e9164762cfcc8afd3e693a9f], jobID=4202ea6720b3ddc8c9b3f82ef324fcdc, jobVertexID=bc764cd8ddf7a0cff126f51c16239658, subtaskIndex=0}} for 4202ea6720b3ddc8c9b3f82ef324fcdc - bc764cd8ddf7a0cff126f51c16239658 - 0 under allocation id 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,711 DEBUG o.a.f.r.io.network.partition.ResultPartitionFactory - Source: Custom File source (1/1)#0 (56a8a7eaf61a1c9778ec2910a7e8b378): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@240acf7b
2021-04-15 17:57:47,717 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom File source (1/1)#0 (56a8a7eaf61a1c9778ec2910a7e8b378), deploy into slot with allocation id 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,718 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File source (1/1)#0 (56a8a7eaf61a1c9778ec2910a7e8b378) switched from CREATED to DEPLOYING.
2021-04-15 17:57:47,718 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Source: Custom File source (1/1)#0 (56a8a7eaf61a1c9778ec2910a7e8b378) [DEPLOYING]
2021-04-15 17:57:47,720 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,732 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_915191b9e9164762cfcc8afd3e693a9f], jobID=4202ea6720b3ddc8c9b3f82ef324fcdc, jobVertexID=77af20c908aca598f7bbebd4db138545, subtaskIndex=0}} for 4202ea6720b3ddc8c9b3f82ef324fcdc - 77af20c908aca598f7bbebd4db138545 - 0 under allocation id 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,751 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (0bd850202103b66807f1ab92cd4c2d87): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:57:47,758 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (0bd850202103b66807f1ab92cd4c2d87), deploy into slot with allocation id 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,759 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,775 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_915191b9e9164762cfcc8afd3e693a9f], jobID=4202ea6720b3ddc8c9b3f82ef324fcdc, jobVertexID=feca28aff5a3958840bee985ee7de4d3, subtaskIndex=0}} for 4202ea6720b3ddc8c9b3f82ef324fcdc - feca28aff5a3958840bee985ee7de4d3 - 0 under allocation id 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,775 DEBUG o.a.f.r.io.network.partition.ResultPartitionFactory - Source: Custom File source (1/1)#0 (92aa1adebb2d1dc1601d0f7f4a004df2): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@240acf7b
2021-04-15 17:57:47,776 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom File source (1/1)#0 (92aa1adebb2d1dc1601d0f7f4a004df2), deploy into slot with allocation id 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,777 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,781 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_915191b9e9164762cfcc8afd3e693a9f], jobID=4202ea6720b3ddc8c9b3f82ef324fcdc, jobVertexID=b23642197a427ec5db481d3963c66cfb, subtaskIndex=0}} for 4202ea6720b3ddc8c9b3f82ef324fcdc - b23642197a427ec5db481d3963c66cfb - 0 under allocation id 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,782 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (e5911ca3febd32cb141752fc539271cb): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:57:47,783 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (e5911ca3febd32cb141752fc539271cb), deploy into slot with allocation id 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,784 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,784 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,786 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_915191b9e9164762cfcc8afd3e693a9f], jobID=4202ea6720b3ddc8c9b3f82ef324fcdc, jobVertexID=605b35e407e90cda15ad084365733fdd, subtaskIndex=0}} for 4202ea6720b3ddc8c9b3f82ef324fcdc - 605b35e407e90cda15ad084365733fdd - 0 under allocation id 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,787 DEBUG o.a.f.r.io.network.partition.ResultPartitionFactory - Source: Custom File source (1/1)#0 (962280473929e656fa9a072f81a110fc): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@240acf7b
2021-04-15 17:57:47,795 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom File source (1/1)#0 (962280473929e656fa9a072f81a110fc), deploy into slot with allocation id 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,800 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,805 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_915191b9e9164762cfcc8afd3e693a9f], jobID=4202ea6720b3ddc8c9b3f82ef324fcdc, jobVertexID=a19bdf930ebdf056b3d6de069bc89bdd, subtaskIndex=0}} for 4202ea6720b3ddc8c9b3f82ef324fcdc - a19bdf930ebdf056b3d6de069bc89bdd - 0 under allocation id 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,806 DEBUG o.a.f.r.io.network.partition.ResultPartitionFactory - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (0c86dd8ae9385e8de4892823517d828a): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@240acf7b
2021-04-15 17:57:47,806 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (0c86dd8ae9385e8de4892823517d828a): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:57:47,806 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (0c86dd8ae9385e8de4892823517d828a), deploy into slot with allocation id 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,806 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,818 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom File source (1/1)#0 (56a8a7eaf61a1c9778ec2910a7e8b378) [DEPLOYING].
2021-04-15 17:57:47,819 INFO org.apache.flink.runtime.taskmanager.Task - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (e5911ca3febd32cb141752fc539271cb) switched from CREATED to DEPLOYING.
2021-04-15 17:57:47,819 INFO org.apache.flink.runtime.taskmanager.Task - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (0bd850202103b66807f1ab92cd4c2d87) switched from CREATED to DEPLOYING.
2021-04-15 17:57:47,819 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File source (1/1)#0 (92aa1adebb2d1dc1601d0f7f4a004df2) switched from CREATED to DEPLOYING.
2021-04-15 17:57:47,820 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (e5911ca3febd32cb141752fc539271cb) [DEPLOYING]
2021-04-15 17:57:47,820 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (0bd850202103b66807f1ab92cd4c2d87) [DEPLOYING]
2021-04-15 17:57:47,820 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 56a8a7eaf61a1c9778ec2910a7e8b378 at library cache manager took 2 milliseconds
2021-04-15 17:57:47,828 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Source: Custom File source (1/1)#0 (92aa1adebb2d1dc1601d0f7f4a004df2) [DEPLOYING]
2021-04-15 17:57:47,828 INFO org.apache.flink.runtime.taskmanager.Task - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (0c86dd8ae9385e8de4892823517d828a) switched from CREATED to DEPLOYING.
2021-04-15 17:57:47,828 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_915191b9e9164762cfcc8afd3e693a9f], jobID=4202ea6720b3ddc8c9b3f82ef324fcdc, jobVertexID=6177eb422127981c4dbb05ea3af8a2d4, subtaskIndex=0}} for 4202ea6720b3ddc8c9b3f82ef324fcdc - 6177eb422127981c4dbb05ea3af8a2d4 - 0 under allocation id 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,829 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File source (1/1)#0 (962280473929e656fa9a072f81a110fc) switched from CREATED to DEPLOYING.
2021-04-15 17:57:47,830 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (e5911ca3febd32cb141752fc539271cb) [DEPLOYING].
2021-04-15 17:57:47,830 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (0bd850202103b66807f1ab92cd4c2d87) [DEPLOYING].
2021-04-15 17:57:47,832 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom File source (1/1)#0 (92aa1adebb2d1dc1601d0f7f4a004df2) [DEPLOYING].
2021-04-15 17:57:47,839 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (0c86dd8ae9385e8de4892823517d828a) [DEPLOYING]
2021-04-15 17:57:47,840 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (543e948d2479323821cf9240a4cf531c): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:57:47,840 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom File source (1/1)#0 (56a8a7eaf61a1c9778ec2910a7e8b378) [DEPLOYING].
2021-04-15 17:57:47,840 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Source: Custom File source (1/1)#0 (962280473929e656fa9a072f81a110fc) [DEPLOYING]
2021-04-15 17:57:47,842 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task e5911ca3febd32cb141752fc539271cb at library cache manager took 2 milliseconds
2021-04-15 17:57:47,842 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 0bd850202103b66807f1ab92cd4c2d87 at library cache manager took 0 milliseconds
2021-04-15 17:57:47,843 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 92aa1adebb2d1dc1601d0f7f4a004df2 at library cache manager took 0 milliseconds
2021-04-15 17:57:47,843 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (0c86dd8ae9385e8de4892823517d828a) [DEPLOYING].
2021-04-15 17:57:47,843 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (543e948d2479323821cf9240a4cf531c), deploy into slot with allocation id 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,843 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom File source (1/1)#0 (962280473929e656fa9a072f81a110fc) [DEPLOYING].
2021-04-15 17:57:47,844 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (e5911ca3febd32cb141752fc539271cb) [DEPLOYING].
2021-04-15 17:57:47,848 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (0bd850202103b66807f1ab92cd4c2d87) [DEPLOYING].
2021-04-15 17:57:47,850 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 2-10 buffers
2021-04-15 17:57:47,850 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom File source (1/1)#0 (92aa1adebb2d1dc1601d0f7f4a004df2) [DEPLOYING].
2021-04-15 17:57:47,850 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 0c86dd8ae9385e8de4892823517d828a at library cache manager took 0 milliseconds
2021-04-15 17:57:47,850 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 962280473929e656fa9a072f81a110fc at library cache manager took 0 milliseconds
2021-04-15 17:57:47,850 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,851 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Registered PipelinedResultPartition 16fc7cab54c1def2c796d236a0a0270d#0@56a8a7eaf61a1c9778ec2910a7e8b378 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:57:47,851 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 2-10 buffers
2021-04-15 17:57:47,852 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (0c86dd8ae9385e8de4892823517d828a) [DEPLOYING].
2021-04-15 17:57:47,852 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - registering 16fc7cab54c1def2c796d236a0a0270d#0@56a8a7eaf61a1c9778ec2910a7e8b378
2021-04-15 17:57:47,852 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom File source (1/1)#0 (962280473929e656fa9a072f81a110fc) [DEPLOYING].
2021-04-15 17:57:47,854 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Registered PipelinedResultPartition 2d7690046e5016dcca8b03287d230aa7#0@92aa1adebb2d1dc1601d0f7f4a004df2 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:57:47,854 INFO org.apache.flink.runtime.taskmanager.Task - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (543e948d2479323821cf9240a4cf531c) switched from CREATED to DEPLOYING.
2021-04-15 17:57:47,854 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_915191b9e9164762cfcc8afd3e693a9f], jobID=4202ea6720b3ddc8c9b3f82ef324fcdc, jobVertexID=3ba1d27b7fde4848a86e865c6c402dfa, subtaskIndex=0}} for 4202ea6720b3ddc8c9b3f82ef324fcdc - 3ba1d27b7fde4848a86e865c6c402dfa - 0 under allocation id 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,854 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (543e948d2479323821cf9240a4cf531c) [DEPLOYING]
2021-04-15 17:57:47,854 DEBUG o.a.f.r.io.network.partition.ResultPartitionFactory - Source: Custom File source (1/1)#0 (f38e7381ef80e4fcfb1a02e00ec66f00): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@240acf7b
2021-04-15 17:57:47,854 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (543e948d2479323821cf9240a4cf531c) [DEPLOYING].
2021-04-15 17:57:47,855 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 543e948d2479323821cf9240a4cf531c at library cache manager took 0 milliseconds
2021-04-15 17:57:47,855 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom File source (1/1)#0 (f38e7381ef80e4fcfb1a02e00ec66f00), deploy into slot with allocation id 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,855 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,856 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_915191b9e9164762cfcc8afd3e693a9f], jobID=4202ea6720b3ddc8c9b3f82ef324fcdc, jobVertexID=aecbb8a11dc0c28dc6c178e875ebcc43, subtaskIndex=0}} for 4202ea6720b3ddc8c9b3f82ef324fcdc - aecbb8a11dc0c28dc6c178e875ebcc43 - 0 under allocation id 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,856 DEBUG o.a.f.r.io.network.partition.ResultPartitionFactory - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (83787021e7a56db67c8fd5ee21262bc8): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@240acf7b
2021-04-15 17:57:47,857 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (83787021e7a56db67c8fd5ee21262bc8): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:57:47,855 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (543e948d2479323821cf9240a4cf531c) [DEPLOYING].
2021-04-15 17:57:47,857 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (83787021e7a56db67c8fd5ee21262bc8), deploy into slot with allocation id 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,858 INFO o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,860 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\ccy\AppData\Local\Temp\localState\aid_915191b9e9164762cfcc8afd3e693a9f], jobID=4202ea6720b3ddc8c9b3f82ef324fcdc, jobVertexID=5528b14a6b129894d24927c518acc32a, subtaskIndex=0}} for 4202ea6720b3ddc8c9b3f82ef324fcdc - 5528b14a6b129894d24927c518acc32a - 0 under allocation id 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,860 DEBUG o.a.f.r.i.n.partition.consumer.SingleInputGateFactory - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (4c48ef46868aeabfa4c1687d52cd0352): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2021-04-15 17:57:47,860 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File source (1/1)#0 (f38e7381ef80e4fcfb1a02e00ec66f00) switched from CREATED to DEPLOYING.
2021-04-15 17:57:47,860 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (4c48ef46868aeabfa4c1687d52cd0352), deploy into slot with allocation id 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:47,860 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task Source: Custom File source (1/1)#0 (f38e7381ef80e4fcfb1a02e00ec66f00) [DEPLOYING]
2021-04-15 17:57:47,861 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom File source (1/1)#0 (f38e7381ef80e4fcfb1a02e00ec66f00) [DEPLOYING].
2021-04-15 17:57:47,861 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task f38e7381ef80e4fcfb1a02e00ec66f00 at library cache manager took 0 milliseconds
2021-04-15 17:57:47,861 INFO org.apache.flink.runtime.taskmanager.Task - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (83787021e7a56db67c8fd5ee21262bc8) switched from CREATED to DEPLOYING.
2021-04-15 17:57:47,861 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (83787021e7a56db67c8fd5ee21262bc8) [DEPLOYING]
2021-04-15 17:57:47,861 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (83787021e7a56db67c8fd5ee21262bc8) [DEPLOYING].
2021-04-15 17:57:47,861 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 83787021e7a56db67c8fd5ee21262bc8 at library cache manager took 0 milliseconds
2021-04-15 17:57:47,862 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom File source (1/1)#0 (f38e7381ef80e4fcfb1a02e00ec66f00) [DEPLOYING].
2021-04-15 17:57:47,862 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (83787021e7a56db67c8fd5ee21262bc8) [DEPLOYING].
2021-04-15 17:57:47,862 INFO org.apache.flink.runtime.taskmanager.Task - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (4c48ef46868aeabfa4c1687d52cd0352) switched from CREATED to DEPLOYING.
2021-04-15 17:57:47,863 DEBUG org.apache.flink.runtime.taskmanager.Task - Creating FileSystem stream leak safety net for task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (4c48ef46868aeabfa4c1687d52cd0352) [DEPLOYING]
2021-04-15 17:57:47,863 INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (4c48ef46868aeabfa4c1687d52cd0352) [DEPLOYING].
2021-04-15 17:57:47,863 DEBUG org.apache.flink.runtime.taskmanager.Task - Getting user code class loader for task 4c48ef46868aeabfa4c1687d52cd0352 at library cache manager took 0 milliseconds
2021-04-15 17:57:47,863 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:57:47,864 INFO org.apache.flink.runtime.taskmanager.Task - Registering task at network: GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (4c48ef46868aeabfa4c1687d52cd0352) [DEPLOYING].
2021-04-15 17:57:47,865 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:57:47,866 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:57:47,869 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 2-10 buffers
2021-04-15 17:57:47,870 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Registered PipelinedResultPartition a1e6df2fa256a56d4f8621bc68aee12b#0@83787021e7a56db67c8fd5ee21262bc8 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:57:47,870 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:57:47,874 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 2-10 buffers
2021-04-15 17:57:47,875 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - registering 2d7690046e5016dcca8b03287d230aa7#0@92aa1adebb2d1dc1601d0f7f4a004df2
2021-04-15 17:57:47,876 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - registering a1e6df2fa256a56d4f8621bc68aee12b#0@83787021e7a56db67c8fd5ee21262bc8
2021-04-15 17:57:47,877 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Using partitioner FORWARD for output 0 of task Source: Custom File source
2021-04-15 17:57:47,879 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Using partitioner FORWARD for output 0 of task Source: Custom File source
2021-04-15 17:57:47,882 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Registered PipelinedResultPartition ddcafd25d8473f83e72837e4b4ab9a82#0@f38e7381ef80e4fcfb1a02e00ec66f00 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:57:47,882 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - registering ddcafd25d8473f83e72837e4b4ab9a82#0@f38e7381ef80e4fcfb1a02e00ec66f00
2021-04-15 17:57:47,882 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Using partitioner FORWARD for output 0 of task Source: Custom File source
2021-04-15 17:57:47,884 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Using partitioner HASH for output 0 of task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp])
2021-04-15 17:57:47,885 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:57:47,889 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 2-10 buffers
2021-04-15 17:57:47,890 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Registered PipelinedResultPartition c30d3d8915267dd583f3c188b245bc98#0@962280473929e656fa9a072f81a110fc [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:57:47,890 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - registering c30d3d8915267dd583f3c188b245bc98#0@962280473929e656fa9a072f81a110fc
2021-04-15 17:57:47,891 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Using partitioner FORWARD for output 0 of task Source: Custom File source
2021-04-15 17:57:47,891 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 2-10 buffers
2021-04-15 17:57:47,900 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Registered PipelinedResultPartition 48d9b0c5cb57e41c9a6ee6d2fdcabc79#0@0c86dd8ae9385e8de4892823517d828a [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:57:47,900 DEBUG o.a.flink.runtime.io.network.buffer.LocalBufferPool - Using a local buffer pool with 1-8 buffers
2021-04-15 17:57:47,900 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - registering 48d9b0c5cb57e41c9a6ee6d2fdcabc79#0@0c86dd8ae9385e8de4892823517d828a
2021-04-15 17:57:47,903 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:57:47,905 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Using partitioner HASH for output 0 of task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp])
2021-04-15 17:57:47,905 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:57:47,906 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:57:47,906 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:57:47,907 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:57:47,907 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:57:47,907 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:57:47,908 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:57:47,908 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:57:47,911 INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-15 17:57:47,912 INFO org.apache.flink.runtime.taskmanager.Task - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (543e948d2479323821cf9240a4cf531c) switched from DEPLOYING to RUNNING.
2021-04-15 17:57:47,913 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File source (1/1)#0 (56a8a7eaf61a1c9778ec2910a7e8b378) switched from DEPLOYING to RUNNING.
2021-04-15 17:57:47,913 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File source (1/1)#0 (92aa1adebb2d1dc1601d0f7f4a004df2) switched from DEPLOYING to RUNNING.
2021-04-15 17:57:47,914 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Source: Custom File source (1/1)#0.
2021-04-15 17:57:47,914 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Source: Custom File source (1/1)#0.
2021-04-15 17:57:47,914 INFO org.apache.flink.runtime.taskmanager.Task - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (83787021e7a56db67c8fd5ee21262bc8) switched from DEPLOYING to RUNNING.
2021-04-15 17:57:47,914 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0.
2021-04-15 17:57:47,914 INFO org.apache.flink.runtime.taskmanager.Task - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (0bd850202103b66807f1ab92cd4c2d87) switched from DEPLOYING to RUNNING.
2021-04-15 17:57:47,914 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File source (1/1)#0 (f38e7381ef80e4fcfb1a02e00ec66f00) switched from DEPLOYING to RUNNING.
2021-04-15 17:57:47,915 INFO org.apache.flink.runtime.taskmanager.Task - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (e5911ca3febd32cb141752fc539271cb) switched from DEPLOYING to RUNNING.
2021-04-15 17:57:47,915 INFO org.apache.flink.runtime.taskmanager.Task - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (0c86dd8ae9385e8de4892823517d828a) switched from DEPLOYING to RUNNING.
2021-04-15 17:57:47,915 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0.
2021-04-15 17:57:47,915 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1) (543e948d2479323821cf9240a4cf531c) switched from DEPLOYING to RUNNING.
2021-04-15 17:57:47,916 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File source (1/1)#0 (962280473929e656fa9a072f81a110fc) switched from DEPLOYING to RUNNING.
2021-04-15 17:57:47,917 INFO org.apache.flink.runtime.taskmanager.Task - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (4c48ef46868aeabfa4c1687d52cd0352) switched from DEPLOYING to RUNNING.
2021-04-15 17:57:47,917 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0.
2021-04-15 17:57:47,919 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Source: Custom File source (1/1)#0.
2021-04-15 17:57:47,922 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0.
2021-04-15 17:57:47,924 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0.
2021-04-15 17:57:47,926 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (56a8a7eaf61a1c9778ec2910a7e8b378) switched from DEPLOYING to RUNNING.
2021-04-15 17:57:47,930 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing Source: Custom File source (1/1)#0.
2021-04-15 17:57:47,930 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: SourceConversion$54 

 Code:

      public class SourceConversion$54 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.data.conversion.RowRowConverter converter$53;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SourceConversion$54(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output,
            org.apache.flink.streaming.runtime.tasks.ProcessingTimeService processingTimeService) throws Exception {
          this.references = references;
          converter$53 = (((org.apache.flink.table.data.conversion.RowRowConverter) references[0]));
          this.setup(task, config, output);
          if (this instanceof org.apache.flink.streaming.api.operators.AbstractStreamOperator) {
            ((org.apache.flink.streaming.api.operators.AbstractStreamOperator) this)
              .setProcessingTimeService(processingTimeService);
          }
        }

        @Override
        public void open() throws Exception {
          super.open();
          
          converter$53.open(getRuntimeContext().getUserCodeClassLoader());
                     
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) (org.apache.flink.table.data.RowData) converter$53.toInternalOrNull((org.apache.flink.types.Row) element.getValue());
          
          
          
          output.collect(outElement.replace(in1));
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
2021-04-15 17:57:47,933 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Initializing GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0.
2021-04-15 17:57:47,944 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (92aa1adebb2d1dc1601d0f7f4a004df2) switched from DEPLOYING to RUNNING.
2021-04-15 17:57:47,945 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: SourceConversion$19 

 Code:

      public class SourceConversion$19 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.data.conversion.RowRowConverter converter$18;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SourceConversion$19(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output,
            org.apache.flink.streaming.runtime.tasks.ProcessingTimeService processingTimeService) throws Exception {
          this.references = references;
          converter$18 = (((org.apache.flink.table.data.conversion.RowRowConverter) references[0]));
          this.setup(task, config, output);
          if (this instanceof org.apache.flink.streaming.api.operators.AbstractStreamOperator) {
            ((org.apache.flink.streaming.api.operators.AbstractStreamOperator) this)
              .setProcessingTimeService(processingTimeService);
          }
        }

        @Override
        public void open() throws Exception {
          super.open();
          
          converter$18.open(getRuntimeContext().getUserCodeClassLoader());
                     
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) (org.apache.flink.table.data.RowData) converter$18.toInternalOrNull((org.apache.flink.types.Row) element.getValue());
          
          
          
          output.collect(outElement.replace(in1));
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
2021-04-15 17:57:47,950 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Source: Custom File source (1/1)#0
2021-04-15 17:57:47,953 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Source: Custom File source (1/1)#0
2021-04-15 17:57:47,955 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Source: Custom File source (1/1)#0
2021-04-15 17:57:47,958 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking Source: Custom File source (1/1)#0
2021-04-15 17:57:47,962 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: SinkConversion$17 

 Code:

      public class SinkConversion$17 extends org.apache.flink.table.runtime.operators.TableStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.data.util.DataFormatConverters.RowConverter converter$16;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SinkConversion$17(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output,
            org.apache.flink.streaming.runtime.tasks.ProcessingTimeService processingTimeService) throws Exception {
          this.references = references;
          converter$16 = (((org.apache.flink.table.data.util.DataFormatConverters.RowConverter) references[0]));
          this.setup(task, config, output);
          if (this instanceof org.apache.flink.streaming.api.operators.AbstractStreamOperator) {
            ((org.apache.flink.streaming.api.operators.AbstractStreamOperator) this)
              .setProcessingTimeService(processingTimeService);
          }
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) element.getValue();
          
          
          
          
          
          output.collect(outElement.replace((org.apache.flink.types.Row) converter$16.toExternal((org.apache.flink.table.data.RowData) in1)));
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
2021-04-15 17:57:47,962 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: SinkConversion$52 

 Code:

      public class SinkConversion$52 extends org.apache.flink.table.runtime.operators.TableStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.data.util.DataFormatConverters.RowConverter converter$50;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SinkConversion$52(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output,
            org.apache.flink.streaming.runtime.tasks.ProcessingTimeService processingTimeService) throws Exception {
          this.references = references;
          converter$50 = (((org.apache.flink.table.data.util.DataFormatConverters.RowConverter) references[0]));
          this.setup(task, config, output);
          if (this instanceof org.apache.flink.streaming.api.operators.AbstractStreamOperator) {
            ((org.apache.flink.streaming.api.operators.AbstractStreamOperator) this)
              .setProcessingTimeService(processingTimeService);
          }
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) element.getValue();
          
          
          
          
          
          
          org.apache.flink.api.java.tuple.Tuple2 result$51 = new org.apache.flink.api.java.tuple.Tuple2();
          result$51.setField(org.apache.flink.table.data.util.RowDataUtil.isAccumulateMsg(in1), 0);
          result$51.setField((org.apache.flink.types.Row) converter$50.toExternal((org.apache.flink.table.data.RowData) in1), 1);
          output.collect(outElement.replace(result$51));
                   
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
2021-04-15 17:57:47,963 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: SinkConversion$3 

 Code:

      public class SinkConversion$3 extends org.apache.flink.table.runtime.operators.TableStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.data.util.DataFormatConverters.RowConverter converter$2;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SinkConversion$3(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output,
            org.apache.flink.streaming.runtime.tasks.ProcessingTimeService processingTimeService) throws Exception {
          this.references = references;
          converter$2 = (((org.apache.flink.table.data.util.DataFormatConverters.RowConverter) references[0]));
          this.setup(task, config, output);
          if (this instanceof org.apache.flink.streaming.api.operators.AbstractStreamOperator) {
            ((org.apache.flink.streaming.api.operators.AbstractStreamOperator) this)
              .setProcessingTimeService(processingTimeService);
          }
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) element.getValue();
          
          
          
          
          
          output.collect(outElement.replace((org.apache.flink.types.Row) converter$2.toExternal((org.apache.flink.table.data.RowData) in1)));
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
2021-04-15 17:57:47,965 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: SinkConversion$87 

 Code:

      public class SinkConversion$87 extends org.apache.flink.table.runtime.operators.TableStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.data.util.DataFormatConverters.RowConverter converter$85;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SinkConversion$87(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output,
            org.apache.flink.streaming.runtime.tasks.ProcessingTimeService processingTimeService) throws Exception {
          this.references = references;
          converter$85 = (((org.apache.flink.table.data.util.DataFormatConverters.RowConverter) references[0]));
          this.setup(task, config, output);
          if (this instanceof org.apache.flink.streaming.api.operators.AbstractStreamOperator) {
            ((org.apache.flink.streaming.api.operators.AbstractStreamOperator) this)
              .setProcessingTimeService(processingTimeService);
          }
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) element.getValue();
          
          
          
          
          
          
          org.apache.flink.api.java.tuple.Tuple2 result$86 = new org.apache.flink.api.java.tuple.Tuple2();
          result$86.setField(org.apache.flink.table.data.util.RowDataUtil.isAccumulateMsg(in1), 0);
          result$86.setField((org.apache.flink.types.Row) converter$85.toExternal((org.apache.flink.table.data.RowData) in1), 1);
          output.collect(outElement.replace(result$86));
                   
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
2021-04-15 17:57:47,965 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1) (83787021e7a56db67c8fd5ee21262bc8) switched from DEPLOYING to RUNNING.
2021-04-15 17:57:47,980 WARN org.apache.flink.metrics.MetricGroup - The operator name SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:57:47,996 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSource_3ba1d27b7fde4848a86e865c6c402dfa_(1/1) with empty state.
2021-04-15 17:57:48,012 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: StreamExecCalc$15 

 Code:

      public class StreamExecCalc$15 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.runtime.typeutils.StringDataSerializer typeSerializer$9;
        
        private final org.apache.flink.table.data.binary.BinaryStringData str$11 = org.apache.flink.table.data.binary.BinaryStringData.fromString("sensor_6");
                   
        org.apache.flink.table.data.BoxedWrapperRowData out = new org.apache.flink.table.data.BoxedWrapperRowData(2);
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public StreamExecCalc$15(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output,
            org.apache.flink.streaming.runtime.tasks.ProcessingTimeService processingTimeService) throws Exception {
          this.references = references;
          typeSerializer$9 = (((org.apache.flink.table.runtime.typeutils.StringDataSerializer) references[0]));
          this.setup(task, config, output);
          if (this instanceof org.apache.flink.streaming.api.operators.AbstractStreamOperator) {
            ((org.apache.flink.streaming.api.operators.AbstractStreamOperator) this)
              .setProcessingTimeService(processingTimeService);
          }
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) element.getValue();
          
          org.apache.flink.table.data.binary.BinaryStringData field$8;
          boolean isNull$8;
          org.apache.flink.table.data.binary.BinaryStringData field$10;
          boolean isNull$12;
          boolean result$13;
          double field$14;
          boolean isNull$14;
          
          
          
          isNull$8 = in1.isNullAt(0);
          field$8 = org.apache.flink.table.data.binary.BinaryStringData.EMPTY_UTF8;
          if (!isNull$8) {
            field$8 = ((org.apache.flink.table.data.binary.BinaryStringData) in1.getString(0));
          }
          field$10 = field$8;
          if (!isNull$8) {
            field$10 = (org.apache.flink.table.data.binary.BinaryStringData) (typeSerializer$9.copy(field$10));
          }
                  
          
          
          
          isNull$12 = isNull$8 || false;
          result$13 = false;
          if (!isNull$12) {
            
            result$13 = field$10.equals(((org.apache.flink.table.data.binary.BinaryStringData) str$11));
            
          }
          
          if (result$13) {
            isNull$14 = in1.isNullAt(1);
          field$14 = -1.0d;
          if (!isNull$14) {
            field$14 = in1.getDouble(1);
          }
            
          out.setRowKind(in1.getRowKind());
          
          
          
          
          if (false) {
            out.setNullAt(0);
          } else {
            out.setNonPrimitiveValue(0, ((org.apache.flink.table.data.binary.BinaryStringData) str$11));
          }
                    
          
          
          if (isNull$14) {
            out.setNullAt(1);
          } else {
            out.setDouble(1, field$14);
          }
                    
                  
          output.collect(outElement.replace(out));
          
          }
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
2021-04-15 17:57:48,017 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSource_605b35e407e90cda15ad084365733fdd_(1/1) with empty state.
2021-04-15 17:57:48,018 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSource_feca28aff5a3958840bee985ee7de4d3_(1/1) with empty state.
2021-04-15 17:57:48,022 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1) (0bd850202103b66807f1ab92cd4c2d87) switched from DEPLOYING to RUNNING.
2021-04-15 17:57:48,024 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSource_bc764cd8ddf7a0cff126f51c16239658_(1/1) with empty state.
2021-04-15 17:57:48,051 WARN org.apache.flink.metrics.MetricGroup - The operator name GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:57:48,072 WARN org.apache.flink.metrics.MetricGroup - The operator name SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:57:48,079 WARN org.apache.flink.metrics.MetricGroup - The operator name GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:57:48,085 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (f38e7381ef80e4fcfb1a02e00ec66f00) switched from DEPLOYING to RUNNING.
2021-04-15 17:57:48,086 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1) (e5911ca3febd32cb141752fc539271cb) switched from DEPLOYING to RUNNING.
2021-04-15 17:57:48,086 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1) (0c86dd8ae9385e8de4892823517d828a) switched from DEPLOYING to RUNNING.
2021-04-15 17:57:48,086 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (962280473929e656fa9a072f81a110fc) switched from DEPLOYING to RUNNING.
2021-04-15 17:57:48,086 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1) (4c48ef46868aeabfa4c1687d52cd0352) switched from DEPLOYING to RUNNING.
2021-04-15 17:57:48,098 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: SourceConversion$1 

 Code:

      public class SourceConversion$1 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.data.conversion.RowRowConverter converter$0;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SourceConversion$1(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output,
            org.apache.flink.streaming.runtime.tasks.ProcessingTimeService processingTimeService) throws Exception {
          this.references = references;
          converter$0 = (((org.apache.flink.table.data.conversion.RowRowConverter) references[0]));
          this.setup(task, config, output);
          if (this instanceof org.apache.flink.streaming.api.operators.AbstractStreamOperator) {
            ((org.apache.flink.streaming.api.operators.AbstractStreamOperator) this)
              .setProcessingTimeService(processingTimeService);
          }
        }

        @Override
        public void open() throws Exception {
          super.open();
          
          converter$0.open(getRuntimeContext().getUserCodeClassLoader());
                     
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) (org.apache.flink.table.data.RowData) converter$0.toInternalOrNull((org.apache.flink.types.Row) element.getValue());
          
          
          
          output.collect(outElement.replace(in1));
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
2021-04-15 17:57:48,120 INFO o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - No state to restore for the ContinuousFileMonitoringFunction.
2021-04-15 17:57:48,121 DEBUG o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Opened ContinuousFileMonitoringFunction (taskIdx= 0) for path: src/main/resources/sensor.txt
2021-04-15 17:57:48,125 WARN org.apache.flink.metrics.MetricGroup - The operator name SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:57:48,134 WARN org.apache.flink.metrics.MetricGroup - The operator name Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:57:48,135 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: SourceConversion$7 

 Code:

      public class SourceConversion$7 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.data.conversion.RowRowConverter converter$6;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SourceConversion$7(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output,
            org.apache.flink.streaming.runtime.tasks.ProcessingTimeService processingTimeService) throws Exception {
          this.references = references;
          converter$6 = (((org.apache.flink.table.data.conversion.RowRowConverter) references[0]));
          this.setup(task, config, output);
          if (this instanceof org.apache.flink.streaming.api.operators.AbstractStreamOperator) {
            ((org.apache.flink.streaming.api.operators.AbstractStreamOperator) this)
              .setProcessingTimeService(processingTimeService);
          }
        }

        @Override
        public void open() throws Exception {
          super.open();
          
          converter$6.open(getRuntimeContext().getUserCodeClassLoader());
                     
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.data.RowData in1 = (org.apache.flink.table.data.RowData) (org.apache.flink.table.data.RowData) converter$6.toInternalOrNull((org.apache.flink.types.Row) element.getValue());
          
          
          
          output.collect(outElement.replace(in1));
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
2021-04-15 17:57:48,136 INFO o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - No state to restore for the ContinuousFileMonitoringFunction.
2021-04-15 17:57:48,136 DEBUG o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Opened ContinuousFileMonitoringFunction (taskIdx= 0) for path: src/main/resources/sensor.txt
2021-04-15 17:57:48,137 INFO o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - No state to restore for the ContinuousFileMonitoringFunction.
2021-04-15 17:57:48,137 DEBUG o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Opened ContinuousFileMonitoringFunction (taskIdx= 0) for path: src/main/resources/sensor.txt
2021-04-15 17:57:48,145 WARN org.apache.flink.metrics.MetricGroup - The operator name SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) exceeded the 80 characters length limit and was truncated.
2021-04-15 17:57:48,146 INFO o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - No state to restore for the ContinuousFileMonitoringFunction.
2021-04-15 17:57:48,147 DEBUG o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Opened ContinuousFileMonitoringFunction (taskIdx= 0) for path: src/main/resources/sensor.txt
2021-04-15 17:57:48,151 INFO org.apache.flink.core.fs.FileSystem - Hadoop is not in the classpath/dependencies. The extended set of supported File Systems via Hadoop is not available.
2021-04-15 17:57:48,164 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0
2021-04-15 17:57:48,164 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for SourceConversion$19_7b8b09df1455080a34c77ad3d0c43cb7_(1/1) with empty state.
2021-04-15 17:57:48,165 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0
2021-04-15 17:57:48,165 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_5eabb43907f8f80df1ce4361a6f197f2_(1/1) with empty state.
2021-04-15 17:57:48,166 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for SinkConversion$52_82ccb120c1db7ba31f32cb138318e905_(1/1) with empty state.
2021-04-15 17:57:48,168 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating keyed state backend for KeyedProcessOperator_6177eb422127981c4dbb05ea3af8a2d4_(1/1) with empty state.
2021-04-15 17:57:48,169 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0
2021-04-15 17:57:48,170 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_3ed91adabe57771c56cb72d2e8ef0077_(1/1) with empty state.
2021-04-15 17:57:48,170 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for SinkConversion$87_a0dd144f36ef19961046e87bafc35e9e_(1/1) with empty state.
2021-04-15 17:57:48,172 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating keyed state backend for KeyedProcessOperator_5528b14a6b129894d24927c518acc32a_(1/1) with empty state.
2021-04-15 17:57:48,172 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0
2021-04-15 17:57:48,172 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_1ff151f0e73312424d48b44002b858b2_(1/1) with empty state.
2021-04-15 17:57:48,173 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for SinkConversion$3_a74f42661a9b9f548012fab549771fb0_(1/1) with empty state.
2021-04-15 17:57:48,173 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for SourceConversion$1_e1caecf4e938c7437797fd5ffa107998_(1/1) with empty state.
2021-04-15 17:57:48,173 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for ContinuousFileReaderOperator_77af20c908aca598f7bbebd4db138545_(1/1) with empty state.
2021-04-15 17:57:48,173 INFO o.a.f.s.a.functions.source.ContinuousFileReaderOperator - No state to restore for the ContinuousFileReaderOperator (taskIdx=0).
2021-04-15 17:57:48,177 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0
2021-04-15 17:57:48,177 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamSink_acef8fa5317ebae622515a3dd3a22b5b_(1/1) with empty state.
2021-04-15 17:57:48,177 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for SinkConversion$17_7be2b145deed960935698c82ec6584ff_(1/1) with empty state.
2021-04-15 17:57:48,177 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for StreamExecCalc$15_eac1a1ce1701c72ed31579ebbd62865a_(1/1) with empty state.
2021-04-15 17:57:48,178 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for SourceConversion$7_f747214a7be91c9c2b6cc5b7a3c8c7eb_(1/1) with empty state.
2021-04-15 17:57:48,178 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for ContinuousFileReaderOperator_b23642197a427ec5db481d3963c66cfb_(1/1) with empty state.
2021-04-15 17:57:48,178 INFO o.a.f.s.a.functions.source.ContinuousFileReaderOperator - No state to restore for the ContinuousFileReaderOperator (taskIdx=0).
2021-04-15 17:57:48,179 INFO o.a.f.runtime.state.heap.HeapKeyedStateBackendBuilder - Finished to build heap keyed state-backend.
2021-04-15 17:57:48,180 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for ContinuousFileReaderOperator_a19bdf930ebdf056b3d6de069bc89bdd_(1/1) with empty state.
2021-04-15 17:57:48,180 INFO o.a.f.s.a.functions.source.ContinuousFileReaderOperator - No state to restore for the ContinuousFileReaderOperator (taskIdx=0).
2021-04-15 17:57:48,183 INFO o.a.f.runtime.state.heap.HeapKeyedStateBackendBuilder - Finished to build heap keyed state-backend.
2021-04-15 17:57:48,183 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Invoking CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0
2021-04-15 17:57:48,184 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for SourceConversion$54_fd97fe1bcea3a8dd8f11b0abe0bb8fa7_(1/1) with empty state.
2021-04-15 17:57:48,184 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for ContinuousFileReaderOperator_aecbb8a11dc0c28dc6c178e875ebcc43_(1/1) with empty state.
2021-04-15 17:57:48,184 INFO o.a.f.s.a.functions.source.ContinuousFileReaderOperator - No state to restore for the ContinuousFileReaderOperator (taskIdx=0).
2021-04-15 17:57:48,191 INFO o.apache.flink.runtime.state.heap.HeapKeyedStateBackend - Initializing heap keyed state backend with stream factory.
2021-04-15 17:57:48,192 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for KeyedProcessOperator_6177eb422127981c4dbb05ea3af8a2d4_(1/1) with empty state.
2021-04-15 17:57:48,196 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: GroupAggsHandler$46 

 Code:

        public final class GroupAggsHandler$46 implements org.apache.flink.table.runtime.generated.AggsHandleFunction {

          long agg0_count;
          boolean agg0_countIsNull;
          double agg1_sum;
          boolean agg1_sumIsNull;
          long agg1_count;
          boolean agg1_countIsNull;
          org.apache.flink.table.data.GenericRowData acc$22 = new org.apache.flink.table.data.GenericRowData(3);
          org.apache.flink.table.data.GenericRowData acc$23 = new org.apache.flink.table.data.GenericRowData(3);
          private transient org.apache.flink.table.runtime.typeutils.StringDataSerializer typeSerializer$28;
          org.apache.flink.table.data.GenericRowData aggValue$45 = new org.apache.flink.table.data.GenericRowData(2);

          private org.apache.flink.table.runtime.dataview.StateDataViewStore store;

          public GroupAggsHandler$46(java.lang.Object[] references) throws Exception {
            typeSerializer$28 = (((org.apache.flink.table.runtime.typeutils.StringDataSerializer) references[0]));
          }

          private org.apache.flink.api.common.functions.RuntimeContext getRuntimeContext() {
            return store.getRuntimeContext();
          }

          @Override
          public void open(org.apache.flink.table.runtime.dataview.StateDataViewStore store) throws Exception {
            this.store = store;
            
          }

          @Override
          public void accumulate(org.apache.flink.table.data.RowData accInput) throws Exception {
            
            org.apache.flink.table.data.binary.BinaryStringData field$27;
            boolean isNull$27;
            org.apache.flink.table.data.binary.BinaryStringData field$29;
            boolean isNull$30;
            long result$31;
            double field$33;
            boolean isNull$33;
            boolean isNull$34;
            double result$35;
            boolean isNull$37;
            long result$38;
            isNull$33 = accInput.isNullAt(2);
            field$33 = -1.0d;
            if (!isNull$33) {
              field$33 = accInput.getDouble(2);
            }
            
            isNull$27 = accInput.isNullAt(0);
            field$27 = org.apache.flink.table.data.binary.BinaryStringData.EMPTY_UTF8;
            if (!isNull$27) {
              field$27 = ((org.apache.flink.table.data.binary.BinaryStringData) accInput.getString(0));
            }
            field$29 = field$27;
            if (!isNull$27) {
              field$29 = (org.apache.flink.table.data.binary.BinaryStringData) (typeSerializer$28.copy(field$29));
            }
            
            long result$32 = -1L;
            boolean isNull$32;
            if (isNull$27) {
              
              isNull$32 = agg0_countIsNull;
              if (!isNull$32) {
                result$32 = agg0_count;
              }
            }
            else {
              
            
            
            isNull$30 = agg0_countIsNull || false;
            result$31 = -1L;
            if (!isNull$30) {
              
              result$31 = (long) (agg0_count + ((long) 1L));
              
            }
            
              isNull$32 = isNull$30;
              if (!isNull$32) {
                result$32 = result$31;
              }
            }
            agg0_count = result$32;;
            agg0_countIsNull = isNull$32;
                   
            
            double result$36 = -1.0d;
            boolean isNull$36;
            if (isNull$33) {
              
              isNull$36 = agg1_sumIsNull;
              if (!isNull$36) {
                result$36 = agg1_sum;
              }
            }
            else {
              
            
            
            isNull$34 = agg1_sumIsNull || isNull$33;
            result$35 = -1.0d;
            if (!isNull$34) {
              
              result$35 = (double) (agg1_sum + field$33);
              
            }
            
              isNull$36 = isNull$34;
              if (!isNull$36) {
                result$36 = result$35;
              }
            }
            agg1_sum = result$36;;
            agg1_sumIsNull = isNull$36;
                   
            
            long result$39 = -1L;
            boolean isNull$39;
            if (isNull$33) {
              
              isNull$39 = agg1_countIsNull;
              if (!isNull$39) {
                result$39 = agg1_count;
              }
            }
            else {
              
            
            
            isNull$37 = agg1_countIsNull || false;
            result$38 = -1L;
            if (!isNull$37) {
              
              result$38 = (long) (agg1_count + ((long) 1L));
              
            }
            
              isNull$39 = isNull$37;
              if (!isNull$39) {
                result$39 = result$38;
              }
            }
            agg1_count = result$39;;
            agg1_countIsNull = isNull$39;
                   
            
          }

          @Override
          public void retract(org.apache.flink.table.data.RowData retractInput) throws Exception {
            
            throw new java.lang.RuntimeException("This function not require retract method, but the retract method is called.");
                 
          }

          @Override
          public void merge(org.apache.flink.table.data.RowData otherAcc) throws Exception {
            
            throw new java.lang.RuntimeException("This function not require merge method, but the merge method is called.");
                 
          }

          @Override
          public void setAccumulators(org.apache.flink.table.data.RowData acc) throws Exception {
            
            long field$24;
            boolean isNull$24;
            double field$25;
            boolean isNull$25;
            long field$26;
            boolean isNull$26;
            isNull$24 = acc.isNullAt(0);
            field$24 = -1L;
            if (!isNull$24) {
              field$24 = acc.getLong(0);
            }
            isNull$25 = acc.isNullAt(1);
            field$25 = -1.0d;
            if (!isNull$25) {
              field$25 = acc.getDouble(1);
            }
            isNull$26 = acc.isNullAt(2);
            field$26 = -1L;
            if (!isNull$26) {
              field$26 = acc.getLong(2);
            }
            
            agg0_count = field$24;;
            agg0_countIsNull = isNull$24;
                     
            
            agg1_sum = field$25;;
            agg1_sumIsNull = isNull$25;
                     
            
            agg1_count = field$26;;
            agg1_countIsNull = isNull$26;
                     
                
          }

          @Override
          public void resetAccumulators() throws Exception {
            
            
            
            
            agg0_count = ((long) 0L);
            agg0_countIsNull = false;
                     
            
            
            agg1_sum = ((double) 0.0d);
            agg1_sumIsNull = false;
                     
            
            
            agg1_count = ((long) 0L);
            agg1_countIsNull = false;
                     
                
          }

          @Override
          public org.apache.flink.table.data.RowData getAccumulators() throws Exception {
            
            
            
            acc$23 = new org.apache.flink.table.data.GenericRowData(3);
            
            
            if (agg0_countIsNull) {
              acc$23.setField(0, null);
            } else {
              acc$23.setField(0, agg0_count);
            }
                      
            
            
            if (agg1_sumIsNull) {
              acc$23.setField(1, null);
            } else {
              acc$23.setField(1, agg1_sum);
            }
                      
            
            
            if (agg1_countIsNull) {
              acc$23.setField(2, null);
            } else {
              acc$23.setField(2, agg1_count);
            }
                      
                    
            return acc$23;
                
          }

          @Override
          public org.apache.flink.table.data.RowData createAccumulators() throws Exception {
            
            
            
            acc$22 = new org.apache.flink.table.data.GenericRowData(3);
            
            
            if (false) {
              acc$22.setField(0, null);
            } else {
              acc$22.setField(0, ((long) 0L));
            }
                      
            
            
            if (false) {
              acc$22.setField(1, null);
            } else {
              acc$22.setField(1, ((double) 0.0d));
            }
                      
            
            
            if (false) {
              acc$22.setField(2, null);
            } else {
              acc$22.setField(2, ((long) 0L));
            }
                      
                    
            return acc$22;
                
          }

          @Override
          public org.apache.flink.table.data.RowData getValue() throws Exception {
            
            boolean isNull$40;
            boolean result$41;
            boolean isNull$42;
            double result$43;
            
            aggValue$45 = new org.apache.flink.table.data.GenericRowData(2);
            
            
            if (agg0_countIsNull) {
              aggValue$45.setField(0, null);
            } else {
              aggValue$45.setField(0, agg0_count);
            }
                      
            
            isNull$40 = agg1_countIsNull || false;
            result$41 = false;
            if (!isNull$40) {
              
              result$41 = agg1_count == ((long) 0L);
              
            }
            
            double result$44 = -1.0d;
            boolean isNull$44;
            if (result$41) {
              
              isNull$44 = true;
              if (!isNull$44) {
                result$44 = ((double) -1.0d);
              }
            }
            else {
              
            
            
            isNull$42 = agg1_sumIsNull || agg1_countIsNull;
            result$43 = -1.0d;
            if (!isNull$42) {
              
              result$43 = (double) (agg1_sum / (new java.lang.Long(agg1_count)).doubleValue());
              
            }
            
              isNull$44 = isNull$42;
              if (!isNull$44) {
                result$44 = result$43;
              }
            }
            if (isNull$44) {
              aggValue$45.setField(1, null);
            } else {
              aggValue$45.setField(1, result$44);
            }
                      
                    
            return aggValue$45;
                
          }

          @Override
          public void cleanup() throws Exception {
            
            
          }

          @Override
          public void close() throws Exception {
            
          }
        }
      
2021-04-15 17:57:48,201 INFO o.apache.flink.runtime.state.heap.HeapKeyedStateBackend - Initializing heap keyed state backend with stream factory.
2021-04-15 17:57:48,201 DEBUG o.a.f.streaming.api.operators.BackendRestorerProcedure - Creating operator state backend for KeyedProcessOperator_5528b14a6b129894d24927c518acc32a_(1/1) with empty state.
2021-04-15 17:57:48,201 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: GroupAggsHandler$81 

 Code:

        public final class GroupAggsHandler$81 implements org.apache.flink.table.runtime.generated.AggsHandleFunction {

          long agg0_count;
          boolean agg0_countIsNull;
          double agg1_sum;
          boolean agg1_sumIsNull;
          long agg1_count;
          boolean agg1_countIsNull;
          org.apache.flink.table.data.GenericRowData acc$57 = new org.apache.flink.table.data.GenericRowData(3);
          org.apache.flink.table.data.GenericRowData acc$58 = new org.apache.flink.table.data.GenericRowData(3);
          private transient org.apache.flink.table.runtime.typeutils.StringDataSerializer typeSerializer$63;
          org.apache.flink.table.data.GenericRowData aggValue$80 = new org.apache.flink.table.data.GenericRowData(2);

          private org.apache.flink.table.runtime.dataview.StateDataViewStore store;

          public GroupAggsHandler$81(java.lang.Object[] references) throws Exception {
            typeSerializer$63 = (((org.apache.flink.table.runtime.typeutils.StringDataSerializer) references[0]));
          }

          private org.apache.flink.api.common.functions.RuntimeContext getRuntimeContext() {
            return store.getRuntimeContext();
          }

          @Override
          public void open(org.apache.flink.table.runtime.dataview.StateDataViewStore store) throws Exception {
            this.store = store;
            
          }

          @Override
          public void accumulate(org.apache.flink.table.data.RowData accInput) throws Exception {
            
            org.apache.flink.table.data.binary.BinaryStringData field$62;
            boolean isNull$62;
            org.apache.flink.table.data.binary.BinaryStringData field$64;
            boolean isNull$65;
            long result$66;
            double field$68;
            boolean isNull$68;
            boolean isNull$69;
            double result$70;
            boolean isNull$72;
            long result$73;
            isNull$62 = accInput.isNullAt(0);
            field$62 = org.apache.flink.table.data.binary.BinaryStringData.EMPTY_UTF8;
            if (!isNull$62) {
              field$62 = ((org.apache.flink.table.data.binary.BinaryStringData) accInput.getString(0));
            }
            field$64 = field$62;
            if (!isNull$62) {
              field$64 = (org.apache.flink.table.data.binary.BinaryStringData) (typeSerializer$63.copy(field$64));
            }
                    
            isNull$68 = accInput.isNullAt(1);
            field$68 = -1.0d;
            if (!isNull$68) {
              field$68 = accInput.getDouble(1);
            }
            
            long result$67 = -1L;
            boolean isNull$67;
            if (isNull$62) {
              
              isNull$67 = agg0_countIsNull;
              if (!isNull$67) {
                result$67 = agg0_count;
              }
            }
            else {
              
            
            
            isNull$65 = agg0_countIsNull || false;
            result$66 = -1L;
            if (!isNull$65) {
              
              result$66 = (long) (agg0_count + ((long) 1L));
              
            }
            
              isNull$67 = isNull$65;
              if (!isNull$67) {
                result$67 = result$66;
              }
            }
            agg0_count = result$67;;
            agg0_countIsNull = isNull$67;
                   
            
            double result$71 = -1.0d;
            boolean isNull$71;
            if (isNull$68) {
              
              isNull$71 = agg1_sumIsNull;
              if (!isNull$71) {
                result$71 = agg1_sum;
              }
            }
            else {
              
            
            
            isNull$69 = agg1_sumIsNull || isNull$68;
            result$70 = -1.0d;
            if (!isNull$69) {
              
              result$70 = (double) (agg1_sum + field$68);
              
            }
            
              isNull$71 = isNull$69;
              if (!isNull$71) {
                result$71 = result$70;
              }
            }
            agg1_sum = result$71;;
            agg1_sumIsNull = isNull$71;
                   
            
            long result$74 = -1L;
            boolean isNull$74;
            if (isNull$68) {
              
              isNull$74 = agg1_countIsNull;
              if (!isNull$74) {
                result$74 = agg1_count;
              }
            }
            else {
              
            
            
            isNull$72 = agg1_countIsNull || false;
            result$73 = -1L;
            if (!isNull$72) {
              
              result$73 = (long) (agg1_count + ((long) 1L));
              
            }
            
              isNull$74 = isNull$72;
              if (!isNull$74) {
                result$74 = result$73;
              }
            }
            agg1_count = result$74;;
            agg1_countIsNull = isNull$74;
                   
            
          }

          @Override
          public void retract(org.apache.flink.table.data.RowData retractInput) throws Exception {
            
            throw new java.lang.RuntimeException("This function not require retract method, but the retract method is called.");
                 
          }

          @Override
          public void merge(org.apache.flink.table.data.RowData otherAcc) throws Exception {
            
            throw new java.lang.RuntimeException("This function not require merge method, but the merge method is called.");
                 
          }

          @Override
          public void setAccumulators(org.apache.flink.table.data.RowData acc) throws Exception {
            
            long field$59;
            boolean isNull$59;
            double field$60;
            boolean isNull$60;
            long field$61;
            boolean isNull$61;
            isNull$59 = acc.isNullAt(0);
            field$59 = -1L;
            if (!isNull$59) {
              field$59 = acc.getLong(0);
            }
            isNull$60 = acc.isNullAt(1);
            field$60 = -1.0d;
            if (!isNull$60) {
              field$60 = acc.getDouble(1);
            }
            isNull$61 = acc.isNullAt(2);
            field$61 = -1L;
            if (!isNull$61) {
              field$61 = acc.getLong(2);
            }
            
            agg0_count = field$59;;
            agg0_countIsNull = isNull$59;
                     
            
            agg1_sum = field$60;;
            agg1_sumIsNull = isNull$60;
                     
            
            agg1_count = field$61;;
            agg1_countIsNull = isNull$61;
                     
                
          }

          @Override
          public void resetAccumulators() throws Exception {
            
            
            
            
            agg0_count = ((long) 0L);
            agg0_countIsNull = false;
                     
            
            
            agg1_sum = ((double) 0.0d);
            agg1_sumIsNull = false;
                     
            
            
            agg1_count = ((long) 0L);
            agg1_countIsNull = false;
                     
                
          }

          @Override
          public org.apache.flink.table.data.RowData getAccumulators() throws Exception {
            
            
            
            acc$58 = new org.apache.flink.table.data.GenericRowData(3);
            
            
            if (agg0_countIsNull) {
              acc$58.setField(0, null);
            } else {
              acc$58.setField(0, agg0_count);
            }
                      
            
            
            if (agg1_sumIsNull) {
              acc$58.setField(1, null);
            } else {
              acc$58.setField(1, agg1_sum);
            }
                      
            
            
            if (agg1_countIsNull) {
              acc$58.setField(2, null);
            } else {
              acc$58.setField(2, agg1_count);
            }
                      
                    
            return acc$58;
                
          }

          @Override
          public org.apache.flink.table.data.RowData createAccumulators() throws Exception {
            
            
            
            acc$57 = new org.apache.flink.table.data.GenericRowData(3);
            
            
            if (false) {
              acc$57.setField(0, null);
            } else {
              acc$57.setField(0, ((long) 0L));
            }
                      
            
            
            if (false) {
              acc$57.setField(1, null);
            } else {
              acc$57.setField(1, ((double) 0.0d));
            }
                      
            
            
            if (false) {
              acc$57.setField(2, null);
            } else {
              acc$57.setField(2, ((long) 0L));
            }
                      
                    
            return acc$57;
                
          }

          @Override
          public org.apache.flink.table.data.RowData getValue() throws Exception {
            
            boolean isNull$75;
            boolean result$76;
            boolean isNull$77;
            double result$78;
            
            aggValue$80 = new org.apache.flink.table.data.GenericRowData(2);
            
            
            if (agg0_countIsNull) {
              aggValue$80.setField(0, null);
            } else {
              aggValue$80.setField(0, agg0_count);
            }
                      
            
            isNull$75 = agg1_countIsNull || false;
            result$76 = false;
            if (!isNull$75) {
              
              result$76 = agg1_count == ((long) 0L);
              
            }
            
            double result$79 = -1.0d;
            boolean isNull$79;
            if (result$76) {
              
              isNull$79 = true;
              if (!isNull$79) {
                result$79 = ((double) -1.0d);
              }
            }
            else {
              
            
            
            isNull$77 = agg1_sumIsNull || agg1_countIsNull;
            result$78 = -1.0d;
            if (!isNull$77) {
              
              result$78 = (double) (agg1_sum / (new java.lang.Long(agg1_count)).doubleValue());
              
            }
            
              isNull$79 = isNull$77;
              if (!isNull$79) {
                result$79 = result$78;
              }
            }
            if (isNull$79) {
              aggValue$80.setField(1, null);
            } else {
              aggValue$80.setField(1, result$79);
            }
                      
                    
            return aggValue$80;
                
          }

          @Override
          public void cleanup() throws Exception {
            
            
          }

          @Override
          public void close() throws Exception {
            
          }
        }
      
2021-04-15 17:57:48,204 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf - -Dorg.apache.flink.shaded.netty4.io.netty.buffer.checkAccessible: true
2021-04-15 17:57:48,205 DEBUG o.a.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf - -Dorg.apache.flink.shaded.netty4.io.netty.buffer.checkBounds: true
2021-04-15 17:57:48,208 DEBUG o.a.f.s.n.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.flink.shaded.netty4.io.netty.util.ResourceLeakDetector@505fa316
2021-04-15 17:57:48,213 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (e5911ca3febd32cb141752fc539271cb)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:57:48,237 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: GroupAggValueEqualiser$82 

 Code:

        public final class GroupAggValueEqualiser$82 implements org.apache.flink.table.runtime.generated.RecordEqualiser {

          

          public GroupAggValueEqualiser$82(Object[] references) throws Exception {
            
          }

          @Override
          public boolean equals(org.apache.flink.table.data.RowData left, org.apache.flink.table.data.RowData right) {
            if (left instanceof org.apache.flink.table.data.binary.BinaryRowData && right instanceof org.apache.flink.table.data.binary.BinaryRowData) {
              return left.equals(right);
            } else {
              
              if (left.getRowKind() != right.getRowKind()) {
                return false;
              }
                     
              
              
              boolean leftIsNull$0 = left.isNullAt(0);
              boolean rightIsNull$0 = right.isNullAt(0);
              boolean cmp0;
              if (leftIsNull$0 && rightIsNull$0) {
                cmp0 = true;
              } else if (leftIsNull$0|| rightIsNull$0) {
                cmp0 = false;
              } else {
                long leftField$0 = left.getLong(0);
                long rightField$0 = right.getLong(0);
                
                cmp0 = leftField$0 == rightField$0;
              }
              if (!cmp0) {
                return false;
              }
                    
              
              boolean leftIsNull$1 = left.isNullAt(1);
              boolean rightIsNull$1 = right.isNullAt(1);
              boolean cmp1;
              if (leftIsNull$1 && rightIsNull$1) {
                cmp1 = true;
              } else if (leftIsNull$1|| rightIsNull$1) {
                cmp1 = false;
              } else {
                double leftField$1 = left.getDouble(1);
                double rightField$1 = right.getDouble(1);
                
                cmp1 = leftField$1 == rightField$1;
              }
              if (!cmp1) {
                return false;
              }
                    
              return true;
            }
          }
        }
      
2021-04-15 17:57:48,244 DEBUG org.apache.flink.core.fs.FileSystem - Loading extension file systems via services
2021-04-15 17:57:48,272 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: GroupAggValueEqualiser$47 

 Code:

        public final class GroupAggValueEqualiser$47 implements org.apache.flink.table.runtime.generated.RecordEqualiser {

          

          public GroupAggValueEqualiser$47(Object[] references) throws Exception {
            
          }

          @Override
          public boolean equals(org.apache.flink.table.data.RowData left, org.apache.flink.table.data.RowData right) {
            if (left instanceof org.apache.flink.table.data.binary.BinaryRowData && right instanceof org.apache.flink.table.data.binary.BinaryRowData) {
              return left.equals(right);
            } else {
              
              if (left.getRowKind() != right.getRowKind()) {
                return false;
              }
                     
              
              
              boolean leftIsNull$0 = left.isNullAt(0);
              boolean rightIsNull$0 = right.isNullAt(0);
              boolean cmp0;
              if (leftIsNull$0 && rightIsNull$0) {
                cmp0 = true;
              } else if (leftIsNull$0|| rightIsNull$0) {
                cmp0 = false;
              } else {
                long leftField$0 = left.getLong(0);
                long rightField$0 = right.getLong(0);
                
                cmp0 = leftField$0 == rightField$0;
              }
              if (!cmp0) {
                return false;
              }
                    
              
              boolean leftIsNull$1 = left.isNullAt(1);
              boolean rightIsNull$1 = right.isNullAt(1);
              boolean cmp1;
              if (leftIsNull$1 && rightIsNull$1) {
                cmp1 = true;
              } else if (leftIsNull$1|| rightIsNull$1) {
                cmp1 = false;
              } else {
                double leftField$1 = left.getDouble(1);
                double rightField$1 = right.getDouble(1);
                
                cmp1 = leftField$1 == rightField$1;
              }
              if (!cmp1) {
                return false;
              }
                    
              return true;
            }
          }
        }
      
2021-04-15 17:57:48,283 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:57:48,284 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (83787021e7a56db67c8fd5ee21262bc8)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:57:48,284 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (0bd850202103b66807f1ab92cd4c2d87)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:57:48,296 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (0c86dd8ae9385e8de4892823517d828a)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:57:48,297 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:57:48,318 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:57:48,319 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:57:48,319 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:57:48,319 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:57:48,320 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [2d7690046e5016dcca8b03287d230aa7#0@92aa1adebb2d1dc1601d0f7f4a004df2]: Requesting LOCAL subpartition 0 of partition 2d7690046e5016dcca8b03287d230aa7#0@92aa1adebb2d1dc1601d0f7f4a004df2. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:57:48,320 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 0 of PipelinedResultPartition 2d7690046e5016dcca8b03287d230aa7#0@92aa1adebb2d1dc1601d0f7f4a004df2 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:57:48,321 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [c30d3d8915267dd583f3c188b245bc98#0@962280473929e656fa9a072f81a110fc]: Requesting LOCAL subpartition 0 of partition c30d3d8915267dd583f3c188b245bc98#0@962280473929e656fa9a072f81a110fc. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:57:48,327 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [ddcafd25d8473f83e72837e4b4ab9a82#0@f38e7381ef80e4fcfb1a02e00ec66f00]: Requesting LOCAL subpartition 0 of partition ddcafd25d8473f83e72837e4b4ab9a82#0@f38e7381ef80e4fcfb1a02e00ec66f00. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:57:48,330 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (543e948d2479323821cf9240a4cf531c)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:57:48,330 DEBUG o.a.f.r.i.n.partition.consumer.RecoveredInputChannel - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (4c48ef46868aeabfa4c1687d52cd0352)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2021-04-15 17:57:48,331 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File source (1/1)#0 (92aa1adebb2d1dc1601d0f7f4a004df2): Creating read view for subpartition 0 of partition 2d7690046e5016dcca8b03287d230aa7#0@92aa1adebb2d1dc1601d0f7f4a004df2.
2021-04-15 17:57:48,331 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:57:48,332 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:57:48,333 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 0) of ResultPartition 2d7690046e5016dcca8b03287d230aa7#0@92aa1adebb2d1dc1601d0f7f4a004df2
2021-04-15 17:57:48,339 INFO o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Forwarding split: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 17:57:48,342 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:57:48,342 INFO o.a.f.r.io.network.partition.consumer.SingleInputGate - Converting recovered input channels (1 channels)
2021-04-15 17:57:48,342 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:57:48,343 INFO o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Forwarding split: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 17:57:48,343 INFO o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Forwarding split: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 17:57:48,343 INFO o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Forwarding split: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 17:57:48,343 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 0 of PipelinedResultPartition ddcafd25d8473f83e72837e4b4ab9a82#0@f38e7381ef80e4fcfb1a02e00ec66f00 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:57:48,344 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [16fc7cab54c1def2c796d236a0a0270d#0@56a8a7eaf61a1c9778ec2910a7e8b378]: Requesting LOCAL subpartition 0 of partition 16fc7cab54c1def2c796d236a0a0270d#0@56a8a7eaf61a1c9778ec2910a7e8b378. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:57:48,344 DEBUG o.a.f.r.i.n.partition.consumer.ChannelStatePersister - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2021-04-15 17:57:48,344 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [48d9b0c5cb57e41c9a6ee6d2fdcabc79#0@0c86dd8ae9385e8de4892823517d828a]: Requesting LOCAL subpartition 0 of partition 48d9b0c5cb57e41c9a6ee6d2fdcabc79#0@0c86dd8ae9385e8de4892823517d828a. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:57:48,344 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File source (1/1)#0 (f38e7381ef80e4fcfb1a02e00ec66f00): Creating read view for subpartition 0 of partition ddcafd25d8473f83e72837e4b4ab9a82#0@f38e7381ef80e4fcfb1a02e00ec66f00.
2021-04-15 17:57:48,345 DEBUG o.a.f.r.io.network.partition.consumer.LocalInputChannel - LocalInputChannel [a1e6df2fa256a56d4f8621bc68aee12b#0@83787021e7a56db67c8fd5ee21262bc8]: Requesting LOCAL subpartition 0 of partition a1e6df2fa256a56d4f8621bc68aee12b#0@83787021e7a56db67c8fd5ee21262bc8. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2021-04-15 17:57:48,345 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 0) of ResultPartition ddcafd25d8473f83e72837e4b4ab9a82#0@f38e7381ef80e4fcfb1a02e00ec66f00
2021-04-15 17:57:48,346 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 0 of PipelinedResultPartition c30d3d8915267dd583f3c188b245bc98#0@962280473929e656fa9a072f81a110fc [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:57:48,347 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File source (1/1)#0 (962280473929e656fa9a072f81a110fc): Creating read view for subpartition 0 of partition c30d3d8915267dd583f3c188b245bc98#0@962280473929e656fa9a072f81a110fc.
2021-04-15 17:57:48,347 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 0) of ResultPartition c30d3d8915267dd583f3c188b245bc98#0@962280473929e656fa9a072f81a110fc
2021-04-15 17:57:48,349 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 0 of PipelinedResultPartition a1e6df2fa256a56d4f8621bc68aee12b#0@83787021e7a56db67c8fd5ee21262bc8 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:57:48,352 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (83787021e7a56db67c8fd5ee21262bc8): Creating read view for subpartition 0 of partition a1e6df2fa256a56d4f8621bc68aee12b#0@83787021e7a56db67c8fd5ee21262bc8.
2021-04-15 17:57:48,352 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 0) of ResultPartition a1e6df2fa256a56d4f8621bc68aee12b#0@83787021e7a56db67c8fd5ee21262bc8
2021-04-15 17:57:48,352 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 0 of PipelinedResultPartition 48d9b0c5cb57e41c9a6ee6d2fdcabc79#0@0c86dd8ae9385e8de4892823517d828a [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:57:48,352 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (0c86dd8ae9385e8de4892823517d828a): Creating read view for subpartition 0 of partition 48d9b0c5cb57e41c9a6ee6d2fdcabc79#0@0c86dd8ae9385e8de4892823517d828a.
2021-04-15 17:57:48,352 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 0) of ResultPartition 48d9b0c5cb57e41c9a6ee6d2fdcabc79#0@0c86dd8ae9385e8de4892823517d828a
2021-04-15 17:57:48,353 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Requesting subpartition 0 of PipelinedResultPartition 16fc7cab54c1def2c796d236a0a0270d#0@56a8a7eaf61a1c9778ec2910a7e8b378 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2021-04-15 17:57:48,353 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File source (1/1)#0 (56a8a7eaf61a1c9778ec2910a7e8b378): Creating read view for subpartition 0 of partition 16fc7cab54c1def2c796d236a0a0270d#0@56a8a7eaf61a1c9778ec2910a7e8b378.
2021-04-15 17:57:48,353 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Created PipelinedSubpartitionView(index: 0) of ResultPartition 16fc7cab54c1def2c796d236a0a0270d#0@56a8a7eaf61a1c9778ec2910a7e8b378
2021-04-15 17:57:48,514 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task Source: Custom File source (1/1)#0
2021-04-15 17:57:48,514 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task Source: Custom File source (1/1)#0
2021-04-15 17:57:48,514 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task Source: Custom File source (1/1)#0
2021-04-15 17:57:48,514 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task Source: Custom File source (1/1)#0
2021-04-15 17:57:48,517 DEBUG o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Closed File Monitoring Source for path: src/main/resources/sensor.txt.
2021-04-15 17:57:48,517 DEBUG o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Closed File Monitoring Source for path: src/main/resources/sensor.txt.
2021-04-15 17:57:48,517 DEBUG o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Closed File Monitoring Source for path: src/main/resources/sensor.txt.
2021-04-15 17:57:48,517 DEBUG o.a.f.s.a.f.source.ContinuousFileMonitoringFunction - Closed File Monitoring Source for path: src/main/resources/sensor.txt.
2021-04-15 17:57:48,518 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task Source: Custom File source (1/1)#0
2021-04-15 17:57:48,518 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task Source: Custom File source (1/1)#0
2021-04-15 17:57:48,518 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task Source: Custom File source (1/1)#0
2021-04-15 17:57:48,518 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task Source: Custom File source (1/1)#0
2021-04-15 17:57:48,530 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File source (1/1)#0 (92aa1adebb2d1dc1601d0f7f4a004df2): Finished PipelinedSubpartition#0 [number of buffers: 2 (133 bytes), number of buffers in backlog: 1, finished? true, read view? true].
2021-04-15 17:57:48,530 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File source (1/1)#0 (92aa1adebb2d1dc1601d0f7f4a004df2) switched from RUNNING to FINISHED.
2021-04-15 17:57:48,530 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Source: Custom File source (1/1)#0 (92aa1adebb2d1dc1601d0f7f4a004df2).
2021-04-15 17:57:48,530 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task Source: Custom File source (1/1)#0 network resources (state: FINISHED).
2021-04-15 17:57:48,530 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - unregistering 2d7690046e5016dcca8b03287d230aa7#0@92aa1adebb2d1dc1601d0f7f4a004df2
2021-04-15 17:57:48,532 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Source: Custom File source (1/1)#0 (92aa1adebb2d1dc1601d0f7f4a004df2) [FINISHED]
2021-04-15 17:57:48,534 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File source (1/1)#0 (962280473929e656fa9a072f81a110fc): Finished PipelinedSubpartition#0 [number of buffers: 2 (133 bytes), number of buffers in backlog: 1, finished? true, read view? true].
2021-04-15 17:57:48,534 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File source (1/1)#0 (962280473929e656fa9a072f81a110fc) switched from RUNNING to FINISHED.
2021-04-15 17:57:48,534 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Source: Custom File source (1/1)#0 (962280473929e656fa9a072f81a110fc).
2021-04-15 17:57:48,534 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task Source: Custom File source (1/1)#0 network resources (state: FINISHED).
2021-04-15 17:57:48,534 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - unregistering c30d3d8915267dd583f3c188b245bc98#0@962280473929e656fa9a072f81a110fc
2021-04-15 17:57:48,534 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File source (1/1)#0 (f38e7381ef80e4fcfb1a02e00ec66f00): Finished PipelinedSubpartition#0 [number of buffers: 2 (133 bytes), number of buffers in backlog: 1, finished? true, read view? true].
2021-04-15 17:57:48,534 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File source (1/1)#0 (f38e7381ef80e4fcfb1a02e00ec66f00) switched from RUNNING to FINISHED.
2021-04-15 17:57:48,534 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Source: Custom File source (1/1)#0 (f38e7381ef80e4fcfb1a02e00ec66f00).
2021-04-15 17:57:48,534 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task Source: Custom File source (1/1)#0 network resources (state: FINISHED).
2021-04-15 17:57:48,534 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - unregistering ddcafd25d8473f83e72837e4b4ab9a82#0@f38e7381ef80e4fcfb1a02e00ec66f00
2021-04-15 17:57:48,535 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File source (1/1)#0 (56a8a7eaf61a1c9778ec2910a7e8b378): Finished PipelinedSubpartition#0 [number of buffers: 2 (133 bytes), number of buffers in backlog: 1, finished? true, read view? true].
2021-04-15 17:57:48,535 INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom File source (1/1)#0 (56a8a7eaf61a1c9778ec2910a7e8b378) switched from RUNNING to FINISHED.
2021-04-15 17:57:48,535 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Source: Custom File source (1/1)#0 (56a8a7eaf61a1c9778ec2910a7e8b378).
2021-04-15 17:57:48,535 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task Source: Custom File source (1/1)#0 network resources (state: FINISHED).
2021-04-15 17:57:48,535 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - unregistering 16fc7cab54c1def2c796d236a0a0270d#0@56a8a7eaf61a1c9778ec2910a7e8b378
2021-04-15 17:57:48,537 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task Source: Custom File source (1/1)#0 92aa1adebb2d1dc1601d0f7f4a004df2.
2021-04-15 17:57:48,541 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Source: Custom File source (1/1)#0 (962280473929e656fa9a072f81a110fc) [FINISHED]
2021-04-15 17:57:48,542 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Source: Custom File source (1/1)#0 (56a8a7eaf61a1c9778ec2910a7e8b378) [FINISHED]
2021-04-15 17:57:48,543 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Source: Custom File source (1/1)#0 (f38e7381ef80e4fcfb1a02e00ec66f00) [FINISHED]
2021-04-15 17:57:48,559 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task Source: Custom File source (1/1)#0 962280473929e656fa9a072f81a110fc.
2021-04-15 17:57:48,560 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task Source: Custom File source (1/1)#0 56a8a7eaf61a1c9778ec2910a7e8b378.
2021-04-15 17:57:48,560 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task Source: Custom File source (1/1)#0 f38e7381ef80e4fcfb1a02e00ec66f00.
2021-04-15 17:57:48,564 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (92aa1adebb2d1dc1601d0f7f4a004df2) switched from RUNNING to FINISHED.
2021-04-15 17:57:48,565 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Source: Custom File source (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 17:57:48,566 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{1a87552f8a7062503ca02711bd24dac4}) for execution vertex (id feca28aff5a3958840bee985ee7de4d3_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:48,569 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (962280473929e656fa9a072f81a110fc) switched from RUNNING to FINISHED.
2021-04-15 17:57:48,570 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Source: Custom File source (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 17:57:48,570 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{81e6ddc90fe8fd184c21a67ec0aa8720}) for execution vertex (id 605b35e407e90cda15ad084365733fdd_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:48,582 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (56a8a7eaf61a1c9778ec2910a7e8b378) switched from RUNNING to FINISHED.
2021-04-15 17:57:48,583 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Source: Custom File source (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 17:57:48,583 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{d9934b227092dad05c6f5b66420bc4dd}) for execution vertex (id bc764cd8ddf7a0cff126f51c16239658_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:48,588 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: IDLE -> OPENING
2021-04-15 17:57:48,588 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - load split: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 17:57:48,588 DEBUG org.apache.flink.api.common.io.FileInputFormat - Opening input split file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt [0,315]
2021-04-15 17:57:48,590 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom File source (1/1) (f38e7381ef80e4fcfb1a02e00ec66f00) switched from RUNNING to FINISHED.
2021-04-15 17:57:48,591 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Source: Custom File source (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 17:57:48,591 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{a4e3f5a6275ea538b362bd2665892b25}) for execution vertex (id 3ba1d27b7fde4848a86e865c6c402dfa_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:48,592 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: IDLE -> OPENING
2021-04-15 17:57:48,592 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - load split: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 17:57:48,592 DEBUG org.apache.flink.api.common.io.FileInputFormat - Opening input split file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt [0,315]
2021-04-15 17:57:48,593 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: IDLE -> OPENING
2021-04-15 17:57:48,593 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - load split: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 17:57:48,593 DEBUG org.apache.flink.api.common.io.FileInputFormat - Opening input split file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt [0,315]
2021-04-15 17:57:48,594 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: IDLE -> OPENING
2021-04-15 17:57:48,594 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - load split: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 17:57:48,594 DEBUG org.apache.flink.api.common.io.FileInputFormat - Opening input split file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt [0,315]
2021-04-15 17:57:48,602 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: OPENING -> READING
2021-04-15 17:57:48,603 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: KeyProjection$20 

 Code:

public class KeyProjection$20 implements org.apache.flink.table.runtime.generated.Projection<org.apache.flink.table.data.RowData, org.apache.flink.table.data.binary.BinaryRowData> {

  org.apache.flink.table.data.binary.BinaryRowData out = new org.apache.flink.table.data.binary.BinaryRowData(1);
org.apache.flink.table.data.writer.BinaryRowWriter outWriter = new org.apache.flink.table.data.writer.BinaryRowWriter(out);

  public KeyProjection$20(Object[] references) throws Exception {
    
  }

  @Override
  public org.apache.flink.table.data.binary.BinaryRowData apply(org.apache.flink.table.data.RowData in1) {
    org.apache.flink.table.data.binary.BinaryStringData field$21;
boolean isNull$21;
    



outWriter.reset();

isNull$21 = in1.isNullAt(0);
field$21 = org.apache.flink.table.data.binary.BinaryStringData.EMPTY_UTF8;
if (!isNull$21) {
  field$21 = ((org.apache.flink.table.data.binary.BinaryStringData) in1.getString(0));
}
if (isNull$21) {
  outWriter.setNullAt(0);
} else {
  outWriter.writeString(0, field$21);
}
             
outWriter.complete();
        
        
    return out;
  }
}
        
2021-04-15 17:57:48,605 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: OPENING -> READING
2021-04-15 17:57:48,609 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: OPENING -> READING
2021-04-15 17:57:48,612 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: OPENING -> READING
2021-04-15 17:57:48,619 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: KeyProjection$55 

 Code:

public class KeyProjection$55 implements org.apache.flink.table.runtime.generated.Projection<org.apache.flink.table.data.RowData, org.apache.flink.table.data.binary.BinaryRowData> {

  org.apache.flink.table.data.binary.BinaryRowData out = new org.apache.flink.table.data.binary.BinaryRowData(1);
org.apache.flink.table.data.writer.BinaryRowWriter outWriter = new org.apache.flink.table.data.writer.BinaryRowWriter(out);

  public KeyProjection$55(Object[] references) throws Exception {
    
  }

  @Override
  public org.apache.flink.table.data.binary.BinaryRowData apply(org.apache.flink.table.data.RowData in1) {
    org.apache.flink.table.data.binary.BinaryStringData field$56;
boolean isNull$56;
    



outWriter.reset();

isNull$56 = in1.isNullAt(0);
field$56 = org.apache.flink.table.data.binary.BinaryStringData.EMPTY_UTF8;
if (!isNull$56) {
  field$56 = ((org.apache.flink.table.data.binary.BinaryStringData) in1.getString(0));
}
if (isNull$56) {
  outWriter.setNullAt(0);
} else {
  outWriter.writeString(0, field$56);
}
             
outWriter.complete();
        
        
    return out;
  }
}
        
2021-04-15 17:57:48,622 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - PipelinedResultPartition 2d7690046e5016dcca8b03287d230aa7#0@92aa1adebb2d1dc1601d0f7f4a004df2 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
2021-04-15 17:57:48,623 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Received consume notification from PipelinedResultPartition 2d7690046e5016dcca8b03287d230aa7#0@92aa1adebb2d1dc1601d0f7f4a004df2 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 17:57:48,623 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Source: Custom File source (1/1)#0 (92aa1adebb2d1dc1601d0f7f4a004df2): Releasing PipelinedResultPartition 2d7690046e5016dcca8b03287d230aa7#0@92aa1adebb2d1dc1601d0f7f4a004df2 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 17:57:48,624 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File source (1/1)#0 (92aa1adebb2d1dc1601d0f7f4a004df2): Released PipelinedSubpartition#0 [number of buffers: 2 (137 bytes), number of buffers in backlog: 0, finished? true, read view? false].
2021-04-15 17:57:48,624 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Released partition 2d7690046e5016dcca8b03287d230aa7#0 produced by 92aa1adebb2d1dc1601d0f7f4a004df2.
2021-04-15 17:57:48,624 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0
2021-04-15 17:57:48,626 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - closing
2021-04-15 17:57:48,626 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: READING -> CLOSING
2021-04-15 17:57:48,628 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - split 1 processed: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 17:57:48,629 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: CLOSING -> CLOSED
2021-04-15 17:57:48,629 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - cleanup, state=CLOSED
2021-04-15 17:57:48,630 WARN o.a.f.s.a.functions.source.ContinuousFileReaderOperator - not processing any records while closed
2021-04-15 17:57:48,631 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - PipelinedResultPartition 16fc7cab54c1def2c796d236a0a0270d#0@56a8a7eaf61a1c9778ec2910a7e8b378 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
2021-04-15 17:57:48,631 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0
2021-04-15 17:57:48,631 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Received consume notification from PipelinedResultPartition 16fc7cab54c1def2c796d236a0a0270d#0@56a8a7eaf61a1c9778ec2910a7e8b378 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 17:57:48,631 INFO org.apache.flink.runtime.taskmanager.Task - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (e5911ca3febd32cb141752fc539271cb) switched from RUNNING to FINISHED.
2021-04-15 17:57:48,632 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Source: Custom File source (1/1)#0 (56a8a7eaf61a1c9778ec2910a7e8b378): Releasing PipelinedResultPartition 16fc7cab54c1def2c796d236a0a0270d#0@56a8a7eaf61a1c9778ec2910a7e8b378 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 17:57:48,633 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (e5911ca3febd32cb141752fc539271cb).
2021-04-15 17:57:48,633 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File source (1/1)#0 (56a8a7eaf61a1c9778ec2910a7e8b378): Released PipelinedSubpartition#0 [number of buffers: 2 (137 bytes), number of buffers in backlog: 0, finished? true, read view? false].
2021-04-15 17:57:48,633 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 network resources (state: FINISHED).
2021-04-15 17:57:48,633 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Released partition 16fc7cab54c1def2c796d236a0a0270d#0 produced by 56a8a7eaf61a1c9778ec2910a7e8b378.
2021-04-15 17:57:48,635 DEBUG o.a.f.r.io.network.partition.consumer.SingleInputGate - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (e5911ca3febd32cb141752fc539271cb): Releasing SingleInputGate{owningTaskName='CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (e5911ca3febd32cb141752fc539271cb)', gateIndex=0}.
2021-04-15 17:57:48,637 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0
2021-04-15 17:57:48,637 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (e5911ca3febd32cb141752fc539271cb) [FINISHED]
2021-04-15 17:57:48,637 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - closing
2021-04-15 17:57:48,639 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - PipelinedResultPartition ddcafd25d8473f83e72837e4b4ab9a82#0@f38e7381ef80e4fcfb1a02e00ec66f00 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
2021-04-15 17:57:48,639 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 e5911ca3febd32cb141752fc539271cb.
2021-04-15 17:57:48,640 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: READING -> CLOSING
2021-04-15 17:57:48,640 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - PipelinedResultPartition c30d3d8915267dd583f3c188b245bc98#0@962280473929e656fa9a072f81a110fc [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
2021-04-15 17:57:48,640 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Received consume notification from PipelinedResultPartition ddcafd25d8473f83e72837e4b4ab9a82#0@f38e7381ef80e4fcfb1a02e00ec66f00 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 17:57:48,641 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1) (e5911ca3febd32cb141752fc539271cb) switched from RUNNING to FINISHED.
2021-04-15 17:57:48,643 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Received consume notification from PipelinedResultPartition c30d3d8915267dd583f3c188b245bc98#0@962280473929e656fa9a072f81a110fc [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 17:57:48,643 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Source: Custom File source (1/1)#0 (f38e7381ef80e4fcfb1a02e00ec66f00): Releasing PipelinedResultPartition ddcafd25d8473f83e72837e4b4ab9a82#0@f38e7381ef80e4fcfb1a02e00ec66f00 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 17:57:48,643 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) -> Calc(select=[CAST(_UTF-16LE'sensor_6':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS id, temp], where=[(id = _UTF-16LE'sensor_6')]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 17:57:48,643 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File source (1/1)#0 (f38e7381ef80e4fcfb1a02e00ec66f00): Released PipelinedSubpartition#0 [number of buffers: 2 (137 bytes), number of buffers in backlog: 0, finished? true, read view? false].
2021-04-15 17:57:48,643 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{befec021a1fc4559379be6dc0f63a1f2}) for execution vertex (id b23642197a427ec5db481d3963c66cfb_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:48,643 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Released partition ddcafd25d8473f83e72837e4b4ab9a82#0 produced by f38e7381ef80e4fcfb1a02e00ec66f00.
2021-04-15 17:57:48,645 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - split 1 processed: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 17:57:48,645 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0
2021-04-15 17:57:48,645 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: CLOSING -> CLOSED
2021-04-15 17:57:48,645 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - Source: Custom File source (1/1)#0 (962280473929e656fa9a072f81a110fc): Releasing PipelinedResultPartition c30d3d8915267dd583f3c188b245bc98#0@962280473929e656fa9a072f81a110fc [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 17:57:48,645 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - closing
2021-04-15 17:57:48,646 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - cleanup, state=CLOSED
2021-04-15 17:57:48,646 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - Source: Custom File source (1/1)#0 (962280473929e656fa9a072f81a110fc): Released PipelinedSubpartition#0 [number of buffers: 2 (137 bytes), number of buffers in backlog: 0, finished? true, read view? false].
2021-04-15 17:57:48,646 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: READING -> CLOSING
2021-04-15 17:57:48,646 WARN o.a.f.s.a.functions.source.ContinuousFileReaderOperator - not processing any records while closed
2021-04-15 17:57:48,646 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Released partition c30d3d8915267dd583f3c188b245bc98#0 produced by 962280473929e656fa9a072f81a110fc.
2021-04-15 17:57:48,649 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0
2021-04-15 17:57:48,649 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - split 1 processed: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 17:57:48,649 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0
2021-04-15 17:57:48,649 INFO org.apache.flink.runtime.taskmanager.Task - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (0bd850202103b66807f1ab92cd4c2d87) switched from RUNNING to FINISHED.
2021-04-15 17:57:48,649 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: CLOSING -> CLOSED
2021-04-15 17:57:48,651 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - closing
2021-04-15 17:57:48,651 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (0bd850202103b66807f1ab92cd4c2d87).
2021-04-15 17:57:48,651 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - cleanup, state=CLOSED
2021-04-15 17:57:48,651 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: READING -> CLOSING
2021-04-15 17:57:48,651 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 network resources (state: FINISHED).
2021-04-15 17:57:48,651 WARN o.a.f.s.a.functions.source.ContinuousFileReaderOperator - not processing any records while closed
2021-04-15 17:57:48,652 DEBUG o.a.f.r.io.network.partition.consumer.SingleInputGate - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (0bd850202103b66807f1ab92cd4c2d87): Releasing SingleInputGate{owningTaskName='CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (0bd850202103b66807f1ab92cd4c2d87)', gateIndex=0}.
2021-04-15 17:57:48,652 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0
2021-04-15 17:57:48,652 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 (0bd850202103b66807f1ab92cd4c2d87) [FINISHED]
2021-04-15 17:57:48,653 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1)#0 0bd850202103b66807f1ab92cd4c2d87.
2021-04-15 17:57:48,653 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: KeyProjection$83 

 Code:

public class KeyProjection$83 implements org.apache.flink.table.runtime.generated.Projection<org.apache.flink.table.data.RowData, org.apache.flink.table.data.binary.BinaryRowData> {

  org.apache.flink.table.data.binary.BinaryRowData out = new org.apache.flink.table.data.binary.BinaryRowData(1);
org.apache.flink.table.data.writer.BinaryRowWriter outWriter = new org.apache.flink.table.data.writer.BinaryRowWriter(out);

  public KeyProjection$83(Object[] references) throws Exception {
    
  }

  @Override
  public org.apache.flink.table.data.binary.BinaryRowData apply(org.apache.flink.table.data.RowData in1) {
    org.apache.flink.table.data.binary.BinaryStringData field$84;
boolean isNull$84;
    



outWriter.reset();

isNull$84 = in1.isNullAt(0);
field$84 = org.apache.flink.table.data.binary.BinaryStringData.EMPTY_UTF8;
if (!isNull$84) {
  field$84 = ((org.apache.flink.table.data.binary.BinaryStringData) in1.getString(0));
}
if (isNull$84) {
  outWriter.setNullAt(0);
} else {
  outWriter.writeString(0, field$84);
}
             
outWriter.complete();
        
        
    return out;
  }
}
        
2021-04-15 17:57:48,657 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1) (0bd850202103b66807f1ab92cd4c2d87) switched from RUNNING to FINISHED.
2021-04-15 17:57:48,657 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) -> SinkConversionToRow -> Sink: Print to Std. Out (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 17:57:48,657 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{051965ca28d42de89a07a022a3dd2ca6}) for execution vertex (id 77af20c908aca598f7bbebd4db138545_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:48,659 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - split 1 processed: [0] file:/D:/flink/flinks/00_quickstart/src/main/resources/sensor.txt mod@ 1618229127431 : 0 + 315
2021-04-15 17:57:48,659 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - switch state: CLOSING -> CLOSED
2021-04-15 17:57:48,659 DEBUG o.a.f.s.a.functions.source.ContinuousFileReaderOperator - cleanup, state=CLOSED
2021-04-15 17:57:48,659 WARN o.a.f.s.a.functions.source.ContinuousFileReaderOperator - not processing any records while closed
2021-04-15 17:57:48,659 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0
2021-04-15 17:57:48,660 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (83787021e7a56db67c8fd5ee21262bc8): Finished PipelinedSubpartition#0 [number of buffers: 2 (521 bytes), number of buffers in backlog: 1, finished? true, read view? true].
2021-04-15 17:57:48,660 INFO org.apache.flink.runtime.taskmanager.Task - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (83787021e7a56db67c8fd5ee21262bc8) switched from RUNNING to FINISHED.
2021-04-15 17:57:48,660 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (83787021e7a56db67c8fd5ee21262bc8).
2021-04-15 17:57:48,660 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 network resources (state: FINISHED).
2021-04-15 17:57:48,660 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - unregistering a1e6df2fa256a56d4f8621bc68aee12b#0@83787021e7a56db67c8fd5ee21262bc8
2021-04-15 17:57:48,660 DEBUG o.a.f.r.io.network.partition.consumer.SingleInputGate - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (83787021e7a56db67c8fd5ee21262bc8): Releasing SingleInputGate{owningTaskName='CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (83787021e7a56db67c8fd5ee21262bc8)', gateIndex=0}.
2021-04-15 17:57:48,660 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (83787021e7a56db67c8fd5ee21262bc8) [FINISHED]
2021-04-15 17:57:48,661 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 83787021e7a56db67c8fd5ee21262bc8.
2021-04-15 17:57:48,663 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1) (83787021e7a56db67c8fd5ee21262bc8) switched from RUNNING to FINISHED.
2021-04-15 17:57:48,664 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 17:57:48,664 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{ecc6474d1a1ef6a742e529fe1034ce02}) for execution vertex (id aecbb8a11dc0c28dc6c178e875ebcc43_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:48,665 DEBUG org.apache.flink.table.runtime.generated.CompileUtils - Compiling: KeyProjection$48 

 Code:

public class KeyProjection$48 implements org.apache.flink.table.runtime.generated.Projection<org.apache.flink.table.data.RowData, org.apache.flink.table.data.binary.BinaryRowData> {

  org.apache.flink.table.data.binary.BinaryRowData out = new org.apache.flink.table.data.binary.BinaryRowData(1);
org.apache.flink.table.data.writer.BinaryRowWriter outWriter = new org.apache.flink.table.data.writer.BinaryRowWriter(out);

  public KeyProjection$48(Object[] references) throws Exception {
    
  }

  @Override
  public org.apache.flink.table.data.binary.BinaryRowData apply(org.apache.flink.table.data.RowData in1) {
    org.apache.flink.table.data.binary.BinaryStringData field$49;
boolean isNull$49;
    



outWriter.reset();

isNull$49 = in1.isNullAt(0);
field$49 = org.apache.flink.table.data.binary.BinaryStringData.EMPTY_UTF8;
if (!isNull$49) {
  field$49 = ((org.apache.flink.table.data.binary.BinaryStringData) in1.getString(0));
}
if (isNull$49) {
  outWriter.setNullAt(0);
} else {
  outWriter.writeString(0, field$49);
}
             
outWriter.complete();
        
        
    return out;
  }
}
        
2021-04-15 17:57:48,665 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (0c86dd8ae9385e8de4892823517d828a): Finished PipelinedSubpartition#0 [number of buffers: 2 (617 bytes), number of buffers in backlog: 1, finished? true, read view? true].
2021-04-15 17:57:48,666 INFO org.apache.flink.runtime.taskmanager.Task - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (0c86dd8ae9385e8de4892823517d828a) switched from RUNNING to FINISHED.
2021-04-15 17:57:48,666 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (0c86dd8ae9385e8de4892823517d828a).
2021-04-15 17:57:48,666 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 network resources (state: FINISHED).
2021-04-15 17:57:48,666 DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - unregistering 48d9b0c5cb57e41c9a6ee6d2fdcabc79#0@0c86dd8ae9385e8de4892823517d828a
2021-04-15 17:57:48,666 DEBUG o.a.f.r.io.network.partition.consumer.SingleInputGate - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (0c86dd8ae9385e8de4892823517d828a): Releasing SingleInputGate{owningTaskName='CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (0c86dd8ae9385e8de4892823517d828a)', gateIndex=0}.
2021-04-15 17:57:48,666 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (0c86dd8ae9385e8de4892823517d828a) [FINISHED]
2021-04-15 17:57:48,666 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 0c86dd8ae9385e8de4892823517d828a.
2021-04-15 17:57:48,667 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1) (0c86dd8ae9385e8de4892823517d828a) switched from RUNNING to FINISHED.
2021-04-15 17:57:48,668 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 17:57:48,669 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{c372b731ac3a85a1363c047265d823cf}) for execution vertex (id a19bdf930ebdf056b3d6de069bc89bdd_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:48,674 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - PipelinedResultPartition a1e6df2fa256a56d4f8621bc68aee12b#0@83787021e7a56db67c8fd5ee21262bc8 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
2021-04-15 17:57:48,674 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Received consume notification from PipelinedResultPartition a1e6df2fa256a56d4f8621bc68aee12b#0@83787021e7a56db67c8fd5ee21262bc8 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 17:57:48,674 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (83787021e7a56db67c8fd5ee21262bc8): Releasing PipelinedResultPartition a1e6df2fa256a56d4f8621bc68aee12b#0@83787021e7a56db67c8fd5ee21262bc8 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 17:57:48,674 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - CsvTableSource(read fields: id, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, temp)]], fields=[id, temp]) (1/1)#0 (83787021e7a56db67c8fd5ee21262bc8): Released PipelinedSubpartition#0 [number of buffers: 2 (525 bytes), number of buffers in backlog: 0, finished? true, read view? false].
2021-04-15 17:57:48,674 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Released partition a1e6df2fa256a56d4f8621bc68aee12b#0 produced by 83787021e7a56db67c8fd5ee21262bc8.
2021-04-15 17:57:48,674 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0
2021-04-15 17:57:48,675 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0
2021-04-15 17:57:48,675 INFO org.apache.flink.runtime.taskmanager.Task - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (4c48ef46868aeabfa4c1687d52cd0352) switched from RUNNING to FINISHED.
2021-04-15 17:57:48,676 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (4c48ef46868aeabfa4c1687d52cd0352).
2021-04-15 17:57:48,676 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 network resources (state: FINISHED).
2021-04-15 17:57:48,676 DEBUG o.a.f.r.io.network.partition.consumer.SingleInputGate - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (4c48ef46868aeabfa4c1687d52cd0352): Releasing SingleInputGate{owningTaskName='GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (4c48ef46868aeabfa4c1687d52cd0352)', gateIndex=0}.
2021-04-15 17:57:48,676 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (4c48ef46868aeabfa4c1687d52cd0352) [FINISHED]
2021-04-15 17:57:48,676 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 4c48ef46868aeabfa4c1687d52cd0352.
2021-04-15 17:57:48,678 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1) (4c48ef46868aeabfa4c1687d52cd0352) switched from RUNNING to FINISHED.
2021-04-15 17:57:48,678 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS cnt, AVG(temp) AS avgTemp]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 17:57:48,678 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{317da2b0fc07f6c82b370f5da9864a30}) for execution vertex (id 5528b14a6b129894d24927c518acc32a_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:48,681 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - PipelinedResultPartition 48d9b0c5cb57e41c9a6ee6d2fdcabc79#0@0c86dd8ae9385e8de4892823517d828a [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
2021-04-15 17:57:48,682 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Received consume notification from PipelinedResultPartition 48d9b0c5cb57e41c9a6ee6d2fdcabc79#0@0c86dd8ae9385e8de4892823517d828a [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 17:57:48,682 DEBUG o.a.flink.runtime.io.network.partition.ResultPartition - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (0c86dd8ae9385e8de4892823517d828a): Releasing PipelinedResultPartition 48d9b0c5cb57e41c9a6ee6d2fdcabc79#0@0c86dd8ae9385e8de4892823517d828a [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2021-04-15 17:57:48,682 DEBUG o.a.f.r.io.network.partition.PipelinedSubpartition - CsvTableSource(read fields: id, timestamp, temp) -> SourceConversion(table=[default_catalog.default_database.inputTable, source: [CsvTableSource(read fields: id, timestamp, temp)]], fields=[id, timestamp, temp]) (1/1)#0 (0c86dd8ae9385e8de4892823517d828a): Released PipelinedSubpartition#0 [number of buffers: 2 (621 bytes), number of buffers in backlog: 0, finished? true, read view? false].
2021-04-15 17:57:48,682 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Released partition 48d9b0c5cb57e41c9a6ee6d2fdcabc79#0 produced by 0c86dd8ae9385e8de4892823517d828a.
2021-04-15 17:57:48,682 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Finished task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0
2021-04-15 17:57:48,682 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask - Closed operators for task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0
2021-04-15 17:57:48,683 INFO org.apache.flink.runtime.taskmanager.Task - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (543e948d2479323821cf9240a4cf531c) switched from RUNNING to FINISHED.
2021-04-15 17:57:48,683 INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (543e948d2479323821cf9240a4cf531c).
2021-04-15 17:57:48,683 DEBUG org.apache.flink.runtime.taskmanager.Task - Release task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 network resources (state: FINISHED).
2021-04-15 17:57:48,683 DEBUG o.a.f.r.io.network.partition.consumer.SingleInputGate - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (543e948d2479323821cf9240a4cf531c): Releasing SingleInputGate{owningTaskName='GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (543e948d2479323821cf9240a4cf531c)', gateIndex=0}.
2021-04-15 17:57:48,683 DEBUG org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 (543e948d2479323821cf9240a4cf531c) [FINISHED]
2021-04-15 17:57:48,683 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1)#0 543e948d2479323821cf9240a4cf531c.
2021-04-15 17:57:48,685 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1) (543e948d2479323821cf9240a4cf531c) switched from RUNNING to FINISHED.
2021-04-15 17:57:48,686 DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex GroupAggregate(groupBy=[id], select=[id, COUNT(id) AS EXPR$0, AVG(temp) AS EXPR$1]) -> SinkConversionToTuple2 -> Sink: Print to Std. Out (1/1) - execution #0 to FAILED while being FINISHED.
2021-04-15 17:57:48,686 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Remove logical slot (SlotRequestId{748b7d08cf0c4d7584d04c0c2a99599f}) for execution vertex (id 6177eb422127981c4dbb05ea3af8a2d4_0) from the physical slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:48,686 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Release shared slot externally (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:48,686 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Releasing slot [SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8}] because: Slot is being returned from SlotSharingExecutionSlotAllocator.
2021-04-15 17:57:48,686 DEBUG org.apache.flink.runtime.scheduler.SharedSlot - Release shared slot (SlotRequestId{5bb9fd812414228c4f5a95a5f13f5dd8})
2021-04-15 17:57:48,687 DEBUG o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Adding slot [915191b9e9164762cfcc8afd3e693a9f] to available slots
2021-04-15 17:57:48,688 INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Job Flink Streaming Job (4202ea6720b3ddc8c9b3f82ef324fcdc) switched from state RUNNING to FINISHED.
2021-04-15 17:57:48,688 INFO o.apache.flink.runtime.checkpoint.CheckpointCoordinator - Stopping checkpoint coordinator for job 4202ea6720b3ddc8c9b3f82ef324fcdc.
2021-04-15 17:57:48,693 INFO o.a.f.r.checkpoint.StandaloneCompletedCheckpointStore - Shutting down
2021-04-15 17:57:48,701 INFO org.apache.flink.runtime.minicluster.MiniCluster - Shutting down Flink Mini Cluster
2021-04-15 17:57:48,701 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Shutting down rest endpoint.
2021-04-15 17:57:48,701 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Job 4202ea6720b3ddc8c9b3f82ef324fcdc reached globally terminal state FINISHED.
2021-04-15 17:57:48,702 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Stopping TaskExecutor akka://flink/user/rpc/taskmanager_0.
2021-04-15 17:57:48,702 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Close ResourceManager connection f93803cdf624d62cbec39d32b44b78cb.
org.apache.flink.util.FlinkException: The TaskExecutor is shutting down.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:424) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:214) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:563) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:186) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 17:57:48,704 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Close JobManager connection for job 4202ea6720b3ddc8c9b3f82ef324fcdc.
org.apache.flink.util.FlinkException: The TaskExecutor is shutting down.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:424) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:214) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:563) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:186) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 17:57:48,705 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Closing TaskExecutor connection 5825669a-8d86-4e2a-99d8-ca5e01d959fa because: The TaskExecutor is shutting down.
2021-04-15 17:57:48,706 INFO org.apache.flink.runtime.jobmaster.JobMaster - Stopping the JobMaster for job Flink Streaming Job(4202ea6720b3ddc8c9b3f82ef324fcdc).
2021-04-15 17:57:48,707 DEBUG o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Unregister TaskManager 3ffd65fb658322224a5495ed94311761 from the SlotManager.
2021-04-15 17:57:48,709 DEBUG o.a.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Free slot TaskSlot(index:0, state:ALLOCATED, resource profile: ResourceProfile{managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}, allocationId: 915191b9e9164762cfcc8afd3e693a9f, jobId: 4202ea6720b3ddc8c9b3f82ef324fcdc).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:169) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:441) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:214) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:563) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:186) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 17:57:48,713 DEBUG o.a.f.r.i.n.p.ResourceManagerPartitionTrackerImpl - Processing shutdown of task executor 5825669a-8d86-4e2a-99d8-ca5e01d959fa.
2021-04-15 17:57:48,714 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Disconnect TaskExecutor 5825669a-8d86-4e2a-99d8-ca5e01d959fa because: Stopping JobMaster for job Flink Streaming Job(4202ea6720b3ddc8c9b3f82ef324fcdc).
2021-04-15 17:57:48,719 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Suspending SlotPool.
2021-04-15 17:57:48,719 DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Close ResourceManager connection f93803cdf624d62cbec39d32b44b78cb.
org.apache.flink.util.FlinkException: Stopping JobMaster for job Flink Streaming Job(4202ea6720b3ddc8c9b3f82ef324fcdc).
	at org.apache.flink.runtime.jobmaster.JobMaster.onStop(JobMaster.java:416) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:214) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:563) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:186) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 17:57:48,720 INFO o.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Stopping SlotPool.
2021-04-15 17:57:48,723 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Disconnect job manager 88d90394f4c80399f154de81bc5b4727@akka://flink/user/rpc/jobmanager_3 for job 4202ea6720b3ddc8c9b3f82ef324fcdc from the resource manager.
2021-04-15 17:57:48,734 DEBUG org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor - The RpcEndpoint jobmanager_3 terminated successfully.
2021-04-15 17:57:48,744 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Free slot with allocation id 915191b9e9164762cfcc8afd3e693a9f because: Stopping JobMaster for job Flink Streaming Job(4202ea6720b3ddc8c9b3f82ef324fcdc).
2021-04-15 17:57:48,744 DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Could not free slot for allocation id 915191b9e9164762cfcc8afd3e693a9f.
org.apache.flink.runtime.taskexecutor.slot.SlotNotFoundException: Could not find slot for 915191b9e9164762cfcc8afd3e693a9f.
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.freeSlot(TaskSlotTableImpl.java:409) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlotInternal(TaskExecutor.java:1798) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlot(TaskExecutor.java:1105) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:566) ~[na:na]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:305) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:212) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:158) ~[flink-runtime_2.11-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) ~[scala-library-2.11.12.jar:na]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[scala-library-2.11.12.jar:na]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ~[akka-actor_2.11-2.5.21.jar:2.5.21]
2021-04-15 17:57:48,745 DEBUG o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Releasing local state under allocation id 915191b9e9164762cfcc8afd3e693a9f.
2021-04-15 17:57:48,759 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - AkkaRpcActor akka://flink/user/rpc/jobmanager_3 has terminated.
2021-04-15 17:57:48,760 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Stop job leader service.
2021-04-15 17:57:48,762 DEBUG o.a.flink.runtime.resourcemanager.JobLeaderIdService - Found a new job leader null@null.
2021-04-15 17:57:48,763 INFO o.a.f.runtime.state.TaskExecutorLocalStateStoresManager - Shutting down TaskExecutorLocalStateStoresManager.
2021-04-15 17:57:48,763 DEBUG org.apache.flink.runtime.io.disk.iomanager.IOManager - Shutting down I/O manager.
2021-04-15 17:57:48,764 DEBUG o.a.f.runtime.resourcemanager.StandaloneResourceManager - Discard job leader lost leadership for outdated leader 88d90394f4c80399f154de81bc5b4727 for job 4202ea6720b3ddc8c9b3f82ef324fcdc.
2021-04-15 17:57:48,768 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Removing cache directory C:\Users\ccy\AppData\Local\Temp\flink-web-ui
2021-04-15 17:57:48,769 INFO o.a.flink.runtime.dispatcher.DispatcherRestEndpoint - Shut down complete.
2021-04-15 17:57:48,769 INFO org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager removed spill file directory C:\Users\ccy\AppData\Local\Temp\flink-io-fcf4f52c-a1ee-4529-99e1-242d040ac8fe
2021-04-15 17:57:48,769 INFO o.a.flink.runtime.io.network.NettyShuffleEnvironment - Shutting down the network environment and its components.
2021-04-15 17:57:48,769 DEBUG o.a.flink.runtime.io.network.NettyShuffleEnvironment - Shutting down network connection manager
2021-04-15 17:57:48,770 DEBUG o.a.flink.runtime.io.network.NettyShuffleEnvironment - Shutting down intermediate result partition manager
2021-04-15 17:57:48,770 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Releasing 0 partitions because of shutdown.
2021-04-15 17:57:48,770 DEBUG o.a.f.r.io.network.partition.ResultPartitionManager - Successful shutdown.
2021-04-15 17:57:48,773 INFO org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager removed spill file directory C:\Users\ccy\AppData\Local\Temp\flink-netty-shuffle-d1eb3332-90b7-44e7-a6f5-3f604c6bf91d
2021-04-15 17:57:48,773 INFO org.apache.flink.runtime.taskexecutor.KvStateService - Shutting down the kvState service and its components.
2021-04-15 17:57:48,773 INFO o.a.flink.runtime.taskexecutor.DefaultJobLeaderService - Stop job leader service.
2021-04-15 17:57:48,780 INFO org.apache.flink.runtime.filecache.FileCache - removed file cache directory C:\Users\ccy\AppData\Local\Temp\flink-dist-cache-4bc36192-9a10-49ef-bf9c-979b1c6f2c2f
2021-04-15 17:57:48,780 INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Stopped TaskExecutor akka://flink/user/rpc/taskmanager_0.
2021-04-15 17:57:48,780 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcActor - The RpcEndpoint taskmanager_0 terminated successfully.
2021-04-15 17:57:48,781 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - AkkaRpcActor akka://flink/user/rpc/taskmanager_0 has terminated.
2021-04-15 17:57:48,789 INFO o.a.f.runtime.resourcemanager.StandaloneResourceManager - Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..
2021-04-15 17:57:48,793 INFO o.a.f.r.e.component.DispatcherResourceManagerComponent - Closing components.
2021-04-15 17:57:48,795 INFO o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Stopping SessionDispatcherLeaderProcess.
2021-04-15 17:57:48,795 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Stopping dispatcher akka://flink/user/rpc/dispatcher_2.
2021-04-15 17:57:48,795 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Stopping all currently running jobs of dispatcher akka://flink/user/rpc/dispatcher_2.
2021-04-15 17:57:48,798 INFO o.a.f.r.r.h.l.b.BackPressureRequestCoordinator - Shutting down back pressure request coordinator.
2021-04-15 17:57:48,798 INFO o.apache.flink.runtime.dispatcher.StandaloneDispatcher - Stopped dispatcher akka://flink/user/rpc/dispatcher_2.
2021-04-15 17:57:48,798 DEBUG org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor - The RpcEndpoint dispatcher_2 terminated successfully.
2021-04-15 17:57:48,801 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - AkkaRpcActor akka://flink/user/rpc/dispatcher_2 has terminated.
2021-04-15 17:57:48,805 INFO o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Closing the SlotManager.
2021-04-15 17:57:48,805 INFO o.a.f.r.resourcemanager.slotmanager.SlotManagerImpl - Suspending the SlotManager.
2021-04-15 17:57:48,806 DEBUG org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor - The RpcEndpoint resourcemanager_1 terminated successfully.
2021-04-15 17:57:48,806 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - AkkaRpcActor akka://flink/user/rpc/resourcemanager_1 has terminated.
2021-04-15 17:57:48,815 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Stopping Akka RPC service.
2021-04-15 17:57:48,816 DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcActor - The RpcEndpoint MetricQueryService terminated successfully.
2021-04-15 17:57:48,816 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - AkkaRpcActor akka://flink-metrics/user/rpc/MetricQueryService has terminated.
2021-04-15 17:57:48,836 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Stopping supervisor actor.
2021-04-15 17:57:48,863 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Stopping Akka RPC service.
2021-04-15 17:57:48,863 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Stopped Akka RPC service.
2021-04-15 17:57:48,864 DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor - Stopping supervisor actor.
2021-04-15 17:57:48,865 DEBUG akka.event.EventStream - shutting down: StandardOutLogger
2021-04-15 17:57:48,877 INFO org.apache.flink.runtime.blob.PermanentBlobCache - Shutting down BLOB cache
2021-04-15 17:57:48,879 INFO org.apache.flink.runtime.blob.TransientBlobCache - Shutting down BLOB cache
2021-04-15 17:57:48,881 INFO org.apache.flink.runtime.blob.BlobServer - Stopped BLOB server at 0.0.0.0:62344
2021-04-15 17:57:48,881 INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Stopped Akka RPC service.
